{"pr_number": 1823, "pr_title": "HADOOP-16794 S3 Encryption keys not propagating correctly during copy operation", "pr_createdAt": "2020-01-28T16:18:17Z", "pr_url": "https://github.com/apache/hadoop/pull/1823", "timeline": [{"oid": "e12ba53ef8212dcae6ec109d97dc859d57d5f4b5", "url": "https://github.com/apache/hadoop/commit/e12ba53ef8212dcae6ec109d97dc859d57d5f4b5", "message": "HADOOP-16794 S3 Encryption key is not getting set properly during put operation.", "committedDate": "2020-01-31T12:02:58Z", "type": "forcePushed"}, {"oid": "499b0449e89a9455177e2402b6b7d03669a2d4fc", "url": "https://github.com/apache/hadoop/commit/499b0449e89a9455177e2402b6b7d03669a2d4fc", "message": "HADOOP-16794 S3 Encryption key is not getting set properly during put operation.", "committedDate": "2020-02-03T12:31:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDExMzQ3Mg==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r374113472", "bodyText": "should go into the same block as the amazon one", "author": "steveloughran", "createdAt": "2020-02-03T13:54:11Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.s3a;\n+\n+import java.io.IOException;\n+\n+import com.amazonaws.services.s3.model.ObjectMetadata;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.junit.Ignore;", "originalCommit": "499b0449e89a9455177e2402b6b7d03669a2d4fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "db822aa905537ee266c8146633d973cad165a887", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\nindex c8e12838330..9f48e00ec79 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\n\n@@ -21,12 +21,12 @@\n import java.io.IOException;\n \n import com.amazonaws.services.s3.model.ObjectMetadata;\n+import org.junit.Ignore;\n+import org.junit.Test;\n \n import org.apache.commons.lang3.StringUtils;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.Path;\n-import org.junit.Ignore;\n-import org.junit.Test;\n \n import static org.apache.hadoop.fs.contract.ContractTestUtils.skip;\n import static org.apache.hadoop.fs.s3a.Constants.SERVER_SIDE_ENCRYPTION_KEY;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDExMzk2MQ==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r374113961", "bodyText": "not needed", "author": "steveloughran", "createdAt": "2020-02-03T13:55:06Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.s3a;\n+\n+import java.io.IOException;\n+\n+import com.amazonaws.services.s3.model.ObjectMetadata;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import static org.apache.hadoop.fs.contract.ContractTestUtils.skip;\n+import static org.apache.hadoop.fs.s3a.Constants.SERVER_SIDE_ENCRYPTION_KEY;\n+import static org.apache.hadoop.fs.s3a.S3AEncryptionMethods.SSE_KMS;\n+\n+/**\n+ * Concrete class that extends {@link AbstractTestS3AEncryption}\n+ * and tests already configured bucket level encryption using s3 console.\n+ * This requires the SERVER_SIDE_ENCRYPTION_KEY\n+ * to be set in auth-keys.xml for it to run. The value should match with the\n+ * kms key set for the bucket.\n+ */\n+public class ITestS3AEncryptionWithDefaultS3Settings extends\n+        AbstractTestS3AEncryption {\n+\n+  @Override\n+  protected Configuration getConfiguration() {\n+    // get the KMS key for this test.\n+    Configuration c = new Configuration();\n+    String kmsKey = c.get(SERVER_SIDE_ENCRYPTION_KEY);\n+    if (StringUtils.isBlank(kmsKey)) {\n+      skip(SERVER_SIDE_ENCRYPTION_KEY + \" is not set for \" +\n+              SSE_KMS.getMethod());\n+    }\n+    return super.createConfiguration();\n+  }\n+\n+  /**\n+   * Setting this to NONE as we don't want to overwrite\n+   * already configured encryption settings.\n+   * @return\n+   */\n+  @Override\n+  protected S3AEncryptionMethods getSSEAlgorithm() {\n+    return S3AEncryptionMethods.NONE;\n+  }\n+\n+  @Override\n+  protected void assertEncrypted(Path path) throws IOException {\n+    Configuration c = new Configuration();\n+    String kmsKey = c.get(SERVER_SIDE_ENCRYPTION_KEY);\n+    ObjectMetadata objectMetadata = getFileSystem().getObjectMetadata(path);\n+    assertEquals(\"SSE KMS key id should match\", kmsKey, objectMetadata.getSSEAwsKmsKeyId());\n+  }\n+\n+  @Override\n+  @Ignore\n+  @Test\n+  public void testEncryptionSettingPropagation() throws Throwable {\n+    super.testEncryptionSettingPropagation();\n+  }\n+\n+  @Override\n+  @Ignore\n+  @Test\n+  public void testEncryption() throws Throwable {\n+    super.testEncryption();", "originalCommit": "499b0449e89a9455177e2402b6b7d03669a2d4fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "db822aa905537ee266c8146633d973cad165a887", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\nindex c8e12838330..9f48e00ec79 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\n\n@@ -21,12 +21,12 @@\n import java.io.IOException;\n \n import com.amazonaws.services.s3.model.ObjectMetadata;\n+import org.junit.Ignore;\n+import org.junit.Test;\n \n import org.apache.commons.lang3.StringUtils;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.Path;\n-import org.junit.Ignore;\n-import org.junit.Test;\n \n import static org.apache.hadoop.fs.contract.ContractTestUtils.skip;\n import static org.apache.hadoop.fs.s3a.Constants.SERVER_SIDE_ENCRYPTION_KEY;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDExNDk1MQ==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r374114951", "bodyText": "see checkstyle -line needs splitting. We like under/near 80 chars for better side-by-side review", "author": "steveloughran", "createdAt": "2020-02-03T13:56:43Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ *  or more contributor license agreements.  See the NOTICE file\n+ *  distributed with this work for additional information\n+ *  regarding copyright ownership.  The ASF licenses this file\n+ *  to you under the Apache License, Version 2.0 (the\n+ *  \"License\"); you may not use this file except in compliance\n+ *  with the License.  You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.s3a;\n+\n+import java.io.IOException;\n+\n+import com.amazonaws.services.s3.model.ObjectMetadata;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+import static org.apache.hadoop.fs.contract.ContractTestUtils.skip;\n+import static org.apache.hadoop.fs.s3a.Constants.SERVER_SIDE_ENCRYPTION_KEY;\n+import static org.apache.hadoop.fs.s3a.S3AEncryptionMethods.SSE_KMS;\n+\n+/**\n+ * Concrete class that extends {@link AbstractTestS3AEncryption}\n+ * and tests already configured bucket level encryption using s3 console.\n+ * This requires the SERVER_SIDE_ENCRYPTION_KEY\n+ * to be set in auth-keys.xml for it to run. The value should match with the\n+ * kms key set for the bucket.\n+ */\n+public class ITestS3AEncryptionWithDefaultS3Settings extends\n+        AbstractTestS3AEncryption {\n+\n+  @Override\n+  protected Configuration getConfiguration() {\n+    // get the KMS key for this test.\n+    Configuration c = new Configuration();\n+    String kmsKey = c.get(SERVER_SIDE_ENCRYPTION_KEY);\n+    if (StringUtils.isBlank(kmsKey)) {\n+      skip(SERVER_SIDE_ENCRYPTION_KEY + \" is not set for \" +\n+              SSE_KMS.getMethod());\n+    }\n+    return super.createConfiguration();\n+  }\n+\n+  /**\n+   * Setting this to NONE as we don't want to overwrite\n+   * already configured encryption settings.\n+   * @return\n+   */\n+  @Override\n+  protected S3AEncryptionMethods getSSEAlgorithm() {\n+    return S3AEncryptionMethods.NONE;\n+  }\n+\n+  @Override\n+  protected void assertEncrypted(Path path) throws IOException {\n+    Configuration c = new Configuration();\n+    String kmsKey = c.get(SERVER_SIDE_ENCRYPTION_KEY);\n+    ObjectMetadata objectMetadata = getFileSystem().getObjectMetadata(path);\n+    assertEquals(\"SSE KMS key id should match\", kmsKey, objectMetadata.getSSEAwsKmsKeyId());", "originalCommit": "499b0449e89a9455177e2402b6b7d03669a2d4fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "db822aa905537ee266c8146633d973cad165a887", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\nindex c8e12838330..9f48e00ec79 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/ITestS3AEncryptionWithDefaultS3Settings.java\n\n@@ -21,12 +21,12 @@\n import java.io.IOException;\n \n import com.amazonaws.services.s3.model.ObjectMetadata;\n+import org.junit.Ignore;\n+import org.junit.Test;\n \n import org.apache.commons.lang3.StringUtils;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.Path;\n-import org.junit.Ignore;\n-import org.junit.Test;\n \n import static org.apache.hadoop.fs.contract.ContractTestUtils.skip;\n import static org.apache.hadoop.fs.s3a.Constants.SERVER_SIDE_ENCRYPTION_KEY;\n"}}, {"oid": "db822aa905537ee266c8146633d973cad165a887", "url": "https://github.com/apache/hadoop/commit/db822aa905537ee266c8146633d973cad165a887", "message": "HADOOP-16794 S3 Encryption key is not getting set properly during put operation.", "committedDate": "2020-02-03T14:28:34Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzU3MTQ0Mw==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r377571443", "bodyText": "I am looking at this, trying to understand what it is doing.\nBefore: we created a file src, renamed it to dest and verified the contents were unchanged; dest encrypted.\nAfter:\n\nsrc is created as a dataset\nnew path targetDir created\nfile dest is created in a target/src+\"-another\" with a different dataset; contents verified\nrename(src, targetDir) to create the file targetDir/src\nwhich is verified\ndest file is completely ignored\n\nSo why the change here? I don't see why we need the new test file, and the only change is now that you're renaming into a subdirectory  which already exists rather than a path of the destination file.\nI need some clarification here.\n\nwhy the change\nbefore the encryption settings were changed in copy, how did this new test fail?", "author": "steveloughran", "createdAt": "2020-02-11T11:12:59Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractTestS3AEncryption.java", "diffHunk": "@@ -107,10 +106,15 @@ public void testEncryptionOverRename() throws Throwable {\n     validateEncrytionSecrets(secrets);\n     writeDataset(fs, src, data, data.length, 1024 * 1024, true);\n     ContractTestUtils.verifyFileContents(fs, src, data);\n-    Path dest = path(src.getName() + \"-copy\");\n-    fs.rename(src, dest);\n-    ContractTestUtils.verifyFileContents(fs, dest, data);\n-    assertEncrypted(dest);\n+    Path targetDir = path(\"target\");", "originalCommit": "db822aa905537ee266c8146633d973cad165a887", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzY5MzM1NQ==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r377693355", "bodyText": "dest file is completely ignored\n\n\nThe reason dest file has to be created is to enforce rename to consider targetDir as a directory else it considers it as file.\n\nI need some clarification here.\n\nwhy the change\n\n\nThis change was done to address one of your above comment.\n\"Maybe: in testEncryptionOverRename , rename the file into a directory.\"\n\n\nbefore the encryption settings were changed in copy, how did this new test fail?\n\n\nThe encryption key of the destination file  targetDir/src was not matching with the configured kms key of the bucket rather it was equal to some default key generated by the S3 itself.", "author": "mukund-thakur", "createdAt": "2020-02-11T15:07:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzU3MTQ0Mw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg0MjAzNQ==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r377842035", "bodyText": "bq. The reason dest file has to be created is to enforce rename to consider targetDir as a directory else it considers it as file.\nmkdir(targetDir) should have done that. Or is it not because of that funny \"rename into empty dir\" problem with rename() which everyone hates (historical mistake, BTW)\nIf somehow that doesn't work and you want to create a file, ContractTestUtils.touch() will do that; add a comment above about why its needed", "author": "steveloughran", "createdAt": "2020-02-11T19:13:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzU3MTQ0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "2e0d896f69dfce9260a16fc070dc78dc84f9d270", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractTestS3AEncryption.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractTestS3AEncryption.java\nindex 3cfdd71a852..268d1adb1d0 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractTestS3AEncryption.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractTestS3AEncryption.java\n\n@@ -107,10 +107,7 @@ public void testEncryptionOverRename() throws Throwable {\n     writeDataset(fs, src, data, data.length, 1024 * 1024, true);\n     ContractTestUtils.verifyFileContents(fs, src, data);\n     Path targetDir = path(\"target\");\n-    Path dest = new Path(targetDir, src.getName() + \"-another\");\n-    byte[] dataTarget = dataset(1024, 'A', 'Z');\n-    writeDataset(fs, dest, dataTarget, dataTarget.length, 1024*1024, true);\n-    ContractTestUtils.verifyFileContents(fs, dest, dataTarget);\n+    mkdirs(targetDir);\n     fs.rename(src, targetDir);\n     Path renamedFile = new Path(targetDir, src.getName());\n     ContractTestUtils.verifyFileContents(fs, renamedFile, data);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDcyNDI1OA==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384724258", "bodyText": "pull that up into the if() clause and you can avoid doing the optional work, just\nsetSSE...(new SS3AwsKMP(sourceKMSId)).\nnow, troublespot, and its one I'm curious about. What if there's SSE-C set, as it is also being set on the request? FWIW, I think things will break trying to read the file by setting the SSE-C key will inevitably break too.", "author": "steveloughran", "createdAt": "2020-02-26T19:46:07Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -3394,6 +3396,42 @@ private CopyResult copyFile(String srcKey, String dstKey, long size,\n         });\n   }\n \n+  /**\n+   * Propagate encryption parameters from source file if set else use the\n+   * current file system encryption settings.\n+   * @param srcom\n+   * @param copyObjectRequest\n+   */\n+  private void propagateEncryptionParams(ObjectMetadata srcom,\n+                                         CopyObjectRequest copyObjectRequest) {\n+    Optional<SSEAwsKeyManagementParams> kmsParams = Optional.empty();\n+    String sourceKMSId = srcom.getSSEAwsKmsKeyId();\n+    if (isNotEmpty(sourceKMSId)) {\n+      // source KMS ID is propagated\n+      LOG.debug(\"Propagating SSE-KMS settings from source {}\",\n+          sourceKMSId);\n+      kmsParams = Optional.of(new SSEAwsKeyManagementParams(sourceKMSId));\n+    }\n+    kmsParams.ifPresent(", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTg1NzQwMw==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r385857403", "bodyText": "pull that up into the if() clause and you can avoid doing the optional work, just\nsetSSE...(new SS3AwsKMP(sourceKMSId)).\n\nDone\n\nnow, troublespot, and its one I'm curious about. What if there's SSE-C set, as it is also being set on the request? FWIW, I think things will break trying to read the file by setting the SSE-C key will inevitably break too.\n\nIf SSE-C is used, sseKmsKey won't be present in the sourceObjectMeta. So that shouldn't be a problem. I debugged this test ITestS3AEncryptionSSEC#testRenameFile and it works fine. Please let me know if I am missing something.", "author": "mukund-thakur", "createdAt": "2020-02-28T18:38:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDcyNDI1OA=="}], "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\nindex e593974e8b8..2f7ad19acca 100644\n--- a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n+++ b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n\n@@ -3396,42 +3489,6 @@ private CopyResult copyFile(String srcKey, String dstKey, long size,\n         });\n   }\n \n-  /**\n-   * Propagate encryption parameters from source file if set else use the\n-   * current file system encryption settings.\n-   * @param srcom\n-   * @param copyObjectRequest\n-   */\n-  private void propagateEncryptionParams(ObjectMetadata srcom,\n-                                         CopyObjectRequest copyObjectRequest) {\n-    Optional<SSEAwsKeyManagementParams> kmsParams = Optional.empty();\n-    String sourceKMSId = srcom.getSSEAwsKmsKeyId();\n-    if (isNotEmpty(sourceKMSId)) {\n-      // source KMS ID is propagated\n-      LOG.debug(\"Propagating SSE-KMS settings from source {}\",\n-          sourceKMSId);\n-      kmsParams = Optional.of(new SSEAwsKeyManagementParams(sourceKMSId));\n-    }\n-    kmsParams.ifPresent(\n-            copyObjectRequest::setSSEAwsKeyManagementParams);\n-    switch(encryptionSecrets.getEncryptionMethod()) {\n-    /**\n-     * Overriding with client encryption settings.\n-     */\n-    case SSE_C:\n-      generateSSECustomerKey().ifPresent(customerKey -> {\n-        copyObjectRequest.setSourceSSECustomerKey(customerKey);\n-        copyObjectRequest.setDestinationSSECustomerKey(customerKey);\n-      });\n-      break;\n-    case SSE_KMS:\n-      generateSSEAwsKeyParams().ifPresent(\n-              copyObjectRequest::setSSEAwsKeyManagementParams);\n-      break;\n-    default:\n-    }\n-  }\n-\n   /**\n    * Set the optional parameters when initiating the request (encryption,\n    * headers, storage, etc).\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDcyNTYwNw==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384725607", "bodyText": "use  getServerSideEncryptionAlgorithm() as before", "author": "steveloughran", "createdAt": "2020-02-26T19:48:34Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -3394,6 +3396,42 @@ private CopyResult copyFile(String srcKey, String dstKey, long size,\n         });\n   }\n \n+  /**\n+   * Propagate encryption parameters from source file if set else use the\n+   * current file system encryption settings.\n+   * @param srcom\n+   * @param copyObjectRequest\n+   */\n+  private void propagateEncryptionParams(ObjectMetadata srcom,\n+                                         CopyObjectRequest copyObjectRequest) {\n+    Optional<SSEAwsKeyManagementParams> kmsParams = Optional.empty();\n+    String sourceKMSId = srcom.getSSEAwsKmsKeyId();\n+    if (isNotEmpty(sourceKMSId)) {\n+      // source KMS ID is propagated\n+      LOG.debug(\"Propagating SSE-KMS settings from source {}\",\n+          sourceKMSId);\n+      kmsParams = Optional.of(new SSEAwsKeyManagementParams(sourceKMSId));\n+    }\n+    kmsParams.ifPresent(\n+            copyObjectRequest::setSSEAwsKeyManagementParams);\n+    switch(encryptionSecrets.getEncryptionMethod()) {", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\nindex e593974e8b8..2f7ad19acca 100644\n--- a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n+++ b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n\n@@ -3396,42 +3489,6 @@ private CopyResult copyFile(String srcKey, String dstKey, long size,\n         });\n   }\n \n-  /**\n-   * Propagate encryption parameters from source file if set else use the\n-   * current file system encryption settings.\n-   * @param srcom\n-   * @param copyObjectRequest\n-   */\n-  private void propagateEncryptionParams(ObjectMetadata srcom,\n-                                         CopyObjectRequest copyObjectRequest) {\n-    Optional<SSEAwsKeyManagementParams> kmsParams = Optional.empty();\n-    String sourceKMSId = srcom.getSSEAwsKmsKeyId();\n-    if (isNotEmpty(sourceKMSId)) {\n-      // source KMS ID is propagated\n-      LOG.debug(\"Propagating SSE-KMS settings from source {}\",\n-          sourceKMSId);\n-      kmsParams = Optional.of(new SSEAwsKeyManagementParams(sourceKMSId));\n-    }\n-    kmsParams.ifPresent(\n-            copyObjectRequest::setSSEAwsKeyManagementParams);\n-    switch(encryptionSecrets.getEncryptionMethod()) {\n-    /**\n-     * Overriding with client encryption settings.\n-     */\n-    case SSE_C:\n-      generateSSECustomerKey().ifPresent(customerKey -> {\n-        copyObjectRequest.setSourceSSECustomerKey(customerKey);\n-        copyObjectRequest.setDestinationSSECustomerKey(customerKey);\n-      });\n-      break;\n-    case SSE_KMS:\n-      generateSSEAwsKeyParams().ifPresent(\n-              copyObjectRequest::setSSEAwsKeyManagementParams);\n-      break;\n-    default:\n-    }\n-  }\n-\n   /**\n    * Set the optional parameters when initiating the request (encryption,\n    * headers, storage, etc).\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDcyNzM3Ng==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384727376", "bodyText": "can you move down to where setOptionalCopyObjectRequestParameters() was before; it will make it easier to cherry pick.\nRestore the original name, with new args (and javadoc). Same reason -and because we may want add more options in future", "author": "steveloughran", "createdAt": "2020-02-26T19:51:52Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -3394,6 +3396,42 @@ private CopyResult copyFile(String srcKey, String dstKey, long size,\n         });\n   }\n \n+  /**", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\nindex e593974e8b8..2f7ad19acca 100644\n--- a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n+++ b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n\n@@ -3396,42 +3489,6 @@ private CopyResult copyFile(String srcKey, String dstKey, long size,\n         });\n   }\n \n-  /**\n-   * Propagate encryption parameters from source file if set else use the\n-   * current file system encryption settings.\n-   * @param srcom\n-   * @param copyObjectRequest\n-   */\n-  private void propagateEncryptionParams(ObjectMetadata srcom,\n-                                         CopyObjectRequest copyObjectRequest) {\n-    Optional<SSEAwsKeyManagementParams> kmsParams = Optional.empty();\n-    String sourceKMSId = srcom.getSSEAwsKmsKeyId();\n-    if (isNotEmpty(sourceKMSId)) {\n-      // source KMS ID is propagated\n-      LOG.debug(\"Propagating SSE-KMS settings from source {}\",\n-          sourceKMSId);\n-      kmsParams = Optional.of(new SSEAwsKeyManagementParams(sourceKMSId));\n-    }\n-    kmsParams.ifPresent(\n-            copyObjectRequest::setSSEAwsKeyManagementParams);\n-    switch(encryptionSecrets.getEncryptionMethod()) {\n-    /**\n-     * Overriding with client encryption settings.\n-     */\n-    case SSE_C:\n-      generateSSECustomerKey().ifPresent(customerKey -> {\n-        copyObjectRequest.setSourceSSECustomerKey(customerKey);\n-        copyObjectRequest.setDestinationSSECustomerKey(customerKey);\n-      });\n-      break;\n-    case SSE_KMS:\n-      generateSSEAwsKeyParams().ifPresent(\n-              copyObjectRequest::setSSEAwsKeyManagementParams);\n-      break;\n-    default:\n-    }\n-  }\n-\n   /**\n    * Set the optional parameters when initiating the request (encryption,\n    * headers, storage, etc).\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDcyNzgxMA==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384727810", "bodyText": "cut. I know, we all hate imports. But S3A FS is big and even minor changes break other patches", "author": "steveloughran", "createdAt": "2020-02-26T19:52:39Z", "path": "hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java", "diffHunk": "@@ -45,6 +45,7 @@\n import java.util.concurrent.ThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n+", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\nindex e593974e8b8..2f7ad19acca 100644\n--- a/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n+++ b/hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3a/S3AFileSystem.java\n\n@@ -45,7 +45,6 @@\n import java.util.concurrent.ThreadPoolExecutor;\n import java.util.concurrent.TimeUnit;\n import java.util.concurrent.atomic.AtomicBoolean;\n-\n import javax.annotation.Nullable;\n \n import com.amazonaws.AmazonClientException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMDg2Ng==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384730866", "bodyText": "lets stick this one above L22 in its own block", "author": "steveloughran", "createdAt": "2020-02-26T19:57:44Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java", "diffHunk": "@@ -32,8 +34,11 @@\n \n import java.io.IOException;\n \n+import com.amazonaws.services.s3.model.ObjectMetadata;", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\nindex e7d1136e06d..a789eb5fa9f 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n\n@@ -34,11 +32,8 @@\n \n import java.io.IOException;\n \n-import com.amazonaws.services.s3.model.ObjectMetadata;\n-\n import static org.apache.hadoop.fs.contract.ContractTestUtils.dataset;\n import static org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset;\n-import static org.apache.hadoop.fs.s3a.Constants.SERVER_SIDE_ENCRYPTION_KEY;\n import static org.apache.hadoop.fs.s3a.S3ATestUtils.getTestDynamoTablePrefix;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMjkwNg==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384732906", "bodyText": "add a javadoc entry for the argument; just delete the @throws IOE line altogether", "author": "steveloughran", "createdAt": "2020-02-26T20:01:34Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java", "diffHunk": "@@ -159,4 +168,63 @@ protected void assertStatusCode(AWSServiceIOException e, int code)\n       throw e;\n     }\n   }\n+\n+  /**\n+   * Assert that a path is encrypted with right encryption settings.\n+   * @param path file path.\n+   * @param algorithm encryption algorithm.\n+   * @param kmsKeyArn", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\nindex e7d1136e06d..a789eb5fa9f 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n\n@@ -168,63 +159,4 @@ protected void assertStatusCode(AWSServiceIOException e, int code)\n       throw e;\n     }\n   }\n-\n-  /**\n-   * Assert that a path is encrypted with right encryption settings.\n-   * @param path file path.\n-   * @param algorithm encryption algorithm.\n-   * @param kmsKeyArn\n-   * @throws IOException\n-   */\n-  protected void assertEncrypted(final Path path,\n-                                 final S3AEncryptionMethods algorithm,\n-                                 final String kmsKeyArn)\n-          throws IOException {\n-    ObjectMetadata md = getFileSystem().getObjectMetadata(path);\n-    String details = String.format(\n-            \"file %s with encryption algorthm %s and key %s\",\n-            path,\n-            md.getSSEAlgorithm(),\n-            md.getSSEAwsKmsKeyId());\n-    switch(algorithm) {\n-    case SSE_C:\n-      assertNull(\"Metadata algorithm should have been null in \"\n-                      + details,\n-              md.getSSEAlgorithm());\n-      assertEquals(\"Wrong SSE-C algorithm in \"\n-                      + details,\n-              SSE_C_ALGORITHM, md.getSSECustomerAlgorithm());\n-      String md5Key = convertKeyToMd5();\n-      assertEquals(\"getSSECustomerKeyMd5() wrong in \" + details,\n-              md5Key, md.getSSECustomerKeyMd5());\n-      break;\n-    case SSE_KMS:\n-      assertEquals(\"Wrong algorithm in \" + details,\n-              AWS_KMS_SSE_ALGORITHM, md.getSSEAlgorithm());\n-      assertEquals(\"Wrong KMS key in \" + details,\n-              kmsKeyArn,\n-              md.getSSEAwsKmsKeyId());\n-      break;\n-    default:\n-      assertEquals(\"AES256\", md.getSSEAlgorithm());\n-    }\n-  }\n-\n-  /**\n-   * Decodes the SERVER_SIDE_ENCRYPTION_KEY from base64 into an AES key, then\n-   * gets the md5 of it, then encodes it in base64 so it will match the version\n-   * that AWS returns to us.\n-   *\n-   * @return md5'd base64 encoded representation of the server side encryption\n-   * key\n-   */\n-  private String convertKeyToMd5() {\n-    String base64Key = getFileSystem().getConf().getTrimmed(\n-            SERVER_SIDE_ENCRYPTION_KEY\n-    );\n-    byte[] key = Base64.decodeBase64(base64Key);\n-    byte[] md5 =  DigestUtils.md5(key);\n-    return Base64.encodeBase64String(md5).trim();\n-  }\n-\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczMzE4OQ==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384733189", "bodyText": "Typo", "author": "steveloughran", "createdAt": "2020-02-26T20:02:06Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java", "diffHunk": "@@ -159,4 +168,63 @@ protected void assertStatusCode(AWSServiceIOException e, int code)\n       throw e;\n     }\n   }\n+\n+  /**\n+   * Assert that a path is encrypted with right encryption settings.\n+   * @param path file path.\n+   * @param algorithm encryption algorithm.\n+   * @param kmsKeyArn\n+   * @throws IOException\n+   */\n+  protected void assertEncrypted(final Path path,\n+                                 final S3AEncryptionMethods algorithm,\n+                                 final String kmsKeyArn)\n+          throws IOException {\n+    ObjectMetadata md = getFileSystem().getObjectMetadata(path);\n+    String details = String.format(\n+            \"file %s with encryption algorthm %s and key %s\",", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\nindex e7d1136e06d..a789eb5fa9f 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n\n@@ -168,63 +159,4 @@ protected void assertStatusCode(AWSServiceIOException e, int code)\n       throw e;\n     }\n   }\n-\n-  /**\n-   * Assert that a path is encrypted with right encryption settings.\n-   * @param path file path.\n-   * @param algorithm encryption algorithm.\n-   * @param kmsKeyArn\n-   * @throws IOException\n-   */\n-  protected void assertEncrypted(final Path path,\n-                                 final S3AEncryptionMethods algorithm,\n-                                 final String kmsKeyArn)\n-          throws IOException {\n-    ObjectMetadata md = getFileSystem().getObjectMetadata(path);\n-    String details = String.format(\n-            \"file %s with encryption algorthm %s and key %s\",\n-            path,\n-            md.getSSEAlgorithm(),\n-            md.getSSEAwsKmsKeyId());\n-    switch(algorithm) {\n-    case SSE_C:\n-      assertNull(\"Metadata algorithm should have been null in \"\n-                      + details,\n-              md.getSSEAlgorithm());\n-      assertEquals(\"Wrong SSE-C algorithm in \"\n-                      + details,\n-              SSE_C_ALGORITHM, md.getSSECustomerAlgorithm());\n-      String md5Key = convertKeyToMd5();\n-      assertEquals(\"getSSECustomerKeyMd5() wrong in \" + details,\n-              md5Key, md.getSSECustomerKeyMd5());\n-      break;\n-    case SSE_KMS:\n-      assertEquals(\"Wrong algorithm in \" + details,\n-              AWS_KMS_SSE_ALGORITHM, md.getSSEAlgorithm());\n-      assertEquals(\"Wrong KMS key in \" + details,\n-              kmsKeyArn,\n-              md.getSSEAwsKmsKeyId());\n-      break;\n-    default:\n-      assertEquals(\"AES256\", md.getSSEAlgorithm());\n-    }\n-  }\n-\n-  /**\n-   * Decodes the SERVER_SIDE_ENCRYPTION_KEY from base64 into an AES key, then\n-   * gets the md5 of it, then encodes it in base64 so it will match the version\n-   * that AWS returns to us.\n-   *\n-   * @return md5'd base64 encoded representation of the server side encryption\n-   * key\n-   */\n-  private String convertKeyToMd5() {\n-    String base64Key = getFileSystem().getConf().getTrimmed(\n-            SERVER_SIDE_ENCRYPTION_KEY\n-    );\n-    byte[] key = Base64.decodeBase64(base64Key);\n-    byte[] md5 =  DigestUtils.md5(key);\n-    return Base64.encodeBase64String(md5).trim();\n-  }\n-\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDczNDc5Mw==", "url": "https://github.com/apache/hadoop/pull/1823#discussion_r384734793", "bodyText": "add this to org.apache.hadoop.fs.s3a.test.ExtraAssertions", "author": "steveloughran", "createdAt": "2020-02-26T20:05:07Z", "path": "hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java", "diffHunk": "@@ -159,4 +168,63 @@ protected void assertStatusCode(AWSServiceIOException e, int code)\n       throw e;\n     }\n   }\n+", "originalCommit": "85bfd490a1662f42c9f65df2a121498c0f5a6b5e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "chunk": "diff --git a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\nindex e7d1136e06d..a789eb5fa9f 100644\n--- a/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n+++ b/hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/s3a/AbstractS3ATestBase.java\n\n@@ -168,63 +159,4 @@ protected void assertStatusCode(AWSServiceIOException e, int code)\n       throw e;\n     }\n   }\n-\n-  /**\n-   * Assert that a path is encrypted with right encryption settings.\n-   * @param path file path.\n-   * @param algorithm encryption algorithm.\n-   * @param kmsKeyArn\n-   * @throws IOException\n-   */\n-  protected void assertEncrypted(final Path path,\n-                                 final S3AEncryptionMethods algorithm,\n-                                 final String kmsKeyArn)\n-          throws IOException {\n-    ObjectMetadata md = getFileSystem().getObjectMetadata(path);\n-    String details = String.format(\n-            \"file %s with encryption algorthm %s and key %s\",\n-            path,\n-            md.getSSEAlgorithm(),\n-            md.getSSEAwsKmsKeyId());\n-    switch(algorithm) {\n-    case SSE_C:\n-      assertNull(\"Metadata algorithm should have been null in \"\n-                      + details,\n-              md.getSSEAlgorithm());\n-      assertEquals(\"Wrong SSE-C algorithm in \"\n-                      + details,\n-              SSE_C_ALGORITHM, md.getSSECustomerAlgorithm());\n-      String md5Key = convertKeyToMd5();\n-      assertEquals(\"getSSECustomerKeyMd5() wrong in \" + details,\n-              md5Key, md.getSSECustomerKeyMd5());\n-      break;\n-    case SSE_KMS:\n-      assertEquals(\"Wrong algorithm in \" + details,\n-              AWS_KMS_SSE_ALGORITHM, md.getSSEAlgorithm());\n-      assertEquals(\"Wrong KMS key in \" + details,\n-              kmsKeyArn,\n-              md.getSSEAwsKmsKeyId());\n-      break;\n-    default:\n-      assertEquals(\"AES256\", md.getSSEAlgorithm());\n-    }\n-  }\n-\n-  /**\n-   * Decodes the SERVER_SIDE_ENCRYPTION_KEY from base64 into an AES key, then\n-   * gets the md5 of it, then encodes it in base64 so it will match the version\n-   * that AWS returns to us.\n-   *\n-   * @return md5'd base64 encoded representation of the server side encryption\n-   * key\n-   */\n-  private String convertKeyToMd5() {\n-    String base64Key = getFileSystem().getConf().getTrimmed(\n-            SERVER_SIDE_ENCRYPTION_KEY\n-    );\n-    byte[] key = Base64.decodeBase64(base64Key);\n-    byte[] md5 =  DigestUtils.md5(key);\n-    return Base64.encodeBase64String(md5).trim();\n-  }\n-\n }\n"}}, {"oid": "2d80ce7b1adcc20690bf22190c5e1178408c71fe", "url": "https://github.com/apache/hadoop/commit/2d80ce7b1adcc20690bf22190c5e1178408c71fe", "message": "HADOOP-16794 S3 Encryption key is not getting set properly during put operation.", "committedDate": "2020-02-27T08:45:58Z", "type": "commit"}, {"oid": "2e0d896f69dfce9260a16fc070dc78dc84f9d270", "url": "https://github.com/apache/hadoop/commit/2e0d896f69dfce9260a16fc070dc78dc84f9d270", "message": "Removing creation of extra file-Review comment", "committedDate": "2020-02-27T08:45:58Z", "type": "commit"}, {"oid": "64cefc3100b3b8af883ee3b8b24adeaf9b0ee993", "url": "https://github.com/apache/hadoop/commit/64cefc3100b3b8af883ee3b8b24adeaf9b0ee993", "message": "HADOOP-16794. encryption over rename/copy\n\nreturns to copying sse algorithm header, but then\n\n* extracts full KMS settings from src and sets on request\n* overriding with S3A KMS client settings.\n* tries to test it better\n\nThis is still not ready to go in.\n\nI think we should have a consistent policy here of\n\n1. if the client has any encryption settings, including explicit AES256, KMS+default key, KMS+custom key, then they will set the encryption options on the copy.\n2. else the encryption settings of the source file are retained.\n\nThis is nice and memorable. It needs to apply for all s3a encryption settings; this patch only does it for SSE-KMS.\n\nChange-Id: I6c07d5bdbec27da94d6ab1b51aec9b5707f44634", "committedDate": "2020-02-27T08:45:58Z", "type": "commit"}, {"oid": "4f49e0396b524d9204ecae7b3a2dd81b64ce34db", "url": "https://github.com/apache/hadoop/commit/4f49e0396b524d9204ecae7b3a2dd81b64ce34db", "message": "HADOOP-16794 Encryption settings propagation", "committedDate": "2020-02-27T08:45:58Z", "type": "commit"}, {"oid": "781215d8fad1f21c4bb11536cd84e5acbe688b97", "url": "https://github.com/apache/hadoop/commit/781215d8fad1f21c4bb11536cd84e5acbe688b97", "message": "HADOOP-16794  tests for big files.", "committedDate": "2020-02-27T08:45:58Z", "type": "commit"}, {"oid": "9d616ed3f7c6b277c13f9f2ce08226eb62851590", "url": "https://github.com/apache/hadoop/commit/9d616ed3f7c6b277c13f9f2ce08226eb62851590", "message": "HADOOP-16794 fixing checkstyle", "committedDate": "2020-02-27T08:45:58Z", "type": "commit"}, {"oid": "b8cabde842a8feb7c76ab5d4761ecdd272db93ec", "url": "https://github.com/apache/hadoop/commit/b8cabde842a8feb7c76ab5d4761ecdd272db93ec", "message": "HADOOP-16794 Final set of review comments", "committedDate": "2020-02-27T19:13:19Z", "type": "commit"}, {"oid": "b8cabde842a8feb7c76ab5d4761ecdd272db93ec", "url": "https://github.com/apache/hadoop/commit/b8cabde842a8feb7c76ab5d4761ecdd272db93ec", "message": "HADOOP-16794 Final set of review comments", "committedDate": "2020-02-27T19:13:19Z", "type": "forcePushed"}, {"oid": "801a5e7d4eb6eb7593d7cbdb1df4365f47f2e118", "url": "https://github.com/apache/hadoop/commit/801a5e7d4eb6eb7593d7cbdb1df4365f47f2e118", "message": "HADOOP-16794 fixing checkstyle", "committedDate": "2020-02-28T14:10:19Z", "type": "commit"}]}