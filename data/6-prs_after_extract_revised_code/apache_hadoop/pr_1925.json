{"pr_number": 1925, "pr_title": "HADOOP-16948. Support single writer dirs.", "pr_createdAt": "2020-03-30T16:43:36Z", "pr_url": "https://github.com/apache/hadoop/pull/1925", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MjYyMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401582621", "bodyText": "this seems to be recurrent merge pain point: too many patches adding more things to every rest call.\nProposed: how about adding a RestOperationContext struct which gets passed down, leaseId would go in there, and later other stuff (statistics, trace context, etc) ?", "author": "steveloughran", "createdAt": "2020-04-01T12:39:36Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -328,13 +406,16 @@ public AbfsRestOperation renamePath(String source, final String destination, fin\n   }\n \n   public AbfsRestOperation append(final String path, final long position, final byte[] buffer, final int offset,\n-                                  final int length, boolean flush, boolean isClose)\n+                                  final int length, boolean flush, boolean isClose, final String leaseId)", "originalCommit": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6658798a5140edf4743e47ef0ff1a08f2142551", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex 40324b993a6..1ee8e42c90a 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -401,13 +409,73 @@ public AbfsRestOperation renamePath(String source, final String destination, fin\n             HTTP_METHOD_PUT,\n             url,\n             requestHeaders);\n-    op.execute();\n+    Instant renameRequestStartTime = Instant.now();\n+    try {\n+      op.execute();\n+    } catch (AzureBlobFileSystemException e) {\n+        final AbfsRestOperation idempotencyOp = renameIdempotencyCheckOp(\n+            renameRequestStartTime, op, destination);\n+        if (idempotencyOp.getResult().getStatusCode()\n+            == op.getResult().getStatusCode()) {\n+          // idempotency did not return different result\n+          // throw back the exception\n+          throw e;\n+        } else {\n+          return idempotencyOp;\n+        }\n+    }\n+\n+    return op;\n+  }\n+\n+  /**\n+   * Check if the rename request failure is post a retry and if earlier rename\n+   * request might have succeeded at back-end.\n+   *\n+   * If there is a parallel rename activity happening from any other store\n+   * interface, the logic here will detect the rename to have happened due to\n+   * the one initiated from this ABFS filesytem instance as it was retried. This\n+   * should be a corner case hence going ahead with LMT check.\n+   * @param renameRequestStartTime startTime for the rename request\n+   * @param op Rename request REST operation response\n+   * @param destination rename destination path\n+   * @return REST operation response post idempotency check\n+   * @throws AzureBlobFileSystemException if GetFileStatus hits any exception\n+   */\n+  public AbfsRestOperation renameIdempotencyCheckOp(\n+      final Instant renameRequestStartTime,\n+      final AbfsRestOperation op,\n+      final String destination) throws AzureBlobFileSystemException {\n+    if ((op.isARetriedRequest())\n+        && (op.getResult().getStatusCode() == HttpURLConnection.HTTP_NOT_FOUND)) {\n+      // Server has returned HTTP 404, which means rename source no longer\n+      // exists. Check on destination status and if it has a recent LMT timestamp.\n+      // If yes, return success, else fall back to original rename request failure response.\n+\n+      try {\n+        final AbfsRestOperation destStatusOp = getPathStatus(destination,\n+            false);\n+        if (destStatusOp.getResult().getStatusCode()\n+            == HttpURLConnection.HTTP_OK) {\n+          String lmt = destStatusOp.getResult().getResponseHeader(\n+              HttpHeaderConfigurations.LAST_MODIFIED);\n+\n+          if (DateTimeUtils.isRecentlyModified(lmt, renameRequestStartTime)) {\n+            return destStatusOp;\n+          }\n+        }\n+      } catch (AzureBlobFileSystemException e) {\n+        // GetFileStatus on the destination failed, return original op\n+        return op;\n+      }\n+    }\n+\n     return op;\n   }\n \n   public AbfsRestOperation append(final String path, final long position, final byte[] buffer, final int offset,\n-                                  final int length, boolean flush, boolean isClose, final String leaseId)\n-                                  throws AzureBlobFileSystemException {\n+                                  final int length, final String cachedSasToken, final boolean isAppendBlob,\n+                                  final String leaseId) throws AzureBlobFileSystemException {\n     final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n     // JDK7 does not support PATCH, so to workaround the issue we will use\n     // PUT and specify the real method in the X-Http-Method-Override header.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MzQxMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401583411", "bodyText": "PathIOException with path; make error string a const to use when matching in tests. Consider also a new LeaseRequiredException if that helps testing", "author": "steveloughran", "createdAt": "2020-04-01T12:40:51Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -168,6 +177,10 @@ public synchronized void write(final byte[] data, final int off, final int lengt\n       throw new IndexOutOfBoundsException();\n     }\n \n+    if (lease != null && lease.isFreed()) {\n+      throw new IOException(\"Attempted to write to file without lease: \" + path);", "originalCommit": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6658798a5140edf4743e47ef0ff1a08f2142551", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 72fa060baff..ca6c28c93f4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -178,7 +207,7 @@ public synchronized void write(final byte[] data, final int off, final int lengt\n     }\n \n     if (lease != null && lease.isFreed()) {\n-      throw new IOException(\"Attempted to write to file without lease: \" + path);\n+      throw new PathIOException(path, ERR_WRITE_WITHOUT_LEASE);\n     }\n \n     int currentOffset = off;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MzQ4MA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401583480", "bodyText": "will this ever fail?", "author": "steveloughran", "createdAt": "2020-04-01T12:41:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -261,6 +274,9 @@ public synchronized void close() throws IOException {\n       // See HADOOP-16785\n       throw wrapException(path, e.getMessage(), e);\n     } finally {\n+      if (lease != null) {\n+        lease.free();", "originalCommit": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6658798a5140edf4743e47ef0ff1a08f2142551", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 72fa060baff..ca6c28c93f4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -275,7 +314,11 @@ public synchronized void close() throws IOException {\n       throw wrapException(path, e.getMessage(), e);\n     } finally {\n       if (lease != null) {\n+        if (LOG.isDebugEnabled()) {\n+          LOG.info(\"Freeing lease {}\", leaseId);\n+        }\n         lease.free();\n+        lease = null;\n       }\n       lastError = new IOException(FSExceptionMessages.STREAM_IS_CLOSED);\n       buffer = null;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4MzgzNw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401583837", "bodyText": "we are on SLF4J now", "author": "steveloughran", "createdAt": "2020-04-01T12:41:34Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.commons.logging.Log;", "originalCommit": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6658798a5140edf4743e47ef0ff1a08f2142551", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 1b41213ad63..43de22a0ad0 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,16 +18,18 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import org.apache.commons.logging.Log;\n-import org.apache.commons.logging.LogFactory;\n-\n-import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n import java.util.concurrent.atomic.AtomicInteger;\n \n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+\n /**\n  * An Azure blob lease that automatically renews itself indefinitely\n  * using a background thread. Use it to synchronize distributed processes,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4NDQzMA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401584430", "bodyText": "switch to SLF4J logging style; include full stack @ debug level", "author": "steveloughran", "createdAt": "2020-04-01T12:42:39Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n+ *\n+ * Call free() to release the Lease.\n+ *\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ */\n+public class SelfRenewingLease {\n+\n+  private final AzureBlobFileSystemStore store;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n+\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  private static final Log LOG = LogFactory.getLog(SelfRenewingLease.class);\n+\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+\n+\n+  // Time to wait to retry getting the lease in milliseconds\n+  @VisibleForTesting\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+\n+  public SelfRenewingLease(AzureBlobFileSystemStore store, Path path) {\n+\n+    this.leaseFreed = false;\n+    this.store = store;\n+    this.path = path;\n+\n+    // Keep trying to get the lease until you get it.\n+    while(leaseID == null) {\n+      try {\n+        leaseID = store.acquireLease(this.path, LEASE_TIMEOUT);\n+      } catch (IOException e) {\n+        LOG.info(\"Caught exception when trying to get lease on blob \" + path + \". \" + e.getMessage());\n+      }\n+      if (leaseID == null) {\n+        try {\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n+        } catch (InterruptedException e) {\n+\n+          // Restore the interrupted status\n+          Thread.currentThread().interrupt();\n+        }\n+      }\n+    }\n+    renewer = new Thread(new Renewer());\n+\n+    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n+    renewer.setDaemon(true);\n+    renewer.setName(\"AzureLeaseRenewer-\" + threadNumber.getAndIncrement());\n+    renewer.start();\n+    LOG.debug(\"Acquired lease \" + leaseID + \" on \" + path\n+        + \" managed by thread \" + renewer.getName());\n+  }\n+\n+  /**\n+   * Free the lease and stop the keep-alive thread.\n+   */\n+  public void free() {\n+    try {\n+      store.releaseLease(path, leaseID);\n+    } catch (IOException e) {\n+      LOG.info(\"Exception when trying to free lease \" + leaseID + \" on \" + path + \". \" + e.getMessage());", "originalCommit": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6658798a5140edf4743e47ef0ff1a08f2142551", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 1b41213ad63..43de22a0ad0 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,16 +18,18 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import org.apache.commons.logging.Log;\n-import org.apache.commons.logging.LogFactory;\n-\n-import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n import java.util.concurrent.atomic.AtomicInteger;\n \n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+\n /**\n  * An Azure blob lease that automatically renews itself indefinitely\n  * using a background thread. Use it to synchronize distributed processes,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTU4NTE1MA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r401585150", "bodyText": "should be tied in to the FileSystem instance lifecycle too: an FS instance should really have a weak ref to all leases created under it, and fs.close to stop them all", "author": "steveloughran", "createdAt": "2020-04-01T12:43:51Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.commons.logging.Log;\n+import org.apache.commons.logging.LogFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n+ *\n+ * Call free() to release the Lease.\n+ *\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ */\n+public class SelfRenewingLease {\n+\n+  private final AzureBlobFileSystemStore store;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n+\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  private static final Log LOG = LogFactory.getLog(SelfRenewingLease.class);\n+\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+\n+\n+  // Time to wait to retry getting the lease in milliseconds\n+  @VisibleForTesting\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+\n+  public SelfRenewingLease(AzureBlobFileSystemStore store, Path path) {\n+\n+    this.leaseFreed = false;\n+    this.store = store;\n+    this.path = path;\n+\n+    // Keep trying to get the lease until you get it.\n+    while(leaseID == null) {\n+      try {\n+        leaseID = store.acquireLease(this.path, LEASE_TIMEOUT);\n+      } catch (IOException e) {\n+        LOG.info(\"Caught exception when trying to get lease on blob \" + path + \". \" + e.getMessage());\n+      }\n+      if (leaseID == null) {\n+        try {\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n+        } catch (InterruptedException e) {\n+\n+          // Restore the interrupted status\n+          Thread.currentThread().interrupt();\n+        }\n+      }\n+    }\n+    renewer = new Thread(new Renewer());\n+\n+    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n+    renewer.setDaemon(true);\n+    renewer.setName(\"AzureLeaseRenewer-\" + threadNumber.getAndIncrement());\n+    renewer.start();\n+    LOG.debug(\"Acquired lease \" + leaseID + \" on \" + path\n+        + \" managed by thread \" + renewer.getName());\n+  }\n+\n+  /**\n+   * Free the lease and stop the keep-alive thread.\n+   */\n+  public void free() {\n+    try {\n+      store.releaseLease(path, leaseID);\n+    } catch (IOException e) {\n+      LOG.info(\"Exception when trying to free lease \" + leaseID + \" on \" + path + \". \" + e.getMessage());\n+    } finally {\n+\n+      // Even if releasing the lease fails (e.g. because the file was deleted),\n+      // make sure to record that we freed the lease, to terminate the\n+      // keep-alive thread.\n+      leaseFreed = true;\n+      LOG.debug(\"Freed lease \" + leaseID + \" on \" + path\n+          + \" managed by thread \" + renewer.getName());\n+    }\n+  }\n+\n+  public boolean isFreed() {\n+    return leaseFreed;\n+  }\n+\n+  public String getLeaseID() {\n+    return leaseID;\n+  }\n+\n+  private class Renewer implements Runnable {\n+\n+    /**\n+     * Start a keep-alive thread that will continue to renew\n+     * the lease until it is freed or the process dies.", "originalCommit": "d98c26ca2a785f2523c75b59b8eb1e356af56f4a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d6658798a5140edf4743e47ef0ff1a08f2142551", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 1b41213ad63..43de22a0ad0 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,16 +18,18 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import org.apache.commons.logging.Log;\n-import org.apache.commons.logging.LogFactory;\n-\n-import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n import java.util.concurrent.atomic.AtomicInteger;\n \n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+\n /**\n  * An Azure blob lease that automatically renews itself indefinitely\n  * using a background thread. Use it to synchronize distributed processes,\n"}}, {"oid": "d6658798a5140edf4743e47ef0ff1a08f2142551", "url": "https://github.com/apache/hadoop/commit/d6658798a5140edf4743e47ef0ff1a08f2142551", "message": "HADOOP-16948. Support single writer dirs.", "committedDate": "2020-10-27T21:11:28Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MDE1Ng==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514450156", "bodyText": "This likely to take time? I'm worried about what happens if there's network problems and this gets invoked. Ideally this would be done in parallel, but abfs doesnt (yet) have a thread pool", "author": "steveloughran", "createdAt": "2020-10-29T17:45:18Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -243,6 +252,16 @@ public String getPrimaryGroup() {\n \n   @Override\n   public void close() throws IOException {\n+    for (SelfRenewingLease lease : leaseRefs.keySet()) {", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex 64f4e9e21cd..bdf8b631728 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n\n@@ -252,17 +255,24 @@ public String getPrimaryGroup() {\n \n   @Override\n   public void close() throws IOException {\n+    List<ListenableFuture<?>> futures = new ArrayList<>();\n     for (SelfRenewingLease lease : leaseRefs.keySet()) {\n       if (lease == null) {\n         continue;\n       }\n-      try {\n-        lease.free();\n-      } catch (Exception e) {\n-        LOG.debug(\"Got exception freeing lease {}\", lease.getLeaseID(), e);\n-      }\n+      ListenableFuture<?> future = client.submit(() -> lease.free());\n+      futures.add(future);\n+    }\n+    try {\n+      Futures.allAsList(futures).get();\n+    } catch (InterruptedException e) {\n+      LOG.error(\"Interrupted freeing leases\", e);\n+      Thread.currentThread().interrupt();\n+    } catch (ExecutionException e) {\n+      LOG.error(\"Error freeing leases\", e);\n+    } finally {\n+      IOUtils.cleanupWithLogger(LOG, client);\n     }\n-    IOUtils.cleanupWithLogger(LOG, client);\n   }\n \n   byte[] encodeAttribute(String value) throws UnsupportedEncodingException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MDQ5NQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514450495", "bodyText": "go on, add some javadocs", "author": "steveloughran", "createdAt": "2020-10-29T17:45:47Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -685,10 +712,38 @@ public OutputStream openFileForWrite(final Path path, final FileSystem.Statistic\n           statistics,\n           relativePath,\n           offset,\n-          populateAbfsOutputStreamContext(isAppendBlob));\n+          leaseRefs,\n+          populateAbfsOutputStreamContext(isAppendBlob, enableSingleWriter));\n     }\n   }\n \n+  public String acquireLease(final Path path, final int duration) throws AzureBlobFileSystemException {", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex 64f4e9e21cd..bdf8b631728 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n\n@@ -717,6 +733,14 @@ public OutputStream openFileForWrite(final Path path, final FileSystem.Statistic\n     }\n   }\n \n+  /**\n+   * Acquire a lease on an ABFS file for a specified duration. This requires the file to exist.\n+   *\n+   * @param path file name\n+   * @param duration time lease will be held before expiring\n+   * @return the acquired lease ID\n+   * @throws AzureBlobFileSystemException\n+   */\n   public String acquireLease(final Path path, final int duration) throws AzureBlobFileSystemException {\n     LOG.debug(\"lease path: {}\", path);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MjI5MQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514452291", "bodyText": "as well as the usual import grouping/ordering, we've gone to shaded guava on trunk", "author": "steveloughran", "createdAt": "2020-10-29T17:48:23Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import com.google.common.base.Preconditions;", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 5da17490147..73700abd7f8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,124 +18,187 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import com.google.common.base.Preconditions;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n-import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n \n+import static java.net.HttpURLConnection.HTTP_INTERNAL_ERROR;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n \n /**\n- * An Azure blob lease that automatically renews itself indefinitely\n- * using a background thread. Use it to synchronize distributed processes,\n- * or to prevent writes to the blob by other processes that don't\n- * have the lease.\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n  *\n- * Creating a new Lease object blocks the caller until the Azure blob lease is\n- * acquired.\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n  *\n- * Call free() to release the Lease.\n- *\n- * You can use this Lease like a distributed lock. If the holder process\n- * dies, the lease will time out since it won't be renewed.\n- *\n- * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n  */\n public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n \n-  private final AbfsClient client;\n-  private final Path path;\n-  private Thread renewer;\n-  private volatile boolean leaseFreed;\n-  private String leaseID = null;\n-  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n-\n-  // Time to wait to renew lease in milliseconds\n-  public static final int LEASE_RENEWAL_PERIOD = 40000;\n-  public static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+  static final int LEASE_DURATION = 60; // Lease duration in seconds\n+  static final int LEASE_RENEWAL_PERIOD = 40; // Lease renewal interval in seconds\n \n-  // Used to allocate thread serial numbers in thread name\n-  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n \n+  private final AbfsClient client;\n+  private final String path;\n \n-  // Time to wait to retry getting the lease in milliseconds\n-  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n-  static final int LEASE_MAX_RETRIES = 5;\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n \n   public static class LeaseException extends AzureBlobFileSystemException {\n-    public LeaseException(Exception innerException) {\n-      super(ERR_ACQUIRING_LEASE, innerException);\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t.getMessage());\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n     }\n   }\n \n   public SelfRenewingLease(AbfsClient client, Path path) throws AzureBlobFileSystemException {\n-\n     this.leaseFreed = false;\n     this.client = client;\n-    this.path = path;\n+    this.path = getRelativePath(path);\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n \n     // Try to get the lease a specified number of times, else throw an error\n-    int numRetries = 0;\n-    while (leaseID == null && numRetries < LEASE_MAX_RETRIES) {\n-      numRetries++;\n-      try {\n-        LOG.debug(\"lease path: {}\", path);\n-        final AbfsRestOperation op =\n-            client.acquireLease(getRelativePath(path),\n-                LEASE_TIMEOUT);\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n \n+    while (leaseID == null && exception == null) {\n+    }\n+    if (exception != null) {\n+      LOG.error(\"Failed to acquire lease on {}\", path);\n+      throw new LeaseException(exception);\n+    }\n+\n+    renewLease(LEASE_RENEWAL_PERIOD);\n+\n+    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+  }\n+\n+  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n+      throws LeaseException {\n+    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n+    if (future != null && !future.isDone()) {\n+      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n+    }\n+    future = client.schedule(() -> client.acquireLease(path, LEASE_DURATION),\n+        delay, TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n         leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n-      } catch (IOException e) {\n-        if (numRetries < LEASE_MAX_RETRIES) {\n-          LOG.info(\"Caught exception when trying to acquire lease on blob {}, retrying: {}\", path,\n-              e.getMessage());\n-          LOG.debug(\"Exception acquiring lease\", e);\n-        } else {\n-          throw new LeaseException(e);\n-        }\n+        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n       }\n-      if (leaseID == null) {\n-        try {\n-          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n-        } catch (InterruptedException e) {\n \n-          // Restore the interrupted status\n-          Thread.currentThread().interrupt();\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        try {\n+          if (RetryPolicy.RetryAction.RetryDecision.RETRY ==\n+              retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n+            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);\n+            acquireLease(retryPolicy, numRetries + 1, LEASE_ACQUIRE_RETRY_INTERVAL);\n+          } else {\n+            exception = throwable;\n+          }\n+        } catch (Exception e) {\n+          exception = throwable;\n         }\n       }\n+    });\n+  }\n+\n+  private void renewLease(long delay) {\n+    LOG.debug(\"Attempting to renew lease on {}, renew lease id {}, delay {}\", path, leaseID, delay);\n+    if (future != null && !future.isDone()) {\n+      LOG.warn(\"Unexpected new lease renewal operation occurred while operation already existed. \"\n+          + \"Not initiating new renewal\");\n+      return;\n     }\n-    renewer = new Thread(new Renewer());\n+    future = client.schedule(() -> client.renewLease(path, leaseID), delay,\n+            TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n+        LOG.debug(\"Renewed lease {} on {}\", leaseID, path);\n+        renewLease(delay);\n+      }\n+\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        if (throwable instanceof CancellationException) {\n+          LOG.info(\"Stopping renewal due to cancellation\");\n+          free();\n+          return;\n+        } else if (throwable instanceof AbfsRestOperationException) {\n+          AbfsRestOperationException opEx = ((AbfsRestOperationException) throwable);\n+          if (opEx.getStatusCode() < HTTP_INTERNAL_ERROR) {\n+            // error in 400 range indicates a type of error that should not result in a retry\n+            // such as the lease being broken or a different lease being present\n+            LOG.info(\"Stopping renewal due to {}: {}, {}\", opEx.getStatusCode(),\n+                opEx.getErrorCode(), opEx.getErrorMessage());\n+            free();\n+            return;\n+          }\n+        }\n \n-    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n-    renewer.setDaemon(true);\n-    renewer.setName(\"AzureBFSLeaseRenewer-\" + threadNumber.getAndIncrement());\n-    renewer.start();\n-    LOG.debug(\"Acquired lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n+        LOG.debug(\"Failed to renew lease on {}, renew lease id {}, retrying: {}\", path, leaseID,\n+            throwable);\n+        renewLease(0);\n+      }\n+    });\n   }\n \n   /**\n-   * Free the lease and stop the keep-alive thread.\n+   * Cancel renewal and free the lease. If an exception occurs, this method assumes the lease\n+   * will expire after the lease duration.\n    */\n   public void free() {\n     try {\n-      LOG.debug(\"lease path: {}, release lease id: {}\", path, leaseID);\n-      client.releaseLease(getRelativePath(path), leaseID);\n+      LOG.debug(\"Freeing lease: path {}, lease id {}\", path, leaseID);\n+      if (future != null && !future.isDone()) {\n+        future.cancel(true);\n+      }\n+      client.releaseLease(path, leaseID);\n     } catch (IOException e) {\n       LOG.info(\"Exception when trying to release lease {} on {}. Lease will be left to expire: {}\",\n           leaseID, path, e.getMessage());\n-      LOG.debug(\"Exception releasing lease\", e);\n     } finally {\n \n       // Even if releasing the lease fails (e.g. because the file was deleted),\n       // make sure to record that we freed the lease, to terminate the\n       // keep-alive thread.\n       leaseFreed = true;\n-      LOG.debug(\"Freed lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n+      LOG.debug(\"Freed lease {} on {}\", leaseID, path);\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MzQxNg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r514453416", "bodyText": "Prefer you use our normal RetryPolicy if possible", "author": "steveloughran", "createdAt": "2020-10-29T17:49:59Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,199 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n+ *\n+ * Call free() to release the Lease.\n+ *\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ */\n+public final class SelfRenewingLease {\n+\n+  private final AbfsClient client;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n+\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  public static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+\n+\n+  // Time to wait to retry getting the lease in milliseconds\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+  static final int LEASE_MAX_RETRIES = 5;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Exception innerException) {\n+      super(ERR_ACQUIRING_LEASE, innerException);\n+    }\n+  }\n+\n+  public SelfRenewingLease(AbfsClient client, Path path) throws AzureBlobFileSystemException {\n+\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    int numRetries = 0;\n+    while (leaseID == null && numRetries < LEASE_MAX_RETRIES) {\n+      numRetries++;\n+      try {\n+        LOG.debug(\"lease path: {}\", path);\n+        final AbfsRestOperation op =\n+            client.acquireLease(getRelativePath(path),\n+                LEASE_TIMEOUT);\n+\n+        leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+      } catch (IOException e) {\n+        if (numRetries < LEASE_MAX_RETRIES) {\n+          LOG.info(\"Caught exception when trying to acquire lease on blob {}, retrying: {}\", path,\n+              e.getMessage());\n+          LOG.debug(\"Exception acquiring lease\", e);\n+        } else {\n+          throw new LeaseException(e);\n+        }\n+      }\n+      if (leaseID == null) {\n+        try {\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 5da17490147..73700abd7f8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,124 +18,187 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import com.google.common.base.Preconditions;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.io.IOException;\n-import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n \n+import static java.net.HttpURLConnection.HTTP_INTERNAL_ERROR;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n \n /**\n- * An Azure blob lease that automatically renews itself indefinitely\n- * using a background thread. Use it to synchronize distributed processes,\n- * or to prevent writes to the blob by other processes that don't\n- * have the lease.\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n  *\n- * Creating a new Lease object blocks the caller until the Azure blob lease is\n- * acquired.\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n  *\n- * Call free() to release the Lease.\n- *\n- * You can use this Lease like a distributed lock. If the holder process\n- * dies, the lease will time out since it won't be renewed.\n- *\n- * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n  */\n public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n \n-  private final AbfsClient client;\n-  private final Path path;\n-  private Thread renewer;\n-  private volatile boolean leaseFreed;\n-  private String leaseID = null;\n-  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n-\n-  // Time to wait to renew lease in milliseconds\n-  public static final int LEASE_RENEWAL_PERIOD = 40000;\n-  public static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+  static final int LEASE_DURATION = 60; // Lease duration in seconds\n+  static final int LEASE_RENEWAL_PERIOD = 40; // Lease renewal interval in seconds\n \n-  // Used to allocate thread serial numbers in thread name\n-  private static AtomicInteger threadNumber = new AtomicInteger(0);\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n \n+  private final AbfsClient client;\n+  private final String path;\n \n-  // Time to wait to retry getting the lease in milliseconds\n-  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n-  static final int LEASE_MAX_RETRIES = 5;\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n \n   public static class LeaseException extends AzureBlobFileSystemException {\n-    public LeaseException(Exception innerException) {\n-      super(ERR_ACQUIRING_LEASE, innerException);\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t.getMessage());\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n     }\n   }\n \n   public SelfRenewingLease(AbfsClient client, Path path) throws AzureBlobFileSystemException {\n-\n     this.leaseFreed = false;\n     this.client = client;\n-    this.path = path;\n+    this.path = getRelativePath(path);\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n \n     // Try to get the lease a specified number of times, else throw an error\n-    int numRetries = 0;\n-    while (leaseID == null && numRetries < LEASE_MAX_RETRIES) {\n-      numRetries++;\n-      try {\n-        LOG.debug(\"lease path: {}\", path);\n-        final AbfsRestOperation op =\n-            client.acquireLease(getRelativePath(path),\n-                LEASE_TIMEOUT);\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n \n+    while (leaseID == null && exception == null) {\n+    }\n+    if (exception != null) {\n+      LOG.error(\"Failed to acquire lease on {}\", path);\n+      throw new LeaseException(exception);\n+    }\n+\n+    renewLease(LEASE_RENEWAL_PERIOD);\n+\n+    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+  }\n+\n+  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n+      throws LeaseException {\n+    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n+    if (future != null && !future.isDone()) {\n+      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n+    }\n+    future = client.schedule(() -> client.acquireLease(path, LEASE_DURATION),\n+        delay, TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n         leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n-      } catch (IOException e) {\n-        if (numRetries < LEASE_MAX_RETRIES) {\n-          LOG.info(\"Caught exception when trying to acquire lease on blob {}, retrying: {}\", path,\n-              e.getMessage());\n-          LOG.debug(\"Exception acquiring lease\", e);\n-        } else {\n-          throw new LeaseException(e);\n-        }\n+        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n       }\n-      if (leaseID == null) {\n-        try {\n-          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n-        } catch (InterruptedException e) {\n \n-          // Restore the interrupted status\n-          Thread.currentThread().interrupt();\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        try {\n+          if (RetryPolicy.RetryAction.RetryDecision.RETRY ==\n+              retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n+            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);\n+            acquireLease(retryPolicy, numRetries + 1, LEASE_ACQUIRE_RETRY_INTERVAL);\n+          } else {\n+            exception = throwable;\n+          }\n+        } catch (Exception e) {\n+          exception = throwable;\n         }\n       }\n+    });\n+  }\n+\n+  private void renewLease(long delay) {\n+    LOG.debug(\"Attempting to renew lease on {}, renew lease id {}, delay {}\", path, leaseID, delay);\n+    if (future != null && !future.isDone()) {\n+      LOG.warn(\"Unexpected new lease renewal operation occurred while operation already existed. \"\n+          + \"Not initiating new renewal\");\n+      return;\n     }\n-    renewer = new Thread(new Renewer());\n+    future = client.schedule(() -> client.renewLease(path, leaseID), delay,\n+            TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n+        LOG.debug(\"Renewed lease {} on {}\", leaseID, path);\n+        renewLease(delay);\n+      }\n+\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        if (throwable instanceof CancellationException) {\n+          LOG.info(\"Stopping renewal due to cancellation\");\n+          free();\n+          return;\n+        } else if (throwable instanceof AbfsRestOperationException) {\n+          AbfsRestOperationException opEx = ((AbfsRestOperationException) throwable);\n+          if (opEx.getStatusCode() < HTTP_INTERNAL_ERROR) {\n+            // error in 400 range indicates a type of error that should not result in a retry\n+            // such as the lease being broken or a different lease being present\n+            LOG.info(\"Stopping renewal due to {}: {}, {}\", opEx.getStatusCode(),\n+                opEx.getErrorCode(), opEx.getErrorMessage());\n+            free();\n+            return;\n+          }\n+        }\n \n-    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n-    renewer.setDaemon(true);\n-    renewer.setName(\"AzureBFSLeaseRenewer-\" + threadNumber.getAndIncrement());\n-    renewer.start();\n-    LOG.debug(\"Acquired lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n+        LOG.debug(\"Failed to renew lease on {}, renew lease id {}, retrying: {}\", path, leaseID,\n+            throwable);\n+        renewLease(0);\n+      }\n+    });\n   }\n \n   /**\n-   * Free the lease and stop the keep-alive thread.\n+   * Cancel renewal and free the lease. If an exception occurs, this method assumes the lease\n+   * will expire after the lease duration.\n    */\n   public void free() {\n     try {\n-      LOG.debug(\"lease path: {}, release lease id: {}\", path, leaseID);\n-      client.releaseLease(getRelativePath(path), leaseID);\n+      LOG.debug(\"Freeing lease: path {}, lease id {}\", path, leaseID);\n+      if (future != null && !future.isDone()) {\n+        future.cancel(true);\n+      }\n+      client.releaseLease(path, leaseID);\n     } catch (IOException e) {\n       LOG.info(\"Exception when trying to release lease {} on {}. Lease will be left to expire: {}\",\n           leaseID, path, e.getMessage());\n-      LOG.debug(\"Exception releasing lease\", e);\n     } finally {\n \n       // Even if releasing the lease fails (e.g. because the file was deleted),\n       // make sure to record that we freed the lease, to terminate the\n       // keep-alive thread.\n       leaseFreed = true;\n-      LOG.debug(\"Freed lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n+      LOG.debug(\"Freed lease {} on {}\", leaseID, path);\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3NzE5NA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531177194", "bodyText": "how about using DurationInfo in the try with resources (logging @ debug) to track how long acquire/release took. I can imagine it can take a while to acquire. Indeed, do we have to worry about timeouts, heartbeats, etc?", "author": "steveloughran", "createdAt": "2020-11-26T18:11:38Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -475,6 +475,55 @@ public FileStatus getFileStatus(final Path f) throws IOException {\n     }\n   }\n \n+  public String acquireLease(final Path f, final int duration) throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.acquireLease path: {}\", f);\n+\n+    Path qualifiedPath = makeQualified(f);\n+\n+    try {\n+      return abfsStore.acquireLease(qualifiedPath, duration);", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\nindex 703c7a560d4..d1f05a63235 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n\n@@ -480,7 +481,8 @@ public String acquireLease(final Path f, final int duration) throws IOException\n \n     Path qualifiedPath = makeQualified(f);\n \n-    try {\n+    try (DurationInfo ignored = new DurationInfo(LOG, false, \"Acquire lease for %s\",\n+        qualifiedPath)) {\n       return abfsStore.acquireLease(qualifiedPath, duration);\n     } catch(AzureBlobFileSystemException ex) {\n       checkException(f, ex);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3NzY2MQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531177661", "bodyText": "o.a.h.utils.IOUtils.close methods do this", "author": "steveloughran", "createdAt": "2020-11-26T18:13:12Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_PARALLEL_ACCESS_DETECTED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+    try {\n+      out.close();\n+      Assert.fail(\"Expected exception on close after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+\n+    Assert.assertTrue(((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed());\n+\n+    try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+      out2.write(2);\n+      out2.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedAfterBreak() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = null;\n+    try {\n+      out = fs.create(testFilePath);\n+      out.write(0);\n+\n+      fs.breakLease(testFilePath);\n+      while (!((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed()) {\n+        try {\n+          Thread.sleep(1000);\n+        } catch (InterruptedException e) {\n+        }\n+      }\n+    } finally {\n+      try {\n+        if (out != null) {", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\nindex 8eebcda0df0..f1aa34a3414 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n\n@@ -17,16 +17,23 @@\n  */\n package org.apache.hadoop.fs.azurebfs;\n \n+import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n import org.junit.Assert;\n import org.junit.Test;\n \n import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n \n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3NzkyMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531177921", "bodyText": "GenericTestUtils lets you assert something is in the error message. Its critical to rethrow (maybe wrapped) the exception if it is not the one you were expecting", "author": "steveloughran", "createdAt": "2020-11-26T18:14:02Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_PARALLEL_ACCESS_DETECTED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+    try {\n+      out.close();\n+      Assert.fail(\"Expected exception on close after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+\n+    Assert.assertTrue(((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed());\n+\n+    try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+      out2.write(2);\n+      out2.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedAfterBreak() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = null;\n+    try {\n+      out = fs.create(testFilePath);\n+      out.write(0);\n+\n+      fs.breakLease(testFilePath);\n+      while (!((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed()) {\n+        try {\n+          Thread.sleep(1000);\n+        } catch (InterruptedException e) {\n+        }\n+      }\n+    } finally {\n+      try {\n+        if (out != null) {\n+          out.close();\n+        }\n+        // exception might or might not occur\n+      } catch (IOException e) {", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\nindex 8eebcda0df0..f1aa34a3414 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n\n@@ -17,16 +17,23 @@\n  */\n package org.apache.hadoop.fs.azurebfs;\n \n+import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n import org.junit.Assert;\n import org.junit.Test;\n \n import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n \n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMTE3ODIzNw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r531178237", "bodyText": "and add a message to raise if the condition is met.\nnote, it's ok to use AssertJ for your asserts, we are adopting it more broadly and enjoying its diagnostics.", "author": "steveloughran", "createdAt": "2020-11-26T18:14:53Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,249 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_PARALLEL_ACCESS_DETECTED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+    try {\n+      out.close();\n+      Assert.fail(\"Expected exception on close after lease break\");\n+    } catch (IOException e) {\n+      Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+          e.getMessage().contains(ERR_LEASE_EXPIRED));\n+    }\n+\n+    Assert.assertTrue(((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed());\n+\n+    try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+      out2.write(2);\n+      out2.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedAfterBreak() throws IOException {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    fs.mkdirs(testFilePath.getParent());\n+    fs.getAbfsStore().getAbfsConfiguration()\n+        .setAzureSingleWriterDirs(testFilePath.getParent().toString());\n+    fs.getAbfsStore().updateSingleWriterDirs();\n+\n+    FSDataOutputStream out = null;\n+    try {\n+      out = fs.create(testFilePath);\n+      out.write(0);\n+\n+      fs.breakLease(testFilePath);\n+      while (!((AbfsOutputStream) out.getWrappedStream()).isLeaseFreed()) {\n+        try {\n+          Thread.sleep(1000);\n+        } catch (InterruptedException e) {\n+        }\n+      }\n+    } finally {\n+      try {\n+        if (out != null) {\n+          out.close();\n+        }\n+        // exception might or might not occur\n+      } catch (IOException e) {\n+        Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+            e.getMessage().contains(ERR_LEASE_EXPIRED));\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());", "originalCommit": "bb65e714888f104676915e8c54a0c2b00b3168e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\nindex 8eebcda0df0..f1aa34a3414 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n\n@@ -17,16 +17,23 @@\n  */\n package org.apache.hadoop.fs.azurebfs;\n \n+import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n import org.junit.Assert;\n import org.junit.Test;\n \n import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n \n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n \n /**\n"}}, {"oid": "43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "url": "https://github.com/apache/hadoop/commit/43faa3962f8835b5a7b7749f1628d9dd3f8a3fa1", "message": "HADOOP-16948. Convert ABFS client to use an executor for lease ops", "committedDate": "2021-01-14T15:28:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MDgxMw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558290813", "bodyText": "can you pull up to the .thirdparty section and add a newline after. Our guava shading project is confusing IDEs and making backporting/cherrypicking harder", "author": "steveloughran", "createdAt": "2021-01-15T13:00:07Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -29,13 +29,23 @@\n import java.util.ArrayList;\n import java.util.List;\n import java.util.Locale;\n+import java.util.UUID;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n \n import org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting;\n import org.apache.hadoop.thirdparty.com.google.common.base.Strings;\n import org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory;\n import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n import org.apache.hadoop.fs.azurebfs.constants.HttpQueryParams;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex b95ae10c3ac..9a4fc5fad45 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -31,24 +31,25 @@\n import java.util.Locale;\n import java.util.UUID;\n import java.util.concurrent.Callable;\n-import java.util.concurrent.Executors;\n+import java.util.concurrent.ThreadFactory;\n import java.util.concurrent.TimeUnit;\n \n import org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting;\n import org.apache.hadoop.thirdparty.com.google.common.base.Strings;\n-import org.apache.hadoop.security.ssl.DelegatingSSLSocketFactory;\n-import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n-import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n-import org.apache.hadoop.fs.azurebfs.constants.HttpQueryParams;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.Futures;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableFuture;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListeningScheduledExecutorService;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.MoreExecutors;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;\n+\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import org.apache.hadoop.fs.azurebfs.constants.AbfsHttpConstants;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpQueryParams;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.InvalidUriException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.SASTokenProviderException;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MTc4OQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558291789", "bodyText": "Prefer you use HadoopExecutors here.", "author": "steveloughran", "createdAt": "2021-01-15T13:01:59Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -106,6 +118,9 @@ private AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCreden\n     this.userAgent = initializeUserAgent(abfsConfiguration, sslProviderName);\n     this.abfsPerfTracker = abfsClientContext.getAbfsPerfTracker();\n     this.abfsCounters = abfsClientContext.getAbfsCounters();\n+\n+    this.executorService = MoreExecutors.listeningDecorator(\n+        Executors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex b95ae10c3ac..9a4fc5fad45 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -119,8 +122,10 @@ private AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCreden\n     this.abfsPerfTracker = abfsClientContext.getAbfsPerfTracker();\n     this.abfsCounters = abfsClientContext.getAbfsCounters();\n \n+    ThreadFactory tf =\n+        new ThreadFactoryBuilder().setNameFormat(\"AbfsClient Lease Ops\").setDaemon(true).build();\n     this.executorService = MoreExecutors.listeningDecorator(\n-        Executors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));\n+        HadoopExecutors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads(), tf));\n   }\n \n   public AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCredentials,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MTk1OQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558291959", "bodyText": "HadoopExecutors.shutdown has some error handling here", "author": "steveloughran", "createdAt": "2021-01-15T13:02:20Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -129,6 +144,7 @@ public void close() throws IOException {\n     if (tokenProvider instanceof Closeable) {\n       IOUtils.cleanupWithLogger(LOG, (Closeable) tokenProvider);\n     }\n+    executorService.shutdownNow();", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex b95ae10c3ac..9a4fc5fad45 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -144,7 +149,7 @@ public void close() throws IOException {\n     if (tokenProvider instanceof Closeable) {\n       IOUtils.cleanupWithLogger(LOG, (Closeable) tokenProvider);\n     }\n-    executorService.shutdownNow();\n+    HadoopExecutors.shutdown(executorService, LOG, 0, TimeUnit.SECONDS);\n   }\n \n   public String getFileSystem() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MjQxMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558292411", "bodyText": "if the RestOperation doesn't log anything, add something here. Will help debug locking problems", "author": "steveloughran", "createdAt": "2021-01-15T13:03:23Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -306,6 +322,83 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n     return op;\n   }\n \n+  public AbfsRestOperation acquireLease(final String path, int duration) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, ACQUIRE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_DURATION, Integer.toString(duration)));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_PROPOSED_LEASE_ID, UUID.randomUUID().toString()));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODQ1OTkwOQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558459909", "bodyText": "There is some good debug logging when the rest operation is executed, so I think we're okay here.", "author": "billierinaldi", "createdAt": "2021-01-15T17:35:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MjQxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex b95ae10c3ac..db92b496f4b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -318,7 +303,18 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n             HTTP_METHOD_PUT,\n             url,\n             requestHeaders);\n-    op.execute();\n+    try {\n+      op.execute();\n+    } catch (AzureBlobFileSystemException ex) {\n+      if (!isFile && op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+        String existingResource =\n+            op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n+        if (existingResource != null && existingResource.equals(DIRECTORY)) {\n+          return op; //don't throw ex on mkdirs for existing directory\n+        }\n+      }\n+      throw ex;\n+    }\n     return op;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MjYzMg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558292632", "bodyText": "add a log if needed", "author": "steveloughran", "createdAt": "2021-01-15T13:03:52Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -306,6 +322,83 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n     return op;\n   }\n \n+  public AbfsRestOperation acquireLease(final String path, int duration) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, ACQUIRE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_DURATION, Integer.toString(duration)));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_PROPOSED_LEASE_ID, UUID.randomUUID().toString()));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(\n+        AbfsRestOperationType.LeasePath,\n+        this,\n+        HTTP_METHOD_POST,\n+        url,\n+        requestHeaders);\n+    op.execute();\n+    return op;\n+  }\n+\n+  public AbfsRestOperation renewLease(final String path, final String leaseId) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, RENEW_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ID, leaseId));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex b95ae10c3ac..db92b496f4b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -318,7 +303,18 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n             HTTP_METHOD_PUT,\n             url,\n             requestHeaders);\n-    op.execute();\n+    try {\n+      op.execute();\n+    } catch (AzureBlobFileSystemException ex) {\n+      if (!isFile && op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+        String existingResource =\n+            op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n+        if (existingResource != null && existingResource.equals(DIRECTORY)) {\n+          return op; //don't throw ex on mkdirs for existing directory\n+        }\n+      }\n+      throw ex;\n+    }\n     return op;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MjY5Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558292697", "bodyText": "+log", "author": "steveloughran", "createdAt": "2021-01-15T13:03:59Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -306,6 +322,83 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n     return op;\n   }\n \n+  public AbfsRestOperation acquireLease(final String path, int duration) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, ACQUIRE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_DURATION, Integer.toString(duration)));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_PROPOSED_LEASE_ID, UUID.randomUUID().toString()));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(\n+        AbfsRestOperationType.LeasePath,\n+        this,\n+        HTTP_METHOD_POST,\n+        url,\n+        requestHeaders);\n+    op.execute();\n+    return op;\n+  }\n+\n+  public AbfsRestOperation renewLease(final String path, final String leaseId) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, RENEW_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ID, leaseId));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(\n+        AbfsRestOperationType.LeasePath,\n+        this,\n+        HTTP_METHOD_POST,\n+        url,\n+        requestHeaders);\n+    op.execute();\n+    return op;\n+  }\n+\n+  public AbfsRestOperation releaseLease(final String path, final String leaseId) throws AzureBlobFileSystemException {\n+    final List<AbfsHttpHeader> requestHeaders = createDefaultHeaders();\n+\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ACTION, RELEASE_LEASE_ACTION));\n+    requestHeaders.add(new AbfsHttpHeader(X_MS_LEASE_ID, leaseId));\n+\n+    final AbfsUriQueryBuilder abfsUriQueryBuilder = createDefaultUriQueryBuilder();\n+\n+    final URL url = createRequestUrl(path, abfsUriQueryBuilder.toString());\n+    final AbfsRestOperation op = new AbfsRestOperation(", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex b95ae10c3ac..db92b496f4b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -318,7 +303,18 @@ public AbfsRestOperation createPath(final String path, final boolean isFile, fin\n             HTTP_METHOD_PUT,\n             url,\n             requestHeaders);\n-    op.execute();\n+    try {\n+      op.execute();\n+    } catch (AzureBlobFileSystemException ex) {\n+      if (!isFile && op.getResult().getStatusCode() == HttpURLConnection.HTTP_CONFLICT) {\n+        String existingResource =\n+            op.getResult().getResponseHeader(X_MS_EXISTING_RESOURCE_TYPE);\n+        if (existingResource != null && existingResource.equals(DIRECTORY)) {\n+          return op; //don't throw ex on mkdirs for existing directory\n+        }\n+      }\n+      throw ex;\n+    }\n     return op;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5MzYzNQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558293635", "bodyText": "this should go into the AbfsOutputStreamContext, its where we are adding more state for a stream constructor", "author": "steveloughran", "createdAt": "2021-01-15T13:05:51Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -113,7 +120,8 @@ public AbfsOutputStream(\n           final Statistics statistics,\n           final String path,\n           final long position,\n-          AbfsOutputStreamContext abfsOutputStreamContext) {\n+          final Map<SelfRenewingLease, Object> leaseRefs,", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 2377a404a60..1ca92404b51 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -120,7 +118,6 @@ public AbfsOutputStream(\n           final Statistics statistics,\n           final String path,\n           final long position,\n-          final Map<SelfRenewingLease, Object> leaseRefs,\n           AbfsOutputStreamContext abfsOutputStreamContext) throws AzureBlobFileSystemException {\n     this.client = client;\n     this.statistics = statistics;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5NDM4OQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558294389", "bodyText": "is isLeaseFreed()", "author": "steveloughran", "createdAt": "2021-01-15T13:07:16Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -209,6 +226,10 @@ public synchronized void write(final byte[] data, final int off, final int lengt\n       throw new IndexOutOfBoundsException();\n     }\n \n+    if (lease != null && lease.isFreed()) {", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 2377a404a60..1ca92404b51 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -226,7 +212,7 @@ public synchronized void write(final byte[] data, final int off, final int lengt\n       throw new IndexOutOfBoundsException();\n     }\n \n-    if (lease != null && lease.isFreed()) {\n+    if (hasLease() && isLeaseFreed()) {\n       throw new PathIOException(path, ERR_WRITE_WITHOUT_LEASE);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5NDQ3MQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558294471", "bodyText": "use hasLease()", "author": "steveloughran", "createdAt": "2021-01-15T13:07:29Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -312,6 +333,10 @@ public synchronized void close() throws IOException {\n       // See HADOOP-16785\n       throw wrapException(path, e.getMessage(), e);\n     } finally {\n+      if (lease != null) {", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 2377a404a60..1ca92404b51 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -333,7 +319,7 @@ public synchronized void close() throws IOException {\n       // See HADOOP-16785\n       throw wrapException(path, e.getMessage(), e);\n     } finally {\n-      if (lease != null) {\n+      if (hasLease()) {\n         lease.free();\n         lease = null;\n       }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5ODM1Mw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558298353", "bodyText": "import ordering. should be java.* javax.* \\n non-asf-and-hadoop.thirdparty \\n o.a.a", "author": "steveloughran", "createdAt": "2021-01-15T13:14:48Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.Path;", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex b4bc5a4f330..3ad45719fb3 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,24 +18,24 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n-import org.apache.hadoop.io.retry.RetryPolicies;\n-import org.apache.hadoop.io.retry.RetryPolicy;\n-import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.io.IOException;\n-import java.util.concurrent.CancellationException;\n-import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n \n-import static java.net.HttpURLConnection.HTTP_INTERNAL_ERROR;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5ODgwMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558298801", "bodyText": "keep t's stack trace by passing up to superclass or in initCause()", "author": "steveloughran", "createdAt": "2021-01-15T13:15:38Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import static java.net.HttpURLConnection.HTTP_INTERNAL_ERROR;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  static final int LEASE_DURATION = 60; // Lease duration in seconds\n+  static final int LEASE_RENEWAL_PERIOD = 40; // Lease renewal interval in seconds\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t.getMessage());", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex b4bc5a4f330..3ad45719fb3 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,24 +18,24 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n-import org.apache.hadoop.io.retry.RetryPolicies;\n-import org.apache.hadoop.io.retry.RetryPolicy;\n-import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import java.io.IOException;\n-import java.util.concurrent.CancellationException;\n-import java.util.concurrent.TimeUnit;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n \n-import static java.net.HttpURLConnection.HTTP_INTERNAL_ERROR;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI5OTQyMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558299421", "bodyText": "move to lower group", "author": "steveloughran", "createdAt": "2021-01-15T13:16:48Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -39,6 +39,7 @@\n \n import org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting;\n import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import org.apache.hadoop.util.DurationInfo;", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\nindex d1f05a63235..2d9f1fc42bf 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n\n@@ -26,12 +26,16 @@\n import java.net.HttpURLConnection;\n import java.net.URI;\n import java.net.URISyntaxException;\n+import java.nio.file.AccessDeniedException;\n import java.util.Hashtable;\n import java.util.List;\n import java.util.ArrayList;\n+import java.util.Collections;\n import java.util.EnumSet;\n import java.util.Map;\n+import java.util.Optional;\n import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.ExecutionException;\n import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Executors;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMDA5NA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558300094", "bodyText": "do we need to worry about running out of workers here, timeouts etc?", "author": "steveloughran", "createdAt": "2021-01-15T13:17:59Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -243,7 +255,24 @@ public String getPrimaryGroup() {\n \n   @Override\n   public void close() throws IOException {\n-    IOUtils.cleanupWithLogger(LOG, client);\n+    List<ListenableFuture<?>> futures = new ArrayList<>();\n+    for (SelfRenewingLease lease : leaseRefs.keySet()) {\n+      if (lease == null) {\n+        continue;\n+      }\n+      ListenableFuture<?> future = client.submit(() -> lease.free());", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTIzMjc5Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r559232797", "bodyText": "I am not sure. This is kind of a failsafe; I would not expect code to close the filesystem without closing output streams first, so ideally this loop will only be double checking that free() has already been called on these lease instances without actually performing REST ops. If the output streams opened for this FS instance (for designated single writer directories) have not been closed before the filesystem is closed, this would perform a REST op for each one.", "author": "billierinaldi", "createdAt": "2021-01-17T20:18:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMDA5NA=="}], "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex f1e1430ef1c..59304efda89 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n\n@@ -255,24 +255,17 @@ public String getPrimaryGroup() {\n \n   @Override\n   public void close() throws IOException {\n-    List<ListenableFuture<?>> futures = new ArrayList<>();\n     for (SelfRenewingLease lease : leaseRefs.keySet()) {\n       if (lease == null) {\n         continue;\n       }\n-      ListenableFuture<?> future = client.submit(() -> lease.free());\n-      futures.add(future);\n-    }\n-    try {\n-      Futures.allAsList(futures).get();\n-    } catch (InterruptedException e) {\n-      LOG.error(\"Interrupted freeing leases\", e);\n-      Thread.currentThread().interrupt();\n-    } catch (ExecutionException e) {\n-      LOG.error(\"Error freeing leases\", e);\n-    } finally {\n-      IOUtils.cleanupWithLogger(LOG, client);\n+      try {\n+        lease.free();\n+      } catch (Exception e) {\n+        LOG.debug(\"Got exception freeing lease {}\", lease.getLeaseID(), e);\n+      }\n     }\n+    IOUtils.cleanupWithLogger(LOG, client);\n   }\n \n   byte[] encodeAttribute(String value) throws UnsupportedEncodingException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMTAxNA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558301014", "bodyText": "usual comment about import ordering.", "author": "steveloughran", "createdAt": "2021-01-15T13:19:43Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.conf.Configuration;", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\nindex 347bd45facf..745b18dd3cd 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n\n@@ -17,22 +17,30 @@\n  */\n package org.apache.hadoop.fs.azurebfs;\n \n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n import org.apache.hadoop.test.GenericTestUtils;\n-import org.junit.Assert;\n-import org.junit.Test;\n-\n-import java.io.IOException;\n-import java.util.concurrent.RejectedExecutionException;\n+import org.apache.hadoop.test.LambdaTestUtils;\n \n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_ALREADY_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_BROKEN;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_DID_NOT_MATCH;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_ID_NOT_PRESENT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMjkxNA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558302914", "bodyText": "use LambdaTestUtils; return a string with that error message in the closure for it to be used in the exception. Ideally add out.toString() too. eg.\nintercept(ioe, ERR_LEASE_EXPIRED, () -> {\n  out..write(1);\n  out.hsync();\n  return \"expected exception but got \" + out;\n  });", "author": "steveloughran", "createdAt": "2021-01-15T13:23:14Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+  private final boolean isHNSEnabled;\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+\n+    this.isHNSEnabled = getConfiguration()\n+        .getBoolean(FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT, false);\n+  }\n+\n+  private AzureBlobFileSystem getCustomFileSystem(String singleWriterDirs, int numLeaseThreads)\n+      throws Exception {\n+    Configuration conf = getRawConfiguration();\n+    conf.setBoolean(String.format(\"fs.%s.impl.disable.cache\", getAbfsScheme()), true);\n+    conf.set(FS_AZURE_SINGLE_WRITER_KEY, singleWriterDirs);\n+    conf.setInt(FS_AZURE_LEASE_THREADS, numLeaseThreads);\n+    return getFileSystem(conf);\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testNoLeaseThreads() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 0);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.fail(\"No failure when lease requested with 0 lease threads\");\n+    } catch (Exception e) {\n+      GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_THREADS, e);\n+    }\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws Exception {\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    final AzureBlobFileSystem fs =\n+        getCustomFileSystem(testFilePath.getParent().getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        if (isHNSEnabled) {\n+          GenericTestUtils.assertExceptionContains(ERR_PARALLEL_ACCESS_DETECTED, e);\n+        } else {\n+          GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_ID_SPECIFIED, e);\n+        }\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\nindex 347bd45facf..745b18dd3cd 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n\n@@ -17,22 +17,30 @@\n  */\n package org.apache.hadoop.fs.azurebfs;\n \n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n import org.apache.hadoop.test.GenericTestUtils;\n-import org.junit.Assert;\n-import org.junit.Test;\n-\n-import java.io.IOException;\n-import java.util.concurrent.RejectedExecutionException;\n+import org.apache.hadoop.test.LambdaTestUtils;\n \n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_ALREADY_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_BROKEN;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_DID_NOT_MATCH;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_ID_NOT_PRESENT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558303127", "bodyText": "do we really want a failure in close?", "author": "steveloughran", "createdAt": "2021-01-15T13:23:39Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -0,0 +1,295 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.test.GenericTestUtils;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_PARALLEL_ACCESS_DETECTED;\n+\n+/**\n+ * Test lease operations.\n+ */\n+public class ITestAzureBlobFileSystemLease extends AbstractAbfsIntegrationTest {\n+  private static final int TEST_EXECUTION_TIMEOUT = 30 * 1000;\n+  private static final int LONG_TEST_EXECUTION_TIMEOUT = 90 * 1000;\n+  private static final String TEST_FILE = \"testfile\";\n+  private final boolean isHNSEnabled;\n+\n+  public ITestAzureBlobFileSystemLease() throws Exception {\n+    super();\n+\n+    this.isHNSEnabled = getConfiguration()\n+        .getBoolean(FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT, false);\n+  }\n+\n+  private AzureBlobFileSystem getCustomFileSystem(String singleWriterDirs, int numLeaseThreads)\n+      throws Exception {\n+    Configuration conf = getRawConfiguration();\n+    conf.setBoolean(String.format(\"fs.%s.impl.disable.cache\", getAbfsScheme()), true);\n+    conf.set(FS_AZURE_SINGLE_WRITER_KEY, singleWriterDirs);\n+    conf.setInt(FS_AZURE_LEASE_THREADS, numLeaseThreads);\n+    return getFileSystem(conf);\n+  }\n+\n+  @Test\n+  public void testNoSingleWriter() throws IOException {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.assertFalse(\"Output stream should not have lease\",\n+          ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testNoLeaseThreads() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 0);\n+    fs.mkdirs(testFilePath.getParent());\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      Assert.fail(\"No failure when lease requested with 0 lease threads\");\n+    } catch (Exception e) {\n+      GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_THREADS, e);\n+    }\n+  }\n+\n+  @Test\n+  public void testOneWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testSubDir() throws Exception {\n+    final Path testFilePath = new Path(new Path(path(methodName.getMethodName()), \"subdir\"),\n+        TEST_FILE);\n+    final AzureBlobFileSystem fs =\n+        getCustomFileSystem(testFilePath.getParent().getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent().getParent());\n+\n+    FSDataOutputStream out = fs.create(testFilePath);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test\n+  public void testTwoCreate() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.create(testFilePath)) {\n+        Assert.fail(\"Second create succeeded\");\n+      } catch (IOException e) {\n+        if (isHNSEnabled) {\n+          GenericTestUtils.assertExceptionContains(ERR_PARALLEL_ACCESS_DETECTED, e);\n+        } else {\n+          GenericTestUtils.assertExceptionContains(ERR_NO_LEASE_ID_SPECIFIED, e);\n+        }\n+      }\n+    }\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expectException) throws Exception {\n+    try (FSDataOutputStream out = fs.create(testFilePath)) {\n+      try (FSDataOutputStream out2 = fs.append(testFilePath)) {\n+        out2.writeInt(2);\n+        out2.hsync();\n+      } catch (IOException e) {\n+        if (expectException) {\n+          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n+              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+        } else {\n+          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+        }\n+      }\n+      out.writeInt(1);\n+      out.hsync();\n+    }\n+\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendNoSingleWriter() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, false);\n+  }\n+\n+  @Test(timeout = LONG_TEST_EXECUTION_TIMEOUT)\n+  public void testTwoWritersCreateAppendWithSingleWriterEnabled() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    twoWriters(fs, testFilePath, true);\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testLeaseFreedOnClose() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    Assert.assertTrue(\"Output stream should have lease\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    out.close();\n+    Assert.assertFalse(\"Output stream should not have lease after close\",\n+        ((AbfsOutputStream) out.getWrappedStream()).hasLease());\n+    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+  }\n+\n+  @Test(timeout = TEST_EXECUTION_TIMEOUT)\n+  public void testWriteAfterBreakLease() throws Exception {\n+    final Path testFilePath = new Path(path(methodName.getMethodName()), TEST_FILE);\n+    final AzureBlobFileSystem fs = getCustomFileSystem(testFilePath.getParent().toString(), 1);\n+    fs.mkdirs(testFilePath.getParent());\n+\n+    FSDataOutputStream out;\n+    out = fs.create(testFilePath);\n+    out.write(0);\n+    out.hsync();\n+\n+    fs.breakLease(testFilePath);\n+    try {\n+      out.write(1);\n+      out.hsync();\n+      Assert.fail(\"Expected exception on write after lease break\");\n+    } catch (IOException e) {\n+      GenericTestUtils.assertExceptionContains(ERR_LEASE_EXPIRED, e);\n+    }\n+    try {\n+      out.close();", "originalCommit": "c4082f019e25b010c1c36f0688cf0cb676b727d7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODQ4MTMxMg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558481312", "bodyText": "I think as you mentioned this is due to flushing buffers on close, so I am not sure we can do much about it. I can check what happens when close is called after the lease has expired or is broken and the buffer is empty, to see if we can avoid an exception in that case.", "author": "billierinaldi", "createdAt": "2021-01-15T18:07:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODU3ODg5Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r558578897", "bodyText": "Looks like there is a flush call to the storage API even when the buffer is empty, so it will always throw an exception if the lease is broken.", "author": "billierinaldi", "createdAt": "2021-01-15T20:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNzU1Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560137557", "bodyText": "should it be doing that flush?", "author": "steveloughran", "createdAt": "2021-01-19T12:21:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NjQzOTEzNQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r566439135", "bodyText": "I looked over the API docs and it seems like it is potentially important to perform that operation.", "author": "billierinaldi", "createdAt": "2021-01-28T22:06:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MjI4OTAyMA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r572289020", "bodyText": "ok, let's go with the flush", "author": "steveloughran", "createdAt": "2021-02-08T18:53:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODMwMzEyNw=="}], "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\nindex 347bd45facf..745b18dd3cd 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n\n@@ -17,22 +17,30 @@\n  */\n package org.apache.hadoop.fs.azurebfs;\n \n+import java.io.IOException;\n+import java.util.concurrent.RejectedExecutionException;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n import org.apache.hadoop.test.GenericTestUtils;\n-import org.junit.Assert;\n-import org.junit.Test;\n-\n-import java.io.IOException;\n-import java.util.concurrent.RejectedExecutionException;\n+import org.apache.hadoop.test.LambdaTestUtils;\n \n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_LEASE_THREADS;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_SINGLE_WRITER_KEY;\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.constants.TestConfigurationKeys.FS_AZURE_TEST_NAMESPACE_ENABLED_ACCOUNT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_ALREADY_PRESENT;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_BROKEN;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_DID_NOT_MATCH;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_EXPIRED;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_ID_NOT_PRESENT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_NOT_PRESENT;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_ID_SPECIFIED;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNTQ4OQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560135489", "bodyText": "can you make sure this executor marks its threads as daemons. Otherwise processes can hang during shutdown. @bgaborg has encountered this elsewhere", "author": "steveloughran", "createdAt": "2021-01-19T12:17:43Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java", "diffHunk": "@@ -120,7 +120,7 @@ private AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCreden\n     this.abfsCounters = abfsClientContext.getAbfsCounters();\n \n     this.executorService = MoreExecutors.listeningDecorator(\n-        Executors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));\n+        HadoopExecutors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));", "originalCommit": "978cedb7b63d6a1b09db291511cc87ae53c7cab0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\nindex 0711a788705..9a4fc5fad45 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsClient.java\n\n@@ -119,8 +122,10 @@ private AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCreden\n     this.abfsPerfTracker = abfsClientContext.getAbfsPerfTracker();\n     this.abfsCounters = abfsClientContext.getAbfsCounters();\n \n+    ThreadFactory tf =\n+        new ThreadFactoryBuilder().setNameFormat(\"AbfsClient Lease Ops\").setDaemon(true).build();\n     this.executorService = MoreExecutors.listeningDecorator(\n-        HadoopExecutors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads()));\n+        HadoopExecutors.newScheduledThreadPool(this.abfsConfiguration.getNumLeaseThreads(), tf));\n   }\n \n   public AbfsClient(final URL baseUrl, final SharedKeyCredentials sharedKeyCredentials,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNjUxNA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560136514", "bodyText": "I think I'd keep that t text in the superclass text, in case a deep tree causes the nested cause not to be listed.\nbut: use toString() (implicitly) rather than getMessage, because some exceptions (NPW) have a null message.", "author": "steveloughran", "createdAt": "2021-01-19T12:19:31Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -71,7 +72,7 @@\n \n   public static class LeaseException extends AzureBlobFileSystemException {\n     public LeaseException(Throwable t) {\n-      super(ERR_ACQUIRING_LEASE + \": \" + t.getMessage());\n+      super(ERR_ACQUIRING_LEASE, t);", "originalCommit": "978cedb7b63d6a1b09db291511cc87ae53c7cab0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 12649aafe74..3ad45719fb3 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -72,7 +72,7 @@\n \n   public static class LeaseException extends AzureBlobFileSystemException {\n     public LeaseException(Throwable t) {\n-      super(ERR_ACQUIRING_LEASE, t);\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n     }\n \n     public LeaseException(String s) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzNzE3Mg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560137172", "bodyText": "just rethrow it or wrap in an assertion error. we need that full stack trace", "author": "steveloughran", "createdAt": "2021-01-19T12:20:36Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java", "diffHunk": "@@ -146,8 +150,7 @@ private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expec\n         out2.hsync();\n       } catch (IOException e) {\n         if (expectException) {\n-          Assert.assertTrue(\"Unexpected error message: \" + e.getMessage(),\n-              e.getMessage().contains(ERR_ACQUIRING_LEASE));\n+          GenericTestUtils.assertExceptionContains(ERR_ACQUIRING_LEASE, e);\n         } else {\n           Assert.fail(\"Unexpected exception \" + e.getMessage());", "originalCommit": "978cedb7b63d6a1b09db291511cc87ae53c7cab0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\nindex a2b0469c223..745b18dd3cd 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemLease.java\n\n@@ -152,14 +159,14 @@ private void twoWriters(AzureBlobFileSystem fs, Path testFilePath, boolean expec\n         if (expectException) {\n           GenericTestUtils.assertExceptionContains(ERR_ACQUIRING_LEASE, e);\n         } else {\n-          Assert.fail(\"Unexpected exception \" + e.getMessage());\n+          throw e;\n         }\n       }\n       out.writeInt(1);\n       out.hsync();\n     }\n \n-    Assert.assertTrue(fs.getAbfsStore().areLeasesFreed());\n+    Assert.assertTrue(\"Store leases were not freed\", fs.getAbfsStore().areLeasesFreed());\n   }\n \n   @Test(timeout = TEST_EXECUTION_TIMEOUT)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzOTA5Mg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r560139092", "bodyText": "little architecture question. Would this be better in the Store than the FS? I don't know, and it is higher level than the Rest API, isn't it? Which implies this is the right place.", "author": "steveloughran", "createdAt": "2021-01-19T12:24:22Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -476,6 +476,20 @@ public FileStatus getFileStatus(final Path f) throws IOException {\n     }\n   }\n \n+  /**\n+   * Acquire a lease on an ABFS file for a specified duration. This requires the file to exist.", "originalCommit": "978cedb7b63d6a1b09db291511cc87ae53c7cab0", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\nindex f07efaeae3b..faa1fdc9220 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n\n@@ -476,27 +505,12 @@ public FileStatus getFileStatus(final Path f) throws IOException {\n     }\n   }\n \n-  /**\n-   * Acquire a lease on an ABFS file for a specified duration. This requires the file to exist.\n-   * Writes will not be able to be performed while the lease is held because there is not\n-   * currently a way to provide a previously acquired lease ID to AbfsOutputStream.\n-   *\n-   * If the file is in a single writer directory, the client will automatically acquire, renew,\n-   * and release a lease and this method does not need to be used. The output stream holding the\n-   * lease will be able to write to the file in that case.\n-   *\n-   * @param f file name\n-   * @param duration time lease will be held before expiring\n-   * @return the acquired lease ID\n-   * @throws IOException on any exception while acquiring the lease\n-   */\n   public String acquireLease(final Path f, final int duration) throws IOException {\n     LOG.debug(\"AzureBlobFileSystem.acquireLease path: {}\", f);\n \n     Path qualifiedPath = makeQualified(f);\n \n-    try (DurationInfo ignored = new DurationInfo(LOG, false, \"Acquire lease for %s\",\n-        qualifiedPath)) {\n+    try {\n       return abfsStore.acquireLease(qualifiedPath, duration);\n     } catch(AzureBlobFileSystemException ex) {\n       checkException(f, ex);\n"}}, {"oid": "a176dc742dcae1efc5a3515f5fba53e4198861ae", "url": "https://github.com/apache/hadoop/commit/a176dc742dcae1efc5a3515f5fba53e4198861ae", "message": "HADOOP-16948. Add error messages to test assertions", "committedDate": "2021-03-03T00:00:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzMxNQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r593783315", "bodyText": "Background threads that will renew lease every 67% of lease i.e. 10 seconds for 15 second lease and 40 seconds for 60 second lease will add extra cost to customers", "author": "snehavarma", "createdAt": "2021-03-13T18:17:21Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  static final float LEASE_RENEWAL_PERCENT_OF_DURATION = 0.67f; // Lease renewal percent of duration\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+  private final int duration;\n+  private final int renewalPeriod;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public SelfRenewingLease(AbfsClient client, String path, int duration) throws AzureBlobFileSystemException {", "originalCommit": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDY3ODgxMg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594678812", "bodyText": "Thanks Sneha, I didn't realize the lease renewals would be charged as write ops. It might be a poor experience for a user to have unexpected charges related to this lease configuration.", "author": "billierinaldi", "createdAt": "2021-03-15T20:57:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzMxNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDY5NzQ3Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594697477", "bodyText": "Hey Billie just wanted to add that it might not be charged as write ops but instead come under other ops or metadata ops. Either way it will be extra cost just not as high as write transaction charges.", "author": "snehavarma", "createdAt": "2021-03-15T21:31:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzMxNQ=="}], "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 3ad45719fb3..43de22a0ad0 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,193 +18,124 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import java.io.IOException;\n-import java.net.HttpURLConnection;\n-import java.util.concurrent.CancellationException;\n-import java.util.concurrent.TimeUnit;\n-\n-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n-import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n-import org.apache.hadoop.io.retry.RetryPolicies;\n-import org.apache.hadoop.io.retry.RetryPolicy;\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n-import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n-import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n-import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n \n /**\n- * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n- * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n- * that don't have the lease.\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n  *\n- * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n- * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ * Call free() to release the Lease.\n  *\n- * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n- * won't be renewed.\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n  */\n-public final class SelfRenewingLease {\n-  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+public class SelfRenewingLease {\n \n-  static final float LEASE_RENEWAL_PERCENT_OF_DURATION = 0.67f; // Lease renewal percent of duration\n+  private final AbfsClient client;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n \n-  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n-  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  public static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n \n-  private final AbfsClient client;\n-  private final String path;\n-  private final int duration;\n-  private final int renewalPeriod;\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n \n-  // Lease status variables\n-  private volatile boolean leaseFreed;\n-  private volatile String leaseID = null;\n-  private volatile Throwable exception = null;\n-  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n \n-  public static class LeaseException extends AzureBlobFileSystemException {\n-    public LeaseException(Throwable t) {\n-      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n-    }\n+  // Time to wait to retry getting the lease in milliseconds\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+  static final int LEASE_MAX_RETRIES = 5;\n \n-    public LeaseException(String s) {\n-      super(s);\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Exception innerException) {\n+      super(ERR_ACQUIRING_LEASE, innerException);\n     }\n   }\n \n-  public SelfRenewingLease(AbfsClient client, String path, int duration) throws AzureBlobFileSystemException {\n+  public SelfRenewingLease(AbfsClient client, Path path) throws AzureBlobFileSystemException {\n+\n     this.leaseFreed = false;\n     this.client = client;\n     this.path = path;\n-    this.duration = duration;\n-    this.renewalPeriod = (int) (LEASE_RENEWAL_PERCENT_OF_DURATION * this.duration);\n-\n-    if (client.getNumLeaseThreads() < 1) {\n-      throw new LeaseException(ERR_NO_LEASE_THREADS);\n-    }\n \n     // Try to get the lease a specified number of times, else throw an error\n-    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n-        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n-    acquireLease(retryPolicy, 0, 0);\n+    int numRetries = 0;\n+    while (leaseID == null && numRetries < LEASE_MAX_RETRIES) {\n+      numRetries++;\n+      try {\n+        LOG.debug(\"lease path: {}\", path);\n+        final AbfsRestOperation op =\n+            client.acquireLease(getRelativePath(path),\n+                LEASE_TIMEOUT);\n \n-    while (leaseID == null && exception == null) {\n-    }\n-    if (exception != null) {\n-      LOG.error(\"Failed to acquire lease on {}\", path);\n-      throw new LeaseException(exception);\n-    }\n-\n-    if (duration != INFINITE_LEASE_DURATION) {\n-      renewLease(renewalPeriod);\n-    }\n-\n-    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n-  }\n-\n-  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n-      throws LeaseException {\n-    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n-    if (future != null && !future.isDone()) {\n-      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n-    }\n-    future = client.schedule(() -> client.acquireLease(path, duration),\n-        delay, TimeUnit.SECONDS);\n-    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n-      @Override\n-      public void onSuccess(@Nullable AbfsRestOperation op) {\n         leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n-        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+      } catch (IOException e) {\n+        if (numRetries < LEASE_MAX_RETRIES) {\n+          LOG.info(\"Caught exception when trying to acquire lease on blob {}, retrying: {}\", path,\n+              e.getMessage());\n+          LOG.debug(\"Exception acquiring lease\", e);\n+        } else {\n+          throw new LeaseException(e);\n+        }\n       }\n-\n-      @Override\n-      public void onFailure(Throwable throwable) {\n+      if (leaseID == null) {\n         try {\n-          if (RetryPolicy.RetryAction.RetryDecision.RETRY\n-              == retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n-            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);\n-            acquireLease(retryPolicy, numRetries + 1, LEASE_ACQUIRE_RETRY_INTERVAL);\n-          } else {\n-            exception = throwable;\n-          }\n-        } catch (Exception e) {\n-          exception = throwable;\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n+        } catch (InterruptedException e) {\n+\n+          // Restore the interrupted status\n+          Thread.currentThread().interrupt();\n         }\n       }\n-    });\n-  }\n-\n-  private void renewLease(long delay) {\n-    LOG.debug(\"Attempting to renew lease on {}, renew lease id {}, delay {}\", path, leaseID, delay);\n-    if (future != null && !future.isDone()) {\n-      LOG.warn(\"Unexpected new lease renewal operation occurred while operation already existed. \"\n-          + \"Not initiating new renewal\");\n-      return;\n     }\n-    future = client.schedule(() -> client.renewLease(path, leaseID), delay,\n-            TimeUnit.SECONDS);\n-    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n-      @Override\n-      public void onSuccess(@Nullable AbfsRestOperation op) {\n-        LOG.debug(\"Renewed lease {} on {}\", leaseID, path);\n-        renewLease(delay);\n-      }\n+    renewer = new Thread(new Renewer());\n \n-      @Override\n-      public void onFailure(Throwable throwable) {\n-        if (throwable instanceof CancellationException) {\n-          LOG.info(\"Stopping renewal due to cancellation\");\n-          free();\n-          return;\n-        } else if (throwable instanceof AbfsRestOperationException) {\n-          AbfsRestOperationException opEx = ((AbfsRestOperationException) throwable);\n-          if (opEx.getStatusCode() < HttpURLConnection.HTTP_INTERNAL_ERROR) {\n-            // error in 400 range indicates a type of error that should not result in a retry\n-            // such as the lease being broken or a different lease being present\n-            LOG.info(\"Stopping renewal due to {}: {}, {}\", opEx.getStatusCode(),\n-                opEx.getErrorCode(), opEx.getErrorMessage());\n-            free();\n-            return;\n-          }\n-        }\n-\n-        LOG.debug(\"Failed to renew lease on {}, renew lease id {}, retrying: {}\", path, leaseID,\n-            throwable);\n-        renewLease(0);\n-      }\n-    });\n+    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n+    renewer.setDaemon(true);\n+    renewer.setName(\"AzureBFSLeaseRenewer-\" + threadNumber.getAndIncrement());\n+    renewer.start();\n+    LOG.debug(\"Acquired lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n   }\n \n   /**\n-   * Cancel renewal and free the lease. If an exception occurs, this method assumes the lease\n-   * will expire after the lease duration.\n+   * Free the lease and stop the keep-alive thread.\n    */\n   public void free() {\n-    if (leaseFreed) {\n-      return;\n-    }\n     try {\n-      LOG.debug(\"Freeing lease: path {}, lease id {}\", path, leaseID);\n-      if (future != null && !future.isDone()) {\n-        future.cancel(true);\n-      }\n-      client.releaseLease(path, leaseID);\n+      LOG.debug(\"lease path: {}, release lease id: {}\", path, leaseID);\n+      client.releaseLease(getRelativePath(path), leaseID);\n     } catch (IOException e) {\n       LOG.info(\"Exception when trying to release lease {} on {}. Lease will be left to expire: {}\",\n           leaseID, path, e.getMessage());\n+      LOG.debug(\"Exception releasing lease\", e);\n     } finally {\n+\n       // Even if releasing the lease fails (e.g. because the file was deleted),\n-      // make sure to record that we freed the lease\n+      // make sure to record that we freed the lease, to terminate the\n+      // keep-alive thread.\n       leaseFreed = true;\n-      LOG.debug(\"Freed lease {} on {}\", leaseID, path);\n+      LOG.debug(\"Freed lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzcwMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r593783701", "bodyText": "Please check if infinite lease is sufficient for your use case.", "author": "snehavarma", "createdAt": "2021-03-13T18:20:14Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+", "originalCommit": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcwNTIzMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594705231", "bodyText": "I think infinite leases are sufficient for my use case. I would be okay with removing lease renewal from this patch and leaving finite leases for future work in HADOOP-17590, but I am not sure what the best way to handle the configuration properties would be. It sounds like you are proposing a boolean fs.azure.write.enforcelease that would control whether lease ops are applied for all files, and all files would have the same finite lease duration, is that right? I am wondering how to make that work together with the fs.azure.singlewriter.directories property in this patch. Would we want to specify a special set of directories that uses infinite leases? Or do we need to figure out a way to specify lease duration for each directory that supports lease ops?", "author": "billierinaldi", "createdAt": "2021-03-15T21:45:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcwNzI4Ng==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594707286", "bodyText": "Yes, We should specify a special set of directories that uses infinite leases. By default we would keep 60 seconds as lease duration for all files.\n\n\nOr do we need to figure out a way to specify lease duration for each directory that supports lease ops?\nThis will not scale.", "author": "snehavarma", "createdAt": "2021-03-15T21:49:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcxMjkxMQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594712911", "bodyText": "So, does the property name fs.azure.singlewriter.directories still make sense, or should it be changed to something else such as fs.azure.infinite-lease-directories?", "author": "billierinaldi", "createdAt": "2021-03-15T22:00:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzcwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcxNDY2MA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594714660", "bodyText": "Agree,   fs.azure.singlewriter.directories would confuse the users. We can name it something else.", "author": "snehavarma", "createdAt": "2021-03-15T22:03:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4MzcwMQ=="}], "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 3ad45719fb3..43de22a0ad0 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,193 +18,124 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import java.io.IOException;\n-import java.net.HttpURLConnection;\n-import java.util.concurrent.CancellationException;\n-import java.util.concurrent.TimeUnit;\n-\n-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n-import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n-import org.apache.hadoop.io.retry.RetryPolicies;\n-import org.apache.hadoop.io.retry.RetryPolicy;\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n-import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n-import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n-import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n \n /**\n- * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n- * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n- * that don't have the lease.\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n  *\n- * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n- * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ * Call free() to release the Lease.\n  *\n- * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n- * won't be renewed.\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n  */\n-public final class SelfRenewingLease {\n-  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+public class SelfRenewingLease {\n \n-  static final float LEASE_RENEWAL_PERCENT_OF_DURATION = 0.67f; // Lease renewal percent of duration\n+  private final AbfsClient client;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n \n-  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n-  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  public static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n \n-  private final AbfsClient client;\n-  private final String path;\n-  private final int duration;\n-  private final int renewalPeriod;\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n \n-  // Lease status variables\n-  private volatile boolean leaseFreed;\n-  private volatile String leaseID = null;\n-  private volatile Throwable exception = null;\n-  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n \n-  public static class LeaseException extends AzureBlobFileSystemException {\n-    public LeaseException(Throwable t) {\n-      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n-    }\n+  // Time to wait to retry getting the lease in milliseconds\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+  static final int LEASE_MAX_RETRIES = 5;\n \n-    public LeaseException(String s) {\n-      super(s);\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Exception innerException) {\n+      super(ERR_ACQUIRING_LEASE, innerException);\n     }\n   }\n \n-  public SelfRenewingLease(AbfsClient client, String path, int duration) throws AzureBlobFileSystemException {\n+  public SelfRenewingLease(AbfsClient client, Path path) throws AzureBlobFileSystemException {\n+\n     this.leaseFreed = false;\n     this.client = client;\n     this.path = path;\n-    this.duration = duration;\n-    this.renewalPeriod = (int) (LEASE_RENEWAL_PERCENT_OF_DURATION * this.duration);\n-\n-    if (client.getNumLeaseThreads() < 1) {\n-      throw new LeaseException(ERR_NO_LEASE_THREADS);\n-    }\n \n     // Try to get the lease a specified number of times, else throw an error\n-    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n-        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n-    acquireLease(retryPolicy, 0, 0);\n+    int numRetries = 0;\n+    while (leaseID == null && numRetries < LEASE_MAX_RETRIES) {\n+      numRetries++;\n+      try {\n+        LOG.debug(\"lease path: {}\", path);\n+        final AbfsRestOperation op =\n+            client.acquireLease(getRelativePath(path),\n+                LEASE_TIMEOUT);\n \n-    while (leaseID == null && exception == null) {\n-    }\n-    if (exception != null) {\n-      LOG.error(\"Failed to acquire lease on {}\", path);\n-      throw new LeaseException(exception);\n-    }\n-\n-    if (duration != INFINITE_LEASE_DURATION) {\n-      renewLease(renewalPeriod);\n-    }\n-\n-    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n-  }\n-\n-  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n-      throws LeaseException {\n-    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n-    if (future != null && !future.isDone()) {\n-      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n-    }\n-    future = client.schedule(() -> client.acquireLease(path, duration),\n-        delay, TimeUnit.SECONDS);\n-    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n-      @Override\n-      public void onSuccess(@Nullable AbfsRestOperation op) {\n         leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n-        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+      } catch (IOException e) {\n+        if (numRetries < LEASE_MAX_RETRIES) {\n+          LOG.info(\"Caught exception when trying to acquire lease on blob {}, retrying: {}\", path,\n+              e.getMessage());\n+          LOG.debug(\"Exception acquiring lease\", e);\n+        } else {\n+          throw new LeaseException(e);\n+        }\n       }\n-\n-      @Override\n-      public void onFailure(Throwable throwable) {\n+      if (leaseID == null) {\n         try {\n-          if (RetryPolicy.RetryAction.RetryDecision.RETRY\n-              == retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n-            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);\n-            acquireLease(retryPolicy, numRetries + 1, LEASE_ACQUIRE_RETRY_INTERVAL);\n-          } else {\n-            exception = throwable;\n-          }\n-        } catch (Exception e) {\n-          exception = throwable;\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n+        } catch (InterruptedException e) {\n+\n+          // Restore the interrupted status\n+          Thread.currentThread().interrupt();\n         }\n       }\n-    });\n-  }\n-\n-  private void renewLease(long delay) {\n-    LOG.debug(\"Attempting to renew lease on {}, renew lease id {}, delay {}\", path, leaseID, delay);\n-    if (future != null && !future.isDone()) {\n-      LOG.warn(\"Unexpected new lease renewal operation occurred while operation already existed. \"\n-          + \"Not initiating new renewal\");\n-      return;\n     }\n-    future = client.schedule(() -> client.renewLease(path, leaseID), delay,\n-            TimeUnit.SECONDS);\n-    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n-      @Override\n-      public void onSuccess(@Nullable AbfsRestOperation op) {\n-        LOG.debug(\"Renewed lease {} on {}\", leaseID, path);\n-        renewLease(delay);\n-      }\n+    renewer = new Thread(new Renewer());\n \n-      @Override\n-      public void onFailure(Throwable throwable) {\n-        if (throwable instanceof CancellationException) {\n-          LOG.info(\"Stopping renewal due to cancellation\");\n-          free();\n-          return;\n-        } else if (throwable instanceof AbfsRestOperationException) {\n-          AbfsRestOperationException opEx = ((AbfsRestOperationException) throwable);\n-          if (opEx.getStatusCode() < HttpURLConnection.HTTP_INTERNAL_ERROR) {\n-            // error in 400 range indicates a type of error that should not result in a retry\n-            // such as the lease being broken or a different lease being present\n-            LOG.info(\"Stopping renewal due to {}: {}, {}\", opEx.getStatusCode(),\n-                opEx.getErrorCode(), opEx.getErrorMessage());\n-            free();\n-            return;\n-          }\n-        }\n-\n-        LOG.debug(\"Failed to renew lease on {}, renew lease id {}, retrying: {}\", path, leaseID,\n-            throwable);\n-        renewLease(0);\n-      }\n-    });\n+    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n+    renewer.setDaemon(true);\n+    renewer.setName(\"AzureBFSLeaseRenewer-\" + threadNumber.getAndIncrement());\n+    renewer.start();\n+    LOG.debug(\"Acquired lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n   }\n \n   /**\n-   * Cancel renewal and free the lease. If an exception occurs, this method assumes the lease\n-   * will expire after the lease duration.\n+   * Free the lease and stop the keep-alive thread.\n    */\n   public void free() {\n-    if (leaseFreed) {\n-      return;\n-    }\n     try {\n-      LOG.debug(\"Freeing lease: path {}, lease id {}\", path, leaseID);\n-      if (future != null && !future.isDone()) {\n-        future.cancel(true);\n-      }\n-      client.releaseLease(path, leaseID);\n+      LOG.debug(\"lease path: {}, release lease id: {}\", path, leaseID);\n+      client.releaseLease(getRelativePath(path), leaseID);\n     } catch (IOException e) {\n       LOG.info(\"Exception when trying to release lease {} on {}. Lease will be left to expire: {}\",\n           leaseID, path, e.getMessage());\n+      LOG.debug(\"Exception releasing lease\", e);\n     } finally {\n+\n       // Even if releasing the lease fails (e.g. because the file was deleted),\n-      // make sure to record that we freed the lease\n+      // make sure to record that we freed the lease, to terminate the\n+      // keep-alive thread.\n       leaseFreed = true;\n-      LOG.debug(\"Freed lease {} on {}\", leaseID, path);\n+      LOG.debug(\"Freed lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5Mzc4Mzc5Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r593783797", "bodyText": "Error handling for cases when append may take more time than lease expiry needs to be added incase there is a finite lease.", "author": "snehavarma", "createdAt": "2021-03-13T18:21:36Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.util.concurrent.CancellationException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n+ * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n+ * that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n+ * won't be renewed.\n+ */\n+public final class SelfRenewingLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+\n+  static final float LEASE_RENEWAL_PERCENT_OF_DURATION = 0.67f; // Lease renewal percent of duration\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+  private final int duration;\n+  private final int renewalPeriod;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public SelfRenewingLease(AbfsClient client, String path, int duration) throws AzureBlobFileSystemException {\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+    this.duration = duration;\n+    this.renewalPeriod = (int) (LEASE_RENEWAL_PERCENT_OF_DURATION * this.duration);\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n+\n+    while (leaseID == null && exception == null) {\n+    }\n+    if (exception != null) {\n+      LOG.error(\"Failed to acquire lease on {}\", path);\n+      throw new LeaseException(exception);\n+    }\n+\n+    if (duration != INFINITE_LEASE_DURATION) {\n+      renewLease(renewalPeriod);\n+    }\n+\n+    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+  }\n+\n+  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n+      throws LeaseException {\n+    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n+    if (future != null && !future.isDone()) {\n+      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n+    }\n+    future = client.schedule(() -> client.acquireLease(path, duration),\n+        delay, TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n+        leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+      }\n+\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        try {\n+          if (RetryPolicy.RetryAction.RetryDecision.RETRY\n+              == retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n+            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);\n+            acquireLease(retryPolicy, numRetries + 1, LEASE_ACQUIRE_RETRY_INTERVAL);\n+          } else {\n+            exception = throwable;\n+          }\n+        } catch (Exception e) {\n+          exception = throwable;\n+        }\n+      }\n+    });\n+  }\n+\n+  private void renewLease(long delay) {\n+    LOG.debug(\"Attempting to renew lease on {}, renew lease id {}, delay {}\", path, leaseID, delay);", "originalCommit": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\nindex 3ad45719fb3..43de22a0ad0 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/SelfRenewingLease.java\n\n@@ -18,193 +18,124 @@\n \n package org.apache.hadoop.fs.azurebfs.services;\n \n-import java.io.IOException;\n-import java.net.HttpURLConnection;\n-import java.util.concurrent.CancellationException;\n-import java.util.concurrent.TimeUnit;\n-\n-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n-import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import com.google.common.base.Preconditions;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n-import org.apache.hadoop.io.retry.RetryPolicies;\n-import org.apache.hadoop.io.retry.RetryPolicy;\n+import java.io.IOException;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n-import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n-import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n-import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n \n /**\n- * An Azure blob lease that automatically renews itself indefinitely by scheduling lease\n- * operations through the ABFS client. Use it to prevent writes to the blob by other processes\n- * that don't have the lease.\n+ * An Azure blob lease that automatically renews itself indefinitely\n+ * using a background thread. Use it to synchronize distributed processes,\n+ * or to prevent writes to the blob by other processes that don't\n+ * have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is\n+ * acquired.\n  *\n- * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n- * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ * Call free() to release the Lease.\n  *\n- * Call free() to release the Lease. If the holder process dies, the lease will time out since it\n- * won't be renewed.\n+ * You can use this Lease like a distributed lock. If the holder process\n+ * dies, the lease will time out since it won't be renewed.\n+ *\n+ * See also {@link org.apache.hadoop.fs.azure.SelfRenewingLease}.\n  */\n-public final class SelfRenewingLease {\n-  private static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n+public class SelfRenewingLease {\n \n-  static final float LEASE_RENEWAL_PERCENT_OF_DURATION = 0.67f; // Lease renewal percent of duration\n+  private final AbfsClient client;\n+  private final Path path;\n+  private Thread renewer;\n+  private volatile boolean leaseFreed;\n+  private String leaseID = null;\n+  private static final int LEASE_TIMEOUT = 60;  // Lease timeout in seconds\n \n-  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n-  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+  // Time to wait to renew lease in milliseconds\n+  public static final int LEASE_RENEWAL_PERIOD = 40000;\n+  public static final Logger LOG = LoggerFactory.getLogger(SelfRenewingLease.class);\n \n-  private final AbfsClient client;\n-  private final String path;\n-  private final int duration;\n-  private final int renewalPeriod;\n+  // Used to allocate thread serial numbers in thread name\n+  private static AtomicInteger threadNumber = new AtomicInteger(0);\n \n-  // Lease status variables\n-  private volatile boolean leaseFreed;\n-  private volatile String leaseID = null;\n-  private volatile Throwable exception = null;\n-  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n \n-  public static class LeaseException extends AzureBlobFileSystemException {\n-    public LeaseException(Throwable t) {\n-      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n-    }\n+  // Time to wait to retry getting the lease in milliseconds\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 2000;\n+  static final int LEASE_MAX_RETRIES = 5;\n \n-    public LeaseException(String s) {\n-      super(s);\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Exception innerException) {\n+      super(ERR_ACQUIRING_LEASE, innerException);\n     }\n   }\n \n-  public SelfRenewingLease(AbfsClient client, String path, int duration) throws AzureBlobFileSystemException {\n+  public SelfRenewingLease(AbfsClient client, Path path) throws AzureBlobFileSystemException {\n+\n     this.leaseFreed = false;\n     this.client = client;\n     this.path = path;\n-    this.duration = duration;\n-    this.renewalPeriod = (int) (LEASE_RENEWAL_PERCENT_OF_DURATION * this.duration);\n-\n-    if (client.getNumLeaseThreads() < 1) {\n-      throw new LeaseException(ERR_NO_LEASE_THREADS);\n-    }\n \n     // Try to get the lease a specified number of times, else throw an error\n-    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n-        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n-    acquireLease(retryPolicy, 0, 0);\n+    int numRetries = 0;\n+    while (leaseID == null && numRetries < LEASE_MAX_RETRIES) {\n+      numRetries++;\n+      try {\n+        LOG.debug(\"lease path: {}\", path);\n+        final AbfsRestOperation op =\n+            client.acquireLease(getRelativePath(path),\n+                LEASE_TIMEOUT);\n \n-    while (leaseID == null && exception == null) {\n-    }\n-    if (exception != null) {\n-      LOG.error(\"Failed to acquire lease on {}\", path);\n-      throw new LeaseException(exception);\n-    }\n-\n-    if (duration != INFINITE_LEASE_DURATION) {\n-      renewLease(renewalPeriod);\n-    }\n-\n-    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n-  }\n-\n-  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n-      throws LeaseException {\n-    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n-    if (future != null && !future.isDone()) {\n-      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n-    }\n-    future = client.schedule(() -> client.acquireLease(path, duration),\n-        delay, TimeUnit.SECONDS);\n-    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n-      @Override\n-      public void onSuccess(@Nullable AbfsRestOperation op) {\n         leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n-        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+      } catch (IOException e) {\n+        if (numRetries < LEASE_MAX_RETRIES) {\n+          LOG.info(\"Caught exception when trying to acquire lease on blob {}, retrying: {}\", path,\n+              e.getMessage());\n+          LOG.debug(\"Exception acquiring lease\", e);\n+        } else {\n+          throw new LeaseException(e);\n+        }\n       }\n-\n-      @Override\n-      public void onFailure(Throwable throwable) {\n+      if (leaseID == null) {\n         try {\n-          if (RetryPolicy.RetryAction.RetryDecision.RETRY\n-              == retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n-            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);\n-            acquireLease(retryPolicy, numRetries + 1, LEASE_ACQUIRE_RETRY_INTERVAL);\n-          } else {\n-            exception = throwable;\n-          }\n-        } catch (Exception e) {\n-          exception = throwable;\n+          Thread.sleep(LEASE_ACQUIRE_RETRY_INTERVAL);\n+        } catch (InterruptedException e) {\n+\n+          // Restore the interrupted status\n+          Thread.currentThread().interrupt();\n         }\n       }\n-    });\n-  }\n-\n-  private void renewLease(long delay) {\n-    LOG.debug(\"Attempting to renew lease on {}, renew lease id {}, delay {}\", path, leaseID, delay);\n-    if (future != null && !future.isDone()) {\n-      LOG.warn(\"Unexpected new lease renewal operation occurred while operation already existed. \"\n-          + \"Not initiating new renewal\");\n-      return;\n     }\n-    future = client.schedule(() -> client.renewLease(path, leaseID), delay,\n-            TimeUnit.SECONDS);\n-    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n-      @Override\n-      public void onSuccess(@Nullable AbfsRestOperation op) {\n-        LOG.debug(\"Renewed lease {} on {}\", leaseID, path);\n-        renewLease(delay);\n-      }\n+    renewer = new Thread(new Renewer());\n \n-      @Override\n-      public void onFailure(Throwable throwable) {\n-        if (throwable instanceof CancellationException) {\n-          LOG.info(\"Stopping renewal due to cancellation\");\n-          free();\n-          return;\n-        } else if (throwable instanceof AbfsRestOperationException) {\n-          AbfsRestOperationException opEx = ((AbfsRestOperationException) throwable);\n-          if (opEx.getStatusCode() < HttpURLConnection.HTTP_INTERNAL_ERROR) {\n-            // error in 400 range indicates a type of error that should not result in a retry\n-            // such as the lease being broken or a different lease being present\n-            LOG.info(\"Stopping renewal due to {}: {}, {}\", opEx.getStatusCode(),\n-                opEx.getErrorCode(), opEx.getErrorMessage());\n-            free();\n-            return;\n-          }\n-        }\n-\n-        LOG.debug(\"Failed to renew lease on {}, renew lease id {}, retrying: {}\", path, leaseID,\n-            throwable);\n-        renewLease(0);\n-      }\n-    });\n+    // A Renewer running should not keep JVM from exiting, so make it a daemon.\n+    renewer.setDaemon(true);\n+    renewer.setName(\"AzureBFSLeaseRenewer-\" + threadNumber.getAndIncrement());\n+    renewer.start();\n+    LOG.debug(\"Acquired lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n   }\n \n   /**\n-   * Cancel renewal and free the lease. If an exception occurs, this method assumes the lease\n-   * will expire after the lease duration.\n+   * Free the lease and stop the keep-alive thread.\n    */\n   public void free() {\n-    if (leaseFreed) {\n-      return;\n-    }\n     try {\n-      LOG.debug(\"Freeing lease: path {}, lease id {}\", path, leaseID);\n-      if (future != null && !future.isDone()) {\n-        future.cancel(true);\n-      }\n-      client.releaseLease(path, leaseID);\n+      LOG.debug(\"lease path: {}, release lease id: {}\", path, leaseID);\n+      client.releaseLease(getRelativePath(path), leaseID);\n     } catch (IOException e) {\n       LOG.info(\"Exception when trying to release lease {} on {}. Lease will be left to expire: {}\",\n           leaseID, path, e.getMessage());\n+      LOG.debug(\"Exception releasing lease\", e);\n     } finally {\n+\n       // Even if releasing the lease fails (e.g. because the file was deleted),\n-      // make sure to record that we freed the lease\n+      // make sure to record that we freed the lease, to terminate the\n+      // keep-alive thread.\n       leaseFreed = true;\n-      LOG.debug(\"Freed lease {} on {}\", leaseID, path);\n+      LOG.debug(\"Freed lease {} on {} managed by thread {}\", leaseID, path, renewer.getName());\n     }\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcxMDg5MQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r594710891", "bodyText": "this code should not be required", "author": "snehavarma", "createdAt": "2021-03-15T21:56:17Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -702,15 +735,72 @@ public OutputStream openFileForWrite(final Path path, final FileSystem.Statistic\n         isAppendBlob = true;\n       }\n \n+      SelfRenewingLease lease = maybeCreateLease(relativePath);\n+\n       return new AbfsOutputStream(\n           client,\n           statistics,\n           relativePath,\n           offset,\n-          populateAbfsOutputStreamContext(isAppendBlob));\n+          populateAbfsOutputStreamContext(isAppendBlob, lease));\n     }\n   }\n \n+  /**\n+   * Acquire a lease on an ABFS file for a specified duration. This requires the file to exist.\n+   *\n+   * @param path file name\n+   * @param duration time lease will be held before expiring\n+   * @return the acquired lease ID\n+   * @throws AzureBlobFileSystemException on any exception while acquiring the lease\n+   */\n+  public String acquireLease(final Path path, final int duration) throws AzureBlobFileSystemException {\n+    LOG.debug(\"lease path: {}\", path);\n+\n+    final AbfsRestOperation op =\n+        client.acquireLease(getRelativePath(path), duration);\n+\n+    return op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+  }\n+\n+  /**", "originalCommit": "e4c7a815ec2f33c9561e2a8446499b46e7004b9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTI1NTY5Mw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r595255693", "bodyText": "I'm not sure what you mean. Do you mean that we shouldn't have an acquireLease method in the store because leases will be acquired automatically?", "author": "billierinaldi", "createdAt": "2021-03-16T15:01:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcxMDg5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTMyNzU2Ng==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r595327566", "bodyText": "Yes if the file is being created then infinite lease can be automatically taken, for other cases yes you may need the acquire lease code till we integrate bundling of lease with append.\nRenewLease code might be something you can completely get rid of", "author": "snehavarma", "createdAt": "2021-03-16T16:18:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NDcxMDg5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex 7e4ddfcda65..59304efda89 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n\n@@ -735,25 +732,16 @@ public OutputStream openFileForWrite(final Path path, final FileSystem.Statistic\n         isAppendBlob = true;\n       }\n \n-      SelfRenewingLease lease = maybeCreateLease(relativePath);\n-\n       return new AbfsOutputStream(\n           client,\n           statistics,\n           relativePath,\n           offset,\n-          populateAbfsOutputStreamContext(isAppendBlob, lease));\n+          leaseRefs,\n+          populateAbfsOutputStreamContext(isAppendBlob, enableSingleWriter));\n     }\n   }\n \n-  /**\n-   * Acquire a lease on an ABFS file for a specified duration. This requires the file to exist.\n-   *\n-   * @param path file name\n-   * @param duration time lease will be held before expiring\n-   * @return the acquired lease ID\n-   * @throws AzureBlobFileSystemException on any exception while acquiring the lease\n-   */\n   public String acquireLease(final Path path, final int duration) throws AzureBlobFileSystemException {\n     LOG.debug(\"lease path: {}\", path);\n \n"}}, {"oid": "5a2ef896128b2aecf5ff2c9b83281d1d517628db", "url": "https://github.com/apache/hadoop/commit/5a2ef896128b2aecf5ff2c9b83281d1d517628db", "message": "HADOOP-16948. Support single writer dirs.", "committedDate": "2021-03-16T21:48:10Z", "type": "commit"}, {"oid": "86246dc3243ff290766d1a760d128e0194f26a13", "url": "https://github.com/apache/hadoop/commit/86246dc3243ff290766d1a760d128e0194f26a13", "message": "HADOOP-16948. Fix findbugs and checkstyle problems.", "committedDate": "2021-03-16T21:48:10Z", "type": "commit"}, {"oid": "fe3dd135a060400cb761799f8fd1d189deadcd7e", "url": "https://github.com/apache/hadoop/commit/fe3dd135a060400cb761799f8fd1d189deadcd7e", "message": "HADOOP-16948. Fix remaining checkstyle problems.", "committedDate": "2021-03-16T21:48:10Z", "type": "commit"}, {"oid": "1cd1a927f0b63b8c5153a4d8c8c30c10d7e4bb79", "url": "https://github.com/apache/hadoop/commit/1cd1a927f0b63b8c5153a4d8c8c30c10d7e4bb79", "message": "HADOOP-16948. Add DurationInfo, retry policy for acquiring lease, and javadocs", "committedDate": "2021-03-16T21:48:10Z", "type": "commit"}, {"oid": "eeb4ba0f9bc6986d84ea176d8f02ef73cc2fb0e3", "url": "https://github.com/apache/hadoop/commit/eeb4ba0f9bc6986d84ea176d8f02ef73cc2fb0e3", "message": "HADOOP-16948. Convert ABFS client to use an executor for lease ops", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "8e91f6165f8bf599a72bc4e826ef2c19474b1b60", "url": "https://github.com/apache/hadoop/commit/8e91f6165f8bf599a72bc4e826ef2c19474b1b60", "message": "HADOOP-16948. Fix ABFS lease test for non-HNS", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "8eceabb9052daaac60a4fac203ee85073b7ac118", "url": "https://github.com/apache/hadoop/commit/8eceabb9052daaac60a4fac203ee85073b7ac118", "message": "HADOOP-16948. Fix checkstyle and javadoc", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "42f68c2a835ed74fd788e8b87ed19231ce0eded1", "url": "https://github.com/apache/hadoop/commit/42f68c2a835ed74fd788e8b87ed19231ce0eded1", "message": "HADOOP-16948. Address review comments", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "9f3d6897f7cd1cc43061e144abe73c8da18de93d", "url": "https://github.com/apache/hadoop/commit/9f3d6897f7cd1cc43061e144abe73c8da18de93d", "message": "HADOOP-16948. Use daemon threads for ABFS lease ops", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "d67882f80615f8467716a3ed37c10e38249f2afa", "url": "https://github.com/apache/hadoop/commit/d67882f80615f8467716a3ed37c10e38249f2afa", "message": "HADOOP-16948. Make lease duration configurable", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "f00c1459e99b6cdd88ffc55af66fdb44267837bc", "url": "https://github.com/apache/hadoop/commit/f00c1459e99b6cdd88ffc55af66fdb44267837bc", "message": "HADOOP-16948. Add error messages to test assertions", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "f00178355c66810ce7664e21a366cd24fc4c1965", "url": "https://github.com/apache/hadoop/commit/f00178355c66810ce7664e21a366cd24fc4c1965", "message": "HADOOP-16948. Remove extra isSingleWriterKey call", "committedDate": "2021-03-16T21:48:11Z", "type": "commit"}, {"oid": "92e7343b26eb67cf7f2a6ebc885fdd6eb9c9b551", "url": "https://github.com/apache/hadoop/commit/92e7343b26eb67cf7f2a6ebc885fdd6eb9c9b551", "message": "HADOOP-16948. Use only infinite lease duration due to cost of renewal ops", "committedDate": "2021-03-16T21:48:12Z", "type": "commit"}, {"oid": "eca41b4d4ad9aab9ea5caf0df348ddaa824797bc", "url": "https://github.com/apache/hadoop/commit/eca41b4d4ad9aab9ea5caf0df348ddaa824797bc", "message": "HADOOP-16948. Remove acquire/renew/release lease methods", "committedDate": "2021-03-16T21:48:12Z", "type": "commit"}, {"oid": "822615efbf93f3c4056ae62284c631f4bc46554c", "url": "https://github.com/apache/hadoop/commit/822615efbf93f3c4056ae62284c631f4bc46554c", "message": "HADOOP-16948. Rename single writer dirs to infinite lease dirs", "committedDate": "2021-03-16T21:48:12Z", "type": "commit"}, {"oid": "822615efbf93f3c4056ae62284c631f4bc46554c", "url": "https://github.com/apache/hadoop/commit/822615efbf93f3c4056ae62284c631f4bc46554c", "message": "HADOOP-16948. Rename single writer dirs to infinite lease dirs", "committedDate": "2021-03-16T21:48:12Z", "type": "forcePushed"}, {"oid": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "url": "https://github.com/apache/hadoop/commit/9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "message": "HADOOP-16948. Fix checkstyle", "committedDate": "2021-03-17T04:44:31Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTcyNTYwNA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r595725604", "bodyText": "Do we need these? i.e. Lease threads", "author": "snehavarma", "createdAt": "2021-03-17T05:38:27Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "diffHunk": "@@ -208,6 +209,15 @@\n       DefaultValue = DEFAULT_FS_AZURE_APPEND_BLOB_DIRECTORIES)\n   private String azureAppendBlobDirs;\n \n+  @StringConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_INFINITE_LEASE_KEY,\n+      DefaultValue = DEFAULT_FS_AZURE_INFINITE_LEASE_DIRECTORIES)\n+  private String azureInfiniteLeaseDirs;\n+\n+  @IntegerConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_LEASE_THREADS,", "originalCommit": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NjIwMjU5MA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r596202590", "bodyText": "I think it will still be useful to issue the acquire and release operations in a thread pool for now. Possibly this could be removed if all acquire and release operations are moved into create and flush-with-close in the future.", "author": "billierinaldi", "createdAt": "2021-03-17T16:47:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTcyNTYwNA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTczNDE4MA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r595734180", "bodyText": "Is the feature for both namespace and flatnamespace enabled accounts?", "author": "snehavarma", "createdAt": "2021-03-17T06:03:35Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AbfsConfiguration.java", "diffHunk": "@@ -208,6 +209,15 @@\n       DefaultValue = DEFAULT_FS_AZURE_APPEND_BLOB_DIRECTORIES)\n   private String azureAppendBlobDirs;\n \n+  @StringConfigurationValidatorAnnotation(ConfigurationKey = FS_AZURE_INFINITE_LEASE_KEY,", "originalCommit": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NjIwMzc4NQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r596203785", "bodyText": "I have run the unit test with HNS and flat namespace storage accounts, so I think it will work. I have not done extensive testing with HNS disabled, however.", "author": "billierinaldi", "createdAt": "2021-03-17T16:48:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5NTczNDE4MA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODMyMDc0MA==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r598320740", "bodyText": "This looks a CPU-heavy loop. I know it makes for a more responsive app, but it's a busy wait. Any way to replace with some concurrency class?", "author": "steveloughran", "createdAt": "2021-03-21T18:44:54Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * AbfsLease manages an Azure blob lease. It acquires an infinite lease on instantiation and\n+ * releases the lease when free() is called. Use it to prevent writes to the blob by other\n+ * processes that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, AzureBlobFileSystem breakLease\n+ * will need to be called before another client will be able to write to the file.\n+ */\n+public final class AbfsLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(AbfsLease.class);\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemException {\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n+\n+    while (leaseID == null && exception == null) {", "originalCommit": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODc2NDIxMg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r598764212", "bodyText": "Good point. We will have the Future at that point, so we could wait for it to complete.", "author": "billierinaldi", "createdAt": "2021-03-22T14:27:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODMyMDc0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODc2Nzg2Ng==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r598767866", "bodyText": "I pushed a new change to address this. I am also looking into figuring out if I can mock an acquire lease failure to test this out a bit better.", "author": "billierinaldi", "createdAt": "2021-03-22T14:31:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODMyMDc0MA=="}], "type": "inlineReview", "revised_code": {"commit": "b6803cfa25040895401bc7b6fdeccc2a96e2da7b", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java\nindex 814879332d2..4185bcb5dcd 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java\n\n@@ -88,6 +88,12 @@ public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemExcep\n     acquireLease(retryPolicy, 0, 0);\n \n     while (leaseID == null && exception == null) {\n+      try {\n+        future.get();\n+      } catch (Exception e) {\n+        LOG.debug(\"Got exception waiting for acquire lease future. Checking if lease ID or \"\n+            + \"exception have been set\", e);\n+      }\n     }\n     if (exception != null) {\n       LOG.error(\"Failed to acquire lease on {}\", path);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5ODMyMDg5OQ==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r598320899", "bodyText": "Failed to", "author": "steveloughran", "createdAt": "2021-03-21T18:45:39Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java", "diffHunk": "@@ -0,0 +1,165 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.FutureCallback;\n+import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ListenableScheduledFuture;\n+import org.apache.hadoop.thirdparty.org.checkerframework.checker.nullness.qual.Nullable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.azurebfs.constants.HttpHeaderConfigurations;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.io.retry.RetryPolicies;\n+import org.apache.hadoop.io.retry.RetryPolicy;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.FileSystemConfigurations.INFINITE_LEASE_DURATION;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_ACQUIRING_LEASE;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_LEASE_FUTURE_EXISTS;\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsErrors.ERR_NO_LEASE_THREADS;\n+\n+/**\n+ * AbfsLease manages an Azure blob lease. It acquires an infinite lease on instantiation and\n+ * releases the lease when free() is called. Use it to prevent writes to the blob by other\n+ * processes that don't have the lease.\n+ *\n+ * Creating a new Lease object blocks the caller until the Azure blob lease is acquired. It will\n+ * retry a fixed number of times before failing if there is a problem acquiring the lease.\n+ *\n+ * Call free() to release the Lease. If the holder process dies, AzureBlobFileSystem breakLease\n+ * will need to be called before another client will be able to write to the file.\n+ */\n+public final class AbfsLease {\n+  private static final Logger LOG = LoggerFactory.getLogger(AbfsLease.class);\n+\n+  static final int LEASE_ACQUIRE_RETRY_INTERVAL = 10; // Retry interval for acquiring lease in secs\n+  static final int LEASE_ACQUIRE_MAX_RETRIES = 7; // Number of retries for acquiring lease\n+\n+  private final AbfsClient client;\n+  private final String path;\n+\n+  // Lease status variables\n+  private volatile boolean leaseFreed;\n+  private volatile String leaseID = null;\n+  private volatile Throwable exception = null;\n+  private volatile ListenableScheduledFuture<AbfsRestOperation> future = null;\n+\n+  public static class LeaseException extends AzureBlobFileSystemException {\n+    public LeaseException(Throwable t) {\n+      super(ERR_ACQUIRING_LEASE + \": \" + t, t);\n+    }\n+\n+    public LeaseException(String s) {\n+      super(s);\n+    }\n+  }\n+\n+  public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemException {\n+    this.leaseFreed = false;\n+    this.client = client;\n+    this.path = path;\n+\n+    if (client.getNumLeaseThreads() < 1) {\n+      throw new LeaseException(ERR_NO_LEASE_THREADS);\n+    }\n+\n+    // Try to get the lease a specified number of times, else throw an error\n+    RetryPolicy retryPolicy = RetryPolicies.retryUpToMaximumCountWithFixedSleep(\n+        LEASE_ACQUIRE_MAX_RETRIES, LEASE_ACQUIRE_RETRY_INTERVAL, TimeUnit.SECONDS);\n+    acquireLease(retryPolicy, 0, 0);\n+\n+    while (leaseID == null && exception == null) {\n+    }\n+    if (exception != null) {\n+      LOG.error(\"Failed to acquire lease on {}\", path);\n+      throw new LeaseException(exception);\n+    }\n+\n+    LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+  }\n+\n+  private void acquireLease(RetryPolicy retryPolicy, int numRetries, long delay)\n+      throws LeaseException {\n+    LOG.debug(\"Attempting to acquire lease on {}, retry {}\", path, numRetries);\n+    if (future != null && !future.isDone()) {\n+      throw new LeaseException(ERR_LEASE_FUTURE_EXISTS);\n+    }\n+    future = client.schedule(() -> client.acquireLease(path, INFINITE_LEASE_DURATION),\n+        delay, TimeUnit.SECONDS);\n+    client.addCallback(future, new FutureCallback<AbfsRestOperation>() {\n+      @Override\n+      public void onSuccess(@Nullable AbfsRestOperation op) {\n+        leaseID = op.getResult().getResponseHeader(HttpHeaderConfigurations.X_MS_LEASE_ID);\n+        LOG.debug(\"Acquired lease {} on {}\", leaseID, path);\n+      }\n+\n+      @Override\n+      public void onFailure(Throwable throwable) {\n+        try {\n+          if (RetryPolicy.RetryAction.RetryDecision.RETRY\n+              == retryPolicy.shouldRetry(null, numRetries, 0, true).action) {\n+            LOG.debug(\"Failed acquire lease on {}, retrying: {}\", path, throwable);", "originalCommit": "9fc4f08bbf794eab83ffaed74a79e0a4ff4aec22", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b6803cfa25040895401bc7b6fdeccc2a96e2da7b", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java\nindex 814879332d2..4185bcb5dcd 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java\n\n@@ -88,6 +88,12 @@ public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemExcep\n     acquireLease(retryPolicy, 0, 0);\n \n     while (leaseID == null && exception == null) {\n+      try {\n+        future.get();\n+      } catch (Exception e) {\n+        LOG.debug(\"Got exception waiting for acquire lease future. Checking if lease ID or \"\n+            + \"exception have been set\", e);\n+      }\n     }\n     if (exception != null) {\n       LOG.error(\"Failed to acquire lease on {}\", path);\n"}}, {"oid": "b6803cfa25040895401bc7b6fdeccc2a96e2da7b", "url": "https://github.com/apache/hadoop/commit/b6803cfa25040895401bc7b6fdeccc2a96e2da7b", "message": "HADOOP-16948. Wait for acquire lease future", "committedDate": "2021-03-22T14:26:15Z", "type": "commit"}, {"oid": "4fdfc08089b7a126a8c455ba663637f247ae4d29", "url": "https://github.com/apache/hadoop/commit/4fdfc08089b7a126a8c455ba663637f247ae4d29", "message": "HADOOP-16948. Add unit test for acquire lease failure", "committedDate": "2021-03-23T02:01:24Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTg0MDgwMg==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r599840802", "bodyText": "if this raises an exception, is there any way the while loop will exit?", "author": "steveloughran", "createdAt": "2021-03-23T18:42:59Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsLease.java", "diffHunk": "@@ -88,6 +88,12 @@ public AbfsLease(AbfsClient client, String path) throws AzureBlobFileSystemExcep\n     acquireLease(retryPolicy, 0, 0);\n \n     while (leaseID == null && exception == null) {\n+      try {\n+        future.get();\n+      } catch (Exception e) {\n+        LOG.debug(\"Got exception waiting for acquire lease future. Checking if lease ID or \"\n+            + \"exception have been set\", e);\n+      }", "originalCommit": "b6803cfa25040895401bc7b6fdeccc2a96e2da7b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTk5NzU2Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r599997567", "bodyText": "Yes, in this section it will retry if it is below the max retries and otherwise set the exception variable. So by max retries we should either have a lease ID or an exception set, and the while loop will exit. In the unit test, I mocked two failures followed by a success as well as persistent failure and verified it had the correct behavior.", "author": "billierinaldi", "createdAt": "2021-03-23T22:22:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTg0MDgwMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDYxMTg2NzI4Nw==", "url": "https://github.com/apache/hadoop/pull/1925#discussion_r611867287", "bodyText": "understood", "author": "steveloughran", "createdAt": "2021-04-12T18:40:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU5OTg0MDgwMg=="}], "type": "inlineReview", "revised_code": null}]}