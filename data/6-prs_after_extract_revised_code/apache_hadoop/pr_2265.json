{"pr_number": 2265, "pr_title": "HDFS-15551. Tiny Improve for DeadNode detector", "pr_createdAt": "2020-09-01T12:25:36Z", "pr_url": "https://github.com/apache/hadoop/pull/2265", "timeline": [{"oid": "ec130e9ae0975010049695892addae02f26b36f0", "url": "https://github.com/apache/hadoop/commit/ec130e9ae0975010049695892addae02f26b36f0", "message": "DeadNode detector's tiny improve\n\n1. add or improve some logs for adding local & global deadnodes\n2. logic improve\n3. fix typo", "committedDate": "2020-09-01T09:24:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzNDEwNA==", "url": "https://github.com/apache/hadoop/pull/2265#discussion_r481234104", "bodyText": "1\u3001Is it necessary to add log in Local dead nodes?\n2\u3001if add debug log in DFSInputStream#addToLocalDeadNodes, do you need add log in DFSInputStream#removeFromLocalDeadNodes?", "author": "leosunli", "createdAt": "2020-09-01T15:32:19Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java", "diffHunk": "@@ -181,6 +181,8 @@ private boolean isPeriodicRefreshEnabled() {\n   private byte[] oneByteBuf; // used for 'int read()'\n \n   protected void addToLocalDeadNodes(DatanodeInfo dnInfo) {\n+    DFSClient.LOG.debug(\"Add {} to local dead nodes, previously was {}\",", "originalCommit": "ec130e9ae0975010049695892addae02f26b36f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTU1NDk0OQ==", "url": "https://github.com/apache/hadoop/pull/2265#discussion_r481554949", "bodyText": "From the statistics of the production environment, the log output of local deadnode information is too few, so that it is troublesome to find the problem reason\nThe reason to use the DEBUG log level is to separate from the INFO log level of the detector, and the impact is small.\nRemove logs can be added at the same time(I think both are OK). It was not added before considering that the local dead node removal method will almost never be called, unless the detector is turned on and there is already log output there.", "author": "imbajin", "createdAt": "2020-09-02T02:11:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzNDEwNA=="}], "type": "inlineReview", "revised_code": {"commit": "1d3aa75b7b7856b43f76f81d04d8cb09b83ce1f5", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\nindex 7e8b75d09ec..772354a489d 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DFSInputStream.java\n\n@@ -181,12 +181,13 @@ private boolean isPeriodicRefreshEnabled() {\n   private byte[] oneByteBuf; // used for 'int read()'\n \n   protected void addToLocalDeadNodes(DatanodeInfo dnInfo) {\n-    DFSClient.LOG.debug(\"Add {} to local dead nodes, previously was {}\",\n+    DFSClient.LOG.debug(\"Add {} to local dead nodes, previously was {}.\",\n             dnInfo, deadNodes);\n     deadNodes.put(dnInfo, dnInfo);\n   }\n \n   protected void removeFromLocalDeadNodes(DatanodeInfo dnInfo) {\n+    DFSClient.LOG.debug(\"Remove {} from local dead nodes.\", dnInfo);\n     deadNodes.remove(dnInfo);\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM4Mjc1MQ==", "url": "https://github.com/apache/hadoop/pull/2265#discussion_r483382751", "bodyText": "One case: when a lot of stale relicas, will the log flood?", "author": "leosunli", "createdAt": "2020-09-04T04:43:10Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java", "diffHunk": "@@ -475,6 +475,7 @@ public synchronized void addNodeToDetect(DFSInputStream dfsInputStream,\n       datanodeInfos.add(datanodeInfo);\n     }\n \n+    LOG.warn(\"Add datanode {} to suspectAndDeadNodes\", datanodeInfo);", "originalCommit": "ec130e9ae0975010049695892addae02f26b36f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzYxOTA2MA==", "url": "https://github.com/apache/hadoop/pull/2265#discussion_r483619060", "bodyText": "use DEBUG as default now", "author": "imbajin", "createdAt": "2020-09-04T13:34:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM4Mjc1MQ=="}], "type": "inlineReview", "revised_code": {"commit": "1d3aa75b7b7856b43f76f81d04d8cb09b83ce1f5", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java\nindex 2c00627e6a1..aaa12dbc77c 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java\n\n@@ -475,7 +475,7 @@ public synchronized void addNodeToDetect(DFSInputStream dfsInputStream,\n       datanodeInfos.add(datanodeInfo);\n     }\n \n-    LOG.warn(\"Add datanode {} to suspectAndDeadNodes\", datanodeInfo);\n+    LOG.debug(\"Add datanode {} to suspectAndDeadNodes.\", datanodeInfo);\n     addSuspectNodeToDetect(datanodeInfo);\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM4NDA0Nw==", "url": "https://github.com/apache/hadoop/pull/2265#discussion_r483384047", "bodyText": "when a lot of stale relicas,  it should have many supsect nodes  but not dead nodes.\nThese nodes all will print this log.\nWhat is the purpose of printing this log?\nThe client can access normally the suspect node.", "author": "leosunli", "createdAt": "2020-09-04T04:48:46Z", "path": "hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java", "diffHunk": "@@ -396,13 +395,13 @@ private void probeCallBack(Probe probe, boolean success) {\n             probe.getDatanodeInfo());\n         removeDeadNode(probe.getDatanodeInfo());\n       } else if (probe.getType() == ProbeType.CHECK_SUSPECT) {\n-        LOG.debug(\"Remove the node out from suspect node list: {}.\",\n+        LOG.info(\"Remove the node out from suspect node list: {}.\",", "originalCommit": "ec130e9ae0975010049695892addae02f26b36f0", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDYyMDc2Mg==", "url": "https://github.com/apache/hadoop/pull/2265#discussion_r484620762", "bodyText": "ditto", "author": "imbajin", "createdAt": "2020-09-08T02:45:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM4NDA0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "1d3aa75b7b7856b43f76f81d04d8cb09b83ce1f5", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java\nindex 2c00627e6a1..aaa12dbc77c 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/DeadNodeDetector.java\n\n@@ -395,7 +395,7 @@ private void probeCallBack(Probe probe, boolean success) {\n             probe.getDatanodeInfo());\n         removeDeadNode(probe.getDatanodeInfo());\n       } else if (probe.getType() == ProbeType.CHECK_SUSPECT) {\n-        LOG.info(\"Remove the node out from suspect node list: {}.\",\n+        LOG.debug(\"Remove the node out from suspect node list: {}.\",\n             probe.getDatanodeInfo());\n         removeNodeFromDeadNodeDetector(probe.getDatanodeInfo());\n       }\n"}}, {"oid": "1d3aa75b7b7856b43f76f81d04d8cb09b83ce1f5", "url": "https://github.com/apache/hadoop/commit/1d3aa75b7b7856b43f76f81d04d8cb09b83ce1f5", "message": "adjust LOG level", "committedDate": "2020-09-04T10:25:32Z", "type": "commit"}]}