{"pr_number": 2422, "pr_title": "HADOOP-17311. ABFS: Logs should redact SAS signature", "pr_createdAt": "2020-10-29T10:13:17Z", "pr_url": "https://github.com/apache/hadoop/pull/2422", "timeline": [{"oid": "0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "url": "https://github.com/apache/hadoop/commit/0e4dbc8a2dd892c6c2088dc355fcfaf76c7bb6de", "message": "ABFS: Masking SAS signatures from logs", "committedDate": "2020-10-29T10:17:25Z", "type": "forcePushed"}, {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "url": "https://github.com/apache/hadoop/commit/8883b59a819d5aa77cb37a2a422d9039cab943a3", "message": "ABFS: Masking SAS signatures from logs", "committedDate": "2020-10-29T10:20:05Z", "type": "commit"}, {"oid": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "url": "https://github.com/apache/hadoop/commit/8883b59a819d5aa77cb37a2a422d9039cab943a3", "message": "ABFS: Masking SAS signatures from logs", "committedDate": "2020-10-29T10:20:05Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0MjM5Ng==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514442396", "bodyText": "now all shaded I'm afraid. Making backporting harder already", "author": "steveloughran", "createdAt": "2020-10-29T17:33:26Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -36,6 +36,7 @@\n import org.codehaus.jackson.JsonParser;\n import org.codehaus.jackson.JsonToken;\n import org.codehaus.jackson.map.ObjectMapper;\n+import com.google.common.annotations.VisibleForTesting;", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDQ4OQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894489", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0MjM5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\nindex 08e0ea291de..b9b5f6350a9 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n\n@@ -36,7 +36,6 @@\n import org.codehaus.jackson.JsonParser;\n import org.codehaus.jackson.JsonToken;\n import org.codehaus.jackson.map.ObjectMapper;\n-import com.google.common.annotations.VisibleForTesting;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0Mzc3MA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514443770", "bodyText": "While you are there\n\nadd a catch for UnknownHostException\nmove from String.format to Log.warn(\"unknown host {}\", httpOperation,getHost()", "author": "steveloughran", "createdAt": "2020-10-29T17:35:29Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java", "diffHunk": "@@ -256,7 +256,9 @@ private boolean executeHttpOperation(final int retryCount) throws AzureBlobFileS\n       }\n     } catch (IOException ex) {\n       if (ex instanceof UnknownHostException) {\n-        LOG.warn(String.format(\"Unknown host name: %s. Retrying to resolve the host name...\", httpOperation.getUrl().getHost()));\n+        LOG.warn(String.format(\n+            \"Unknown host name: %s. Retrying to resolve the host name...\",\n+            httpOperation.getHost()));", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDU0Mw==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894543", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0Mzc3MA=="}], "type": "inlineReview", "revised_code": {"commit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java\nindex 6a902f908a8..3f65b24d570 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsRestOperation.java\n\n@@ -254,13 +254,10 @@ private boolean executeHttpOperation(final int retryCount) throws AzureBlobFileS\n         incrementCounter(AbfsStatistic.BYTES_RECEIVED,\n             httpOperation.getBytesReceived());\n       }\n+    } catch (UnknownHostException ex) {\n+      LOG.warn(\"Unknown host name: %s. Retrying to resolve the host name...\",\n+          httpOperation.getHost());\n     } catch (IOException ex) {\n-      if (ex instanceof UnknownHostException) {\n-        LOG.warn(String.format(\n-            \"Unknown host name: %s. Retrying to resolve the host name...\",\n-            httpOperation.getHost()));\n-      }\n-\n       if (LOG.isDebugEnabled()) {\n         if (httpOperation != null) {\n           LOG.debug(\"HttpRequestFailure: \" + httpOperation.toString(), ex);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NDU1NA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514444554", "bodyText": "use LambdaTestUtils.intercept(). Not only simpler, it will (correctly) fail if the rest operation didn't actually raise an exception", "author": "steveloughran", "createdAt": "2020-10-29T17:36:42Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemDelegationSAS.java", "diffHunk": "@@ -381,4 +383,39 @@ public void testProperties() throws Exception {\n \n     assertArrayEquals(propertyValue, fs.getXAttr(reqPath, propertyName));\n   }\n+\n+  @Test\n+  public void testSignatureMask() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String src = \"/testABC/test.xt\";\n+    fs.create(new Path(src));\n+    AbfsRestOperation abfsHttpRestOperation = fs.getAbfsClient()\n+        .renamePath(src, \"/testABC\" + \"/abc.txt\", null);\n+    AbfsHttpOperation result = abfsHttpRestOperation.getResult();\n+    String url = result.getSignatureMaskedUrlStr();\n+    String encodedUrl = result.getSignatureMaskedEncodedUrlStr();\n+    Assertions.assertThat(url.substring(url.indexOf(\"sig=\")))\n+        .describedAs(\"Signature query param should be masked\")\n+        .startsWith(\"sig=XXXX\");\n+    Assertions.assertThat(encodedUrl.substring(encodedUrl.indexOf(\"sig%3D\")))\n+        .describedAs(\"Signature query param should be masked\")\n+        .startsWith(\"sig%3DXXXX\");\n+  }\n+\n+  @Test\n+  public void testSignatureMaskOnExceptionMessage() {\n+    final AzureBlobFileSystem fs;\n+    String msg = null;\n+    try {\n+      fs = getFileSystem();", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDU3NQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894575", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NDU1NA=="}], "type": "inlineReview", "revised_code": {"commit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemDelegationSAS.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemDelegationSAS.java\nindex f78d6071c22..bfde8bb3c74 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemDelegationSAS.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemDelegationSAS.java\n\n@@ -403,19 +404,10 @@ public void testSignatureMask() throws Exception {\n   }\n \n   @Test\n-  public void testSignatureMaskOnExceptionMessage() {\n-    final AzureBlobFileSystem fs;\n-    String msg = null;\n-    try {\n-      fs = getFileSystem();\n-      AbfsRestOperation abfsHttpRestOperation = fs.getAbfsClient()\n-          .renamePath(\"testABC/test.xt\", \"testABC/abc.txt\", null);\n-    } catch (IOException e) {\n-      msg = e.getMessage();\n-    }\n-    Assertions.assertThat(msg.substring(msg.indexOf(\"sig=\")))\n-        .describedAs(\"Signature query param should be masked\")\n-        .startsWith(\"sig=XXXX\");\n+  public void testSignatureMaskOnExceptionMessage() throws Exception {\n+    intercept(IOException.class, \"sig=XXXX\",\n+        () -> getFileSystem().getAbfsClient()\n+            .renamePath(\"testABC/test.xt\", \"testABC/abc.txt\", null));\n   }\n \n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NTcwNg==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r514445706", "bodyText": "This is complicated enough it could be pulled out into a static method, and so its handling fully tested in (new) Unit tests, as well as in the ITests.", "author": "steveloughran", "createdAt": "2020-10-29T17:38:30Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDY5Ng==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894696", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:00:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ0NTcwNg=="}], "type": "inlineReview", "revised_code": {"commit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\nindex 08e0ea291de..b9b5f6350a9 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n\n@@ -516,23 +518,15 @@ public String getSignatureMaskedUrlStr() {\n       return this.maskedUrlStr;\n     }\n     final String urlStr = url.toString();\n-    final String qpStr = \"sig=\";\n-    final int qpStrIdx = urlStr.indexOf(qpStr);\n-    if (qpStrIdx < 0) {\n+    final int qpStrIdx = urlStr.indexOf(SIGNATURE_QUERY_PARAM_KEY);\n+    if (qpStrIdx == -1) {\n       return urlStr;\n     }\n-    final StringBuilder sb = new StringBuilder();\n-    sb.append(urlStr, 0, qpStrIdx);\n-    sb.append(qpStr);\n-    sb.append(\"XXXX\");\n-    if (qpStrIdx + qpStr.length() < urlStr.length()) {\n-      String urlStrSecondPart = urlStr.substring(qpStrIdx + qpStr.length());\n-      int idx = urlStrSecondPart.indexOf(\"&\");\n-      if (idx > -1) {\n-        sb.append(urlStrSecondPart.substring(idx));\n-      }\n-    }\n-    this.maskedUrlStr = sb.toString();\n+    final int sigStartIdx = qpStrIdx + SIGNATURE_QUERY_PARAM_KEY.length();\n+    final int ampIdx = urlStr.indexOf(\"&\", sigStartIdx);\n+    final int sigEndIndex = (ampIdx != -1) ? ampIdx : urlStr.length();\n+    String signature = urlStr.substring(sigStartIdx, sigEndIndex);\n+    this.maskedUrlStr = urlStr.replace(signature, \"XXXX\");\n     return this.maskedUrlStr;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0ODQzNA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515748434", "bodyText": "create a private static final string. - private static final String SIGNATURE_QUERY_PARAM_KEY = \"sig=\";", "author": "snvijaya", "createdAt": "2020-11-02T05:36:05Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();\n+    final String qpStr = \"sig=\";", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDc1OA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894758", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:01:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0ODQzNA=="}], "type": "inlineReview", "revised_code": {"commit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\nindex 08e0ea291de..b9b5f6350a9 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n\n@@ -516,23 +518,15 @@ public String getSignatureMaskedUrlStr() {\n       return this.maskedUrlStr;\n     }\n     final String urlStr = url.toString();\n-    final String qpStr = \"sig=\";\n-    final int qpStrIdx = urlStr.indexOf(qpStr);\n-    if (qpStrIdx < 0) {\n+    final int qpStrIdx = urlStr.indexOf(SIGNATURE_QUERY_PARAM_KEY);\n+    if (qpStrIdx == -1) {\n       return urlStr;\n     }\n-    final StringBuilder sb = new StringBuilder();\n-    sb.append(urlStr, 0, qpStrIdx);\n-    sb.append(qpStr);\n-    sb.append(\"XXXX\");\n-    if (qpStrIdx + qpStr.length() < urlStr.length()) {\n-      String urlStrSecondPart = urlStr.substring(qpStrIdx + qpStr.length());\n-      int idx = urlStrSecondPart.indexOf(\"&\");\n-      if (idx > -1) {\n-        sb.append(urlStrSecondPart.substring(idx));\n-      }\n-    }\n-    this.maskedUrlStr = sb.toString();\n+    final int sigStartIdx = qpStrIdx + SIGNATURE_QUERY_PARAM_KEY.length();\n+    final int ampIdx = urlStr.indexOf(\"&\", sigStartIdx);\n+    final int sigEndIndex = (ampIdx != -1) ? ampIdx : urlStr.length();\n+    String signature = urlStr.substring(sigStartIdx, sigEndIndex);\n+    this.maskedUrlStr = urlStr.replace(signature, \"XXXX\");\n     return this.maskedUrlStr;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0OTExOQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515749119", "bodyText": "Using string replace should be easier.\nint sigStartIndex = urlStr.indexOf(SIGNATURE_QUERY_PARAM_KEY);\nif (sigStartIndex == -1) {\n  // no signature query param in the url\n  return urlStr;\n}\n\nsigStartIndex += SIGNATURE_QUERY_PARAM_KEY.length();\nint sigEndIndex = urlStr.indexOf(\"&\", sigStartIndex);\nString sigValue = (sigEndIndex == -1)\n    ? urlStr.substring(sigStartIndex)\n    : urlStr.substring(sigStartIndex, sigEndIndex);\n\nreturn urlStr.replace(sigValue, \"XXXX\");", "author": "snvijaya", "createdAt": "2020-11-02T05:39:11Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -513,4 +509,45 @@ private void parseListFilesResponse(final InputStream stream) throws IOException\n   private boolean isNullInputStream(InputStream stream) {\n     return stream == null ? true : false;\n   }\n+\n+  @VisibleForTesting\n+  public String getSignatureMaskedUrlStr() {\n+    if (this.maskedUrlStr != null) {\n+      return this.maskedUrlStr;\n+    }\n+    final String urlStr = url.toString();\n+    final String qpStr = \"sig=\";\n+    final int qpStrIdx = urlStr.indexOf(qpStr);\n+    if (qpStrIdx < 0) {\n+      return urlStr;\n+    }\n+    final StringBuilder sb = new StringBuilder();\n+    sb.append(urlStr, 0, qpStrIdx);\n+    sb.append(qpStr);\n+    sb.append(\"XXXX\");\n+    if (qpStrIdx + qpStr.length() < urlStr.length()) {\n+      String urlStrSecondPart = urlStr.substring(qpStrIdx + qpStr.length());\n+      int idx = urlStrSecondPart.indexOf(\"&\");\n+      if (idx > -1) {\n+        sb.append(urlStrSecondPart.substring(idx));\n+      }", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NDgxNA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515894814", "bodyText": "Done", "author": "bilaharith", "createdAt": "2020-11-02T11:01:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc0OTExOQ=="}], "type": "inlineReview", "revised_code": {"commit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\nindex 08e0ea291de..b9b5f6350a9 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n\n@@ -516,23 +518,15 @@ public String getSignatureMaskedUrlStr() {\n       return this.maskedUrlStr;\n     }\n     final String urlStr = url.toString();\n-    final String qpStr = \"sig=\";\n-    final int qpStrIdx = urlStr.indexOf(qpStr);\n-    if (qpStrIdx < 0) {\n+    final int qpStrIdx = urlStr.indexOf(SIGNATURE_QUERY_PARAM_KEY);\n+    if (qpStrIdx == -1) {\n       return urlStr;\n     }\n-    final StringBuilder sb = new StringBuilder();\n-    sb.append(urlStr, 0, qpStrIdx);\n-    sb.append(qpStr);\n-    sb.append(\"XXXX\");\n-    if (qpStrIdx + qpStr.length() < urlStr.length()) {\n-      String urlStrSecondPart = urlStr.substring(qpStrIdx + qpStr.length());\n-      int idx = urlStrSecondPart.indexOf(\"&\");\n-      if (idx > -1) {\n-        sb.append(urlStrSecondPart.substring(idx));\n-      }\n-    }\n-    this.maskedUrlStr = sb.toString();\n+    final int sigStartIdx = qpStrIdx + SIGNATURE_QUERY_PARAM_KEY.length();\n+    final int ampIdx = urlStr.indexOf(\"&\", sigStartIdx);\n+    final int sigEndIndex = (ampIdx != -1) ? ampIdx : urlStr.length();\n+    String signature = urlStr.substring(sigStartIdx, sigEndIndex);\n+    this.maskedUrlStr = urlStr.replace(signature, \"XXXX\");\n     return this.maskedUrlStr;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc1MDUwOA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515750508", "bodyText": "Is a header called \"sig\" getting added when SAS ?", "author": "snvijaya", "createdAt": "2020-11-02T05:44:53Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsIoUtils.java", "diffHunk": "@@ -58,6 +58,9 @@ public static void dumpHeadersToDebugLog(final String origin,\n         if (key.contains(\"Cookie\")) {\n           values = \"*cookie info*\";\n         }\n+        if (key.equals(\"sig\")) {", "originalCommit": "8883b59a819d5aa77cb37a2a422d9039cab943a3", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5NTE5Mw==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515895193", "bodyText": "The latency tracker sends all the query params through headers.", "author": "bilaharith", "createdAt": "2020-11-02T11:01:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc1MDUwOA=="}], "type": "inlineReview", "revised_code": null}, {"oid": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "url": "https://github.com/apache/hadoop/commit/f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "message": "Addressing review comments", "committedDate": "2020-11-02T09:33:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTg5ODc2NQ==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515898765", "bodyText": "Remove Str suffix", "author": "bilaharith", "createdAt": "2020-11-02T11:08:33Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java", "diffHunk": "@@ -61,6 +64,8 @@\n \n   private final String method;\n   private final URL url;\n+  private String maskedUrlStr;", "originalCommit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d227991654a5f1b49b3ef3bd9144e96b513f731f", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\nindex b9b5f6350a9..aca2699cc4d 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsHttpOperation.java\n\n@@ -64,8 +63,8 @@\n \n   private final String method;\n   private final URL url;\n-  private String maskedUrlStr;\n-  private String maskedEncodedUrlStr;\n+  private String maskedUrl;\n+  private String maskedEncodedUrl;\n \n   private HttpURLConnection connection;\n   private int statusCode;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwODkwOA==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515908908", "bodyText": "query params ending mysig/*sig.", "author": "bilaharith", "createdAt": "2020-11-02T11:27:57Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsHttpOperation.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.UnsupportedEncodingException;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.net.URLEncoder;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+\n+import static org.apache.hadoop.fs.azurebfs.services.AbfsHttpOperation.getAbfsHttpOperationWithFixedResult;\n+\n+public class TestAbfsHttpOperation {\n+\n+  @Test\n+  public void testForURLs()\n+      throws MalformedURLException, UnsupportedEncodingException {\n+    testIfMaskedSuccessfully(\"Where sig is the only query param\"\n+        ,\"http://www.testurl.net?sig=abcd\"\n+        ,\"http://www.testurl.net?sig=XXXX\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is the first query param\"\n+        ,\"http://www.testurl.net?sig=abcd&abc=xyz\"\n+        ,\"http://www.testurl.net?sig=XXXX&abc=xyz\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is neither first nor last query param\"\n+        ,\"http://www.testurl.net?lmn=abc&sig=abcd&abc=xyz\"\n+        ,\"http://www.testurl.net?lmn=abc&sig=XXXX&abc=xyz\");\n+\n+    testIfMaskedSuccessfully(\"Where sig is the last query param\"\n+        ,\"http://www.testurl.net?abc=xyz&sig=abcd\"\n+        ,\"http://www.testurl.net?abc=xyz&sig=XXXX\");\n+\n+    testIfMaskedSuccessfully(\"Where sig query param is not present\"", "originalCommit": "f80dbe12023ee373b5f6fa7f12c62e61b55efc26", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwOTM4Nw==", "url": "https://github.com/apache/hadoop/pull/2422#discussion_r515909387", "bodyText": "sig in other cases, like caps,\nsig as suffix in the param names and values", "author": "bilaharith", "createdAt": "2020-11-02T11:28:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwODkwOA=="}], "type": "inlineReview", "revised_code": {"commit": "d227991654a5f1b49b3ef3bd9144e96b513f731f", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsHttpOperation.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsHttpOperation.java\nindex 59ce89168d7..32bd4ec1687 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsHttpOperation.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsHttpOperation.java\n\n@@ -20,53 +20,71 @@\n \n import java.io.UnsupportedEncodingException;\n import java.net.MalformedURLException;\n-import java.net.URL;\n import java.net.URLEncoder;\n \n import org.assertj.core.api.Assertions;\n import org.junit.Test;\n \n-import static org.apache.hadoop.fs.azurebfs.services.AbfsHttpOperation.getAbfsHttpOperationWithFixedResult;\n-\n public class TestAbfsHttpOperation {\n \n   @Test\n-  public void testForURLs()\n+  public void testMaskingAndEncoding()\n       throws MalformedURLException, UnsupportedEncodingException {\n-    testIfMaskedSuccessfully(\"Where sig is the only query param\"\n+    testIfMaskAndEncodeSuccessful(\"Where sig is the only query param\"\n         ,\"http://www.testurl.net?sig=abcd\"\n         ,\"http://www.testurl.net?sig=XXXX\");\n \n-    testIfMaskedSuccessfully(\"Where sig is the first query param\"\n+    testIfMaskAndEncodeSuccessful(\"Where sig is the first query param\"\n         ,\"http://www.testurl.net?sig=abcd&abc=xyz\"\n         ,\"http://www.testurl.net?sig=XXXX&abc=xyz\");\n \n-    testIfMaskedSuccessfully(\"Where sig is neither first nor last query param\"\n+    testIfMaskAndEncodeSuccessful(\"Where sig is neither first nor last query param\"\n         ,\"http://www.testurl.net?lmn=abc&sig=abcd&abc=xyz\"\n         ,\"http://www.testurl.net?lmn=abc&sig=XXXX&abc=xyz\");\n \n-    testIfMaskedSuccessfully(\"Where sig is the last query param\"\n+    testIfMaskAndEncodeSuccessful(\"Where sig is the last query param\"\n         ,\"http://www.testurl.net?abc=xyz&sig=abcd\"\n         ,\"http://www.testurl.net?abc=xyz&sig=XXXX\");\n \n-    testIfMaskedSuccessfully(\"Where sig query param is not present\"\n+    testIfMaskAndEncodeSuccessful(\"Where sig query param is not present\"\n         ,\"http://www.testurl.net?abc=xyz\"\n         ,\"http://www.testurl.net?abc=xyz\");\n+\n+    testIfMaskAndEncodeSuccessful(\"Where sig query param is not present but mysig\"\n+        ,\"http://www.testurl.net?abc=xyz&mysig=qwerty\"\n+        ,\"http://www.testurl.net?abc=xyz&mysig=qwerty\");\n+\n+    testIfMaskAndEncodeSuccessful(\"Where sig query param is not present but sigmy\"\n+        ,\"http://www.testurl.net?abc=xyz&sigmy=qwerty\"\n+        ,\"http://www.testurl.net?abc=xyz&sigmy=qwerty\");\n+\n+    testIfMaskAndEncodeSuccessful(\"Where sig query param is not present but a \"\n+            + \"value sig\"\n+        ,\"http://www.testurl.net?abc=xyz&mnop=sig\"\n+        ,\"http://www.testurl.net?abc=xyz&mnop=sig\");\n+\n+    testIfMaskAndEncodeSuccessful(\"Where sig query param is not present but a \"\n+            + \"value ends with sig\"\n+        ,\"http://www.testurl.net?abc=xyz&mnop=abcsig\"\n+        ,\"http://www.testurl.net?abc=xyz&mnop=abcsig\");\n+\n+    testIfMaskAndEncodeSuccessful(\"Where sig query param is not present but a \"\n+            + \"value starts with sig\"\n+        ,\"http://www.testurl.net?abc=xyz&mnop=sigabc\"\n+        ,\"http://www.testurl.net?abc=xyz&mnop=sigabc\");\n   }\n \n-  private void testIfMaskedSuccessfully(String scenario, String url,\n+  private void testIfMaskAndEncodeSuccessful(String scenario, String url,\n       String expectedMaskedUrl)\n-      throws MalformedURLException, UnsupportedEncodingException {\n-    AbfsHttpOperation abfsHttpOperation = getAbfsHttpOperationWithFixedResult(\n-        new URL(url), \"GET\", 200);\n+      throws UnsupportedEncodingException {\n \n-    Assertions.assertThat(abfsHttpOperation.getSignatureMaskedUrlStr())\n+    Assertions.assertThat(AbfsHttpOperation.getSignatureMaskedUrl(url))\n         .describedAs(url+\" (\"+scenario+\") after masking should be: \"+expectedMaskedUrl)\n         .isEqualToIgnoringCase(expectedMaskedUrl);\n \n     final String expectedMaskedEncodedUrl =\n         URLEncoder.encode(expectedMaskedUrl, \"UTF-8\");\n-    Assertions.assertThat(abfsHttpOperation.getSignatureMaskedEncodedUrlStr())\n+    Assertions.assertThat(AbfsHttpOperation.encodedUrlStr(expectedMaskedUrl))\n         .describedAs(url+\" (\"+scenario+\") after masking and encoding should \"\n             + \"be: \"+expectedMaskedEncodedUrl)\n         .isEqualToIgnoringCase(expectedMaskedEncodedUrl);\n"}}, {"oid": "d227991654a5f1b49b3ef3bd9144e96b513f731f", "url": "https://github.com/apache/hadoop/commit/d227991654a5f1b49b3ef3bd9144e96b513f731f", "message": "Adding more test cases and addressing review comments", "committedDate": "2020-11-02T14:09:49Z", "type": "commit"}, {"oid": "723f7206e836a7040bbc00c3b639d672e1cfa591", "url": "https://github.com/apache/hadoop/commit/723f7206e836a7040bbc00c3b639d672e1cfa591", "message": "Checkstyle fixes", "committedDate": "2020-11-03T06:16:01Z", "type": "commit"}, {"oid": "bd872b60e7ed0e402b903a90cdf392da9d6e3ada", "url": "https://github.com/apache/hadoop/commit/bd872b60e7ed0e402b903a90cdf392da9d6e3ada", "message": "Fixing findbugs issues", "committedDate": "2020-11-04T07:54:40Z", "type": "commit"}]}