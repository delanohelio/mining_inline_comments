{"pr_number": 2369, "pr_title": "HADOOP-17301. ABFS: Fix bug introduced in HADOOP-16852 which reports read-ahead error back", "pr_createdAt": "2020-10-08T01:04:54Z", "pr_url": "https://github.com/apache/hadoop/pull/2369", "timeline": [{"oid": "32a1a2fe2d1b87720020da7b49b70de4ec5e8091", "url": "https://github.com/apache/hadoop/commit/32a1a2fe2d1b87720020da7b49b70de4ec5e8091", "message": "Readahead fixes", "committedDate": "2020-10-08T00:50:10Z", "type": "commit"}, {"oid": "c22734b1f1cfdc6ea0e350f028d8e9f72a04eb42", "url": "https://github.com/apache/hadoop/commit/c22734b1f1cfdc6ea0e350f028d8e9f72a04eb42", "message": "checkstyle fixes", "committedDate": "2020-10-08T08:14:50Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NTQyNQ==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r501695425", "bodyText": "pull currentTimeMillis() outside the for loop as its an OS call with potential cost, and things probably work best if the same value is used through the loop and the code at L269", "author": "steveloughran", "createdAt": "2020-10-08T12:52:52Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java", "diffHunk": "@@ -242,13 +243,29 @@ private synchronized boolean tryEvict() {\n     }\n \n     // next, try any old nodes that have not been consumed\n+    // Failed read buffers (with buffer index=-1) that are older than\n+    // thresholdAge should be cleaned up, but at the same time should not\n+    // report successful eviction.\n+    // Queue logic expects that a buffer is freed up for read ahead when\n+    // eviction is successful, whereas a failed ReadBuffer would have released\n+    // its buffer when its status was set to READ_FAILED.\n     long earliestBirthday = Long.MAX_VALUE;\n+    ArrayList<ReadBuffer> oldFailedBuffers = new ArrayList<>();\n     for (ReadBuffer buf : completedReadList) {\n-      if (buf.getTimeStamp() < earliestBirthday) {\n+      if ((buf.getBufferindex() != -1)\n+          && (buf.getTimeStamp() < earliestBirthday)) {\n         nodeToEvict = buf;\n         earliestBirthday = buf.getTimeStamp();\n+      } else if ((buf.getBufferindex() == -1)\n+          && (currentTimeMillis() - buf.getTimeStamp()) > thresholdAgeMilliseconds) {", "originalCommit": "c22734b1f1cfdc6ea0e350f028d8e9f72a04eb42", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzMTY4MA==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r503631680", "bodyText": "Done.", "author": "snvijaya", "createdAt": "2020-10-13T02:31:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NTQyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "a0b3ce5dacf7019f37d86cf447dbf00a37fa811d", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java\nindex d9b93d8c73b..d7e031b0383 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java\n\n@@ -257,7 +259,7 @@ private synchronized boolean tryEvict() {\n         nodeToEvict = buf;\n         earliestBirthday = buf.getTimeStamp();\n       } else if ((buf.getBufferindex() == -1)\n-          && (currentTimeMillis() - buf.getTimeStamp()) > thresholdAgeMilliseconds) {\n+          && (currentTimeInMs - buf.getTimeStamp()) > thresholdAgeMilliseconds) {\n         oldFailedBuffers.add(buf);\n       }\n     }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NjI0MA==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r501696240", "bodyText": "add (minimal) javadoc", "author": "steveloughran", "createdAt": "2020-10-08T12:54:06Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java", "diffHunk": "@@ -464,4 +480,10 @@ int getCompletedReadListSize() {\n   void callTryEvict() {\n     tryEvict();\n   }\n+\n+  @VisibleForTesting", "originalCommit": "c22734b1f1cfdc6ea0e350f028d8e9f72a04eb42", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzMTQ4NQ==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r503631485", "bodyText": "Done", "author": "snvijaya", "createdAt": "2020-10-13T02:30:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NjI0MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzMTczNg==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r503631736", "bodyText": "Done", "author": "snvijaya", "createdAt": "2020-10-13T02:31:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NjI0MA=="}], "type": "inlineReview", "revised_code": {"commit": "a0b3ce5dacf7019f37d86cf447dbf00a37fa811d", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java\nindex d9b93d8c73b..d7e031b0383 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ReadBufferManager.java\n\n@@ -481,6 +483,12 @@ void callTryEvict() {\n     tryEvict();\n   }\n \n+  /**\n+   * Test method that can mimic no free buffers scenario and also add a ReadBuffer\n+   * into completedReadList. This readBuffer will get picked up by TryEvict()\n+   * next time a new queue request comes in.\n+   * @param buf that needs to be added to completedReadlist\n+   */\n   @VisibleForTesting\n   void testMimicFullUseAndAddFailedBuffer(ReadBuffer buf) {\n     freeList.clear();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NjUzNA==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r501696534", "bodyText": "use 30_000 style integer", "author": "steveloughran", "createdAt": "2020-10-08T12:54:34Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java", "diffHunk": "@@ -49,6 +49,7 @@\n   private static final int TWO_KB = 2 * 1024;\n   private static final int THREE_KB = 3 * 1024;\n   private static final int REDUCED_READ_BUFFER_AGE_THRESHOLD = 3000; // 3 sec\n+  private static final int INCREASED_READ_BUFFER_AGE_THRESHOLD = 30000; // 30 sec", "originalCommit": "c22734b1f1cfdc6ea0e350f028d8e9f72a04eb42", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a0b3ce5dacf7019f37d86cf447dbf00a37fa811d", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\nindex 8fdaba518a2..ae72c5ae9d4 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\n\n@@ -49,7 +52,8 @@\n   private static final int TWO_KB = 2 * 1024;\n   private static final int THREE_KB = 3 * 1024;\n   private static final int REDUCED_READ_BUFFER_AGE_THRESHOLD = 3000; // 3 sec\n-  private static final int INCREASED_READ_BUFFER_AGE_THRESHOLD = 30000; // 30 sec\n+  private static final int INCREASED_READ_BUFFER_AGE_THRESHOLD =\n+      REDUCED_READ_BUFFER_AGE_THRESHOLD * 10; // 30 sec\n \n   private AbfsRestOperation getMockRestOp() {\n     AbfsRestOperation op = mock(AbfsRestOperation.class);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5Njk3Ng==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r501696976", "bodyText": "import the field rather than a full reference", "author": "steveloughran", "createdAt": "2020-10-08T12:55:12Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java", "diffHunk": "@@ -182,7 +183,39 @@ public void testFailedReadAhead() throws Exception {\n     checkEvictedStatus(inputStream, 0, false);\n   }\n \n+  @Test\n+  public void testFailedReadAheadEviction() throws Exception {\n+    AbfsClient client = getMockAbfsClient();\n+    AbfsRestOperation successOp = getMockRestOp();\n+    ReadBufferManager.setThresholdAgeMilliseconds(INCREASED_READ_BUFFER_AGE_THRESHOLD);\n+    // Stub :\n+    // Read request leads to 3 readahead calls: Fail all 3 readahead-client.read()\n+    // Actual read request fails with the failure in readahead thread\n+    doThrow(new TimeoutException(\"Internal Server error\"))\n+        .when(client)\n+        .read(any(String.class), any(Long.class), any(byte[].class),\n+            any(Integer.class), any(Integer.class), any(String.class),\n+            any(String.class));\n+\n+    AbfsInputStream inputStream = getAbfsInputStream(client, \"testFailedReadAheadEviction.txt\");\n+\n+    // Add a failed buffer to completed queue and set to no free buffers to read ahead.\n+    ReadBuffer buff = new ReadBuffer();\n+    buff.setStatus(\n+        org.apache.hadoop.fs.azurebfs.contracts.services.ReadBufferStatus.READ_FAILED);", "originalCommit": "c22734b1f1cfdc6ea0e350f028d8e9f72a04eb42", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzMTc3NQ==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r503631775", "bodyText": "Done", "author": "snvijaya", "createdAt": "2020-10-13T02:31:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5Njk3Ng=="}], "type": "inlineReview", "revised_code": {"commit": "a0b3ce5dacf7019f37d86cf447dbf00a37fa811d", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\nindex 8fdaba518a2..ae72c5ae9d4 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\n\n@@ -201,8 +205,7 @@ public void testFailedReadAheadEviction() throws Exception {\n \n     // Add a failed buffer to completed queue and set to no free buffers to read ahead.\n     ReadBuffer buff = new ReadBuffer();\n-    buff.setStatus(\n-        org.apache.hadoop.fs.azurebfs.contracts.services.ReadBufferStatus.READ_FAILED);\n+    buff.setStatus(ReadBufferStatus.READ_FAILED);\n     ReadBufferManager.getBufferManager().testMimicFullUseAndAddFailedBuffer(buff);\n \n     // if read failed buffer eviction is tagged as a valid eviction, it will lead to\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5ODMxNg==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r501698316", "bodyText": "use Assertions.assertThat with an explicit isLessThanOrEqualTo(3) assertion.", "author": "steveloughran", "createdAt": "2020-10-08T12:57:20Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java", "diffHunk": "@@ -264,12 +297,24 @@ public void testSuccessfulReadAhead() throws Exception {\n             any(String.class));\n \n     AbfsInputStream inputStream = getAbfsInputStream(client, \"testSuccessfulReadAhead.txt\");\n+    int beforeReadCompletedListSize = ReadBufferManager.getBufferManager().getCompletedReadListSize();\n \n     // First read request that triggers readAheads.\n     inputStream.read(new byte[ONE_KB]);\n \n     // Only the 3 readAhead threads should have triggered client.read\n     verifyReadCallCount(client, 3);\n+    int newAdditionsToCompletedRead =\n+        ReadBufferManager.getBufferManager().getCompletedReadListSize()\n+            - beforeReadCompletedListSize;\n+    // read buffer might be dumped if the ReadBufferManager getblock preceded\n+    // the action of buffer being picked for reading from readaheadqueue, so that\n+    // inputstream can proceed with read and not be blocked on readahead thread\n+    // availability. So the count of buffers in completedReadQueue for the stream\n+    // can be same or lesser than the requests triggered to queue readahead.\n+    assertTrue(", "originalCommit": "c22734b1f1cfdc6ea0e350f028d8e9f72a04eb42", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYzMTgxMQ==", "url": "https://github.com/apache/hadoop/pull/2369#discussion_r503631811", "bodyText": "Done", "author": "snvijaya", "createdAt": "2020-10-13T02:31:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5ODMxNg=="}], "type": "inlineReview", "revised_code": {"commit": "a0b3ce5dacf7019f37d86cf447dbf00a37fa811d", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\nindex 8fdaba518a2..ae72c5ae9d4 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/services/TestAbfsInputStream.java\n\n@@ -312,9 +315,10 @@ public void testSuccessfulReadAhead() throws Exception {\n     // inputstream can proceed with read and not be blocked on readahead thread\n     // availability. So the count of buffers in completedReadQueue for the stream\n     // can be same or lesser than the requests triggered to queue readahead.\n-    assertTrue(\n-        \"New additions to completed reads should be same or less than as number of readaheads\",\n-        newAdditionsToCompletedRead <= 3);\n+    Assertions.assertThat(newAdditionsToCompletedRead)\n+        .describedAs(\n+            \"New additions to completed reads should be same or less than as number of readaheads\")\n+        .isLessThanOrEqualTo(3);\n \n     // Another read request whose requested data is already read ahead.\n     inputStream.read(ONE_KB, new byte[ONE_KB], 0, ONE_KB);\n"}}, {"oid": "a0b3ce5dacf7019f37d86cf447dbf00a37fa811d", "url": "https://github.com/apache/hadoop/commit/a0b3ce5dacf7019f37d86cf447dbf00a37fa811d", "message": "Incorporate review comments", "committedDate": "2020-10-13T02:27:42Z", "type": "commit"}]}