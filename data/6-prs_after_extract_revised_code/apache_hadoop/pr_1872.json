{"pr_number": 1872, "pr_title": "Hadoop 16890: Change in expiry calculation for MSI token provider", "pr_createdAt": "2020-03-02T22:20:52Z", "pr_url": "https://github.com/apache/hadoop/pull/1872", "timeline": [{"oid": "043ab11f0ed345977fdc9428c5fcd598181e3299", "url": "https://github.com/apache/hadoop/commit/043ab11f0ed345977fdc9428c5fcd598181e3299", "message": "Change in expiry calculation for MSI token provider", "committedDate": "2020-03-02T19:17:45Z", "type": "commit"}, {"oid": "e043dfa92bc1a4f14011026d83ec31cfdd33ac49", "url": "https://github.com/apache/hadoop/commit/e043dfa92bc1a4f14011026d83ec31cfdd33ac49", "message": "powermock version update", "committedDate": "2020-03-02T19:22:04Z", "type": "commit"}, {"oid": "386b6e020d8df312ce1adc0bd171c39620582aad", "url": "https://github.com/apache/hadoop/commit/386b6e020d8df312ce1adc0bd171c39620582aad", "message": "Moved powermock dependancies to child pom", "committedDate": "2020-03-02T20:14:43Z", "type": "commit"}, {"oid": "d3d12d9a844f6af2015b295789219460dff6a726", "url": "https://github.com/apache/hadoop/commit/d3d12d9a844f6af2015b295789219460dff6a726", "message": "Change in test file name", "committedDate": "2020-03-02T22:56:36Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386848787", "bodyText": "If expiresOnInSecs is supposed to be the field to rely on and has been returned -1, why not error out in else ?\nWhy is it that we are defaulting to value in expires_in which is not reliable ?", "author": "snvijaya", "createdAt": "2020-03-03T07:57:20Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,29 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();", "originalCommit": "d3d12d9a844f6af2015b295789219460dff6a726", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTQ3MDEzNQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389470135", "bodyText": "This seemed a safer approach. Also its not unreliable when you are retrieving from AAD service itself, it becomes unreliable for cache scenario like msi.", "author": "bilaharith", "createdAt": "2020-03-09T05:35:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMjM2NQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389902365", "bodyText": "Though MSI team confirmed faulty expires_in it still is valid for other flows and MSI response will defenitly contain the expires_in field", "author": "bilaharith", "createdAt": "2020-03-09T19:09:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1MzE3OA==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r391253178", "bodyText": "it'd be good to have some test JSONs here for real-world responses", "author": "steveloughran", "createdAt": "2020-03-11T20:35:59Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODc4Nw=="}], "type": "inlineReview", "revised_code": {"commit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\nindex 9cf2aaed558..a873923dcb5 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n\n@@ -430,6 +430,7 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n             * 1000L; // convert expiryPeriod to milliseconds and add\n         token.setExpiry(new Date(expiry));\n       }\n+\n       LOG.debug(\"AADToken: fetched token with expiry {}, expiresOn passed: {}\",\n           token.getExpiry().toString(), expiresOnInSecs);\n     } catch (Exception ex) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg0ODkwOQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386848909", "bodyText": "new line after if check block needed.", "author": "snvijaya", "createdAt": "2020-03-03T07:57:39Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,29 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();\n+        expiry = expiry + expiryPeriodInSecs\n+            * 1000L; // convert expiryPeriod to milliseconds and add\n+        token.setExpiry(new Date(expiry));\n+      }\n+      LOG.debug(\"AADToken: fetched token with expiry {}, expiresOn passed: {}\",", "originalCommit": "d3d12d9a844f6af2015b295789219460dff6a726", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\nindex 9cf2aaed558..a873923dcb5 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n\n@@ -430,6 +430,7 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n             * 1000L; // convert expiryPeriod to milliseconds and add\n         token.setExpiry(new Date(expiry));\n       }\n+\n       LOG.debug(\"AADToken: fetched token with expiry {}, expiresOn passed: {}\",\n           token.getExpiry().toString(), expiresOnInSecs);\n     } catch (Exception ex) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1NTQ2Ng==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386855466", "bodyText": "Order the non-static imports in the order:\n\njava*\nany non org.apache imports\norg.apache imports", "author": "snvijaya", "createdAt": "2020-03-03T08:14:18Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+", "originalCommit": "d3d12d9a844f6af2015b295789219460dff6a726", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\nindex 87298b66c8c..0080a78dbeb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n\n@@ -27,20 +27,22 @@\n import java.io.IOException;\n import java.util.Date;\n \n+import static org.junit.Assume.assumeThat;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.Matchers.isEmptyOrNullString;\n+import static org.hamcrest.Matchers.isEmptyString;\n+\n import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_CLIENT_ID;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_TENANT;\n-import static org.hamcrest.CoreMatchers.is;\n-import static org.hamcrest.CoreMatchers.not;\n-import static org.hamcrest.Matchers.isEmptyOrNullString;\n-import static org.hamcrest.Matchers.isEmptyString;\n-import static org.junit.Assume.assumeThat;\n \n /**\n- * Test MsiTokenProvider\n+ * Test MsiTokenProvider.\n  */\n public final class ITestAbfsMsiTokenProvider\n     extends AbstractAbfsIntegrationTest {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1NjAxMA==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386856010", "bodyText": "It seems there are javadoc compilers issues with description comments without a dot at end. Please add here and at places such comments are added.", "author": "snvijaya", "createdAt": "2020-03-03T08:15:39Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n+import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n+import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_CLIENT_ID;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n+import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_TENANT;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.Matchers.isEmptyOrNullString;\n+import static org.hamcrest.Matchers.isEmptyString;\n+import static org.junit.Assume.assumeThat;\n+\n+/**\n+ * Test MsiTokenProvider", "originalCommit": "d3d12d9a844f6af2015b295789219460dff6a726", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\nindex 87298b66c8c..0080a78dbeb 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n\n@@ -27,20 +27,22 @@\n import java.io.IOException;\n import java.util.Date;\n \n+import static org.junit.Assume.assumeThat;\n+\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.Matchers.isEmptyOrNullString;\n+import static org.hamcrest.Matchers.isEmptyString;\n+\n import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n import static org.apache.hadoop.fs.azurebfs.constants.AuthConfigurations.DEFAULT_FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_CLIENT_ID;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_AUTHORITY;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_ENDPOINT;\n import static org.apache.hadoop.fs.azurebfs.constants.ConfigurationKeys.FS_AZURE_ACCOUNT_OAUTH_MSI_TENANT;\n-import static org.hamcrest.CoreMatchers.is;\n-import static org.hamcrest.CoreMatchers.not;\n-import static org.hamcrest.Matchers.isEmptyOrNullString;\n-import static org.hamcrest.Matchers.isEmptyString;\n-import static org.junit.Assume.assumeThat;\n \n /**\n- * Test MsiTokenProvider\n+ * Test MsiTokenProvider.\n  */\n public final class ITestAbfsMsiTokenProvider\n     extends AbstractAbfsIntegrationTest {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1NjMxNg==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386856316", "bodyText": "Please refer to non-static import order mentioned in above comment.", "author": "snvijaya", "createdAt": "2020-03-03T08:16:22Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs.unittests;\n+\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;", "originalCommit": "d3d12d9a844f6af2015b295789219460dff6a726", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java\nindex 61e83961373..78139e23e6e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java\n\n@@ -31,12 +31,13 @@\n import java.io.IOException;\n import java.util.Date;\n \n+import static org.junit.Assert.assertThat;\n+\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.greaterThan;\n import static org.hamcrest.Matchers.lessThanOrEqualTo;\n import static org.hamcrest.core.AllOf.allOf;\n import static org.hamcrest.core.Is.is;\n-import static org.junit.Assert.assertThat;\n import static org.mockito.Mockito.when;\n import static org.powermock.api.mockito.PowerMockito.mockStatic;\n import static org.powermock.reflect.Whitebox.getInternalState;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1OTg2OQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r386859869", "bodyText": "With this mock the code which parses the response and sets the expiry from expires_on will not be hit ?", "author": "snvijaya", "createdAt": "2020-03-03T08:25:10Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hadoop.fs.azurebfs.unittests;\n+\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADAuthenticator;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n+import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n+import org.junit.Assert;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mockito;\n+import org.powermock.core.classloader.annotations.PrepareForTest;\n+import org.powermock.modules.junit4.PowerMockRunner;\n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.greaterThan;\n+import static org.hamcrest.Matchers.lessThanOrEqualTo;\n+import static org.hamcrest.core.AllOf.allOf;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.Mockito.when;\n+import static org.powermock.api.mockito.PowerMockito.mockStatic;\n+import static org.powermock.reflect.Whitebox.getInternalState;\n+import static org.powermock.reflect.Whitebox.invokeMethod;\n+import static org.powermock.reflect.Whitebox.setInternalState;\n+\n+/**\n+ * Unit test for MsiTokenProvider\n+ */\n+@RunWith(PowerMockRunner.class)\n+@PrepareForTest(AzureADAuthenticator.class)\n+public class TestMsiTokenProvider {\n+\n+  private static final long ONE_HOUR = 3600 * 1000;\n+  private static final long TWO_HOUR = ONE_HOUR * 2;\n+\n+  @Test\n+  public void testMsiTokenProvider() throws Exception {\n+    String testToken = \"TEST_TOKEN1\";\n+    setMockAzureADAuthenticator(testToken,\n+        System.currentTimeMillis() + TWO_HOUR);\n+\n+    AccessTokenProvider msiTokenProvider = new MsiTokenProvider(\"\", \"\", \"\", \"\");\n+    long tokenFetchTime = getInternalState(msiTokenProvider, \"tokenFetchTime\");\n+    Assert.assertEquals(-1, tokenFetchTime);\n+\n+    long before = System.currentTimeMillis();\n+    AzureADToken token = msiTokenProvider.getToken();\n+    long after = System.currentTimeMillis();\n+    long newTokenFetchTime = getInternalState(msiTokenProvider,\n+        \"tokenFetchTime\");\n+    assertThat(newTokenFetchTime,\n+        is(allOf(greaterThan(before), lessThanOrEqualTo(after))));\n+    assertThat(token.getAccessToken(), is(equalTo(testToken)));\n+\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(false));\n+\n+    setInternalState(msiTokenProvider, \"tokenFetchTime\",\n+        System.currentTimeMillis() - ONE_HOUR);\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(true));\n+\n+    setInternalState(msiTokenProvider, \"tokenFetchTime\",\n+        System.currentTimeMillis() + 2 - ONE_HOUR);\n+    assertThat(invokeMethod(msiTokenProvider, \"isTokenAboutToExpire\"),\n+        is(false));\n+  }\n+\n+  private AzureADToken setMockAzureADAuthenticator(String tokenStr, long expiry)\n+      throws IOException {\n+    AzureADToken token = new AzureADToken();\n+    token.setAccessToken(tokenStr);\n+    token.setExpiry(new Date(expiry));\n+    mockStatic(AzureADAuthenticator.class);\n+    when(AzureADAuthenticator\n+        .getTokenFromMsi(Mockito.anyString(), Mockito.anyString(),", "originalCommit": "d3d12d9a844f6af2015b295789219460dff6a726", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzE3MDc4Mw==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387170783", "bodyText": "No. Planning to do that as a separate task.", "author": "bilaharith", "createdAt": "2020-03-03T17:15:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Njg1OTg2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java\nindex 61e83961373..78139e23e6e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/unittests/TestMsiTokenProvider.java\n\n@@ -31,12 +31,13 @@\n import java.io.IOException;\n import java.util.Date;\n \n+import static org.junit.Assert.assertThat;\n+\n import static org.hamcrest.Matchers.equalTo;\n import static org.hamcrest.Matchers.greaterThan;\n import static org.hamcrest.Matchers.lessThanOrEqualTo;\n import static org.hamcrest.core.AllOf.allOf;\n import static org.hamcrest.core.Is.is;\n-import static org.junit.Assert.assertThat;\n import static org.mockito.Mockito.when;\n import static org.powermock.api.mockito.PowerMockito.mockStatic;\n import static org.powermock.reflect.Whitebox.getInternalState;\n"}}, {"oid": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "url": "https://github.com/apache/hadoop/commit/b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "message": "Review comments addressed", "committedDate": "2020-03-03T17:18:40Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM5OTY1OA==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387399658", "bodyText": "I suppose 0 is not a valid value for expiresOnInSecs, do we need to add value check here?", "author": "DadanielZ", "createdAt": "2020-03-04T01:26:01Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > -1) {", "originalCommit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwNDM3Nw==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389904377", "bodyText": "Changed to expiresOnInSecs > 0, good to have check, for a safer side", "author": "bilaharith", "createdAt": "2020-03-09T19:13:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzM5OTY1OA=="}], "type": "inlineReview", "revised_code": {"commit": "97b70be69cc406ead58202d5f9d311c86b68c6a5", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\nindex a873923dcb5..d0df1035de3 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n\n@@ -422,7 +422,7 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n         jp.nextToken();\n       }\n       jp.close();\n-      if (expiresOnInSecs > -1) {\n+      if (expiresOnInSecs > 0) {\n         token.setExpiry(new Date(expiresOnInSecs * 1000));\n       } else {\n         long expiry = System.currentTimeMillis();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NzQwNzg4OQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r387407889", "bodyText": "need to update this @return documentation too.", "author": "DadanielZ", "createdAt": "2020-03-04T01:56:44Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "diffHunk": "@@ -51,6 +55,35 @@ protected AzureADToken refreshToken() throws IOException {\n     LOG.debug(\"AADToken: refreshing token from MSI\");\n     AzureADToken token = AzureADAuthenticator\n         .getTokenFromMsi(authEndpoint, tenantGuid, clientId, authority, false);\n+    tokenFetchTime = System.currentTimeMillis();\n     return token;\n   }\n+\n+  /**\n+   * Checks if the token is about to expire as per base expiry logic.\n+   * Otherwise try to expire every 1 hour\n+   *\n+   * @return true if the token is expiring in next 5 minutes", "originalCommit": "b717a3c1e1b4129d763b948b5fdc73adc37d3e9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "97b70be69cc406ead58202d5f9d311c86b68c6a5", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java\nindex e20b5d99d7d..ae4ad272a99 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java\n\n@@ -63,7 +63,7 @@ protected AzureADToken refreshToken() throws IOException {\n    * Checks if the token is about to expire as per base expiry logic.\n    * Otherwise try to expire every 1 hour\n    *\n-   * @return true if the token is expiring in next 5 minutes\n+   * @return true if the token is expiring in next 1 hour\n    */\n   @Override\n   protected boolean isTokenAboutToExpire() {\n"}}, {"oid": "41ff89d6947537e56f364d96aa35abc5ace486be", "url": "https://github.com/apache/hadoop/commit/41ff89d6947537e56f364d96aa35abc5ace486be", "message": "Moving dependancy versions to parent pom", "committedDate": "2020-03-04T10:55:50Z", "type": "commit"}, {"oid": "97b70be69cc406ead58202d5f9d311c86b68c6a5", "url": "https://github.com/apache/hadoop/commit/97b70be69cc406ead58202d5f9d311c86b68c6a5", "message": "Review comments addressed", "committedDate": "2020-03-04T14:29:34Z", "type": "commit"}, {"oid": "39496686cb9f8d75c6d42186d7b12be6bf855742", "url": "https://github.com/apache/hadoop/commit/39496686cb9f8d75c6d42186d7b12be6bf855742", "message": "Review comments addressed", "committedDate": "2020-03-04T20:05:50Z", "type": "commit"}, {"oid": "c999b6dc2857a84d9632071aac8f3f18d0ce6da7", "url": "https://github.com/apache/hadoop/commit/c999b6dc2857a84d9632071aac8f3f18d0ce6da7", "message": "Updating the parent pom", "committedDate": "2020-03-06T20:10:48Z", "type": "commit"}, {"oid": "a5fb0fe106f44ff76806dcd40408b7ca8188e713", "url": "https://github.com/apache/hadoop/commit/a5fb0fe106f44ff76806dcd40408b7ca8188e713", "message": "Removing power mock dependancy for now", "committedDate": "2020-03-07T09:18:49Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3Mzc5NA==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389573794", "bodyText": "I'd like some reporting of parse failures here, especially which field isn't parsing.\nAlso, make sure that the code is validating content type before JSON parsing. We've done that for OAuth, needs to be done here so that a bad URL or proxy returns HTML and everything fails for no obvious reason", "author": "steveloughran", "createdAt": "2020-03-09T10:26:39Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {", "originalCommit": "a5fb0fe106f44ff76806dcd40408b7ca8188e713", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMTI0Mg==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389901242", "bodyText": "Added log to indicate based on which field exactly the expiry is calculated", "author": "bilaharith", "createdAt": "2020-03-09T19:06:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3Mzc5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMTY0Mw==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389901643", "bodyText": "content type check is done at the method from where this method is called.", "author": "bilaharith", "createdAt": "2020-03-09T19:07:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3Mzc5NA=="}], "type": "inlineReview", "revised_code": {"commit": "3633c073ec7363e23fbbff43c051e80bcd533bb3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\nindex d0df1035de3..1c9ae175804 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n\n@@ -426,8 +426,7 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n         token.setExpiry(new Date(expiresOnInSecs * 1000));\n       } else {\n         long expiry = System.currentTimeMillis();\n-        expiry = expiry + expiryPeriodInSecs\n-            * 1000L; // convert expiryPeriod to milliseconds and add\n+        expiry = expiry + expiryPeriodInSecs * 1000L; // convert expiryPeriod to milliseconds and add\n         token.setExpiry(new Date(expiry));\n       }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NDkzNg==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389574936", "bodyText": "put expiryPeriod and * 1000 on same line. Also, feel free to use the new java time classes which are complex but powerful once you start to use them", "author": "steveloughran", "createdAt": "2020-03-09T10:28:48Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -408,17 +409,30 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n           if (fieldName.equals(\"access_token\")) {\n             token.setAccessToken(fieldValue);\n           }\n+\n           if (fieldName.equals(\"expires_in\")) {\n-            expiryPeriod = Integer.parseInt(fieldValue);\n+            expiryPeriodInSecs = Integer.parseInt(fieldValue);\n+          }\n+\n+          if (fieldName.equals(\"expires_on\")) {\n+            expiresOnInSecs = Long.parseLong(fieldValue);\n           }\n+\n         }\n         jp.nextToken();\n       }\n       jp.close();\n-      long expiry = System.currentTimeMillis();\n-      expiry = expiry + expiryPeriod * 1000L; // convert expiryPeriod to milliseconds and add\n-      token.setExpiry(new Date(expiry));\n-      LOG.debug(\"AADToken: fetched token with expiry \" + token.getExpiry().toString());\n+      if (expiresOnInSecs > 0) {\n+        token.setExpiry(new Date(expiresOnInSecs * 1000));\n+      } else {\n+        long expiry = System.currentTimeMillis();\n+        expiry = expiry + expiryPeriodInSecs\n+            * 1000L; // convert expiryPeriod to milliseconds and add", "originalCommit": "a5fb0fe106f44ff76806dcd40408b7ca8188e713", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMzY4OA==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389903688", "bodyText": "Not using Java 8 features as we keep a backport to an older Java version branch.", "author": "bilaharith", "createdAt": "2020-03-09T19:11:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NDkzNg=="}], "type": "inlineReview", "revised_code": {"commit": "3633c073ec7363e23fbbff43c051e80bcd533bb3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\nindex d0df1035de3..1c9ae175804 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java\n\n@@ -426,8 +426,7 @@ private static AzureADToken parseTokenFromStream(InputStream httpResponseStream)\n         token.setExpiry(new Date(expiresOnInSecs * 1000));\n       } else {\n         long expiry = System.currentTimeMillis();\n-        expiry = expiry + expiryPeriodInSecs\n-            * 1000L; // convert expiryPeriod to milliseconds and add\n+        expiry = expiry + expiryPeriodInSecs * 1000L; // convert expiryPeriod to milliseconds and add\n         token.setExpiry(new Date(expiry));\n       }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NTI5MQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389575291", "bodyText": "or if a token has never been fetched", "author": "steveloughran", "createdAt": "2020-03-09T10:29:33Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "diffHunk": "@@ -51,6 +55,35 @@ protected AzureADToken refreshToken() throws IOException {\n     LOG.debug(\"AADToken: refreshing token from MSI\");\n     AzureADToken token = AzureADAuthenticator\n         .getTokenFromMsi(authEndpoint, tenantGuid, clientId, authority, false);\n+    tokenFetchTime = System.currentTimeMillis();\n     return token;\n   }\n+\n+  /**\n+   * Checks if the token is about to expire as per base expiry logic.\n+   * Otherwise try to expire every 1 hour\n+   *\n+   * @return true if the token is expiring in next 1 hour", "originalCommit": "a5fb0fe106f44ff76806dcd40408b7ca8188e713", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3633c073ec7363e23fbbff43c051e80bcd533bb3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java\nindex ae4ad272a99..784365b4c9c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java\n\n@@ -63,7 +63,8 @@ protected AzureADToken refreshToken() throws IOException {\n    * Checks if the token is about to expire as per base expiry logic.\n    * Otherwise try to expire every 1 hour\n    *\n-   * @return true if the token is expiring in next 1 hour\n+   * @return true if the token is expiring in next 1 hour or if a token has\n+   * never been fetched\n    */\n   @Override\n   protected boolean isTokenAboutToExpire() {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NTU2Mw==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389575563", "bodyText": "check import ordering. you know what I'll complain about", "author": "steveloughran", "createdAt": "2020-03-09T10:30:02Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.apache.commons.lang3.StringUtils;", "originalCommit": "a5fb0fe106f44ff76806dcd40408b7ca8188e713", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMjQ5NQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r389902495", "bodyText": "Done :)", "author": "bilaharith", "createdAt": "2020-03-09T19:09:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTU3NTU2Mw=="}], "type": "inlineReview", "revised_code": {"commit": "3633c073ec7363e23fbbff43c051e80bcd533bb3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\nindex 0080a78dbeb..8e89bd40775 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n\n@@ -18,14 +18,16 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import org.junit.Test;\n+\n import org.apache.commons.lang3.StringUtils;\n import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n-import org.junit.Test;\n-\n-import java.io.IOException;\n-import java.util.Date;\n \n import static org.junit.Assume.assumeThat;\n \n"}}, {"oid": "3633c073ec7363e23fbbff43c051e80bcd533bb3", "url": "https://github.com/apache/hadoop/commit/3633c073ec7363e23fbbff43c051e80bcd533bb3", "message": "Addressing review comments", "committedDate": "2020-03-09T18:59:26Z", "type": "commit"}, {"oid": "3f794d651df01651941b8e56c005579b988fa0a4", "url": "https://github.com/apache/hadoop/commit/3f794d651df01651941b8e56c005579b988fa0a4", "message": "Addressing review comments", "committedDate": "2020-03-09T19:03:22Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA4Mjc2Mw==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r390082763", "bodyText": "Extra new line.", "author": "snvijaya", "createdAt": "2020-03-10T03:56:08Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+", "originalCommit": "3f794d651df01651941b8e56c005579b988fa0a4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d82bf7e021c7859355fa9f62207f6d3617e24439", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\nindex 8e89bd40775..d871befa430 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-\n import java.io.IOException;\n import java.util.Date;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA4Mjg3Ng==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r390082876", "bodyText": "import ordering still not as expected.", "author": "snvijaya", "createdAt": "2020-03-10T03:56:35Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+\n+import java.io.IOException;\n+import java.util.Date;\n+\n+import org.junit.Test;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AccessTokenProvider;\n+import org.apache.hadoop.fs.azurebfs.oauth2.AzureADToken;\n+import org.apache.hadoop.fs.azurebfs.oauth2.MsiTokenProvider;\n+\n+import static org.junit.Assume.assumeThat;", "originalCommit": "3f794d651df01651941b8e56c005579b988fa0a4", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d82bf7e021c7859355fa9f62207f6d3617e24439", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\nindex 8e89bd40775..d871befa430 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsMsiTokenProvider.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-\n import java.io.IOException;\n import java.util.Date;\n \n"}}, {"oid": "d82bf7e021c7859355fa9f62207f6d3617e24439", "url": "https://github.com/apache/hadoop/commit/d82bf7e021c7859355fa9f62207f6d3617e24439", "message": "Fixing import order", "committedDate": "2020-03-10T07:04:12Z", "type": "commit"}, {"oid": "cd71fd27d651f84a5f2e6e21aa69ee2b3b052c01", "url": "https://github.com/apache/hadoop/commit/cd71fd27d651f84a5f2e6e21aa69ee2b3b052c01", "message": "Added comment regarding the issue", "committedDate": "2020-03-10T10:39:52Z", "type": "commit"}, {"oid": "d32b33fed0478d0e9c57e8393094ee2525f49893", "url": "https://github.com/apache/hadoop/commit/d32b33fed0478d0e9c57e8393094ee2525f49893", "message": "Added comment regarding the issue", "committedDate": "2020-03-11T02:20:31Z", "type": "commit"}, {"oid": "982dad0c57f84b40e5c4b1c761f4c4e5a5f4db43", "url": "https://github.com/apache/hadoop/commit/982dad0c57f84b40e5c4b1c761f4c4e5a5f4db43", "message": "Merge branch 'HADOOP-16890_2' of https://github.com/bilaharith/hadoop into HADOOP-16890_2", "committedDate": "2020-03-11T02:21:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDk1ODc1MQ==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r390958751", "bodyText": "Not something needing changing in this PR, but this should really be Map<> and the code to move to a HashMap; all of Hashtable's methods are synchronized and it underperforms.", "author": "steveloughran", "createdAt": "2020-03-11T13:12:21Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/AzureADAuthenticator.java", "diffHunk": "@@ -258,8 +258,13 @@ public UnexpectedResponseException(final int httpErrorCode,\n   }\n \n   private static AzureADToken getTokenCall(String authEndpoint, String body,\n-                                           Hashtable<String, String> headers, String httpMethod)\n-          throws IOException {\n+      Hashtable<String, String> headers, String httpMethod) throws IOException {\n+    return getTokenCall(authEndpoint, body, headers, httpMethod, false);\n+  }\n+\n+  private static AzureADToken getTokenCall(String authEndpoint, String body,\n+      Hashtable<String, String> headers, String httpMethod, boolean isMsi)", "originalCommit": "982dad0c57f84b40e5c4b1c761f4c4e5a5f4db43", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTI1MzM5Nw==", "url": "https://github.com/apache/hadoop/pull/1872#discussion_r391253397", "bodyText": "better: 3600_1000", "author": "steveloughran", "createdAt": "2020-03-11T20:36:25Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/oauth2/MsiTokenProvider.java", "diffHunk": "@@ -36,6 +36,10 @@\n \n   private final String clientId;\n \n+  private long tokenFetchTime = -1;\n+\n+  private static final long ONE_HOUR = 3600 * 1000;", "originalCommit": "982dad0c57f84b40e5c4b1c761f4c4e5a5f4db43", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}