{"pr_number": 2501, "pr_title": "HDFS-15648. TestFileChecksum should be parameterized.", "pr_createdAt": "2020-11-30T02:45:17Z", "pr_url": "https://github.com/apache/hadoop/pull/2501", "timeline": [{"oid": "357884704d5b9ae9dcf8a12fee6436464c5fe12c", "url": "https://github.com/apache/hadoop/commit/357884704d5b9ae9dcf8a12fee6436464c5fe12c", "message": "HDFS-15648. TestFileChecksum should be parameterized with a boolean flag.", "committedDate": "2020-11-30T02:44:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMDQwNA==", "url": "https://github.com/apache/hadoop/pull/2501#discussion_r533500404", "bodyText": "Do we need three boolean fields? It seems that the three booleans have the same value.\nMaybe we should simplify the implementation by replacing the three fields by a single field (i.e., isCompositeCRC)", "author": "amahussein", "createdAt": "2020-12-01T15:26:56Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java", "diffHunk": "@@ -77,6 +81,31 @@\n   private String stripedFile2 = ecDir + \"/stripedFileChecksum2\";\n   private String replicatedFile = \"/replicatedFileChecksum\";\n \n+  private String checksumCombineMode;\n+  private boolean expectComparableStripedAndReplicatedFiles;\n+  private boolean expectComparableDifferentBlockSizeReplicatedFiles;", "originalCommit": "357884704d5b9ae9dcf8a12fee6436464c5fe12c", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzc5MzE3MQ==", "url": "https://github.com/apache/hadoop/pull/2501#discussion_r533793171", "bodyText": "I removed boolean params and updated issue/PR title.", "author": "iwasakims", "createdAt": "2020-12-01T23:32:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMDQwNA=="}], "type": "inlineReview", "revised_code": {"commit": "e32f6dc2454b529a13b751d93facdd169d5283e3", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java\nindex 4e7eda94828..bfa34944c71 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java\n\n@@ -82,28 +82,16 @@\n   private String replicatedFile = \"/replicatedFileChecksum\";\n \n   private String checksumCombineMode;\n-  private boolean expectComparableStripedAndReplicatedFiles;\n-  private boolean expectComparableDifferentBlockSizeReplicatedFiles;\n-  private boolean expectSupportForSingleFileMixedBytesPerChecksum;\n-\n-  public TestFileChecksum(String checksumCombineMode,\n-      boolean expectComparableStripedAndReplicatedFiles,\n-      boolean expectComparableDifferentBlockSizeReplicatedFiles,\n-      boolean expectSupportForSingleFileMixedBytesPerChecksum) {\n+\n+  public TestFileChecksum(String checksumCombineMode) {\n     this.checksumCombineMode = checksumCombineMode;\n-    this.expectComparableStripedAndReplicatedFiles =\n-        expectComparableStripedAndReplicatedFiles;\n-    this.expectComparableDifferentBlockSizeReplicatedFiles =\n-        expectComparableDifferentBlockSizeReplicatedFiles;\n-    this.expectSupportForSingleFileMixedBytesPerChecksum =\n-        expectSupportForSingleFileMixedBytesPerChecksum;\n   }\n \n   @Parameterized.Parameters\n-  public static Object[][] getParameters() {\n-    return new Object[][] {\n-        {ChecksumCombineMode.MD5MD5CRC.name(), false, false, false},\n-        {ChecksumCombineMode.COMPOSITE_CRC.name(), true, true, true}};\n+  public static Object[] getParameters() {\n+    return new Object[] {\n+        ChecksumCombineMode.MD5MD5CRC.name(),\n+        ChecksumCombineMode.COMPOSITE_CRC.name()};\n   }\n \n   @Rule\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzUwMjg5OA==", "url": "https://github.com/apache/hadoop/pull/2501#discussion_r533502898", "bodyText": "We could keep the methods which returns the isCompositeCRC flag. This will reduce the diff and make the implementation flexible and maintainable for future changes.", "author": "amahussein", "createdAt": "2020-12-01T15:30:07Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java", "diffHunk": "@@ -220,7 +217,7 @@ public void testStripedAndReplicatedFileChecksum() throws Exception {\n     FileChecksum replicatedFileChecksum = getFileChecksum(replicatedFile,\n         10, false);\n \n-    if (expectComparableStripedAndReplicatedFiles()) {\n+    if (expectComparableStripedAndReplicatedFiles) {", "originalCommit": "357884704d5b9ae9dcf8a12fee6436464c5fe12c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e32f6dc2454b529a13b751d93facdd169d5283e3", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java\nindex 4e7eda94828..bfa34944c71 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java\n\n@@ -217,7 +205,7 @@ public void testStripedAndReplicatedFileChecksum() throws Exception {\n     FileChecksum replicatedFileChecksum = getFileChecksum(replicatedFile,\n         10, false);\n \n-    if (expectComparableStripedAndReplicatedFiles) {\n+    if (checksumCombineMode.equals(ChecksumCombineMode.COMPOSITE_CRC.name())) {\n       Assert.assertEquals(stripedFileChecksum1, replicatedFileChecksum);\n     } else {\n       Assert.assertNotEquals(stripedFileChecksum1, replicatedFileChecksum);\n"}}, {"oid": "e32f6dc2454b529a13b751d93facdd169d5283e3", "url": "https://github.com/apache/hadoop/commit/e32f6dc2454b529a13b751d93facdd169d5283e3", "message": "removed boolean params.", "committedDate": "2020-12-01T23:29:17Z", "type": "commit"}]}