{"pr_number": 1899, "pr_title": "HADOOP-16914 Adding Output Stream Counters in ABFS", "pr_createdAt": "2020-03-17T11:38:47Z", "pr_url": "https://github.com/apache/hadoop/pull/1899", "timeline": [{"oid": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "url": "https://github.com/apache/hadoop/commit/20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "message": "Fixing issues", "committedDate": "2020-03-18T08:23:48Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyNzg5NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r394227894", "bodyText": "Need help in simulating Bytes to fail to upload in this test to get some values for bytesUploadFailed counter.", "author": "mehakmeet", "createdAt": "2020-03-18T10:00:23Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -28,28 +26,38 @@ public ITestAbfsOutputStream() throws Exception {\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NjI0OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395756248", "bodyText": "I can't think of any. Maybe just have a unit test to take an AbfsOutputStreamsImpl and verify that when the method is called, the counter is updated.\n(Actually, mocking could simulate failure, ...)", "author": "steveloughran", "createdAt": "2020-03-20T16:34:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyNzg5NA=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -27,101 +50,121 @@ public void testAbfsOutputStreamUploadingBytes() throws IOException {\n     describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     String testBytesToUpload = \"bytes\";\n \n-    AbfsOutputStream outForSomeBytes = null;\n-    try {\n-      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-          statistics,\n-          true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n \n       //Test for zero bytes To upload\n       assertValues(\"bytes to upload\", 0,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n       outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n \n-      //Test for some bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForSomeBytes != null) {\n-        outForSomeBytes.close();\n-      }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n     }\n \n-    AbfsOutputStream outForLargeBytes = null;\n-    try {\n-      outForLargeBytes =\n-          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n-              statistics\n-              , true, FsPermission.getDefault(),\n-              FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n \n-      int largeValue = 100000;\n+      int largeValue = LARGE_OPERATIONS;\n       for (int i = 0; i < largeValue; i++) {\n         outForLargeBytes.write(testBytesToUpload.getBytes());\n       }\n       outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n \n-      //Test for large bytes to upload\n+      //Test for bytes to upload\n       assertValues(\"bytes to upload\",\n           largeValue * (testBytesToUpload.getBytes().length),\n-          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n-\n-      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n-      // and bytesToUpload\n-      assertValues(\"bytesUploadSuccessful equal to difference between \"\n-              + \"bytesToUpload and bytesUploadFailed\",\n-          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n-          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n-              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n-\n-    } finally {\n-      if (outForLargeBytes != null) {\n-        outForLargeBytes.close();\n-      }\n-    }\n+          abfsOutputStreamStatistics.getBytesToUpload());\n \n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n   }\n \n   /**\n-   * Tests to check time spend on waiting for tasks to be complete on a\n+   * Tests to check time spent on waiting for tasks to be complete on a\n    * blocking queue in {@link AbfsOutputStream}.\n    *\n    * @throws IOException\n    */\n   @Test\n-  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n     describe(\"Testing Time Spend on Waiting for Task to be complete\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n \n-    AbfsOutputStream out =\n-        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n-            statistics, true,\n-            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n \n   }\n \n   /**\n-   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n    * calls.\n    * After writing data, AbfsOutputStream doesn't upload the data until\n    * Flushed. Hence, flush() method is called after write() to test Queue\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r394228752", "bodyText": "any way around flush() to get queueShrink() calls after writing ?\nflush() is quite expensive as it takes some time even at 1000 calls to test.", "author": "mehakmeet", "createdAt": "2020-03-18T10:01:47Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -133,58 +133,60 @@ public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n   public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n-    Path TEST_PATH = new Path(\"AbfsOutputStreamStatsPath\");\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n     AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n     abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n     FileSystem.Statistics statistics = fs.getFsStatistics();\n     String testQueueShrink = \"testQueue\";\n \n-\n     AbfsOutputStream outForOneOp = null;\n \n     try {\n-      outForOneOp = (AbfsOutputStream) abfss.createFile(TEST_PATH, statistics,\n-        true,\n-          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n \n       //Test for shrinking Queue zero time\n-      Assert.assertEquals(\"Mismatch in number of queueShrink() Calls\", 0,\n+      assertValues(\"number of queueShrink() Calls\", 0,\n           outForOneOp.getOutputStreamStatistics().queueShrink);\n \n       outForOneOp.write(testQueueShrink.getBytes());\n       // Queue is shrunk 2 times when outStream is flushed\n       outForOneOp.flush();\n \n       //Test for shrinking Queue 2 times\n-      Assert.assertEquals(\"Mismatch in number of queueShrink() Calls\", 2,\n+      assertValues(\"number of queueShrink() Calls\", 2,\n           outForOneOp.getOutputStreamStatistics().queueShrink);\n \n     } finally {\n-      if(outForOneOp != null){\n+      if (outForOneOp != null) {\n         outForOneOp.close();\n       }\n     }\n \n     AbfsOutputStream outForLargeOps = null;\n \n     try {\n-      outForLargeOps = (AbfsOutputStream) abfss.createFile(TEST_PATH,\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n           statistics, true,\n           FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n \n+      int largeValue = 1000;\n       //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n       // give 2000 QueueShrink calls\n-      for (int i = 0; i < 1000; i++) {\n+      for (int i = 0; i < largeValue; i++) {\n         outForLargeOps.write(testQueueShrink.getBytes());\n         //Flush is quite expensive so 1000 calls only which takes 1 min+\n         outForLargeOps.flush();", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTIwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751202", "bodyText": "do you have to call it so many times?", "author": "steveloughran", "createdAt": "2020-03-20T16:26:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxMTY5Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404611696", "bodyText": "You can call flush outside the for loop?", "author": "mukund-thakur", "createdAt": "2020-04-07T07:59:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTA1OTgwNg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405059806", "bodyText": "No I can't, basically calling flush after I write means the write task is done. This would trigger the shrinkWriteOperationQueue() method and we need to do it after each write to get 10 calls to shrinkWriteOperationQueue() .\nIf I flush after the loop, it would take all the write calls as 1 write operation and only 1 time the shrinkWriteOperationQueue() method is triggered.", "author": "mehakmeet", "createdAt": "2020-04-07T19:30:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIyODc1Mg=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -134,22 +177,14 @@ public void testAbfsOutputStreamQueueShrink() throws IOException {\n     describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n-    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n-    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n-    FileSystem.Statistics statistics = fs.getFsStatistics();\n     String testQueueShrink = \"testQueue\";\n \n-    AbfsOutputStream outForOneOp = null;\n-\n-    try {\n-      outForOneOp =\n-          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n-              true,\n-              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n \n       //Test for shrinking Queue zero time\n       assertValues(\"number of queueShrink() Calls\", 0,\n-          outForOneOp.getOutputStreamStatistics().queueShrink);\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n \n       outForOneOp.write(testQueueShrink.getBytes());\n       // Queue is shrunk 2 times when outStream is flushed\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMDI0Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r394230246", "bodyText": "Need help on how to write tests for this counter.", "author": "mehakmeet", "createdAt": "2020-03-18T10:04:18Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTYwMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749601", "bodyText": "I don't see any easy way except to assert that it is > 0", "author": "steveloughran", "createdAt": "2020-03-20T16:24:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMDI0Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTc2Mw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749763", "bodyText": "Also, \"time spent\"", "author": "steveloughran", "createdAt": "2020-03-20T16:24:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDIzMDI0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MzU1MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395743551", "bodyText": "this is input stream; presumably it's come in from somewhere else", "author": "steveloughran", "createdAt": "2020-03-20T16:14:20Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsInputStream.java", "diffHunk": "@@ -101,6 +101,7 @@ public synchronized int read(final byte[] b, final int off, final int len) throw\n     int currentLen = len;\n     int lastReadBytes;\n     int totalReadBytes = 0;\n+    incrementReadOps();", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjIzMDE1Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r396230156", "bodyText": "this is from the master PR(#1881)", "author": "mehakmeet", "createdAt": "2020-03-23T06:13:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MzU1MQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0MzkyMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395743922", "bodyText": "move down to under ElasticByteBufferPool", "author": "steveloughran", "createdAt": "2020-03-20T16:15:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -36,20 +36,25 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n \n+import org.apache.hadoop.fs.FileSystem.Statistics;", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6e5cf8b5fd3..1bd17193594 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -36,10 +36,10 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n \n-import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.io.ElasticByteBufferPool;\n+import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.FSExceptionMessages;\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NDQ3NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395744474", "bodyText": "add both new fields at the bottom of the other fields, e.g Line 85, and keep togeher.", "author": "steveloughran", "createdAt": "2020-03-20T16:15:55Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -36,20 +36,25 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n \n+import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.io.ElasticByteBufferPool;\n import org.apache.hadoop.fs.FSExceptionMessages;\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n \n+import static org.apache.hadoop.io.IOUtils.LOG;\n import static org.apache.hadoop.io.IOUtils.wrapException;\n \n /**\n  * The BlobFsOutputStream for Rest AbfsClient.\n  */\n public class AbfsOutputStream extends OutputStream implements Syncable, StreamCapabilities {\n+", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 6e5cf8b5fd3..1bd17193594 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -36,10 +36,10 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n \n-import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AbfsRestOperationException;\n import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.io.ElasticByteBufferPool;\n+import org.apache.hadoop.fs.FileSystem.Statistics;\n import org.apache.hadoop.fs.FSExceptionMessages;\n import org.apache.hadoop.fs.StreamCapabilities;\n import org.apache.hadoop.fs.Syncable;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NTI0OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395745249", "bodyText": "prefer a more detailed description like uploadFailed(long). It's recording that an upload failed and the number of bytes", "author": "steveloughran", "createdAt": "2020-03-20T16:17:15Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,60 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Number of bytes uploaded Successfully.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  void bytesUploadedSuccessfully(long bytes);\n+\n+  /**\n+   * Number of bytes failed to upload.\n+   *\n+   * @param bytes number of bytes that failed to upload\n+   */\n+  void bytesFailed(long bytes);", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex cb6b9b7074a..e21628623f6 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n\n@@ -1,3 +1,21 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs.services;\n \n import org.apache.hadoop.classification.InterfaceStability;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NjAxMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395746011", "bodyText": "MUST NOT use @link to private/package-private/protected methods. Javadoc will fail", "author": "steveloughran", "createdAt": "2020-03-20T16:18:30Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;\n+  public volatile long bytesUploadSuccessful;\n+  public volatile long bytesUploadFailed;\n+  public volatile long timeSpendOnTaskWait;\n+  public volatile long queueShrink;\n+  public volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded only when bytes passed are positive.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  @Override\n+  public void bytesUploadedSuccessfully(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Number of bytes that weren't uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spend for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -1,3 +1,21 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NjI1Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395746252", "bodyText": "see above comment about javadocs", "author": "steveloughran", "createdAt": "2020-03-20T16:18:52Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;\n+  public volatile long bytesUploadSuccessful;\n+  public volatile long bytesUploadFailed;\n+  public volatile long timeSpendOnTaskWait;\n+  public volatile long queueShrink;\n+  public volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded only when bytes passed are positive.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  @Override\n+  public void bytesUploadedSuccessfully(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Number of bytes that weren't uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spend for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}\n+   * @param endTime   on method completing\n+   */\n+  @Override\n+  public void timeSpendTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * Number of calls to {@link AbfsOutputStream#shrinkWriteOperationQueue()}.", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -1,3 +1,21 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0NjMwMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395746300", "bodyText": "see above comment about javadocs", "author": "steveloughran", "createdAt": "2020-03-20T16:18:57Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;\n+  public volatile long bytesUploadSuccessful;\n+  public volatile long bytesUploadFailed;\n+  public volatile long timeSpendOnTaskWait;\n+  public volatile long queueShrink;\n+  public volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded only when bytes passed are positive.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  @Override\n+  public void bytesUploadedSuccessfully(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Number of bytes that weren't uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spend for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@link AbfsOutputStream#waitForTaskToComplete()}\n+   * @param endTime   on method completing\n+   */\n+  @Override\n+  public void timeSpendTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * Number of calls to {@link AbfsOutputStream#shrinkWriteOperationQueue()}.\n+   */\n+  @Override\n+  public void queueShrinked() {\n+    queueShrink++;\n+  }\n+\n+  /**\n+   * Number of calls to {@link AbfsOutputStream#writeCurrentBufferToService()}.", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -1,3 +1,21 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0ODMwNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395748307", "bodyText": "MUST use { } in all if () clauses.\nIf there's a mismatch, use AssertEquals and include the pos where the problem occurred\n\nImagine: \"A remote test run failed -what information should be in the test report to begin debugging this?\"", "author": "steveloughran", "createdAt": "2020-03-20T16:22:08Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java", "diffHunk": "@@ -67,4 +77,46 @@ public void nameThread() {\n   protected int getTestTimeoutMillis() {\n     return TEST_TIMEOUT;\n   }\n+\n+  /**\n+   * Describe a test in the logs.\n+   *\n+   * @param text text to print\n+   * @param args arguments to format in the printing\n+   */\n+  protected void describe(String text, Object... args) {\n+    LOG.info(\"\\n\\n{}: {}\\n\",\n+        methodName.getMethodName(),\n+        String.format(text, args));\n+  }\n+\n+  /**\n+   * Validate Contents written on a file in Abfs.\n+   *\n+   * @param fs                AzureBlobFileSystem\n+   * @param path              Path of the file\n+   * @param originalByteArray original byte array\n+   * @return if content is validated true else, false\n+   * @throws IOException\n+   */\n+  protected boolean validateContent(AzureBlobFileSystem fs, Path path,\n+      byte[] originalByteArray)\n+      throws IOException {\n+    FSDataInputStream in = fs.open(path);\n+\n+    int pos = 0;\n+    int lenOfOriginalByteArray = originalByteArray.length;\n+    byte valueOfContentAtPos = (byte) in.read();\n+\n+    while (valueOfContentAtPos != -1 && pos < lenOfOriginalByteArray) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java\nindex f6805fb88c4..0485422871e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsTestWithTimeout.java\n\n@@ -102,21 +102,28 @@ protected void describe(String text, Object... args) {\n   protected boolean validateContent(AzureBlobFileSystem fs, Path path,\n       byte[] originalByteArray)\n       throws IOException {\n-    FSDataInputStream in = fs.open(path);\n-\n     int pos = 0;\n     int lenOfOriginalByteArray = originalByteArray.length;\n-    byte valueOfContentAtPos = (byte) in.read();\n \n-    while (valueOfContentAtPos != -1 && pos < lenOfOriginalByteArray) {\n-      if (originalByteArray[pos] != valueOfContentAtPos)\n+    try (FSDataInputStream in = fs.open(path)) {\n+      byte valueOfContentAtPos = (byte) in.read();\n+\n+      while (valueOfContentAtPos != -1 && pos < lenOfOriginalByteArray) {\n+        if (originalByteArray[pos] != valueOfContentAtPos) {\n+          assertEquals(\"Mismatch in content validation at position {}\", pos,\n+              originalByteArray[pos], valueOfContentAtPos);\n+          return false;\n+        }\n+        valueOfContentAtPos = (byte) in.read();\n+        pos++;\n+      }\n+      if (valueOfContentAtPos != -1) {\n+        assertEquals(\"Expected end of file\", -1, valueOfContentAtPos);\n         return false;\n-      valueOfContentAtPos = (byte) in.read();\n-      pos++;\n+      }\n+      return true;\n     }\n-    if (valueOfContentAtPos != -1)\n-      return false;\n-    return true;\n+\n   }\n \n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTAyMw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749023", "bodyText": "IOUtils.closeQuietly(LOG, ...), or try-with-resources", "author": "steveloughran", "createdAt": "2020-03-20T16:23:14Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc0OTIxMw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395749213", "bodyText": "same", "author": "steveloughran", "createdAt": "2020-03-20T16:23:31Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MDAxMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395750011", "bodyText": "will need to be closed", "author": "steveloughran", "createdAt": "2020-03-20T16:24:50Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MDQwMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395750400", "bodyText": "try-with-resources or IOUtils.closeQuietly", "author": "steveloughran", "createdAt": "2020-03-20T16:25:28Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MDk2Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395750967", "bodyText": "you are calling createFile() enough in these tests it makes sense to factor out into it own method", "author": "steveloughran", "createdAt": "2020-03-20T16:26:14Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTQ3MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751470", "bodyText": "@code", "author": "steveloughran", "createdAt": "2020-03-20T16:27:00Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n+          statistics, true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 1000;\n+      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n+      // give 2000 QueueShrink calls\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        //Flush is quite expensive so 1000 calls only which takes 1 min+\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 2000 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().queueShrink);\n+    } finally {\n+      if (outForLargeOps != null) {\n+        outForLargeOps.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@codes writeCurrentBufferToService()}", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTc1MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751750", "bodyText": "try-with-resources or IOUtils.closeQuietly", "author": "steveloughran", "createdAt": "2020-03-20T16:27:22Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n+          statistics, true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 1000;\n+      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n+      // give 2000 QueueShrink calls\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        //Flush is quite expensive so 1000 calls only which takes 1 min+\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 2000 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().queueShrink);\n+    } finally {\n+      if (outForLargeOps != null) {\n+        outForLargeOps.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testWriteBuffer = \"Buffer\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTg3MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395751870", "bodyText": "try-with-resources or IOUtils.closeQuietly", "author": "steveloughran", "createdAt": "2020-03-20T16:27:35Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testBytesToUpload = \"bytes\";\n+\n+    AbfsOutputStream outForSomeBytes = null;\n+    try {\n+      outForSomeBytes = (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+          statistics,\n+          true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+\n+      //Test for some bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForSomeBytes != null) {\n+        outForSomeBytes.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeBytes = null;\n+    try {\n+      outForLargeBytes =\n+          (AbfsOutputStream) abfss.createFile(uploadBytesFilePath,\n+              statistics\n+              , true, FsPermission.getDefault(),\n+              FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 100000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+\n+      //Test for large bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          outForLargeBytes.getOutputStreamStatistics().bytesToUpload);\n+\n+      //Test for relation between bytesUploadSuccessful, bytesUploadFailed\n+      // and bytesToUpload\n+      assertValues(\"bytesUploadSuccessful equal to difference between \"\n+              + \"bytesToUpload and bytesUploadFailed\",\n+          outForSomeBytes.getOutputStreamStatistics().bytesUploadSuccessful,\n+          outForSomeBytes.getOutputStreamStatistics().bytesToUpload -\n+              outForSomeBytes.getOutputStreamStatistics().bytesUploadFailed);\n+\n+    } finally {\n+      if (outForLargeBytes != null) {\n+        outForLargeBytes.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check time spend on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpendOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+\n+    AbfsOutputStream out =\n+        (AbfsOutputStream) abfss.createFile(timeSpendFilePath,\n+            statistics, true,\n+            FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@codes shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testQueueShrink = \"testQueue\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(queueShrinkFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().queueShrink);\n+\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+\n+    try {\n+      outForLargeOps = (AbfsOutputStream) abfss.createFile(queueShrinkFilePath,\n+          statistics, true,\n+          FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      int largeValue = 1000;\n+      //QueueShrink is called 2 times in 1 flush(), hence 1000 flushes must\n+      // give 2000 QueueShrink calls\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        //Flush is quite expensive so 1000 calls only which takes 1 min+\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 2000 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().queueShrink);\n+    } finally {\n+      if (outForLargeOps != null) {\n+        outForLargeOps.close();\n+      }\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@codes writeCurrentBufferToService()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+    String testWriteBuffer = \"Buffer\";\n+\n+    AbfsOutputStream outForOneOp = null;\n+\n+    try {\n+      outForOneOp =\n+          (AbfsOutputStream) abfss.createFile(writeBufferFilePath, statistics,\n+              true,\n+              FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+\n+      //Test for zero time writing Buffer to service\n+      assertValues(\"number writeCurrentBufferToService() calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n+\n+      outForOneOp.write(testWriteBuffer.getBytes());\n+      outForOneOp.flush();\n+\n+      //Test for one time writeCurrentBuffer() call\n+      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+          outForOneOp.getOutputStreamStatistics().writeCurrentBufferOperations);\n+    } finally {\n+      if (outForOneOp != null) {\n+        outForOneOp.close();\n+      }\n+    }\n+\n+    AbfsOutputStream outForLargeOps = null;\n+    try {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MjYwOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395752609", "bodyText": "This is sounds like a slow test.\n\nUse smaller values than 1000, e.g. \"10\"\nmake the value a constant used across all tests.", "author": "steveloughran", "createdAt": "2020-03-20T16:28:41Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,278 @@\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nindex 28ccacbec28..0c82a2c065e 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n\n@@ -1,22 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n+import java.util.Random;\n \n import org.junit.Test;\n \n-import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n  */\n public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-\n   public ITestAbfsOutputStream() throws Exception {\n   }\n \n+  private static int LARGE_OPERATIONS = 10;\n+  private static int LOW_RANGE_FOR_RANDOM_VALUE = 50;\n+  private static int HIGH_RANGE_FOR_RANDOM_VALUE = 10000;\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1Mjk0Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395752947", "bodyText": "not needed", "author": "steveloughran", "createdAt": "2020-03-20T16:29:12Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Njg4NDg2MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r396884860", "bodyText": "I think constructor is needed to handle Exception ?", "author": "mehakmeet", "createdAt": "2020-03-24T03:34:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1Mjk0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n\n@@ -18,13 +18,15 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import org.junit.Assert;\n import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.FSDataInputStream;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n \n /**\n  * Test Abfs Stream.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MzIwNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395753205", "bodyText": "IOUtils.closeQuietly", "author": "steveloughran", "createdAt": "2020-03-20T16:29:38Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n\n@@ -18,13 +18,15 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import org.junit.Assert;\n import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.FSDataInputStream;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n \n /**\n  * Test Abfs Stream.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MzQ0Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395753442", "bodyText": "once validateContent raises exceptions, you don't need to wrap in an assert", "author": "steveloughran", "createdAt": "2020-03-20T16:29:59Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {\n+        inForOneOperation.close();\n+      }\n+      if (outForOneOperation != null) {\n+        outForOneOperation.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in the smallOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n\n@@ -18,13 +18,15 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import org.junit.Assert;\n import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.FSDataInputStream;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n \n /**\n  * Test Abfs Stream.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MzgyMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395753822", "bodyText": "IOUtils.closeQuietly", "author": "steveloughran", "createdAt": "2020-03-20T16:30:33Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {\n+        inForOneOperation.close();\n+      }\n+      if (outForOneOperation != null) {\n+        outForOneOperation.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in the smallOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",\n+        validateContent(fs, smallOperationsFile,\n+            testReadWriteOps.getBytes()));\n+\n+    FSDataOutputStream outForLargeOperations = null;\n+    FSDataInputStream inForLargeOperations = null;\n+    StringBuilder largeOperationsValidationString = new StringBuilder();\n+    try {\n+      outForLargeOperations = fs.create(largeOperationsFile);\n+      statistics.reset();\n+      int largeValue = 1000000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOperations.write(testReadWriteOps.getBytes());\n+\n+        //Creating the String for content Validation\n+        largeOperationsValidationString.append(testReadWriteOps);\n+      }\n+\n+      //Test for 1000000 write operations\n+      assertReadWriteOps(\"write\", largeValue, statistics.getWriteOps());\n+\n+      inForLargeOperations = fs.open(largeOperationsFile);\n+      for (int i = 0; i < largeValue; i++)\n+        inForLargeOperations\n+            .read(testReadWriteOps.getBytes(), 0,\n+                testReadWriteOps.getBytes().length);\n+\n+      //Test for 1000000 read operations\n+      assertReadWriteOps(\"read\", largeValue, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForLargeOperations != null) {", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n\n@@ -18,13 +18,15 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import org.junit.Assert;\n import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.FSDataInputStream;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n \n /**\n  * Test Abfs Stream.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NDEwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395754102", "bodyText": "again, superflous with validateContent raising exceptions", "author": "steveloughran", "createdAt": "2020-03-20T16:31:01Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java", "diffHunk": "@@ -0,0 +1,147 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.FSDataOutputStream;\n+import org.apache.hadoop.fs.FSDataInputStream;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+\n+/**\n+ * Test Abfs Stream.\n+ */\n+\n+public class ITestAbfsStreamStatistics extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsStreamStatistics() throws Exception {\n+  }\n+\n+  /***\n+   * Testing {@code incrementReadOps()} in class {@code AbfsInputStream} and\n+   * {@code incrementWriteOps()} in class {@code AbfsOutputStream}.\n+   *\n+   * @throws Exception\n+   */\n+  @Test\n+  public void testAbfsStreamOps() throws Exception {\n+    describe(\"Test to see correct population of read and write operations in \"\n+        + \"Abfs\");\n+\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path smallOperationsFile = new Path(\"testOneReadWriteOps\");\n+    Path largeOperationsFile = new Path(\"testLargeReadWriteOps\");\n+    FileSystem.Statistics statistics = fs.getFsStatistics();\n+    String testReadWriteOps = \"test this\";\n+    statistics.reset();\n+\n+    //Test for zero write operation\n+    assertReadWriteOps(\"write\", 0, statistics.getWriteOps());\n+\n+    //Test for zero read operation\n+    assertReadWriteOps(\"read\", 0, statistics.getReadOps());\n+\n+    FSDataOutputStream outForOneOperation = null;\n+    FSDataInputStream inForOneOperation = null;\n+    try {\n+      outForOneOperation = fs.create(smallOperationsFile);\n+      statistics.reset();\n+      outForOneOperation.write(testReadWriteOps.getBytes());\n+\n+      //Test for a single write operation\n+      assertReadWriteOps(\"write\", 1, statistics.getWriteOps());\n+\n+      inForOneOperation = fs.open(smallOperationsFile);\n+      inForOneOperation.read(testReadWriteOps.getBytes(), 0,\n+          testReadWriteOps.getBytes().length);\n+\n+      //Test for a single read operation\n+      assertReadWriteOps(\"read\", 1, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForOneOperation != null) {\n+        inForOneOperation.close();\n+      }\n+      if (outForOneOperation != null) {\n+        outForOneOperation.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in the smallOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",\n+        validateContent(fs, smallOperationsFile,\n+            testReadWriteOps.getBytes()));\n+\n+    FSDataOutputStream outForLargeOperations = null;\n+    FSDataInputStream inForLargeOperations = null;\n+    StringBuilder largeOperationsValidationString = new StringBuilder();\n+    try {\n+      outForLargeOperations = fs.create(largeOperationsFile);\n+      statistics.reset();\n+      int largeValue = 1000000;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOperations.write(testReadWriteOps.getBytes());\n+\n+        //Creating the String for content Validation\n+        largeOperationsValidationString.append(testReadWriteOps);\n+      }\n+\n+      //Test for 1000000 write operations\n+      assertReadWriteOps(\"write\", largeValue, statistics.getWriteOps());\n+\n+      inForLargeOperations = fs.open(largeOperationsFile);\n+      for (int i = 0; i < largeValue; i++)\n+        inForLargeOperations\n+            .read(testReadWriteOps.getBytes(), 0,\n+                testReadWriteOps.getBytes().length);\n+\n+      //Test for 1000000 read operations\n+      assertReadWriteOps(\"read\", largeValue, statistics.getReadOps());\n+\n+    } finally {\n+      if (inForLargeOperations != null) {\n+        inForLargeOperations.close();\n+      }\n+      if (outForLargeOperations != null) {\n+        outForLargeOperations.close();\n+      }\n+    }\n+\n+    //Validating if content is being written in largeOperationsFile\n+    Assert.assertTrue(\"Mismatch in content validation\",", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\nindex 9bc082c9cb5..b749f496bbf 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsStreamStatistics.java\n\n@@ -18,13 +18,15 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import org.junit.Assert;\n import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import org.apache.hadoop.fs.FSDataOutputStream;\n import org.apache.hadoop.fs.FSDataInputStream;\n import org.apache.hadoop.fs.FileSystem;\n import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.IOUtils;\n \n /**\n  * Test Abfs Stream.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NDUxOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395754519", "bodyText": "add a .close(), even if the original code didn't. Always good to improve a test", "author": "steveloughran", "createdAt": "2020-03-20T16:31:42Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java", "diffHunk": "@@ -143,7 +143,7 @@ public void testBlobDataReader() throws Exception {\n \n     // TEST WRITE FILE\n     try {\n-      abfsStore.openFileForWrite(EXISTED_FILE_PATH, true);\n+      abfsStore.openFileForWrite(EXISTED_FILE_PATH, fs.getFsStatistics(), true);", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java\nindex 5016609676d..e517f685784 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemOauth.java\n\n@@ -146,6 +151,8 @@ public void testBlobDataReader() throws Exception {\n       abfsStore.openFileForWrite(EXISTED_FILE_PATH, fs.getFsStatistics(), true);\n     } catch (AbfsRestOperationException e) {\n       assertEquals(AzureServiceErrorCode.AUTHORIZATION_PERMISSION_MISS_MATCH, e.getErrorCode());\n+    } finally {\n+      IOUtils.cleanupWithLogger(LOG, abfsStore);\n     }\n \n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1NTM4MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r395755381", "bodyText": "let's make these private and have getters", "author": "steveloughran", "createdAt": "2020-03-20T16:33:05Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,102 @@\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@codes writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  public volatile long bytesToUpload;", "originalCommit": "20e1a7f80c6a0bb50889a7ab0d5c4a51ad8b134e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 4da2c077477..c77e2ff3ea4 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -1,3 +1,21 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n"}}, {"oid": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "url": "https://github.com/apache/hadoop/commit/0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "message": "HADOOP-16914. Fixing review comments", "committedDate": "2020-04-01T10:20:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NTE3Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402095177", "bodyText": "explain more", "author": "mehakmeet", "createdAt": "2020-04-02T07:07:42Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Records a successful upload and the number of bytes uploaded.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  void uploadSuccessful(long bytes);\n+\n+  /**\n+   * Records that upload is failed and the number of bytes.\n+   *\n+   * @param bytes number of bytes that failed to upload\n+   */\n+  void uploadFailed(long bytes);\n+\n+  /**\n+   * Time spent in waiting for tasks to be completed in the blocking Queue.", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex e21628623f6..cbd70ceaa8f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n\n@@ -29,40 +29,41 @@\n   /**\n    * Number of bytes to be uploaded.\n    *\n-   * @param bytes number of bytes to upload\n+   * @param bytes number of bytes to upload.\n    */\n   void bytesToUpload(long bytes);\n \n   /**\n    * Records a successful upload and the number of bytes uploaded.\n    *\n-   * @param bytes number of bytes that were successfully uploaded\n+   * @param bytes number of bytes that were successfully uploaded.\n    */\n   void uploadSuccessful(long bytes);\n \n   /**\n    * Records that upload is failed and the number of bytes.\n    *\n-   * @param bytes number of bytes that failed to upload\n+   * @param bytes number of bytes that failed to upload.\n    */\n   void uploadFailed(long bytes);\n \n   /**\n    * Time spent in waiting for tasks to be completed in the blocking Queue.\n    *\n-   * @param start millisecond at which the wait for task to be complete begins\n-   * @param end   millisecond at which the wait is completed for the task\n+   * @param start millisecond at which the wait for task to be complete begins.\n+   * @param end   millisecond at which the wait is completed for the task.\n    */\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code shrinkWriteOperationQueue()}\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n   void queueShrinked();\n \n   /**\n-   * Number of times {@code writeCurrentBufferToService(boolean, boolean)}\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n    * method was called.\n    */\n   void writeCurrentBuffer();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA5NTQxNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402095417", "bodyText": "this java doc above variable name", "author": "mehakmeet", "createdAt": "2020-04-02T07:08:12Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -20,17 +20,20 @@\n \n /**\n  * OutputStream Statistics Implementation for Abfs.\n- * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n- * Blocking Queue in AbfsOutputStream.\n- *\n- * queueShrink - Number of times Blocking Queue was shrunk after writing\n- * data.\n- *\n- * WriteCurrentBufferOperations - Number of times\n- * {@code writeCurrentBufferToService()} calls were made.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n+\n+  /**\n+   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n+   * Blocking Queue in AbfsOutputStream.\n+   *\n+   * queueShrink - Number of times Blocking Queue was shrunk after writing\n+   * data.\n+   *\n+   * WriteCurrentBufferOperations - Number of times the current buffer which\n+   * was written has been forwarded to the service.\n+   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3MDkyMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402070920", "bodyText": "We should be defining here using the interface not concrete class and initialising it in constructor with concrete class implementation. That whole point of using interface is we can change add the new implementation in future and change the the implementation to be used in constructor using some configuration. Right @steveloughran?", "author": "mukund-thakur", "createdAt": "2020-04-02T06:07:07Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -80,6 +82,7 @@\n           = new ElasticByteBufferPool();\n \n   private final Statistics statistics;\n+  private final AbfsOutputStreamStatisticsImpl outputStreamStatistics;", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA2MDIxNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404060217", "bodyText": "yes. Use the interface in reference/args and pass the instance in", "author": "steveloughran", "createdAt": "2020-04-06T12:43:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3MDkyMA=="}], "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex 1bd17193594..64a0aaa783c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -82,7 +82,7 @@\n           = new ElasticByteBufferPool();\n \n   private final Statistics statistics;\n-  private final AbfsOutputStreamStatisticsImpl outputStreamStatistics;\n+  private final AbfsOutputStreamStatistics outputStreamStatistics;\n \n   public AbfsOutputStream(\n       final AbfsClient client,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3MzE2Mw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402073163", "bodyText": "Add trailing . in the end for all java docs.", "author": "mukund-thakur", "createdAt": "2020-04-02T06:13:22Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex e21628623f6..cbd70ceaa8f 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n\n@@ -29,40 +29,41 @@\n   /**\n    * Number of bytes to be uploaded.\n    *\n-   * @param bytes number of bytes to upload\n+   * @param bytes number of bytes to upload.\n    */\n   void bytesToUpload(long bytes);\n \n   /**\n    * Records a successful upload and the number of bytes uploaded.\n    *\n-   * @param bytes number of bytes that were successfully uploaded\n+   * @param bytes number of bytes that were successfully uploaded.\n    */\n   void uploadSuccessful(long bytes);\n \n   /**\n    * Records that upload is failed and the number of bytes.\n    *\n-   * @param bytes number of bytes that failed to upload\n+   * @param bytes number of bytes that failed to upload.\n    */\n   void uploadFailed(long bytes);\n \n   /**\n    * Time spent in waiting for tasks to be completed in the blocking Queue.\n    *\n-   * @param start millisecond at which the wait for task to be complete begins\n-   * @param end   millisecond at which the wait is completed for the task\n+   * @param start millisecond at which the wait for task to be complete begins.\n+   * @param end   millisecond at which the wait is completed for the task.\n    */\n   void timeSpentTaskWait(long start, long end);\n \n   /**\n-   * Number of times {@code shrinkWriteOperationQueue()}\n+   * Number of times {@code AbfsOutputStream#shrinkWriteOperationQueue()}\n    * method was called.\n    */\n   void queueShrinked();\n \n   /**\n-   * Number of times {@code writeCurrentBufferToService(boolean, boolean)}\n+   * Number of times\n+   * {@code AbfsOutputStream#writeCurrentBufferToService(boolean, boolean)}\n    * method was called.\n    */\n   void writeCurrentBuffer();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3NTc4NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402075785", "bodyText": "Write full method in javadoc like AbfsOutputStream#waitForTaskToComplete() otherwise people will have to figure out where this method actually is.", "author": "mukund-thakur", "createdAt": "2020-04-02T06:21:04Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private volatile long bytesToUpload;\n+  private volatile long bytesUploadSuccessful;\n+  private volatile long bytesUploadFailed;\n+  private volatile long timeSpendOnTaskWait;\n+  private volatile long queueShrink;\n+  private volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload failed and the number of bytes.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spent for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@code waitForTaskToComplete()}", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -20,17 +20,20 @@\n \n /**\n  * OutputStream Statistics Implementation for Abfs.\n- * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n- * Blocking Queue in AbfsOutputStream.\n- *\n- * queueShrink - Number of times Blocking Queue was shrunk after writing\n- * data.\n- *\n- * WriteCurrentBufferOperations - Number of times\n- * {@code writeCurrentBufferToService()} calls were made.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n+\n+  /**\n+   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n+   * Blocking Queue in AbfsOutputStream.\n+   *\n+   * queueShrink - Number of times Blocking Queue was shrunk after writing\n+   * data.\n+   *\n+   * WriteCurrentBufferOperations - Number of times the current buffer which\n+   * was written has been forwarded to the service.\n+   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3NjU4NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402076584", "bodyText": "What is the task here? Please explain. This is for all javadocs. There is no harm in writing more lines :P", "author": "mukund-thakur", "createdAt": "2020-04-02T06:23:09Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private volatile long bytesToUpload;\n+  private volatile long bytesUploadSuccessful;\n+  private volatile long bytesUploadFailed;\n+  private volatile long timeSpendOnTaskWait;\n+  private volatile long queueShrink;\n+  private volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload failed and the number of bytes.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spent for waiting a task to be completed.", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -20,17 +20,20 @@\n \n /**\n  * OutputStream Statistics Implementation for Abfs.\n- * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n- * Blocking Queue in AbfsOutputStream.\n- *\n- * queueShrink - Number of times Blocking Queue was shrunk after writing\n- * data.\n- *\n- * WriteCurrentBufferOperations - Number of times\n- * {@code writeCurrentBufferToService()} calls were made.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n+\n+  /**\n+   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n+   * Blocking Queue in AbfsOutputStream.\n+   *\n+   * queueShrink - Number of times Blocking Queue was shrunk after writing\n+   * data.\n+   *\n+   * WriteCurrentBufferOperations - Number of times the current buffer which\n+   * was written has been forwarded to the service.\n+   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3Njg5OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r402076899", "bodyText": "Once again which queue. How is this metrics important??", "author": "mukund-thakur", "createdAt": "2020-04-02T06:23:58Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n+ * Blocking Queue in AbfsOutputStream.\n+ *\n+ * queueShrink - Number of times Blocking Queue was shrunk after writing\n+ * data.\n+ *\n+ * WriteCurrentBufferOperations - Number of times\n+ * {@code writeCurrentBufferToService()} calls were made.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private volatile long bytesToUpload;\n+  private volatile long bytesUploadSuccessful;\n+  private volatile long bytesUploadFailed;\n+  private volatile long timeSpendOnTaskWait;\n+  private volatile long queueShrink;\n+  private volatile long writeCurrentBufferOperations;\n+\n+  /**\n+   * Number of bytes uploaded.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload successful with the number of bytes.\n+   * @param bytes number of bytes that were successfully uploaded\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Upload failed and the number of bytes.\n+   *\n+   * @param bytes negative values are ignored\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Time spent for waiting a task to be completed.\n+   *\n+   * @param startTime on calling {@code waitForTaskToComplete()}\n+   * @param endTime   on method completing\n+   */\n+  @Override\n+  public void timeSpentTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * Number of calls to {@code shrinkWriteOperationQueue()}.\n+   */\n+  @Override\n+  public void queueShrinked() {", "originalCommit": "0e7e9b2c77b19c5704af07b102633a5fe573eb9e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU5MTM3MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404591370", "bodyText": "How is this metrics important??", "author": "mukund-thakur", "createdAt": "2020-04-07T07:24:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3Njg5OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU5MTYyNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404591627", "bodyText": "typo in times, small t in try.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:25:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjA3Njg5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex c77e2ff3ea4..f70c46e7ee8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -20,17 +20,20 @@\n \n /**\n  * OutputStream Statistics Implementation for Abfs.\n- * timeSpendOnTaskWait - Time spend on waiting for tasks to be complete on\n- * Blocking Queue in AbfsOutputStream.\n- *\n- * queueShrink - Number of times Blocking Queue was shrunk after writing\n- * data.\n- *\n- * WriteCurrentBufferOperations - Number of times\n- * {@code writeCurrentBufferToService()} calls were made.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n+\n+  /**\n+   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n+   * Blocking Queue in AbfsOutputStream.\n+   *\n+   * queueShrink - Number of times Blocking Queue was shrunk after writing\n+   * data.\n+   *\n+   * WriteCurrentBufferOperations - Number of times the current buffer which\n+   * was written has been forwarded to the service.\n+   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n"}}, {"oid": "c8c660884cb509c835e6e4941acdddfabad2d2fe", "url": "https://github.com/apache/hadoop/commit/c8c660884cb509c835e6e4941acdddfabad2d2fe", "message": "HADOOP-16914. Java Docs", "committedDate": "2020-04-06T11:51:23Z", "type": "forcePushed"}, {"oid": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "url": "https://github.com/apache/hadoop/commit/2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "message": "HADOOP-16914. Java Docs", "committedDate": "2020-04-06T12:03:06Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU2Mzc3OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404563779", "bodyText": "Change name to ITestAbfsOutputStreamStatictics.", "author": "mukund-thakur", "createdAt": "2020-04-07T06:26:41Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4NzA2Nw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404587067", "bodyText": "Move the constructor down after the class variables.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:17:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU2Mzc3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4NjE5NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404586195", "bodyText": "use path(methodName.getMethodName());. The current code won't create your files under test directory so the cleanup might miss cleaning up them during teardown.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:15:25Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwNjAwNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404606007", "bodyText": "Create a new protected method in the base clase to get methode name using\nmethodName.getMethodName()", "author": "mukund-thakur", "createdAt": "2020-04-07T07:49:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4NjE5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4ODQxNw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404588417", "bodyText": "extract in variable utForSomeBytes.getOutputStreamStatistics(). like it is done at L65.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:19:27Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4OTAxMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404589011", "bodyText": "Same method was present in earlier patch. Move to base class and reuse.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:20:31Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testQueueShrink = \"testQueue\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        outForLargeOps.flush();\n+      }\n+\n+      //Test for 20 queue shrink calls\n+      assertValues(\"number of queueShrink() Calls\",\n+          2 * largeValue,\n+          outForLargeOps.getOutputStreamStatistics().getQueueShrink());\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@code writeCurrentBufferToService()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testWriteBuffer = \"Buffer\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      //Test for zero time writing Buffer to service\n+      assertValues(\"number writeCurrentBufferToService() calls\", 0,\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n+\n+      outForOneOp.write(testWriteBuffer.getBytes());\n+      outForOneOp.flush();\n+\n+      //Test for one time writeCurrentBuffer() call\n+      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+          outForOneOp.getOutputStreamStatistics()\n+              .getWriteCurrentBufferOperations());\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeOps.write(testWriteBuffer.getBytes());\n+        outForLargeOps.flush();\n+      }\n+      //Test for 10 writeBufferOperations\n+      assertValues(\"number of writeCurrentBufferToService() calls\", largeValue,\n+          outForLargeOps\n+              .getOutputStreamStatistics().getWriteCurrentBufferOperations());\n+    }\n+\n+  }\n+\n+  /**\n+   * Generic create File and setting OutputStreamFlush to false.\n+   *\n+   * @param fs   AzureBlobFileSystem that is initialised in the test\n+   * @param path Path of the file to be created\n+   * @return AbfsOutputStream for writing\n+   * @throws AzureBlobFileSystemException\n+   */\n+  private AbfsOutputStream createAbfsOutputStream(AzureBlobFileSystem fs,\n+      Path path) throws AzureBlobFileSystemException {\n+    AzureBlobFileSystemStore abfss = fs.getAbfsStore();\n+    abfss.getAbfsConfiguration().setDisableOutputStreamFlush(false);\n+\n+    return (AbfsOutputStream) abfss.createFile(path, fs.getFsStatistics(),\n+        true, FsPermission.getDefault(), FsPermission.getUMask(fs.getConf()));\n+  }\n+\n+  /**\n+   * Generic assert method.\n+   *\n+   * @param operation     operation being asserted\n+   * @param expectedValue value that is expected\n+   * @param actualValue   value that is actual\n+   */", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDU4OTc3OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404589778", "bodyText": "Move the java doc to corresponding variables.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:22:01Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+\n+  /**\n+   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n+   * Blocking Queue in AbfsOutputStream.\n+   *\n+   * queueShrink - Number of times Blocking Queue was shrunk after writing\n+   * data.\n+   *\n+   * WriteCurrentBufferOperations - Number of times the current buffer which\n+   * was written has been forwarded to the service.\n+   */", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex f70c46e7ee8..6c06cf0e35b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -23,22 +23,28 @@\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n-\n-  /**\n-   * timeSpentOnTaskWait - Time spent on waiting for tasks to be complete on\n-   * Blocking Queue in AbfsOutputStream.\n-   *\n-   * queueShrink - Number of times Blocking Queue was shrunk after writing\n-   * data.\n-   *\n-   * WriteCurrentBufferOperations - Number of times the current buffer which\n-   * was written has been forwarded to the service.\n-   */\n   private volatile long bytesToUpload;\n   private volatile long bytesUploadSuccessful;\n   private volatile long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n   private volatile long timeSpendOnTaskWait;\n-  private volatile long queueShrink;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private volatile long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n   private volatile long writeCurrentBufferOperations;\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMDU5Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404600592", "bodyText": "Should go down after if clause?", "author": "mukund-thakur", "createdAt": "2020-04-07T07:40:15Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -294,19 +299,23 @@ private synchronized void flushInternalAsync() throws IOException {\n   }\n \n   private synchronized void writeCurrentBufferToService() throws IOException {\n+    outputStreamStatistics.writeCurrentBuffer();", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjg0NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405022845", "bodyText": "yes, let's do that", "author": "steveloughran", "createdAt": "2020-04-07T18:27:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMDU5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex ee15980ca78..b5467de06b7 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -299,10 +301,10 @@ private synchronized void flushInternalAsync() throws IOException {\n   }\n \n   private synchronized void writeCurrentBufferToService() throws IOException {\n-    outputStreamStatistics.writeCurrentBuffer();\n     if (bufferIndex == 0) {\n       return;\n     }\n+    outputStreamStatistics.writeCurrentBuffer();\n \n     final byte[] bytes = buffer;\n     final int bytesLength = bufferIndex;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMTA4NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404601085", "bodyText": "I don't understand the benifits of capturing this metric?", "author": "mukund-thakur", "createdAt": "2020-04-07T07:41:07Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -384,6 +398,7 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n+    outputStreamStatistics.queueShrinked();", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMzI5NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405023294", "bodyText": "it would also be \"queueShrunk\" as a name", "author": "steveloughran", "createdAt": "2020-04-07T18:28:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMTA4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTA2MTM1OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405061359", "bodyText": "It is an expensive method. So, I thought it would benefit in knowing how many times it's being called after some write operations.\nSorry for the spelling mistake.", "author": "mehakmeet", "createdAt": "2020-04-07T19:33:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwMTA4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex ee15980ca78..b5467de06b7 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -398,7 +400,7 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n-    outputStreamStatistics.queueShrinked();\n+    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwNDk4OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404604989", "bodyText": "Use LARGE_OPERATIONS directly. Why to create a new variable.", "author": "mukund-thakur", "createdAt": "2020-04-07T07:48:07Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwNTYyOA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404605628", "bodyText": "same use path(getMethodName())", "author": "mukund-thakur", "createdAt": "2020-04-07T07:49:06Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYwODI5OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404608299", "bodyText": "Looks like this an UT. Should move under UT folder. Create a new class TestAbfsOutputStreamStatictics and write all UT's there. You don't even have to create a file there. What do you say @steveloughran?", "author": "mukund-thakur", "createdAt": "2020-04-07T07:53:35Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxODY1MA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404618650", "bodyText": "I can see you are disabling flush in createAbfsOutputStream(). Then why are you expecting double the actual values?", "author": "mukund-thakur", "createdAt": "2020-04-07T08:10:56Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java", "diffHunk": "@@ -0,0 +1,294 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n+  public ITestAbfsOutputStream() throws Exception {\n+  }\n+\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      //Test for zero bytes To upload\n+      assertValues(\"bytes to upload\", 0,\n+          outForSomeBytes.getOutputStreamStatistics().getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      int largeValue = LARGE_OPERATIONS;\n+      for (int i = 0; i < largeValue; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload\n+      assertValues(\"bytes to upload\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded\n+      assertValues(\"successful bytes uploaded\",\n+          largeValue * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask\n+      assertValues(\"Time spent on waiting tasks\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test\n+       */\n+      assertValues(\"Time spent on waiting tasks\", smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@code shrinkWriteOperationQueue()}\n+   * calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = new Path(\"AbfsOutputStreamStatsPath\");\n+    String testQueueShrink = \"testQueue\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      //Test for shrinking Queue zero time\n+      assertValues(\"number of queueShrink() Calls\", 0,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outStream is flushed\n+      outForOneOp.flush();\n+\n+      //Test for shrinking Queue 2 times\n+      assertValues(\"number of queueShrink() Calls\", 2,\n+          outForOneOp.getOutputStreamStatistics().getQueueShrink());\n+\n+    }\n+", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDgwNzAwNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r404807005", "bodyText": "I am setting disableOutputStreamFlush to false, which implies flush is enabled.", "author": "mehakmeet", "createdAt": "2020-04-07T13:26:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxODY1MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwOTYyMQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405109621", "bodyText": "I had a mistake in the comments of that method so, that is why you could've assumed it to be disabling flush. Sorry for that.", "author": "mehakmeet", "createdAt": "2020-04-07T21:00:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDYxODY1MA=="}], "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nsimilarity index 66%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex 6c29ef9dc06..d36a5441304 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -32,14 +32,15 @@\n /**\n  * Test AbfsOutputStream statistics.\n  */\n-public class ITestAbfsOutputStream extends AbstractAbfsIntegrationTest {\n-  public ITestAbfsOutputStream() throws Exception {\n-  }\n-\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n   private static final int LARGE_OPERATIONS = 10;\n   private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n   private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n \n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n   /**\n    * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAyMjYxMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405022610", "bodyText": "let's guard this with a LOG.isDebugEnabled(), because that toString() operation is doing enough work. Or, use this as the argument and have SLF4J Call this.toString() only if it is printing the log entry", "author": "steveloughran", "createdAt": "2020-04-07T18:27:16Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -279,6 +283,7 @@ public synchronized void close() throws IOException {\n         threadExecutor.shutdownNow();\n       }\n     }\n+    LOG.debug(\"Closing AbfsOutputStream \", toString());", "originalCommit": "2bada7fb3bd6bf93de926ffa07fbf346fc3fbf61", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex ee15980ca78..b5467de06b7 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -283,7 +283,9 @@ public synchronized void close() throws IOException {\n         threadExecutor.shutdownNow();\n       }\n     }\n-    LOG.debug(\"Closing AbfsOutputStream \", toString());\n+    if (LOG.isDebugEnabled()) {\n+      LOG.debug(\"Closing AbfsOutputStream \", toString());\n+    }\n   }\n \n   private synchronized void flushInternal(boolean isClose) throws IOException {\n"}}, {"oid": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "url": "https://github.com/apache/hadoop/commit/7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "message": "HADOOP-16914. Fixing comments and tests", "committedDate": "2020-04-07T20:47:46Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTEwNjQ1Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r405106456", "bodyText": "*disableOutputStreamFlush", "author": "mehakmeet", "createdAt": "2020-04-07T20:54:21Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,296 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+import org.apache.hadoop.fs.permission.FsPermission;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploading in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = path(getMethodName());\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (AbfsOutputStream outForSomeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)\n+    ) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for zero bytes To upload.\n+      assertValues(\"bytes to upload\", 0,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n+\n+      //Populating random value for bytesFailed.\n+      int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatisticsForUploadBytes.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload.\n+      assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadFailed());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeBytes = createAbfsOutputStream(fs,\n+        uploadBytesFilePath)) {\n+\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+      //Populating random values for bytesFailed.\n+      int randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+      //Test for bytes failed to upload.\n+      assertValues(\"bytes failed to upload\", randomBytesFailed,\n+          abfsOutputStreamStatistics.getBytesUploadFailed());\n+    }\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() throws IOException {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path timeSpendFilePath = path(getMethodName());\n+\n+    try (AbfsOutputStream out = createAbfsOutputStream(fs, timeSpendFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          out.getOutputStreamStatistics();\n+\n+      //Test for initial value of timeSpentWaitTask.\n+      assertValues(\"Time spent on waiting tasks\", 0,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int smallRandomStartTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+      int smallRandomEndTime =\n+          new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+              + smallRandomStartTime;\n+      int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+      //Test for small random value of timeSpentWaitTask.\n+      assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+      int largeRandomStartTime =\n+          new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+      int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+          + largeRandomStartTime;\n+      int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+      abfsOutputStreamStatistics\n+          .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      in previous test.\n+       */\n+      assertValues(\"Time spend on waiting for tasks to complete\",\n+          smallDiff + randomDiff,\n+          abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+    }\n+\n+  }\n+\n+  /**\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamQueueShrink() throws IOException {\n+    describe(\"Testing Queue Shrink calls in AbfsOutputStream\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path queueShrinkFilePath = path(getMethodName());\n+    String testQueueShrink = \"testQueue\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue zero time.\n+      assertValues(\"Queue shrunk operations\", 0,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+      outForOneOp.write(testQueueShrink.getBytes());\n+      // Queue is shrunk 2 times when outputStream is flushed.\n+      outForOneOp.flush();\n+\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for shrinking Queue 2 times.\n+      assertValues(\"Queue shrunk operations\", 2,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n+\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        queueShrinkFilePath)) {\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeOps.write(testQueueShrink.getBytes());\n+        outForLargeOps.flush();\n+      }\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+\n+      //Test for 20 queue shrink operations.\n+      assertValues(\"Queue shrunk operations\",\n+          2 * LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getQueueShrunkOps());\n+    }\n+\n+  }\n+\n+  /**\n+   * Test to check number of {@code\n+   * AbfsOutputStream#writeCurrentBufferToService()} calls.\n+   * After writing data, AbfsOutputStream doesn't upload data till flush() is\n+   * called. Hence, flush() calls were made after write() to simulate the\n+   * scenario.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamWriteBuffer() throws IOException {\n+    describe(\"Testing writeCurrentBufferToService() calls\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path writeBufferFilePath = path(getMethodName());\n+    String testWriteBuffer = \"Buffer\";\n+\n+    try (AbfsOutputStream outForOneOp = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for zero time writing Buffer to service.\n+      assertValues(\"number writeCurrentBufferToService() calls\", 0,\n+          abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n+\n+      outForOneOp.write(testWriteBuffer.getBytes());\n+      outForOneOp.flush();\n+\n+      abfsOutputStreamStatistics = outForOneOp.getOutputStreamStatistics();\n+\n+      //Test for one time writeCurrentBuffer() call.\n+      assertValues(\"number writeCurrentBufferToService() calls\", 1,\n+          abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n+    }\n+\n+    try (AbfsOutputStream outForLargeOps = createAbfsOutputStream(fs,\n+        writeBufferFilePath)) {\n+\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeOps.write(testWriteBuffer.getBytes());\n+        outForLargeOps.flush();\n+      }\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeOps.getOutputStreamStatistics();\n+      //Test for 10 writeBufferOperations.\n+      assertValues(\"number of writeCurrentBufferToService() calls\",\n+          LARGE_OPERATIONS,\n+          abfsOutputStreamStatistics.getWriteCurrentBufferOperations());\n+    }\n+\n+  }\n+\n+  /**\n+   * Generic create File and setting OutputStreamFlush to false.", "originalCommit": "7e58998ff063bc8a11b7fa3cea711f95a1e71bc3", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8d86c63f4053d4843323ff58341f2f2a78676625", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex d36a5441304..c24e1412384 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -19,15 +19,12 @@\n package org.apache.hadoop.fs.azurebfs;\n \n import java.io.IOException;\n-import java.util.Random;\n \n import org.junit.Test;\n \n import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.azurebfs.contracts.exceptions.AzureBlobFileSystemException;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n-import org.apache.hadoop.fs.permission.FsPermission;\n \n /**\n  * Test AbfsOutputStream statistics.\n"}}, {"oid": "8d86c63f4053d4843323ff58341f2f2a78676625", "url": "https://github.com/apache/hadoop/commit/8d86c63f4053d4843323ff58341f2f2a78676625", "message": "HADOOP-16914. Fixing comments and tests", "committedDate": "2020-04-08T17:39:23Z", "type": "forcePushed"}, {"oid": "09d0deab572c8ddf34bba64b25437949380356bc", "url": "https://github.com/apache/hadoop/commit/09d0deab572c8ddf34bba64b25437949380356bc", "message": "HADOOP-16914 AbfsOutputStream Counter\n\nChange-Id: Ie976f23c6c3e2f5cf9167794357cfc669a232c80", "committedDate": "2020-04-09T06:43:22Z", "type": "forcePushed"}, {"oid": "a667ab0820443fde451225be1f628f7f451005da", "url": "https://github.com/apache/hadoop/commit/a667ab0820443fde451225be1f628f7f451005da", "message": "HADOOP-16914 AbfsOutputStream Counter\n\nChange-Id: Ie976f23c6c3e2f5cf9167794357cfc669a232c80", "committedDate": "2020-04-14T12:27:26Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE1NDgxOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408154819", "bodyText": "typo.. Remove first word bytes.", "author": "mukund-thakur", "createdAt": "2020-04-14T13:54:41Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload.\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Records a successful upload and the number of bytes uploaded.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded.\n+   */\n+  void uploadSuccessful(long bytes);\n+\n+  /**\n+   * Records that upload is failed and the number of bytes.\n+   *\n+   * @param bytes number of bytes that failed to upload.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4NTM3Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408485372", "bodyText": "that is the name of the param, description follows. It would be color coded in an IDE.", "author": "mehakmeet", "createdAt": "2020-04-14T23:02:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE1NDgxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n\n@@ -48,7 +48,7 @@\n   void uploadFailed(long bytes);\n \n   /**\n-   * Time spent in waiting for tasks to be completed in the blocking Queue.\n+   * Time spent in waiting for tasks to be completed in the blocking queue.\n    *\n    * @param start millisecond at which the wait for task to be complete begins.\n    * @param end   millisecond at which the wait is completed for the task.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE1NDkxOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408154919", "bodyText": "typo.. Remove first word bytes.", "author": "mukund-thakur", "createdAt": "2020-04-14T13:54:48Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+\n+/**\n+ * Interface for {@link AbfsOutputStream} statistics.\n+ */\n+@InterfaceStability.Unstable\n+public interface AbfsOutputStreamStatistics {\n+\n+  /**\n+   * Number of bytes to be uploaded.\n+   *\n+   * @param bytes number of bytes to upload.\n+   */\n+  void bytesToUpload(long bytes);\n+\n+  /**\n+   * Records a successful upload and the number of bytes uploaded.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\nindex 9bdfbda91fe..c9fe0dd4552 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatistics.java\n\n@@ -48,7 +48,7 @@\n   void uploadFailed(long bytes);\n \n   /**\n-   * Time spent in waiting for tasks to be completed in the blocking Queue.\n+   * Time spent in waiting for tasks to be completed in the blocking queue.\n    *\n    * @param start millisecond at which the wait for task to be complete begins.\n    * @param end   millisecond at which the wait is completed for the task.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODQwNA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178404", "bodyText": "A better test would to be call multiple times and see if the summation is working fine rather that resetting the stats?", "author": "mukund-thakur", "createdAt": "2020-04-14T14:25:25Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ5NjA0OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408496049", "bodyText": "I can use the previous value(L61) and see if it's being summed by removing the reset?", "author": "mehakmeet", "createdAt": "2020-04-14T23:35:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODQwNA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import java.io.IOException;\n import java.util.Random;\n \n import org.junit.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODkxMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178910", "bodyText": "Indentation.", "author": "mukund-thakur", "createdAt": "2020-04-14T14:26:03Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import java.io.IOException;\n import java.util.Random;\n \n import org.junit.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTMzMw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179333", "bodyText": "same as comment on L68.", "author": "mukund-thakur", "createdAt": "2020-04-14T14:26:38Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4Njc1Ng==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408486756", "bodyText": "actually in this test I am testing the summation, by expecting a summed value of test at L101 in test at L115. Should I do something similar for above tests(L68) ? or should I do multiple summations using loops ?", "author": "mehakmeet", "createdAt": "2020-04-14T23:06:42Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTMzMw=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import java.io.IOException;\n import java.util.Random;\n \n import org.junit.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4MTAwOQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408181009", "bodyText": "remove bytes.", "author": "mukund-thakur", "createdAt": "2020-04-14T14:28:44Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n+  private long writeCurrentBufferOperations;\n+\n+  /**\n+   * Records the need to upload bytes and increments the total bytes that\n+   * needs to be uploaded.\n+   *\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3MjEwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408172102", "bodyText": "just create your own static LOG", "author": "steveloughran", "createdAt": "2020-04-14T14:17:16Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -279,6 +283,9 @@ public synchronized void close() throws IOException {\n         threadExecutor.shutdownNow();\n       }\n     }\n+    if (LOG.isDebugEnabled()) {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3MzgzMA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408173830", "bodyText": "remember that discussion we had about volatile vs long and you concluded that we could shut yetus up by going non volatile?\nIn #1820 I've moved s3a input stream stats to volatile so that the IOStatistics gets the latest values without blocking...and then turned off findbugs warnings (or at least, I'm trying to)", "author": "steveloughran", "createdAt": "2020-04-14T14:19:30Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY4MTk2Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408681962", "bodyText": "I thought we concluded that AbfsInputStream and AbfsOutputStream uses synchronized for thread safety and we don't need either volatile or AtomicLong for the counters.\nShould I use volatile and suppress the warnings ?", "author": "mehakmeet", "createdAt": "2020-04-15T08:49:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3MzgzMA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDMyNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408174325", "bodyText": "not needed; just cut it", "author": "steveloughran", "createdAt": "2020-04-14T14:20:08Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ4NzcxNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408487715", "bodyText": "Think I need to handle Exception for this Test, and don't know any way other than making a constructor and doing so.", "author": "mehakmeet", "createdAt": "2020-04-14T23:09:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDMyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ3MjA5MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r411472091", "bodyText": "test suites can throw exceptions, but the constructor shouldn't have to. But if you want to keep it, then go ahead and keep it. It's not important", "author": "steveloughran", "createdAt": "2020-04-20T15:28:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDMyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -31,34 +31,31 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int LARGE_OPERATIONS = 10;\n+  private static final int OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)\n+            fs, uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertValues(\"bytes to upload\", 0,\n+      assertEquals(\"Mismatch in bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NDg5OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408174898", "bodyText": "nit: pull up to previous line", "author": "steveloughran", "createdAt": "2020-04-14T14:20:53Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = path(getMethodName());\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (\n+        AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n+            fs,\n+            uploadBytesFilePath)\n+    ) {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -31,34 +31,31 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int LARGE_OPERATIONS = 10;\n+  private static final int OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)\n+            fs, uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertValues(\"bytes to upload\", 0,\n+      assertEquals(\"Mismatch in bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NTM2NA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408175364", "bodyText": "nit: just cut these lines from the javadoc. Nice to see the rest of the detail", "author": "steveloughran", "createdAt": "2020-04-14T14:21:28Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,233 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Test AbfsOutputStream statistics.\n+ */\n+public class ITestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+  private static final int LARGE_OPERATIONS = 10;\n+\n+  public ITestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamUploadingBytes() throws IOException {\n+    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    Path uploadBytesFilePath = path(getMethodName());\n+    String testBytesToUpload = \"bytes\";\n+\n+    try (\n+        AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n+            fs,\n+            uploadBytesFilePath)\n+    ) {\n+\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for zero bytes To upload.\n+      assertValues(\"bytes to upload\", 0,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      outForSomeBytes.write(testBytesToUpload.getBytes());\n+      outForSomeBytes.flush();\n+      abfsOutputStreamStatisticsForUploadBytes =\n+          outForSomeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\", testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          testBytesToUpload.getBytes().length,\n+          abfsOutputStreamStatisticsForUploadBytes.getBytesUploadSuccessful());\n+\n+    }\n+\n+    try (\n+        AbfsOutputStream outForLargeBytes = createAbfsOutputStreamWithFlushEnabled(\n+            fs,\n+            uploadBytesFilePath)) {\n+\n+      for (int i = 0; i < LARGE_OPERATIONS; i++) {\n+        outForLargeBytes.write(testBytesToUpload.getBytes());\n+      }\n+      outForLargeBytes.flush();\n+      AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+          outForLargeBytes.getOutputStreamStatistics();\n+\n+      //Test for bytes to upload.\n+      assertValues(\"bytes to upload\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesToUpload());\n+\n+      //Test for successful bytes uploaded.\n+      assertValues(\"successful bytes uploaded\",\n+          LARGE_OPERATIONS * (testBytesToUpload.getBytes().length),\n+          abfsOutputStreamStatistics.getBytesUploadSuccessful());\n+\n+    }\n+  }\n+\n+  /**\n+   * Tests to check number of {@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} calls.\n+   * After writing data, AbfsOutputStream doesn't upload the data until\n+   * Flushed. Hence, flush() method is called after write() to test Queue\n+   * shrink calls.\n+   *\n+   * @throws IOException", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyNzYzNA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408627634", "bodyText": "So, the throws comments from all the javadoc in the tests, right ?", "author": "mehakmeet", "createdAt": "2020-04-15T07:13:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NTM2NA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\nindex a41aeef3022..bda95cbc814 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsOutputStreamStatistics.java\n\n@@ -31,34 +31,31 @@\n  */\n public class ITestAbfsOutputStreamStatistics\n     extends AbstractAbfsIntegrationTest {\n-  private static final int LARGE_OPERATIONS = 10;\n+  private static final int OPERATIONS = 10;\n \n   public ITestAbfsOutputStreamStatistics() throws Exception {\n   }\n \n   /**\n-   * Tests to check bytes Uploaded successfully in {@link AbfsOutputStream}.\n-   *\n-   * @throws IOException\n+   * Tests to check bytes uploaded successfully in {@link AbfsOutputStream}.\n    */\n   @Test\n   public void testAbfsOutputStreamUploadingBytes() throws IOException {\n-    describe(\"Testing Bytes uploaded successfully in AbfsOutputSteam\");\n+    describe(\"Testing bytes uploaded successfully by AbfsOutputSteam\");\n     final AzureBlobFileSystem fs = getFileSystem();\n     Path uploadBytesFilePath = path(getMethodName());\n     String testBytesToUpload = \"bytes\";\n \n     try (\n         AbfsOutputStream outForSomeBytes = createAbfsOutputStreamWithFlushEnabled(\n-            fs,\n-            uploadBytesFilePath)\n+            fs, uploadBytesFilePath)\n     ) {\n \n       AbfsOutputStreamStatisticsImpl abfsOutputStreamStatisticsForUploadBytes =\n           outForSomeBytes.getOutputStreamStatistics();\n \n       //Test for zero bytes To upload.\n-      assertValues(\"bytes to upload\", 0,\n+      assertEquals(\"Mismatch in bytes to upload\", 0,\n           abfsOutputStreamStatisticsForUploadBytes.getBytesToUpload());\n \n       outForSomeBytes.write(testBytesToUpload.getBytes());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408176558", "bodyText": "why is this being cast rather than returned as is?", "author": "steveloughran", "createdAt": "2020-04-14T14:22:57Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -436,4 +453,28 @@ private void waitForTaskToComplete() throws IOException {\n   public synchronized void waitForPendingUploads() throws IOException {\n     waitForTaskToComplete();\n   }\n+\n+  /**\n+   * Getter method for AbfsOutputStream Statistics.\n+   *\n+   * @return statistics for AbfsOutputStream.\n+   */\n+  @VisibleForTesting\n+  public AbfsOutputStreamStatisticsImpl getOutputStreamStatistics() {", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ5Mjk5NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408492995", "bodyText": "I think it expects to return AbfsOutputStreamStatisticsImpl, and if we return just AbfsOutputStreamStatistics, it would give rise to incompatible types error.", "author": "mehakmeet", "createdAt": "2020-04-14T23:25:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY4MDg1Mg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408680852", "bodyText": "I could cast in the tests where this is called, but I thought it would easier to cast here than casting there as there would be many calls to this method.", "author": "mehakmeet", "createdAt": "2020-04-15T08:47:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTQ3NDU0NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r411474545", "bodyText": "this would be coding into the implementation/semi-public API something only relevant for testing -and make it very hard to ever change to a different implementation.\nJust add some static method in the test suite\nAbfsOutputStreamStatisticsImp getStreamStatistics(AbfsOutputStream)\n\nand you could do the casting in just one place.", "author": "steveloughran", "createdAt": "2020-04-20T15:31:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NjU1OA=="}], "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex b5467de06b7..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -455,7 +460,7 @@ public synchronized void waitForPendingUploads() throws IOException {\n   }\n \n   /**\n-   * Getter method for AbfsOutputStream Statistics.\n+   * Getter method for AbfsOutputStream statistics.\n    *\n    * @return statistics for AbfsOutputStream.\n    */\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3NzkzMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408177932", "bodyText": "too vague a name and no obvious difference with assertEquals.\nPropose:\n\nleave existing test alone,\nand then one of\nuse Junit assertEquals()\nor Assertions.assertThat(object).describedAs().equals().", "author": "steveloughran", "createdAt": "2020-04-14T14:24:44Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java", "diffHunk": "@@ -383,4 +391,34 @@ protected AbfsDelegationTokenManager getDelegationTokenManager()\n       throws IOException {\n     return getFileSystem().getDelegationTokenManager();\n   }\n+\n+  /**\n+   * Generic assert method.\n+   *\n+   * @param operation     operation being asserted.\n+   * @param expectedValue value that is expected.\n+   * @param actualValue   value that is actual.\n+   */\n+  protected void assertValues(String operation, long expectedValue,", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\nindex dab9b91e01f..4d9fc5cae73 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/AbstractAbfsIntegrationTest.java\n\n@@ -392,18 +392,6 @@ protected AbfsDelegationTokenManager getDelegationTokenManager()\n     return getFileSystem().getDelegationTokenManager();\n   }\n \n-  /**\n-   * Generic assert method.\n-   *\n-   * @param operation     operation being asserted.\n-   * @param expectedValue value that is expected.\n-   * @param actualValue   value that is actual.\n-   */\n-  protected void assertValues(String operation, long expectedValue,\n-      long actualValue) {\n-    assertEquals(\"Mismatch in \" + operation, expectedValue, actualValue);\n-  }\n-\n   /**\n    * Generic create File and enabling AbfsOutputStream Flush.\n    *\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODE5OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178198", "bodyText": "nit: typo", "author": "steveloughran", "createdAt": "2020-04-14T14:25:08Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import java.io.IOException;\n import java.util.Random;\n \n import org.junit.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODMxMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178312", "bodyText": "typo", "author": "steveloughran", "createdAt": "2020-04-14T14:25:18Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import java.io.IOException;\n import java.util.Random;\n \n import org.junit.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3ODQ5OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408178498", "bodyText": "nit: newline", "author": "steveloughran", "createdAt": "2020-04-14T14:25:32Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+  }\n+\n+}", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import java.io.IOException;\n import java.util.Random;\n \n import org.junit.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTA5MQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179091", "bodyText": "don't think we need capitals here", "author": "steveloughran", "createdAt": "2020-04-14T14:26:17Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n+  private long writeCurrentBufferOperations;\n+\n+  /**\n+   * Records the need to upload bytes and increments the total bytes that\n+   * needs to be uploaded.\n+   *\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes successfully uploaded through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded. Negative\n+   *              bytes are ignored.\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes failed to upload through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes failed to upload. Negative bytes are ignored.\n+   */\n+  @Override\n+  public void uploadFailed(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadFailed += bytes;\n+    }\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * Records the total time spent waiting for a task.\n+   * When the thread executor has a task\n+   * queue{@link java.util.concurrent.BlockingQueue} of size greater than or equal to 2\n+   * times the maxConcurrentRequestCounts then, it waits for a task in that\n+   * queue to finish, then do the next task in the queue.\n+   *\n+   * This time spent while waiting for the task to be completed is being\n+   * recorded in this counter.\n+   *\n+   * @param startTime time(in milliseconds) before the wait for task to be\n+   *                  completed is begin.\n+   * @param endTime   time(in milliseconds) after the wait for the task to be\n+   *                  completed is done.\n+   */\n+  @Override\n+  public void timeSpentTaskWait(long startTime, long endTime) {\n+    timeSpendOnTaskWait += endTime - startTime;\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream try to remove the completed\n+   * write operations from the beginning of write operation FIFO queue.\n+   */\n+  @Override\n+  public void queueShrunk() {\n+    queueShrunkOps++;\n+  }\n+\n+  /**\n+   * {@inheritDoc}\n+   *\n+   * Records the number of times AbfsOutputStream writes the buffer to the\n+   * service via the AbfsClient and appends the buffer to the service.\n+   */\n+  @Override\n+  public void writeCurrentBuffer() {\n+    writeCurrentBufferOperations++;\n+  }\n+\n+  public long getBytesToUpload() {\n+    return bytesToUpload;\n+  }\n+\n+  public long getBytesUploadSuccessful() {\n+    return bytesUploadSuccessful;\n+  }\n+\n+  public long getBytesUploadFailed() {\n+    return bytesUploadFailed;\n+  }\n+\n+  public long getTimeSpendOnTaskWait() {\n+    return timeSpendOnTaskWait;\n+  }\n+\n+  public long getQueueShrunkOps() {\n+    return queueShrunkOps;\n+  }\n+\n+  public long getWriteCurrentBufferOperations() {\n+    return writeCurrentBufferOperations;\n+  }\n+\n+  /**\n+   * String to show AbfsOutputStream statistics values in AbfsOutputStream.\n+   *\n+   * @return String with AbfsOutputStream statistics.\n+   */\n+  @Override public String toString() {\n+    final StringBuilder outputStreamStats = new StringBuilder(\n+        \"OutputStream Statistics{\");\n+    outputStreamStats.append(\", BYTES_UPLOAD=\").append(bytesToUpload);", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTU5Mw==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179593", "bodyText": "timeSpent", "author": "steveloughran", "createdAt": "2020-04-14T14:26:58Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE3OTczNQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408179735", "bodyText": "typo", "author": "steveloughran", "createdAt": "2020-04-14T14:27:09Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4MTU2OA==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408181568", "bodyText": "Remove bytes.", "author": "mukund-thakur", "createdAt": "2020-04-14T14:29:23Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java", "diffHunk": "@@ -0,0 +1,177 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+/**\n+ * OutputStream Statistics Implementation for Abfs.\n+ */\n+public class AbfsOutputStreamStatisticsImpl\n+    implements AbfsOutputStreamStatistics {\n+  private long bytesToUpload;\n+  private long bytesUploadSuccessful;\n+  private long bytesUploadFailed;\n+  /**\n+   * counter to get the total time spent while waiting for tasks to complete\n+   * in the Blocking queue inside the thread executor.\n+   */\n+  private long timeSpendOnTaskWait;\n+  /**\n+   * counter to get the total number of queue shrink operations done{@code\n+   * AbfsOutputStream#shrinkWriteOperationQueue()} by\n+   * AbfsOutputStream to remove the write operations which were successfully\n+   * done by AbfsOutputStream from the Blocking Queue.\n+   */\n+  private long queueShrunkOps;\n+  /**\n+   * counter to get the total number of times the current buffer is written\n+   * to the service{@code AbfsOutputStream#writeCurrentBufferToService()} via\n+   * AbfsClient and appended to the\n+   * Data store by\n+   * AbfsResOperation.\n+   */\n+  private long writeCurrentBufferOperations;\n+\n+  /**\n+   * Records the need to upload bytes and increments the total bytes that\n+   * needs to be uploaded.\n+   *\n+   * @param bytes Total bytes to upload. Negative bytes are ignored.\n+   */\n+  @Override\n+  public void bytesToUpload(long bytes) {\n+    if (bytes > 0) {\n+      bytesToUpload += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes successfully uploaded through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes that were successfully uploaded. Negative\n+   *              bytes are ignored.\n+   */\n+  @Override\n+  public void uploadSuccessful(long bytes) {\n+    if (bytes > 0) {\n+      bytesUploadSuccessful += bytes;\n+    }\n+  }\n+\n+  /**\n+   * Records the total bytes failed to upload through AbfsOutputStream.\n+   *\n+   * @param bytes number of bytes failed to upload. Negative bytes are ignored.", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\nindex 17b1f50c582..cd5a29e217c 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStreamStatisticsImpl.java\n\n@@ -19,7 +19,7 @@\n package org.apache.hadoop.fs.azurebfs.services;\n \n /**\n- * OutputStream Statistics Implementation for Abfs.\n+ * OutputStream statistics implementation for Abfs.\n  */\n public class AbfsOutputStreamStatisticsImpl\n     implements AbfsOutputStreamStatistics {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4ODI3NQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408188275", "bodyText": "No new line at the end. I think this will cause checkstyle issue.", "author": "mukund-thakur", "createdAt": "2020-04-14T14:38:04Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.util.Random;\n+\n+import org.junit.Test;\n+\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStream;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n+\n+/**\n+ * Unit Tests for AbfsOutputStream Statistics.\n+ */\n+public class TestAbfsOutputStreamStatistics\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int LOW_RANGE_FOR_RANDOM_VALUE = 49;\n+  private static final int HIGH_RANGE_FOR_RANDOM_VALUE = 9999;\n+\n+  public TestAbfsOutputStreamStatistics() throws Exception {\n+  }\n+\n+  /**\n+   * Tests to check bytes failed to Upload in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamBytesFailed() {\n+    describe(\"Testing Bytes Failed during uploading in AbfsOutputSteam\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for zero bytes uploaded.\n+    assertValues(\"number fo bytes failed to upload\", 0,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Populating small random value for bytesFailed.\n+    int randomBytesFailed = new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+\n+    //Initializing again to reset the statistics.\n+    abfsOutputStreamStatistics = new AbfsOutputStreamStatisticsImpl();\n+\n+    //Populating large random values for bytesFailed.\n+    randomBytesFailed = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    abfsOutputStreamStatistics.uploadFailed(randomBytesFailed);\n+    //Test for bytes failed to upload.\n+    assertValues(\"number fo bytes failed to upload\", randomBytesFailed,\n+        abfsOutputStreamStatistics.getBytesUploadFailed());\n+  }\n+\n+  /**\n+   * Tests to check time spent on waiting for tasks to be complete on a\n+   * blocking queue in {@link AbfsOutputStream}.\n+   *\n+   * @throws IOException\n+   */\n+  @Test\n+  public void testAbfsOutputStreamTimeSpentOnWaitTask() {\n+    describe(\"Testing Time Spend on Waiting for Task to be complete\");\n+\n+    AbfsOutputStreamStatisticsImpl abfsOutputStreamStatistics =\n+        new AbfsOutputStreamStatisticsImpl();\n+\n+    //Test for initial value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", 0,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int smallRandomStartTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE);\n+    int smallRandomEndTime =\n+        new Random().nextInt(LOW_RANGE_FOR_RANDOM_VALUE)\n+            + smallRandomStartTime;\n+    int smallDiff = smallRandomEndTime - smallRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(smallRandomStartTime, smallRandomEndTime);\n+    //Test for small random value of timeSpentWaitTask.\n+    assertValues(\"Time spend on waiting for tasks to complete\", smallDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+\n+    int largeRandomStartTime =\n+        new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE);\n+    int largeRandomEndTime = new Random().nextInt(HIGH_RANGE_FOR_RANDOM_VALUE)\n+        + largeRandomStartTime;\n+    int randomDiff = largeRandomEndTime - largeRandomStartTime;\n+    abfsOutputStreamStatistics\n+        .timeSpentTaskWait(largeRandomStartTime, largeRandomEndTime);\n+      /*\n+      Test for large random value of timeSpentWaitTask plus the time spent\n+      waiting in previous test.\n+       */\n+    assertValues(\"Time spend on waiting for tasks to complete\",\n+        smallDiff + randomDiff,\n+        abfsOutputStreamStatistics.getTimeSpendOnTaskWait());\n+  }\n+\n+}", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\nindex 7d313b0e46b..9a76c2e27e6 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/TestAbfsOutputStreamStatistics.java\n\n@@ -18,7 +18,6 @@\n \n package org.apache.hadoop.fs.azurebfs;\n \n-import java.io.IOException;\n import java.util.Random;\n \n import org.junit.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODk5MjE4OQ==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r408992189", "bodyText": "Queue is not actually getting shrunk here, rather inside the while loop. I'll change this and the respective tests.", "author": "mehakmeet", "createdAt": "2020-04-15T16:56:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java", "diffHunk": "@@ -384,6 +400,7 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n+    outputStreamStatistics.queueShrunk();", "originalCommit": "a667ab0820443fde451225be1f628f7f451005da", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\nindex b5467de06b7..6974db92557 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsOutputStream.java\n\n@@ -400,12 +404,13 @@ private synchronized void flushWrittenBytesToServiceInternal(final long offset,\n    * operation FIFO queue.\n    */\n   private synchronized void shrinkWriteOperationQueue() throws IOException {\n-    outputStreamStatistics.queueShrunk();\n     try {\n       while (writeOperations.peek() != null && writeOperations.peek().task.isDone()) {\n         writeOperations.peek().task.get();\n         lastTotalAppendOffset += writeOperations.peek().length;\n         writeOperations.remove();\n+        // Incrementing statistics to indicate queue has been shrunk.\n+        outputStreamStatistics.queueShrunk();\n       }\n     } catch (Exception e) {\n       if (e.getCause() instanceof AzureBlobFileSystemException) {\n"}}, {"oid": "e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "url": "https://github.com/apache/hadoop/commit/e3f98e6a60c1e9f7bff7772cbc1a82b98af96e9e", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-16T08:22:06Z", "type": "forcePushed"}, {"oid": "490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "url": "https://github.com/apache/hadoop/commit/490d33c1e9ce88c2d9340ee2ed471ab30bc6e48d", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-16T09:02:06Z", "type": "forcePushed"}, {"oid": "51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "url": "https://github.com/apache/hadoop/commit/51ea8fbaa3ce030182c6eda841fb9228d3eb352d", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-16T09:56:49Z", "type": "forcePushed"}, {"oid": "01880f57c1ed21e208bb1c17330ac7b613c8b990", "url": "https://github.com/apache/hadoop/commit/01880f57c1ed21e208bb1c17330ac7b613c8b990", "message": "HADOOP-16914. fixing review comments", "committedDate": "2020-04-21T06:12:43Z", "type": "forcePushed"}, {"oid": "f0543e1bd0d994b6f284c825fffffe92ddd06218", "url": "https://github.com/apache/hadoop/commit/f0543e1bd0d994b6f284c825fffffe92ddd06218", "message": "HADOOP-16914. fixing review comments", "committedDate": "2020-04-22T07:03:56Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzcwODkwMg==", "url": "https://github.com/apache/hadoop/pull/1899#discussion_r413708902", "bodyText": "needs to go in with the org.apache block", "author": "steveloughran", "createdAt": "2020-04-23T10:42:15Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -51,6 +51,7 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import com.google.common.base.Strings;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;", "originalCommit": "73c4c69fec5a6ac3b19db1619e1e83c9354e24ce", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "745c377d1a0c57c845ce18298b999566379079a1", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex 18e85ce99e5..6b194a41de2 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n\n@@ -51,7 +51,6 @@\n import com.google.common.annotations.VisibleForTesting;\n import com.google.common.base.Preconditions;\n import com.google.common.base.Strings;\n-import org.apache.hadoop.fs.azurebfs.services.AbfsOutputStreamStatisticsImpl;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n"}}, {"oid": "745c377d1a0c57c845ce18298b999566379079a1", "url": "https://github.com/apache/hadoop/commit/745c377d1a0c57c845ce18298b999566379079a1", "message": "HADOOP-16914 AbfsOutputStream Counter\n\nChange-Id: Ie976f23c6c3e2f5cf9167794357cfc669a232c80", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "url": "https://github.com/apache/hadoop/commit/fd6fe8976fd7ee03a22709ec779eba3cc632b0bb", "message": "HADOOP-16914. review comments", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "url": "https://github.com/apache/hadoop/commit/b2f08581ce853e6cb26a8ca39a3c73c520c00d40", "message": "HADOOP-16914. queueShrunkOps and tests", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "f98a76c746e68fce59593841e881387f7dd74b0d", "url": "https://github.com/apache/hadoop/commit/f98a76c746e68fce59593841e881387f7dd74b0d", "message": "HADOOP-16914. fixing review comments", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "424bb884bd9e96b3893075bcd8ef4158f4f8187b", "url": "https://github.com/apache/hadoop/commit/424bb884bd9e96b3893075bcd8ef4158f4f8187b", "message": "HADOOP-16914. Passing statistics through abfsOutputStreamContext", "committedDate": "2020-04-23T10:47:46Z", "type": "commit"}, {"oid": "424bb884bd9e96b3893075bcd8ef4158f4f8187b", "url": "https://github.com/apache/hadoop/commit/424bb884bd9e96b3893075bcd8ef4158f4f8187b", "message": "HADOOP-16914. Passing statistics through abfsOutputStreamContext", "committedDate": "2020-04-23T10:47:46Z", "type": "forcePushed"}]}