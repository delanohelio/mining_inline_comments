{"pr_number": 2528, "pr_title": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy", "pr_createdAt": "2020-12-07T17:15:16Z", "pr_url": "https://github.com/apache/hadoop/pull/2528", "timeline": [{"oid": "147f2caaf142aad28510391cdb33df68abe210fb", "url": "https://github.com/apache/hadoop/commit/147f2caaf142aad28510391cdb33df68abe210fb", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy", "committedDate": "2020-12-08T00:06:59Z", "type": "forcePushed"}, {"oid": "def653ae9ddbaf48a0eebc84ee800733fde67aa9", "url": "https://github.com/apache/hadoop/commit/def653ae9ddbaf48a0eebc84ee800733fde67aa9", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy", "committedDate": "2020-12-08T14:41:53Z", "type": "commit"}, {"oid": "def653ae9ddbaf48a0eebc84ee800733fde67aa9", "url": "https://github.com/apache/hadoop/commit/def653ae9ddbaf48a0eebc84ee800733fde67aa9", "message": "HDFS-15716. WaitforReplication in TestUpgradeDomainBlockPlacementPolicy", "committedDate": "2020-12-08T14:41:53Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTEyNzI1OA==", "url": "https://github.com/apache/hadoop/pull/2528#discussion_r541127258", "bodyText": "Why not leave this static import?", "author": "goiri", "createdAt": "2020-12-11T17:59:32Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestUpgradeDomainBlockPlacementPolicy.java", "diffHunk": "@@ -231,32 +229,34 @@ public Boolean get() {\n         } catch (IOException ioe) {\n           return false;\n         }\n-        for(LocatedBlock block : locatedBlocks.getLocatedBlocks()) {\n+        for (LocatedBlock block : locatedBlocks.getLocatedBlocks()) {\n           Set<DatanodeInfo> locs = new HashSet<>();\n           for (DatanodeInfo datanodeInfo : block.getLocations()) {\n-            if (datanodeInfo.getAdminState() ==\n-                DatanodeInfo.AdminStates.NORMAL) {\n+            if (datanodeInfo.getAdminState().equals(\n+                DatanodeInfo.AdminStates.NORMAL)) {\n               locs.add(datanodeInfo);\n             }\n           }\n           for (DatanodeID datanodeID : expectedDatanodeIDs) {\n-            successful = successful && locs.contains(datanodeID);\n+            if (!locs.contains(datanodeID)) {\n+              return false;\n+            }\n           }\n         }\n-        return successful;\n+        return true;\n       }\n-    }, 1000, 60000);\n+    }, 1000, WAIT_TIMEOUT_MS);\n \n     // Verify block placement policy of each block.\n-    LocatedBlocks locatedBlocks;\n-    locatedBlocks =\n+    LocatedBlocks locatedBlocks =\n         cluster.getFileSystem().getClient().getLocatedBlocks(\n             path.toString(), 0, fileSize);\n-    for(LocatedBlock block : locatedBlocks.getLocatedBlocks()) {\n-      BlockPlacementStatus status = cluster.getNamesystem().getBlockManager().\n-          getBlockPlacementPolicy().verifyBlockPlacement(\n-              block.getLocations(), REPLICATION_FACTOR);\n-      assertTrue(status.isPlacementPolicySatisfied());", "originalCommit": "def653ae9ddbaf48a0eebc84ee800733fde67aa9", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjg0Mjg3Ng==", "url": "https://github.com/apache/hadoop/pull/2528#discussion_r542842876", "bodyText": "Sorry @goiri  I did not know that static imports are preferred. I remembered it used to be not favorable because of code readability.\nI will take a note of that for future changes.", "author": "amahussein", "createdAt": "2020-12-14T21:59:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTEyNzI1OA=="}], "type": "inlineReview", "revised_code": null}]}