{"pr_number": 2511, "pr_title": "HDFS-15704. Mitigate lease monitor's rapid infinite loop.", "pr_createdAt": "2020-12-02T03:01:35Z", "pr_url": "https://github.com/apache/hadoop/pull/2511", "timeline": [{"oid": "c4ea07f63f462f041eacb81d1d6db243c28b6c99", "url": "https://github.com/apache/hadoop/commit/c4ea07f63f462f041eacb81d1d6db243c28b6c99", "message": "HDFS-15704. Mitigate lease monitor's rapid infinite loop.", "committedDate": "2020-12-02T19:57:17Z", "type": "forcePushed"}, {"oid": "6912c97006fa39afb9a5b8c653b630d4e361a3fb", "url": "https://github.com/apache/hadoop/commit/6912c97006fa39afb9a5b8c653b630d4e361a3fb", "message": "HDFS-15704. replace TreeMap by HashMap for time optimizations", "committedDate": "2020-12-03T16:03:42Z", "type": "forcePushed"}, {"oid": "3cdb03728c6b07319f3f485b6595c6b0c78090d6", "url": "https://github.com/apache/hadoop/commit/3cdb03728c6b07319f3f485b6595c6b0c78090d6", "message": "HDFS-15704. replace TreeMap by HashMap for time optimizations", "committedDate": "2020-12-04T14:30:27Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc0NDc0NA==", "url": "https://github.com/apache/hadoop/pull/2511#discussion_r542744744", "bodyText": "This explanation belongs in the Jira, not in a comment in the code.  When looking at current code, it's not really clear why you are talking about TreeMap at all.\nAlso, I think this comment misses the point of the TreeMap.  The reason a TreeMap was used here was to maintain a sorted order, which allowed the checkLeases() to exit the while loop as soon as it hit an unexpired lease.\nThe new design removes the need for the TreeMap by pruning the list it passes to checkLeases().", "author": "jbrennan333", "createdAt": "2020-12-14T20:26:49Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java", "diffHunk": "@@ -92,21 +91,15 @@\n   private long lastHolderUpdateTime;\n   private String internalLeaseHolder;\n \n+  //\n   // Used for handling lock-leases\n   // Mapping: leaseHolder -> Lease\n-  private final SortedMap<String, Lease> leases = new TreeMap<>();\n-  // Set of: Lease\n-  private final NavigableSet<Lease> sortedLeases = new TreeSet<>(\n-      new Comparator<Lease>() {\n-        @Override\n-        public int compare(Lease o1, Lease o2) {\n-          if (o1.getLastUpdate() != o2.getLastUpdate()) {\n-            return Long.signum(o1.getLastUpdate() - o2.getLastUpdate());\n-          } else {\n-            return o1.holder.compareTo(o2.holder);\n-          }\n-        }\n-  });\n+  // TreeMap has O(log(n)) complexity but it is more space efficient\n+  //             compared to HashMap. Therefore, replacing TreeMap with a\n+  //             HashMap can be considered to get faster O(1) time complexity\n+  //             on the expense of 30% memory waste.\n+  //", "originalCommit": "3cdb03728c6b07319f3f485b6595c6b0c78090d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b086f8f9f869bc264e0a57b5b8f93eed604d20b0", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\nindex 8e974cfa8a8..cb62b7d8892 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n\n@@ -94,12 +92,12 @@\n   //\n   // Used for handling lock-leases\n   // Mapping: leaseHolder -> Lease\n-  // TreeMap has O(log(n)) complexity but it is more space efficient\n+  //TODO: TreeMap has O(log(n)) complexity but it is more space efficient\n   //             compared to HashMap. Therefore, replacing TreeMap with a\n   //             HashMap can be considered to get faster O(1) time complexity\n   //             on the expense of 30% memory waste.\n   //\n-  private final HashMap<String, Lease> leases = new HashMap<>();\n+  private final SortedMap<String, Lease> leases = new TreeMap<>();\n   // INodeID -> Lease\n   private final TreeMap<Long, Lease> leasesById = new TreeMap<>();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1MzgwMA==", "url": "https://github.com/apache/hadoop/pull/2511#discussion_r542753800", "bodyText": "I much prefer the loop in @daryn-sharp's original code.\nCollection<Lease> expired = new HashSet<>();\nfor (Lease lease : leases) {\n  if (lease.expiredHardLimit(now)) {\n    expired.add(lease);\n  }\n}\n\nThis streams code will have to change if we want to pull this back to branch 2.\nI think @daryn-sharp  also said that stream()'s are more expensive.", "author": "jbrennan333", "createdAt": "2020-12-14T20:35:19Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java", "diffHunk": "@@ -515,6 +508,13 @@ public void setLeasePeriod(long softLimit, long hardLimit) {\n     this.softLimit = softLimit;\n     this.hardLimit = hardLimit; \n   }\n+\n+  private synchronized Collection<Lease> getExpiredCandidateLeases() {\n+    final long now = Time.monotonicNow();\n+    return leases.values().stream()\n+        .filter(lease -> lease.expiredHardLimit(now))\n+        .collect(Collectors.toCollection(HashSet::new));\n+  }", "originalCommit": "3cdb03728c6b07319f3f485b6595c6b0c78090d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b086f8f9f869bc264e0a57b5b8f93eed604d20b0", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\nindex 8e974cfa8a8..cb62b7d8892 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n\n@@ -510,10 +508,14 @@ public void setLeasePeriod(long softLimit, long hardLimit) {\n   }\n \n   private synchronized Collection<Lease> getExpiredCandidateLeases() {\n-    final long now = Time.monotonicNow();\n-    return leases.values().stream()\n-        .filter(lease -> lease.expiredHardLimit(now))\n-        .collect(Collectors.toCollection(HashSet::new));\n+    long now = Time.monotonicNow();\n+    Collection<Lease> expired = new HashSet<>();\n+    for (Lease lease : leases.values()) {\n+      if (lease.expiredHardLimit(now)) {\n+        expired.add(lease);\n+      }\n+    }\n+    return expired;\n   }\n   \n   /******************************************************\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1ODc0Nw==", "url": "https://github.com/apache/hadoop/pull/2511#discussion_r542758747", "bodyText": "This LOG.isDebugEnabled() check is not needed anymore.", "author": "jbrennan333", "createdAt": "2020-12-14T20:40:24Z", "path": "hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java", "diffHunk": "@@ -541,10 +550,10 @@ public void run() {\n               fsnamesystem.getEditLog().logSync();\n             }\n           }\n-  \n-          Thread.sleep(fsnamesystem.getLeaseRecheckIntervalMs());\n         } catch(InterruptedException ie) {\n-          LOG.debug(\"{} is interrupted\", name, ie);\n+          if (LOG.isDebugEnabled()) {", "originalCommit": "3cdb03728c6b07319f3f485b6595c6b0c78090d6", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "50c356391dfbe8b41007be74170fd1125b3731f8", "chunk": "diff --git a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\nindex 8e974cfa8a8..f6f240dae1f 100644\n--- a/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n+++ b/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/namenode/LeaseManager.java\n\n@@ -551,9 +550,7 @@ public void run() {\n             }\n           }\n         } catch(InterruptedException ie) {\n-          if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"{} is interrupted\", name, ie);\n-          }\n+          LOG.debug(\"{} is interrupted\", name, ie);\n         } catch(Throwable e) {\n           LOG.warn(\"Unexpected throwable: \", e);\n         }\n"}}, {"oid": "b086f8f9f869bc264e0a57b5b8f93eed604d20b0", "url": "https://github.com/apache/hadoop/commit/b086f8f9f869bc264e0a57b5b8f93eed604d20b0", "message": "HDFS-15704. Mitigate lease monitor's rapid infinite loop.", "committedDate": "2020-12-14T22:01:15Z", "type": "commit"}, {"oid": "c8b8ca26f8abc7a08d7635424c7a729754b5933e", "url": "https://github.com/apache/hadoop/commit/c8b8ca26f8abc7a08d7635424c7a729754b5933e", "message": "HDFS-15704. replace TreeMap by HashMap for time optimizations", "committedDate": "2020-12-14T22:01:15Z", "type": "commit"}, {"oid": "50c356391dfbe8b41007be74170fd1125b3731f8", "url": "https://github.com/apache/hadoop/commit/50c356391dfbe8b41007be74170fd1125b3731f8", "message": "HDFS-15704. address code reviews", "committedDate": "2020-12-14T22:01:15Z", "type": "commit"}, {"oid": "50c356391dfbe8b41007be74170fd1125b3731f8", "url": "https://github.com/apache/hadoop/commit/50c356391dfbe8b41007be74170fd1125b3731f8", "message": "HDFS-15704. address code reviews", "committedDate": "2020-12-14T22:01:15Z", "type": "forcePushed"}]}