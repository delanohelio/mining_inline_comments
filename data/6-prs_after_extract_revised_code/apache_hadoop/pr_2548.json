{"pr_number": 2548, "pr_title": "HADOOP-17475. ABFS: Implementing ListStatusRemoteIterator", "pr_createdAt": "2020-12-15T06:18:29Z", "pr_url": "https://github.com/apache/hadoop/pull/2548", "timeline": [{"oid": "f00cd4e303722bbd7e283034c41def74f7c35d8c", "url": "https://github.com/apache/hadoop/commit/f00cd4e303722bbd7e283034c41def74f7c35d8c", "message": "Implementing ListStatusRemoteIterator", "committedDate": "2020-12-15T06:32:41Z", "type": "commit"}, {"oid": "f00cd4e303722bbd7e283034c41def74f7c35d8c", "url": "https://github.com/apache/hadoop/commit/f00cd4e303722bbd7e283034c41def74f7c35d8c", "message": "Implementing ListStatusRemoteIterator", "committedDate": "2020-12-15T06:32:41Z", "type": "forcePushed"}, {"oid": "baeceb0c4b9efb9513f3cff102f47c152c09e137", "url": "https://github.com/apache/hadoop/commit/baeceb0c4b9efb9513f3cff102f47c152c09e137", "message": "Added test cases. Improved ListIteraor logic.", "committedDate": "2020-12-30T03:31:50Z", "type": "commit"}, {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102", "url": "https://github.com/apache/hadoop/commit/13ddf5274a425bf83c8b25176f53b9e10be03102", "message": "Making the server calls as a background activity", "committedDate": "2020-12-30T11:14:03Z", "type": "commit"}, {"oid": "13ddf5274a425bf83c8b25176f53b9e10be03102", "url": "https://github.com/apache/hadoop/commit/13ddf5274a425bf83c8b25176f53b9e10be03102", "message": "Making the server calls as a background activity", "committedDate": "2020-12-30T11:14:03Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NDU0Mw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550174543", "bodyText": "ArrayBlockingQueue", "author": "vinaysbadami", "createdAt": "2020-12-30T12:15:56Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =", "originalCommit": "13ddf5274a425bf83c8b25176f53b9e10be03102", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4OTE3Mg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557589172", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NDU0Mw=="}], "type": "inlineReview", "revised_code": {"commit": "fc40333f784888c1c381b07472a077d455fd499a", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nindex 6fc4ebe1533..919d82352c8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n\n@@ -20,11 +20,11 @@\n \n import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.LinkedList;\n+import java.util.Collections;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.ListIterator;\n import java.util.NoSuchElementException;\n-import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.CompletableFuture;\n \n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NTMwNQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550175305", "bodyText": "ioExcetion and currentIterator to null", "author": "vinaysbadami", "createdAt": "2020-12-30T12:18:28Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;", "originalCommit": "13ddf5274a425bf83c8b25176f53b9e10be03102", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4OTM0Ng==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557589346", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:04:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NTMwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "fc40333f784888c1c381b07472a077d455fd499a", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nindex 6fc4ebe1533..919d82352c8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n\n@@ -20,11 +20,11 @@\n \n import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.LinkedList;\n+import java.util.Collections;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.ListIterator;\n import java.util.NoSuchElementException;\n-import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.CompletableFuture;\n \n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NTc2MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550175761", "bodyText": "Move to line 106", "author": "vinaysbadami", "createdAt": "2020-12-30T12:19:46Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    fetchAllAsync();\n+    updateCurrentIterator();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    synchronized (this) {\n+      while (!isIterationComplete() && iteratorsQueue.isEmpty()) {\n+        try {\n+          this.wait();\n+        } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n+          LOG.error(\"Thread got interrupted: {}\", e);\n+        }\n+      }\n+      if (!iteratorsQueue.isEmpty()) {\n+        currIterator = iteratorsQueue.poll();\n+      } else if (ioException != null) {\n+        throw ioException;\n+      }\n+    }\n+  }\n+\n+  private void fetchAllAsync() {\n+    CompletableFuture.supplyAsync(() -> {\n+      while (!isIterationComplete()) {\n+        List<FileStatus> fileStatuses = new ArrayList<>();\n+        try {\n+          continuation = abfsStore\n+              .listStatus(path, null, fileStatuses, FETCH_ALL_FALSE,\n+                  continuation);\n+        } catch (IOException e) {\n+          ioException = e;\n+          return null;\n+        } finally {\n+          if (firstRead) {\n+            firstRead = false;\n+          }\n+        }\n+        if (fileStatuses != null && !fileStatuses.isEmpty()) {", "originalCommit": "13ddf5274a425bf83c8b25176f53b9e10be03102", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4OTYxOQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557589619", "bodyText": "Not doing, since the same has to be in the same synchronous block fetching the first page", "author": "bilaharith", "createdAt": "2021-01-14T18:04:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NTc2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "fc40333f784888c1c381b07472a077d455fd499a", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nindex 6fc4ebe1533..919d82352c8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n\n@@ -20,11 +20,11 @@\n \n import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.LinkedList;\n+import java.util.Collections;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.ListIterator;\n import java.util.NoSuchElementException;\n-import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.CompletableFuture;\n \n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NjA0Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550176047", "bodyText": "we just need to add to queue", "author": "vinaysbadami", "createdAt": "2020-12-30T12:20:55Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    fetchAllAsync();\n+    updateCurrentIterator();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    synchronized (this) {\n+      while (!isIterationComplete() && iteratorsQueue.isEmpty()) {\n+        try {\n+          this.wait();\n+        } catch (InterruptedException e) {\n+          Thread.currentThread().interrupt();\n+          LOG.error(\"Thread got interrupted: {}\", e);\n+        }\n+      }\n+      if (!iteratorsQueue.isEmpty()) {\n+        currIterator = iteratorsQueue.poll();\n+      } else if (ioException != null) {\n+        throw ioException;\n+      }\n+    }\n+  }\n+\n+  private void fetchAllAsync() {\n+    CompletableFuture.supplyAsync(() -> {\n+      while (!isIterationComplete()) {\n+        List<FileStatus> fileStatuses = new ArrayList<>();\n+        try {\n+          continuation = abfsStore\n+              .listStatus(path, null, fileStatuses, FETCH_ALL_FALSE,\n+                  continuation);\n+        } catch (IOException e) {\n+          ioException = e;\n+          return null;\n+        } finally {\n+          if (firstRead) {\n+            firstRead = false;\n+          }\n+        }\n+        if (fileStatuses != null && !fileStatuses.isEmpty()) {\n+          iteratorsQueue.add(fileStatuses.listIterator());\n+          synchronized (this) {", "originalCommit": "13ddf5274a425bf83c8b25176f53b9e10be03102", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4OTc1NA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557589754", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3NjA0Nw=="}], "type": "inlineReview", "revised_code": {"commit": "fc40333f784888c1c381b07472a077d455fd499a", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nindex 6fc4ebe1533..919d82352c8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n\n@@ -20,11 +20,11 @@\n \n import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.LinkedList;\n+import java.util.Collections;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.ListIterator;\n import java.util.NoSuchElementException;\n-import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.CompletableFuture;\n \n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3ODU5OQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550178599", "bodyText": "Let us avoid blocking in the ctor", "author": "vinaysbadami", "createdAt": "2020-12-30T12:29:39Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.ListIterator;\n+import java.util.NoSuchElementException;\n+import java.util.Queue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final Queue<ListIterator<FileStatus>> iteratorsQueue =\n+      new LinkedList<>();\n+\n+  private boolean firstRead = true;\n+  private String continuation;\n+  private ListIterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) throws IOException {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    fetchAllAsync();\n+    updateCurrentIterator();", "originalCommit": "13ddf5274a425bf83c8b25176f53b9e10be03102", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU4OTg5NQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557589895", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:05:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE3ODU5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "fc40333f784888c1c381b07472a077d455fd499a", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nindex 6fc4ebe1533..919d82352c8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n\n@@ -20,11 +20,11 @@\n \n import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.LinkedList;\n+import java.util.Collections;\n+import java.util.Iterator;\n import java.util.List;\n-import java.util.ListIterator;\n import java.util.NoSuchElementException;\n-import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.CompletableFuture;\n \n import org.slf4j.Logger;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE4MDUyNg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r550180526", "bodyText": "spacing etc\ncontinuation.IsEmpty", "author": "vinaysbadami", "createdAt": "2020-12-30T12:37:05Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -862,16 +871,16 @@ public FileStatus getFileStatus(final Path path) throws IOException {\n             startFrom);\n \n     final String relativePath = getRelativePath(path);\n-    String continuation = null;\n \n-    // generate continuation token if a valid startFrom is provided.\n-    if (startFrom != null && !startFrom.isEmpty()) {\n-      continuation = getIsNamespaceEnabled()\n-              ? generateContinuationTokenForXns(startFrom)\n-              : generateContinuationTokenForNonXns(relativePath, startFrom);\n+    if(continuation==null ||continuation.length()<1) {", "originalCommit": "13ddf5274a425bf83c8b25176f53b9e10be03102", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MDAwMQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557590001", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:05:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDE4MDUyNg=="}], "type": "inlineReview", "revised_code": {"commit": "fc40333f784888c1c381b07472a077d455fd499a", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex e4866f3d7ba..d6a2b9a36c7 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n\n@@ -872,12 +871,12 @@ public String listStatus(final Path path, final String startFrom,\n \n     final String relativePath = getRelativePath(path);\n \n-    if(continuation==null ||continuation.length()<1) {\n+    if (continuation == null || continuation.length() < 1) {\n       // generate continuation token if a valid startFrom is provided.\n       if (startFrom != null && !startFrom.isEmpty()) {\n-        continuation = getIsNamespaceEnabled() ?\n-            generateContinuationTokenForXns(startFrom) :\n-            generateContinuationTokenForNonXns(relativePath, startFrom);\n+        continuation = getIsNamespaceEnabled()\n+            ? generateContinuationTokenForXns(startFrom)\n+            : generateContinuationTokenForNonXns(relativePath, startFrom);\n       }\n     }\n \n"}}, {"oid": "fc40333f784888c1c381b07472a077d455fd499a", "url": "https://github.com/apache/hadoop/commit/fc40333f784888c1c381b07472a077d455fd499a", "message": "Making the async call exit if the queue is full. Adding more test cases.", "committedDate": "2021-01-11T04:38:13Z", "type": "commit"}, {"oid": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "url": "https://github.com/apache/hadoop/commit/9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "message": "Merge branch 'trunk' into lsitr", "committedDate": "2021-01-11T04:47:55Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcyNjA0MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554726041", "bodyText": "needs to be done under lock", "author": "vinaysbadami", "createdAt": "2021-01-11T05:01:18Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      isAsyncInProgress = false;", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MTM1Mg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557591352", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:07:31Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDcyNjA0MQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nsimilarity index 87%\nrename from hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nrename to hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 919d82352c8..be25288617b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -33,31 +33,30 @@\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n \n-public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n \n   private static final Logger LOG = LoggerFactory\n-      .getLogger(ListStatusRemoteIterator.class);\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n \n   private static final boolean FETCH_ALL_FALSE = false;\n   private static final int MAX_QUEUE_SIZE = 10;\n \n   private final Path path;\n-  private final AzureBlobFileSystemStore abfsStore;\n+  private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n+  private volatile boolean isAsyncInProgress = false;\n   private boolean firstBatch = true;\n-  private boolean isAsyncInProgress = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n   private IOException ioException;\n \n-  public ListStatusRemoteIterator(final Path path,\n-      final AzureBlobFileSystemStore abfsStore) {\n+  public AbfsListStatusRemoteIterator(final Path path,\n+      final ListingSupport listingSupport) {\n     this.path = path;\n-    this.abfsStore = abfsStore;\n+    this.listingSupport = listingSupport;\n     iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n     currIterator = Collections.emptyIterator();\n     fetchBatchesAsync();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDczNDE3OQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554734179", "bodyText": "do under config", "author": "vinaysbadami", "createdAt": "2021-01-11T05:13:19Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -982,6 +984,14 @@ public boolean exists(Path f) throws IOException {\n     return super.exists(f);\n   }\n \n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(Path path)\n+      throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MTQwNQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557591405", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:07:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDczNDE3OQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\nindex d391ac947aa..f6f81860536 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n\n@@ -988,8 +989,14 @@ public boolean exists(Path f) throws IOException {\n   public RemoteIterator<FileStatus> listStatusIterator(Path path)\n       throws IOException {\n     LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);\n-    Path qualifiedPath = makeQualified(path);\n-    return new ListStatusRemoteIterator(qualifiedPath, abfsStore);\n+    if (abfsStore.getAbfsConfiguration().enableAbfsListIterator()) {\n+      Path qualifiedPath = makeQualified(path);\n+      AbfsListStatusRemoteIterator abfsLsItr =\n+          new AbfsListStatusRemoteIterator(qualifiedPath, abfsStore);\n+      return RemoteIterators.typeCastingRemoteIterator(abfsLsItr);\n+    } else {\n+      return super.listStatusIterator(path);\n+    }\n   }\n \n   private FileStatus tryGetFileStatus(final Path f) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0NDk4OQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554744989", "bodyText": "is it right to catch interrupted exception?", "author": "vinaysbadami", "createdAt": "2021-01-11T05:28:31Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MjcxNA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557592714", "bodyText": "Yes. Also we need to set the interrut flag again.", "author": "bilaharith", "createdAt": "2021-01-14T18:09:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0NDk4OQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nsimilarity index 87%\nrename from hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nrename to hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 919d82352c8..be25288617b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -33,31 +33,30 @@\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n \n-public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n \n   private static final Logger LOG = LoggerFactory\n-      .getLogger(ListStatusRemoteIterator.class);\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n \n   private static final boolean FETCH_ALL_FALSE = false;\n   private static final int MAX_QUEUE_SIZE = 10;\n \n   private final Path path;\n-  private final AzureBlobFileSystemStore abfsStore;\n+  private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n+  private volatile boolean isAsyncInProgress = false;\n   private boolean firstBatch = true;\n-  private boolean isAsyncInProgress = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n   private IOException ioException;\n \n-  public ListStatusRemoteIterator(final Path path,\n-      final AzureBlobFileSystemStore abfsStore) {\n+  public AbfsListStatusRemoteIterator(final Path path,\n+      final ListingSupport listingSupport) {\n     this.path = path;\n-    this.abfsStore = abfsStore;\n+    this.listingSupport = listingSupport;\n     iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n     currIterator = Collections.emptyIterator();\n     fetchBatchesAsync();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0ODkzNw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554748937", "bodyText": "do next and ensure correct exception", "author": "vinaysbadami", "createdAt": "2021-01-11T05:33:52Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5Mjc5Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557592797", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:10:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0ODkzNw=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0OTcxMQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554749711", "bodyText": "filename", "author": "vinaysbadami", "createdAt": "2021-01-11T05:34:48Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5Mjg2Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557592867", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:10:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc0OTcxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1MDY5NQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554750695", "bodyText": "Next() and then ensure hasnext return false and NExt throws", "author": "vinaysbadami", "createdAt": "2021-01-11T05:35:59Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MjkyMg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557592922", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:10:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1MDY5NQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1Mjg4OA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554752888", "bodyText": "rename throughout", "author": "vinaysbadami", "createdAt": "2021-01-11T05:39:12Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5Mjk5NQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557592995", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:10:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1Mjg4OA=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1NDc1Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r554754757", "bodyText": "make queue empty by iterating and then set the exception and do another hasNext", "author": "vinaysbadami", "createdAt": "2021-01-11T05:41:51Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MzAyNw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557593027", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:10:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NDc1NDc1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTYzOTYyNg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r555639626", "bodyText": "continuation.isEmpty()", "author": "snvijaya", "createdAt": "2021-01-12T09:47:18Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java", "diffHunk": "@@ -865,16 +873,16 @@ public FileStatus getFileStatus(final Path path) throws IOException {\n             startFrom);\n \n     final String relativePath = getRelativePath(path);\n-    String continuation = null;\n \n-    // generate continuation token if a valid startFrom is provided.\n-    if (startFrom != null && !startFrom.isEmpty()) {\n-      continuation = getIsNamespaceEnabled()\n-              ? generateContinuationTokenForXns(startFrom)\n-              : generateContinuationTokenForNonXns(relativePath, startFrom);\n+    if (continuation == null || continuation.length() < 1) {", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MzA5MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557593091", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:10:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTYzOTYyNg=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\nindex 3ce746eea81..f4be159bf99 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystemStore.java\n\n@@ -874,7 +878,7 @@ public String listStatus(final Path path, final String startFrom,\n \n     final String relativePath = getRelativePath(path);\n \n-    if (continuation == null || continuation.length() < 1) {\n+    if (continuation == null || continuation.isEmpty()) {\n       // generate continuation token if a valid startFrom is provided.\n       if (startFrom != null && !startFrom.isEmpty()) {\n         continuation = getIsNamespaceEnabled()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTY5NDI2Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r555694267", "bodyText": "We are here because the thread already got interrupted ? why call interrupt ?", "author": "snvijaya", "createdAt": "2021-01-12T11:14:03Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MzQ4NA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557593484", "bodyText": "https://stackoverflow.com/questions/4906799/why-invoke-thread-currentthread-interrupt-in-a-catch-interruptexception-block", "author": "bilaharith", "createdAt": "2021-01-14T18:11:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTY5NDI2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nsimilarity index 87%\nrename from hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nrename to hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 919d82352c8..be25288617b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -33,31 +33,30 @@\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n \n-public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n \n   private static final Logger LOG = LoggerFactory\n-      .getLogger(ListStatusRemoteIterator.class);\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n \n   private static final boolean FETCH_ALL_FALSE = false;\n   private static final int MAX_QUEUE_SIZE = 10;\n \n   private final Path path;\n-  private final AzureBlobFileSystemStore abfsStore;\n+  private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n+  private volatile boolean isAsyncInProgress = false;\n   private boolean firstBatch = true;\n-  private boolean isAsyncInProgress = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n   private IOException ioException;\n \n-  public ListStatusRemoteIterator(final Path path,\n-      final AzureBlobFileSystemStore abfsStore) {\n+  public AbfsListStatusRemoteIterator(final Path path,\n+      final ListingSupport listingSupport) {\n     this.path = path;\n-    this.abfsStore = abfsStore;\n+    this.listingSupport = listingSupport;\n     iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n     currIterator = Collections.emptyIterator();\n     fetchBatchesAsync();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTY5NjU3MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r555696571", "bodyText": "Instead of testing failure case by setting ioException field, try to mock abfsStore or lower to give a failure response.", "author": "snvijaya", "createdAt": "2021-01-12T11:17:58Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";\n+    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n+        new IOException(exceptionMessage));\n+    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MzY4MA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557593680", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:11:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NTY5NjU3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3Nzc4Mg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556477782", "bodyText": "use interface for operations, as with org.apache.hadoop.fs.s3a.impl.ListingOperationCallbacks", "author": "steveloughran", "createdAt": "2021-01-13T12:16:47Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5MzgxNw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557593817", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:11:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3Nzc4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nsimilarity index 87%\nrename from hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nrename to hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 919d82352c8..be25288617b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -33,31 +33,30 @@\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n \n-public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n \n   private static final Logger LOG = LoggerFactory\n-      .getLogger(ListStatusRemoteIterator.class);\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n \n   private static final boolean FETCH_ALL_FALSE = false;\n   private static final int MAX_QUEUE_SIZE = 10;\n \n   private final Path path;\n-  private final AzureBlobFileSystemStore abfsStore;\n+  private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n+  private volatile boolean isAsyncInProgress = false;\n   private boolean firstBatch = true;\n-  private boolean isAsyncInProgress = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n   private IOException ioException;\n \n-  public ListStatusRemoteIterator(final Path path,\n-      final AzureBlobFileSystemStore abfsStore) {\n+  public AbfsListStatusRemoteIterator(final Path path,\n+      final ListingSupport listingSupport) {\n     this.path = path;\n-    this.abfsStore = abfsStore;\n+    this.listingSupport = listingSupport;\n     iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n     currIterator = Collections.emptyIterator();\n     fetchBatchesAsync();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3ODU2NA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556478564", "bodyText": "if, at the end of the loop I keep call hasNext() repeatedly, what happens?", "author": "steveloughran", "createdAt": "2021-01-13T12:18:22Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5NDc0MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557594741", "bodyText": "If there is new iterators present in the queue it updates the currentIterator to the one from the queue. Otherwise currentIterator is not updated and the hasNext will be called on the existing iterator which will return false.", "author": "bilaharith", "createdAt": "2021-01-14T18:13:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ3ODU2NA=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nsimilarity index 87%\nrename from hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nrename to hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 919d82352c8..be25288617b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -33,31 +33,30 @@\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n \n-public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n \n   private static final Logger LOG = LoggerFactory\n-      .getLogger(ListStatusRemoteIterator.class);\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n \n   private static final boolean FETCH_ALL_FALSE = false;\n   private static final int MAX_QUEUE_SIZE = 10;\n \n   private final Path path;\n-  private final AzureBlobFileSystemStore abfsStore;\n+  private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n+  private volatile boolean isAsyncInProgress = false;\n   private boolean firstBatch = true;\n-  private boolean isAsyncInProgress = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n   private IOException ioException;\n \n-  public ListStatusRemoteIterator(final Path path,\n-      final AzureBlobFileSystemStore abfsStore) {\n+  public AbfsListStatusRemoteIterator(final Path path,\n+      final ListingSupport listingSupport) {\n     this.path = path;\n-    this.abfsStore = abfsStore;\n+    this.listingSupport = listingSupport;\n     iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n     currIterator = Collections.emptyIterator();\n     fetchBatchesAsync();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MDUzNA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556480534", "bodyText": "should only be scheduled if there isn't one already in progress", "author": "steveloughran", "createdAt": "2021-01-13T12:22:08Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public ListStatusRemoteIterator(final Path path,\n+      final AzureBlobFileSystemStore abfsStore) {\n+    this.path = path;\n+    this.abfsStore = abfsStore;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    CompletableFuture.runAsync(() -> asyncOp());", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5NTI3Ng==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557595276", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:14:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MDUzNA=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nsimilarity index 87%\nrename from hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nrename to hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 919d82352c8..be25288617b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -33,31 +33,30 @@\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n \n-public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n \n   private static final Logger LOG = LoggerFactory\n-      .getLogger(ListStatusRemoteIterator.class);\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n \n   private static final boolean FETCH_ALL_FALSE = false;\n   private static final int MAX_QUEUE_SIZE = 10;\n \n   private final Path path;\n-  private final AzureBlobFileSystemStore abfsStore;\n+  private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n+  private volatile boolean isAsyncInProgress = false;\n   private boolean firstBatch = true;\n-  private boolean isAsyncInProgress = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n   private IOException ioException;\n \n-  public ListStatusRemoteIterator(final Path path,\n-      final AzureBlobFileSystemStore abfsStore) {\n+  public AbfsListStatusRemoteIterator(final Path path,\n+      final ListingSupport listingSupport) {\n     this.path = path;\n-    this.abfsStore = abfsStore;\n+    this.listingSupport = listingSupport;\n     iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n     currIterator = Collections.emptyIterator();\n     fetchBatchesAsync();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MDkyOA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556480928", "bodyText": "these are going to have to be Atomic, aren't they?", "author": "steveloughran", "createdAt": "2021-01-13T12:22:49Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n+\n+public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(ListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final Path path;\n+  private final AzureBlobFileSystemStore abfsStore;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private boolean firstBatch = true;\n+  private boolean isAsyncInProgress = false;", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5Njk1MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557596951", "bodyText": "Not necessary since the writes are made in synchronised block. Also rather than the atomicity synchronisation is the need here.", "author": "bilaharith", "createdAt": "2021-01-14T18:17:30Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MDkyOA=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nsimilarity index 87%\nrename from hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\nrename to hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 919d82352c8..be25288617b 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -33,31 +33,30 @@\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.AzureBlobFileSystemStore;\n \n-public class ListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n \n   private static final Logger LOG = LoggerFactory\n-      .getLogger(ListStatusRemoteIterator.class);\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n \n   private static final boolean FETCH_ALL_FALSE = false;\n   private static final int MAX_QUEUE_SIZE = 10;\n \n   private final Path path;\n-  private final AzureBlobFileSystemStore abfsStore;\n+  private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n+  private volatile boolean isAsyncInProgress = false;\n   private boolean firstBatch = true;\n-  private boolean isAsyncInProgress = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n   private IOException ioException;\n \n-  public ListStatusRemoteIterator(final Path path,\n-      final AzureBlobFileSystemStore abfsStore) {\n+  public AbfsListStatusRemoteIterator(final Path path,\n+      final ListingSupport listingSupport) {\n     this.path = path;\n-    this.abfsStore = abfsStore;\n+    this.listingSupport = listingSupport;\n     iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n     currIterator = Collections.emptyIterator();\n     fetchBatchesAsync();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MjE0OQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556482149", "bodyText": "this is why you need a list callback. This is low-level field abuse. Better to have a {{getAbfsStoreForTesting()}} call, at the very least", "author": "steveloughran", "createdAt": "2021-01-13T12:25:01Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";\n+    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n+        new IOException(exceptionMessage));\n+    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n+        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n+\n+    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n+        \"When ioException is not null and queue is empty exception should be \"\n+            + \"thrown\").isInstanceOf(IOException.class)\n+        .hasMessage(exceptionMessage);\n+  }\n+\n+  private void setPrivateField(Object obj, Class classObj, String fieldName,\n+      Object value) throws NoSuchFieldException, IllegalAccessException {\n+    Field field = classObj.getDeclaredField(fieldName);\n+    field.setAccessible(true);\n+    field.set(obj, value);\n+  }\n+\n+  private void setPrivateFinalField(Object obj, Class classObj,\n+      String fieldName, Object value)\n+      throws NoSuchFieldException, IllegalAccessException {\n+    Field field = classObj.getDeclaredField(fieldName);\n+    field.setAccessible(true);\n+    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n+    modifiersField.setAccessible(true);\n+    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n+    field.set(obj, value);\n+  }\n+\n+  private List<String> createFiles(int numFiles, String rootPathStr,\n+      String filenamePrefix)\n+      throws ExecutionException, InterruptedException, IOException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    final List<String> fileNames = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    final Path rootPath = new Path(rootPathStr);\n+    for (int i = 0; i < numFiles; i++) {\n+      final Path filePath = new Path(rootPath, filenamePrefix + i);\n+      Callable<Void> callable = new Callable<Void>() {\n+        @Override\n+        public Void call() throws Exception {\n+          getFileSystem().create(filePath);\n+          fileNames.add(makeQualified(filePath).toString());\n+          return null;\n+        }\n+      };\n+      tasks.add(es.submit(callable));\n+    }\n+    for (Future<Void> task : tasks) {\n+      task.get();\n+    }\n+    es.shutdownNow();\n+    return fileNames;\n+  }\n+\n+  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5NzAzNg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557597036", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:17:39Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MjE0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4Mjg3Mg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556482872", "bodyText": "also need to test a loop of it.next() until NoMoreElementsException is raised", "author": "steveloughran", "createdAt": "2021-01-13T12:26:22Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5NzExMg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557597112", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:17:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4Mjg3Mg=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MzcyOQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556483729", "bodyText": "this is an abuse of internals. If you use a callback for the listing operations, you can explicitly raise the IOE instead.", "author": "steveloughran", "createdAt": "2021-01-13T12:27:47Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.IOException;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.util.ArrayList;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+/**\n+ * Test listStatus operation.\n+ */\n+public class ITestAzureBlobFileSystemListStatusIterator\n+    extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListPath() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPath = \"testRoot1\";\n+    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n+        \"testListPath\");\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n+    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n+    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n+    int itrCount = 0;\n+    while (fsIt.hasNext()) {\n+      FileStatus fileStatus = fsIt.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    assertEquals(TEST_FILES_NUMBER, itrCount);\n+    assertEquals(0, fileNames.size());\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot2\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\").isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot3\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot4\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().create(rootPath);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+  }\n+\n+  @Test\n+  public void testHasNextForIOException() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String rootPathStr = \"testRoot5\";\n+    Path rootPath = new Path(rootPathStr);\n+    getFileSystem().mkdirs(rootPath);\n+    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n+        .listStatusIterator(rootPath);\n+    Thread.sleep(1000);\n+\n+    String exceptionMessage = \"test exception\";\n+    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU5NzIyOQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r557597229", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-14T18:17:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MzcyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\ndeleted file mode 100644\nindex fb99988ee9a..00000000000\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAzureBlobFileSystemListStatusIterator.java\n+++ /dev/null\n\n@@ -1,190 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- * <p>\n- * http://www.apache.org/licenses/LICENSE-2.0\n- * <p>\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hadoop.fs.azurebfs;\n-\n-import java.io.IOException;\n-import java.lang.reflect.Field;\n-import java.lang.reflect.Modifier;\n-import java.util.ArrayList;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.ArrayBlockingQueue;\n-import java.util.concurrent.Callable;\n-import java.util.concurrent.ExecutionException;\n-import java.util.concurrent.ExecutorService;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Future;\n-\n-import org.assertj.core.api.Assertions;\n-import org.junit.Test;\n-import org.mockito.Mockito;\n-\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n-import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.FileSystem;\n-import org.apache.hadoop.fs.Path;\n-import org.apache.hadoop.fs.RemoteIterator;\n-\n-/**\n- * Test listStatus operation.\n- */\n-public class ITestAzureBlobFileSystemListStatusIterator\n-    extends AbstractAbfsIntegrationTest {\n-\n-  private static final int TEST_FILES_NUMBER = 1000;\n-\n-  public ITestAzureBlobFileSystemListStatusIterator() throws Exception {\n-    super();\n-  }\n-\n-  @Test\n-  public void testListPath() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPath = \"testRoot1\";\n-    final List<String> fileNames = createFiles(TEST_FILES_NUMBER, rootPath,\n-        \"testListPath\");\n-    AzureBlobFileSystemStore abfsStore = getAbfsStore(fs);\n-    abfsStore.getAbfsConfiguration().setListMaxResults(10);\n-    RemoteIterator<FileStatus> fsIt = fs.listStatusIterator(new Path(rootPath));\n-    int itrCount = 0;\n-    while (fsIt.hasNext()) {\n-      FileStatus fileStatus = fsIt.next();\n-      String pathStr = fileStatus.getPath().toString();\n-      fileNames.remove(pathStr);\n-      itrCount++;\n-    }\n-    assertEquals(TEST_FILES_NUMBER, itrCount);\n-    assertEquals(0, fileNames.size());\n-  }\n-\n-  @Test\n-  public void testNextWhenNoMoreElementsPresent() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot2\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    fsItr = Mockito.spy(fsItr);\n-    Mockito.doReturn(false).when(fsItr).hasNext();\n-\n-    RemoteIterator<FileStatus> finalFsItr = fsItr;\n-    Assertions.assertThatThrownBy(() -> finalFsItr.next()).describedAs(\n-        \"next() should throw NoSuchElementException if hasNext() return \"\n-            + \"false\").isInstanceOf(NoSuchElementException.class);\n-  }\n-\n-  @Test\n-  public void testHasNextForEmptyDir() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot3\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns false for empty directory\").isFalse();\n-  }\n-\n-  @Test\n-  public void testHasNextForFile() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot4\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().create(rootPath);\n-    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(rootPath);\n-    Assertions.assertThat(fsItr.hasNext())\n-        .describedAs(\"hasNext returns true for file\").isTrue();\n-  }\n-\n-  @Test\n-  public void testHasNextForIOException() throws Exception {\n-    final AzureBlobFileSystem fs = getFileSystem();\n-    String rootPathStr = \"testRoot5\";\n-    Path rootPath = new Path(rootPathStr);\n-    getFileSystem().mkdirs(rootPath);\n-    ListStatusRemoteIterator fsItr = (ListStatusRemoteIterator) fs\n-        .listStatusIterator(rootPath);\n-    Thread.sleep(1000);\n-\n-    String exceptionMessage = \"test exception\";\n-    setPrivateField(fsItr, ListStatusRemoteIterator.class, \"ioException\",\n-        new IOException(exceptionMessage));\n-    setPrivateFinalField(fsItr, ListStatusRemoteIterator.class,\n-        \"iteratorsQueue\", new ArrayBlockingQueue<Iterator>(1));\n-\n-    Assertions.assertThatThrownBy(() -> fsItr.hasNext()).describedAs(\n-        \"When ioException is not null and queue is empty exception should be \"\n-            + \"thrown\").isInstanceOf(IOException.class)\n-        .hasMessage(exceptionMessage);\n-  }\n-\n-  private void setPrivateField(Object obj, Class classObj, String fieldName,\n-      Object value) throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    field.set(obj, value);\n-  }\n-\n-  private void setPrivateFinalField(Object obj, Class classObj,\n-      String fieldName, Object value)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    Field field = classObj.getDeclaredField(fieldName);\n-    field.setAccessible(true);\n-    Field modifiersField = Field.class.getDeclaredField(\"modifiers\");\n-    modifiersField.setAccessible(true);\n-    modifiersField.setInt(field, field.getModifiers() & ~Modifier.FINAL);\n-    field.set(obj, value);\n-  }\n-\n-  private List<String> createFiles(int numFiles, String rootPathStr,\n-      String filenamePrefix)\n-      throws ExecutionException, InterruptedException, IOException {\n-    final List<Future<Void>> tasks = new ArrayList<>();\n-    final List<String> fileNames = new ArrayList<>();\n-    ExecutorService es = Executors.newFixedThreadPool(10);\n-    final Path rootPath = new Path(rootPathStr);\n-    for (int i = 0; i < numFiles; i++) {\n-      final Path filePath = new Path(rootPath, filenamePrefix + i);\n-      Callable<Void> callable = new Callable<Void>() {\n-        @Override\n-        public Void call() throws Exception {\n-          getFileSystem().create(filePath);\n-          fileNames.add(makeQualified(filePath).toString());\n-          return null;\n-        }\n-      };\n-      tasks.add(es.submit(callable));\n-    }\n-    for (Future<Void> task : tasks) {\n-      task.get();\n-    }\n-    es.shutdownNow();\n-    return fileNames;\n-  }\n-\n-  private AzureBlobFileSystemStore getAbfsStore(FileSystem fs)\n-      throws NoSuchFieldException, IllegalAccessException {\n-    AzureBlobFileSystem abfs = (AzureBlobFileSystem) fs;\n-    Field abfsStoreField = AzureBlobFileSystem.class\n-        .getDeclaredField(\"abfsStore\");\n-    abfsStoreField.setAccessible(true);\n-    return (AzureBlobFileSystemStore) abfsStoreField.get(abfs);\n-  }\n-\n-}\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4NDAwMw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r556484003", "bodyText": "needs to go into the non-shaded bit of hadoop imports.", "author": "steveloughran", "createdAt": "2021-01-13T12:28:16Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -37,6 +37,8 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.Future;\n \n+import org.apache.hadoop.fs.RemoteIterator;", "originalCommit": "9c540338e3ede6794b8a2b1fad0de24d5a0e9788", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyNTU2NA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565225564", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:14:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4NDAwMw=="}], "type": "inlineReview", "revised_code": {"commit": "83ec324f866e78bbacd4416f13d607e5b901b374", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\nindex d391ac947aa..f6f81860536 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n\n@@ -37,16 +37,17 @@\n import java.util.concurrent.Executors;\n import java.util.concurrent.Future;\n \n-import org.apache.hadoop.fs.RemoteIterator;\n-import org.apache.hadoop.fs.azurebfs.services.ListStatusRemoteIterator;\n import org.apache.hadoop.thirdparty.com.google.common.annotations.VisibleForTesting;\n import org.apache.hadoop.thirdparty.com.google.common.base.Preconditions;\n+import org.apache.hadoop.util.functional.RemoteIterators;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import org.apache.commons.lang3.ArrayUtils;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClientThrottlingIntercept;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.BlockLocation;\n"}}, {"oid": "83ec324f866e78bbacd4416f13d607e5b901b374", "url": "https://github.com/apache/hadoop/commit/83ec324f866e78bbacd4416f13d607e5b901b374", "message": "Addressing review comments", "committedDate": "2021-01-14T18:29:34Z", "type": "commit"}, {"oid": "a6e54076877b4ee4d3e5d2acacacbd10e70bee1b", "url": "https://github.com/apache/hadoop/commit/a6e54076877b4ee4d3e5d2acacacbd10e70bee1b", "message": "Putting empty iterator in finally block. This is to prevent the take from hanging in case the first call itself result in exception", "committedDate": "2021-01-15T05:37:37Z", "type": "commit"}, {"oid": "b9ff82c25d3000b4f531bd0b397b7610919ab31c", "url": "https://github.com/apache/hadoop/commit/b9ff82c25d3000b4f531bd0b397b7610919ab31c", "message": "Throwing FileNotFoundException when the directory does not exist", "committedDate": "2021-01-15T10:12:18Z", "type": "commit"}, {"oid": "f2b3ad42d2a79f33f49135a5c44ab29a41f9caa1", "url": "https://github.com/apache/hadoop/commit/f2b3ad42d2a79f33f49135a5c44ab29a41f9caa1", "message": "Making the put on finally non blocking", "committedDate": "2021-01-15T11:08:20Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODI1NzU0OQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r558257549", "bodyText": "did u want to do this even when u did not have an exception?", "author": "vinaysbadami", "createdAt": "2021-01-15T11:51:45Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,157 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (asyncOpLock) {\n+        try {\n+          iteratorsQueue.put(Collections.emptyIterator());", "originalCommit": "b9ff82c25d3000b4f531bd0b397b7610919ab31c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 5b06019e037..f2fbcb37b56 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -31,7 +31,6 @@\n import org.slf4j.LoggerFactory;\n \n import org.apache.hadoop.fs.FileStatus;\n-import org.apache.hadoop.fs.Path;\n import org.apache.hadoop.fs.RemoteIterator;\n \n public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n"}}, {"oid": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "url": "https://github.com/apache/hadoop/commit/d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "message": "Adding empty iterator from the catch block", "committedDate": "2021-01-18T05:31:56Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTQzMTUzNw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r559431537", "bodyText": "|| ioException != null", "author": "vinaysbadami", "createdAt": "2021-01-18T09:39:08Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex f2fbcb37b56..ce5bc7708fb 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -43,14 +43,13 @@\n \n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n-  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n-  private boolean firstBatch = true;\n+  private boolean isIterationComplete = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n-  private IOException ioException;\n \n   public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n       final ListingSupport listingSupport) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNTgyMg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560125822", "bodyText": "should go above so imports are in order; goal is to reduce conflict between patches, branches and versions", "author": "steveloughran", "createdAt": "2021-01-19T11:59:20Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -45,6 +45,8 @@\n import org.apache.commons.lang3.ArrayUtils;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClientThrottlingIntercept;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMDYxNA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565220614", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:06:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNTgyMg=="}], "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\nindex 63ef7cbd6f0..da7759f2700 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java\n\n@@ -45,8 +45,8 @@\n import org.apache.commons.lang3.ArrayUtils;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClient;\n import org.apache.hadoop.fs.azurebfs.services.AbfsClientThrottlingIntercept;\n-import org.apache.hadoop.fs.RemoteIterator;\n import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.RemoteIterator;\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.conf.Configuration;\n import org.apache.hadoop.fs.BlockLocation;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNjczMQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560126731", "bodyText": "would you ever want to make this not optional? one code path == better testing", "author": "steveloughran", "createdAt": "2021-01-19T12:01:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -982,6 +985,19 @@ public boolean exists(Path f) throws IOException {\n     return super.exists(f);\n   }\n \n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(Path path)\n+      throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);\n+    if (abfsStore.getAbfsConfiguration().enableAbfsListIterator()) {", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwODY5Mw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563508693", "bodyText": "after it is used for a while and we have confidence that it is baked", "author": "vinaysbadami", "createdAt": "2021-01-25T07:30:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNjczMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4NjUxNg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567986516", "bodyText": "OK, but it's something to plan to cut after a release has been out. So file a new JIRA about cutting the old one.", "author": "steveloughran", "createdAt": "2021-02-01T17:00:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNjczMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODczNTgzOQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r568735839", "bodyText": "Done\nhttps://issues.apache.org/jira/browse/HADOOP-17512", "author": "bilaharith", "createdAt": "2021-02-02T16:19:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyNjczMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyODA5Ng==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560128096", "bodyText": "you can just use a () -> { } closure here", "author": "steveloughran", "createdAt": "2021-01-19T12:03:36Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java", "diffHunk": "@@ -0,0 +1,339 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListStatusRemoteIterator() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    verify(listngSupport, Mockito.atLeast(100))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testListStatusRemoteIteratorWithoutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    verify(listngSupport, Mockito.atLeast(100))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabled() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabledWithutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+            getFileSystem().getAbfsStore());\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next())\n+        .describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\")\n+        .isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = getFileSystem()\n+        .listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\")\n+        .isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String testFileName = \"testFile\";\n+    Path testFile = new Path(testFileName);\n+    getFileSystem().create(testFile);\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(testFile);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+    Assertions.assertThat(fsItr.next().getPath().toString())\n+        .describedAs(\"next returns the file itself\")\n+        .endsWith(testFileName);\n+  }\n+\n+  @Test\n+  public void testIOException() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    getFileSystem().mkdirs(testDir);\n+\n+    String exceptionMessage = \"test exception\";\n+    ListingSupport lsSupport =getMockListingSupport(exceptionMessage);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+        lsSupport);\n+\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+        \"When ioException is not null and queue is empty exception should be \"\n+            + \"thrown\")\n+        .isInstanceOf(IOException.class)\n+        .hasMessage(exceptionMessage);\n+  }\n+\n+  @Test\n+  public void testNonExistingPath() throws Throwable {\n+    Path nonExistingDir = new Path(\"nonExistingPath\");\n+    Assertions.assertThatThrownBy(\n+        () -> getFileSystem().listStatusIterator(nonExistingDir)).describedAs(\n+        \"test the listStatusIterator call on a path which is not \"\n+            + \"present should result in FileNotFoundException\")\n+        .isInstanceOf(FileNotFoundException.class);\n+  }\n+\n+  private ListingSupport getMockListingSupport(String exceptionMessage) {\n+    return new ListingSupport() {\n+      @Override\n+      public FileStatus[] listStatus(Path path) throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public FileStatus[] listStatus(Path path, String startFrom)\n+          throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public String listStatus(Path path, String startFrom,\n+          List<FileStatus> fileStatuses, boolean fetchAll, String continuation)\n+          throws IOException {\n+        throw new IOException(exceptionMessage);\n+      }\n+    };\n+  }\n+\n+  private Path createTestDirectory() throws IOException {\n+    String testDirectoryName = \"testDirectory\" + System.currentTimeMillis();\n+    Path testDirectory = new Path(testDirectoryName);\n+    getFileSystem().mkdirs(testDirectory);\n+    return testDirectory;\n+  }\n+\n+  private void setEnableAbfsIterator(boolean shouldEnable) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setEnableAbfsListIterator(shouldEnable);\n+  }\n+\n+  private void setPageSize(int pageSize) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setListMaxResults(pageSize);\n+  }\n+\n+  private List<String> createFilesUnderDirectory(int numFiles, Path rootPath,\n+      String filenamePrefix)\n+      throws ExecutionException, InterruptedException, IOException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    final List<String> fileNames = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    for (int i = 0; i < numFiles; i++) {\n+      final Path filePath = new Path(rootPath, filenamePrefix + i);\n+      Callable<Void> callable = new Callable<Void>() {", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMzg0Mw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565223843", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:11:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEyODA5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\nsimilarity index 96%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\nindex e7b1f4cd169..037906f0c51 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\n\n@@ -48,11 +48,11 @@\n /**\n  * Test ListStatusRemoteIterator operation.\n  */\n-public class ITestAbfsListStatusIterator extends AbstractAbfsIntegrationTest {\n+public class ITestAbfsListStatusRemoteIterator extends AbstractAbfsIntegrationTest {\n \n   private static final int TEST_FILES_NUMBER = 1000;\n \n-  public ITestAbfsListStatusIterator() throws Exception {\n+  public ITestAbfsListStatusRemoteIterator() throws Exception {\n     super();\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzMTk2NQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560131965", "bodyText": "should only be set with first IOE, as that's usually first sign of failure. Rest just log message @ warn and stack @ debug.\nwhat about other exceptions? are they handled by the normal Futures code? In which case ExecutionException needs to be picked up and unwrapped. The code in org.apache.hadoop.util.functional.FutureIO can help there", "author": "steveloughran", "createdAt": "2021-01-19T12:11:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMzQxMg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565223412", "bodyText": "Exceptions are also put into the queue. Future is not used.", "author": "bilaharith", "createdAt": "2021-01-27T11:11:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzMTk2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex f2fbcb37b56..ce5bc7708fb 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -43,14 +43,13 @@\n \n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n-  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n-  private boolean firstBatch = true;\n+  private boolean isIterationComplete = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n-  private IOException ioException;\n \n   public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n       final ListingSupport listingSupport) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzMjgwMg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560132802", "bodyText": "With an interface, you don't need to play mockito games any more. Instead just provide a dummy impl to simulate deep/wide directories, controllable page size etc", "author": "steveloughran", "createdAt": "2021-01-19T12:12:35Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java", "diffHunk": "@@ -0,0 +1,339 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testListStatusRemoteIterator() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMjk5OA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565222998", "bodyText": "Here I want to mock so that I can verify on the number of times few of the internal methods called.", "author": "bilaharith", "createdAt": "2021-01-27T11:10:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDEzMjgwMg=="}], "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\nsimilarity index 96%\nrename from hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java\nrename to hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\nindex e7b1f4cd169..037906f0c51 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\n\n@@ -48,11 +48,11 @@\n /**\n  * Test ListStatusRemoteIterator operation.\n  */\n-public class ITestAbfsListStatusIterator extends AbstractAbfsIntegrationTest {\n+public class ITestAbfsListStatusRemoteIterator extends AbstractAbfsIntegrationTest {\n \n   private static final int TEST_FILES_NUMBER = 1000;\n \n-  public ITestAbfsListStatusIterator() throws Exception {\n+  public ITestAbfsListStatusRemoteIterator() throws Exception {\n     super();\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc2OTI3MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560769271", "bodyText": "why synchronized? this will cause contention on line 83. u are holding the lock across a listing call to server.", "author": "vinaysbadami", "createdAt": "2021-01-20T08:40:30Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    }\n+  }\n+\n+  private synchronized boolean isListingComplete() {\n+    return !firstBatch && (continuation == null || continuation.isEmpty());\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isListingComplete() && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      ioException = e;\n+      iteratorsQueue.offer(Collections.emptyIterator());\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (asyncOpLock) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private synchronized void addNextBatchIteratorToQueue()", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMjMyNA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565222324", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:09:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc2OTI3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex f2fbcb37b56..ce5bc7708fb 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -43,14 +43,13 @@\n \n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n-  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n-  private boolean firstBatch = true;\n+  private boolean isIterationComplete = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n-  private IOException ioException;\n \n   public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n       final ListingSupport listingSupport) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc2OTUxMA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560769510", "bodyText": "why recursion?", "author": "vinaysbadami", "createdAt": "2021-01-20T08:40:55Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+  private IOException ioException;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty()) {\n+        if (ioException != null) {\n+          throw ioException;\n+        }\n+        if (isListingComplete()) {\n+          return;\n+        }\n+      }\n+    }\n+    try {\n+      currIterator = iteratorsQueue.take();\n+      if (!currIterator.hasNext() && !isListingComplete()) {\n+        updateCurrentIterator();", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMjIyOQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565222229", "bodyText": "Moved away fro recursion", "author": "bilaharith", "createdAt": "2021-01-27T11:09:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc2OTUxMA=="}], "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex f2fbcb37b56..ce5bc7708fb 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -43,14 +43,13 @@\n \n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n-  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n-  private boolean firstBatch = true;\n+  private boolean isIterationComplete = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n-  private IOException ioException;\n \n   public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n       final ListingSupport listingSupport) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc3NDAzNA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r560774034", "bodyText": "set continuationtoken to empty. why do we need firstbatch?", "author": "vinaysbadami", "createdAt": "2021-01-20T08:46:08Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean firstBatch = true;", "originalCommit": "d3cac7771de5e53ab1c761d55b9dc1d9a295392f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMTg3NQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565221875", "bodyText": "Done, introduced a new variable isIterationComplete.", "author": "bilaharith", "createdAt": "2021-01-27T11:08:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDc3NDAzNA=="}], "type": "inlineReview", "revised_code": {"commit": "7c4f64a45183bd03677c68c241642e41530cf88e", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex f2fbcb37b56..ce5bc7708fb 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -43,14 +43,13 @@\n \n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n-  private final ArrayBlockingQueue<Iterator<FileStatus>> iteratorsQueue;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n   private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n-  private boolean firstBatch = true;\n+  private boolean isIterationComplete = false;\n   private String continuation;\n   private Iterator<FileStatus> currIterator;\n-  private IOException ioException;\n \n   public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n       final ListingSupport listingSupport) {\n"}}, {"oid": "7c4f64a45183bd03677c68c241642e41530cf88e", "url": "https://github.com/apache/hadoop/commit/7c4f64a45183bd03677c68c241642e41530cf88e", "message": "Addressing review comments", "committedDate": "2021-01-24T16:00:34Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwNDUyNA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563504524", "bodyText": "can this be done outside the sync block? If put blocks u are holding the lock.", "author": "vinaysbadami", "createdAt": "2021-01-25T07:19:37Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    if (currIterator == null) {\n+      return false;\n+    }\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    do {\n+      currIterator = getNextIterator();\n+    } while (currIterator != null && !currIterator.hasNext()\n+        && !isIterationComplete);\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty() && isIterationComplete) {\n+          return null;\n+      }\n+    }\n+    try {\n+      Object obj = iteratorsQueue.take();\n+      if(obj instanceof Iterator){\n+        return (Iterator<FileStatus>) obj;\n+      }\n+      throw (IOException) obj;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+      return null;\n+    }\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (asyncOpLock) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isIterationComplete && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      try {\n+        iteratorsQueue.put(e);\n+      } catch (InterruptedException interruptedException) {\n+        Thread.currentThread().interrupt();\n+        LOG.error(\"Thread got interrupted: {}\", interruptedException);\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (asyncOpLock) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private void addNextBatchIteratorToQueue()\n+      throws IOException, InterruptedException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    continuation = listingSupport\n+        .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n+            continuation);\n+    synchronized (this) {\n+      if (continuation == null || continuation.isEmpty()) {\n+        isIterationComplete = true;\n+      }\n+      iteratorsQueue.put(fileStatuses.iterator());", "originalCommit": "7c4f64a45183bd03677c68c241642e41530cf88e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMTU1NA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565221554", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:07:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwNDUyNA=="}], "type": "inlineReview", "revised_code": {"commit": "f578bbd7c776751dfbfc63b1e586c2308c3f2501", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex ce5bc7708fb..ff7bec8a813 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -44,7 +44,6 @@\n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Object> iteratorsQueue;\n-  private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n   private boolean isIterationComplete = false;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwNzg3Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563507877", "bodyText": "can we avoid this completely?", "author": "vinaysbadami", "createdAt": "2021-01-25T07:28:21Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();", "originalCommit": "7c4f64a45183bd03677c68c241642e41530cf88e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMTQ5NA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565221494", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:07:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwNzg3Nw=="}], "type": "inlineReview", "revised_code": {"commit": "f578bbd7c776751dfbfc63b1e586c2308c3f2501", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex ce5bc7708fb..ff7bec8a813 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -44,7 +44,6 @@\n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Object> iteratorsQueue;\n-  private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n   private boolean isIterationComplete = false;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwOTUyNw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563509527", "bodyText": "null or empty iterator? same question for line 106.\nStandrad with collections is to return an empty collection/iterator - not a null object.", "author": "vinaysbadami", "createdAt": "2021-01-25T07:32:31Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+  private final Object asyncOpLock = new Object();\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    if (currIterator == null) {\n+      return false;\n+    }\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    do {\n+      currIterator = getNextIterator();\n+    } while (currIterator != null && !currIterator.hasNext()\n+        && !isIterationComplete);\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty() && isIterationComplete) {\n+          return null;", "originalCommit": "7c4f64a45183bd03677c68c241642e41530cf88e", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMTQ2Mw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565221463", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:07:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzUwOTUyNw=="}], "type": "inlineReview", "revised_code": {"commit": "f578bbd7c776751dfbfc63b1e586c2308c3f2501", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex ce5bc7708fb..ff7bec8a813 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -44,7 +44,6 @@\n   private final FileStatus fileStatus;\n   private final ListingSupport listingSupport;\n   private final ArrayBlockingQueue<Object> iteratorsQueue;\n-  private final Object asyncOpLock = new Object();\n \n   private volatile boolean isAsyncInProgress = false;\n   private boolean isIterationComplete = false;\n"}}, {"oid": "f578bbd7c776751dfbfc63b1e586c2308c3f2501", "url": "https://github.com/apache/hadoop/commit/f578bbd7c776751dfbfc63b1e586c2308c3f2501", "message": "Addressing review comments", "committedDate": "2021-01-25T15:34:59Z", "type": "commit"}, {"oid": "89222d1f2d56cafe5075b5b570a3ca3a73f25b42", "url": "https://github.com/apache/hadoop/commit/89222d1f2d56cafe5075b5b570a3ca3a73f25b42", "message": "Addressing review comments", "committedDate": "2021-01-25T15:38:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzgyODQ3MA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r563828470", "bodyText": "not within sync block", "author": "vinaysbadami", "createdAt": "2021-01-25T15:49:00Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,156 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    updateCurrentIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private void updateCurrentIterator() throws IOException {\n+    do {\n+      currIterator = getNextIterator();\n+    } while (currIterator != null && !currIterator.hasNext()\n+        && !isIterationComplete);\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    synchronized (this) {\n+      if (iteratorsQueue.isEmpty() && isIterationComplete) {\n+          return Collections.emptyIterator();\n+      }\n+    }\n+    try {\n+      Object obj = iteratorsQueue.take();\n+      if(obj instanceof Iterator){\n+        return (Iterator<FileStatus>) obj;\n+      }\n+      throw (IOException) obj;\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+      return Collections.emptyIterator();\n+    }\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress) {\n+      return;\n+    }\n+    synchronized (this) {\n+      if (isAsyncInProgress) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isIterationComplete && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException e) {\n+      try {\n+        iteratorsQueue.put(e);\n+      } catch (InterruptedException interruptedException) {\n+        Thread.currentThread().interrupt();\n+        LOG.error(\"Thread got interrupted: {}\", interruptedException);\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (this  ) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private void addNextBatchIteratorToQueue()\n+      throws IOException, InterruptedException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    continuation = listingSupport\n+        .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n+            continuation);\n+    iteratorsQueue.put(fileStatuses.iterator());\n+    synchronized (this) {\n+      if (continuation == null || continuation.isEmpty()) {\n+        isIterationComplete = true;\n+        iteratorsQueue.put(Collections.emptyIterator());", "originalCommit": "89222d1f2d56cafe5075b5b570a3ca3a73f25b42", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTIyMTMzOQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r565221339", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-01-27T11:07:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzgyODQ3MA=="}], "type": "inlineReview", "revised_code": {"commit": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 3447d778e64..42eddf53ae8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -26,6 +26,8 @@\n import java.util.NoSuchElementException;\n import java.util.concurrent.ArrayBlockingQueue;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.activation.UnsupportedDataTypeException;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n"}}, {"oid": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "url": "https://github.com/apache/hadoop/commit/5970d6ec245c2bfb273435733de5b76f2ddcb22b", "message": "Adressing review comments. Checkstyle fixes.", "committedDate": "2021-01-27T10:59:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4NjY2Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567986667", "bodyText": "nice", "author": "steveloughran", "createdAt": "2021-02-01T17:00:33Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/AzureBlobFileSystem.java", "diffHunk": "@@ -982,6 +985,19 @@ public boolean exists(Path f) throws IOException {\n     return super.exists(f);\n   }\n \n+  @Override\n+  public RemoteIterator<FileStatus> listStatusIterator(Path path)\n+      throws IOException {\n+    LOG.debug(\"AzureBlobFileSystem.listStatusIterator path : {}\", path);\n+    if (abfsStore.getAbfsConfiguration().enableAbfsListIterator()) {\n+      AbfsListStatusRemoteIterator abfsLsItr =\n+          new AbfsListStatusRemoteIterator(getFileStatus(path), abfsStore);\n+      return RemoteIterators.typeCastingRemoteIterator(abfsLsItr);", "originalCommit": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4ODQ1NQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567988455", "bodyText": "nit: space after if", "author": "steveloughran", "createdAt": "2021-02-01T17:03:09Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.activation.UnsupportedDataTypeException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator\n+    implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+  private static final long POLL_WAIT_TIME_IN_MS = 250;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    currIterator = getNextIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    try {\n+      Object obj = null;\n+      while (obj == null\n+          && (!isIterationComplete || !iteratorsQueue.isEmpty())) {\n+        obj = iteratorsQueue.poll(POLL_WAIT_TIME_IN_MS, TimeUnit.MILLISECONDS);\n+      }\n+      if (obj == null) {\n+        return Collections.emptyIterator();\n+      } else if (obj instanceof Iterator) {\n+        return (Iterator<FileStatus>) obj;\n+      } else if (obj instanceof IOException) {\n+        throw (IOException) obj;\n+      } else {\n+        throw new UnsupportedDataTypeException();\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+      throw new IOException(e);\n+    }\n+  }\n+\n+  private void fetchBatchesAsync() {\n+    if (isAsyncInProgress || isIterationComplete) {\n+      return;\n+    }\n+    synchronized (this) {\n+      if (isAsyncInProgress || isIterationComplete) {\n+        return;\n+      }\n+      isAsyncInProgress = true;\n+    }\n+    CompletableFuture.runAsync(() -> asyncOp());\n+  }\n+\n+  private void asyncOp() {\n+    try {\n+      while (!isIterationComplete && iteratorsQueue.size() <= MAX_QUEUE_SIZE) {\n+        addNextBatchIteratorToQueue();\n+      }\n+    } catch (IOException ioe) {\n+      LOG.error(\"Fetching filestatuses failed\", ioe);\n+      try {\n+        iteratorsQueue.put(ioe);\n+      } catch (InterruptedException interruptedException) {\n+        Thread.currentThread().interrupt();\n+        LOG.error(\"Thread got interrupted: {}\", interruptedException);\n+      }\n+    } catch (InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+      LOG.error(\"Thread got interrupted: {}\", e);\n+    } finally {\n+      synchronized (this) {\n+        isAsyncInProgress = false;\n+      }\n+    }\n+  }\n+\n+  private void addNextBatchIteratorToQueue()\n+      throws IOException, InterruptedException {\n+    List<FileStatus> fileStatuses = new ArrayList<>();\n+    continuation = listingSupport\n+        .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n+            continuation);\n+    if(!fileStatuses.isEmpty()) {", "originalCommit": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcyNjI5OA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r568726298", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-02-02T16:07:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4ODQ1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "9b8053c7a32cce97aab5b256452132b4a397c2e9", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 42eddf53ae8..0c664fc2fbb 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -146,7 +146,7 @@ private void addNextBatchIteratorToQueue()\n     continuation = listingSupport\n         .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n             continuation);\n-    if(!fileStatuses.isEmpty()) {\n+    if (!fileStatuses.isEmpty()) {\n       iteratorsQueue.put(fileStatuses.iterator());\n     }\n     synchronized (this) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4OTMzMQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567989331", "bodyText": "add that at the actual interface, along with the @Private . Not that we'd expect anyone to use it", "author": "steveloughran", "createdAt": "2021-02-01T17:04:21Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListingSupport.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.List;\n+\n+import org.apache.hadoop.classification.InterfaceStability;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+\n+public interface ListingSupport {\n+\n+  /**\n+   * @param path The list path.\n+   * @return the entries in the path.\n+   */\n+  FileStatus[] listStatus(Path path) throws IOException;\n+\n+  /**\n+   * @param path      Path the list path.\n+   * @param startFrom The entry name that list results should start with.\n+   *                  For example, if folder \"/folder\" contains four\n+   *                  files: \"afile\", \"bfile\", \"hfile\", \"ifile\". Then\n+   *                  listStatus(Path(\"/folder\"), \"hfile\") will return\n+   *                  \"/folder/hfile\" and \"folder/ifile\" Notice that if\n+   *                  startFrom is a non-existent entry name, then the\n+   *                  list response contains all entries after this\n+   *                  non-existent entry in lexical order: listStatus\n+   *                  (Path(\"/folder\"), \"cfile\") will return\n+   *                  \"/folder/hfile\" and \"/folder/ifile\".\n+   * @return the entries in the path start from  \"startFrom\" in lexical order.\n+   */\n+  @InterfaceStability.Unstable", "originalCommit": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcyNjIyNw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r568726227", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-02-02T16:07:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4OTMzMQ=="}], "type": "inlineReview", "revised_code": {"commit": "9b8053c7a32cce97aab5b256452132b4a397c2e9", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListingSupport.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListingSupport.java\nindex dc3203f11e4..168757d94c8 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListingSupport.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/ListingSupport.java\n\n@@ -21,10 +21,13 @@\n import java.io.IOException;\n import java.util.List;\n \n+import org.apache.hadoop.classification.InterfaceAudience;\n import org.apache.hadoop.classification.InterfaceStability;\n import org.apache.hadoop.fs.FileStatus;\n import org.apache.hadoop.fs.Path;\n \n+@InterfaceAudience.Private\n+@InterfaceStability.Unstable\n public interface ListingSupport {\n \n   /**\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4OTUxMA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567989510", "bodyText": "cut", "author": "steveloughran", "createdAt": "2021-02-01T17:04:38Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusRemoteIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusRemoteIterator() throws Exception {\n+    super();", "originalCommit": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcyNjE1MQ==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r568726151", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-02-02T16:07:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk4OTUxMA=="}], "type": "inlineReview", "revised_code": {"commit": "9b8053c7a32cce97aab5b256452132b4a397c2e9", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\nindex 5e6034827e4..6d5e4cf3bce 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\n\n@@ -53,7 +53,6 @@\n   private static final int TEST_FILES_NUMBER = 1000;\n \n   public ITestAbfsListStatusRemoteIterator() throws Exception {\n-    super();\n   }\n \n   @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk5MDU5Nw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567990597", "bodyText": "this should be in a finally block", "author": "steveloughran", "createdAt": "2021-02-01T17:06:03Z", "path": "hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs;\n+\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n+import org.assertj.core.api.Assertions;\n+import org.junit.Test;\n+import org.mockito.Mockito;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.fs.RemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.AbfsListStatusRemoteIterator;\n+import org.apache.hadoop.fs.azurebfs.services.ListingSupport;\n+\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyBoolean;\n+import static org.mockito.ArgumentMatchers.anyList;\n+import static org.mockito.ArgumentMatchers.nullable;\n+import static org.mockito.Mockito.verify;\n+\n+/**\n+ * Test ListStatusRemoteIterator operation.\n+ */\n+public class ITestAbfsListStatusRemoteIterator extends AbstractAbfsIntegrationTest {\n+\n+  private static final int TEST_FILES_NUMBER = 1000;\n+\n+  public ITestAbfsListStatusRemoteIterator() throws Exception {\n+    super();\n+  }\n+\n+  @Test\n+  public void testAbfsIteratorWithHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    int minNumberOfInvokations = TEST_FILES_NUMBER / 10;\n+    verify(listngSupport, Mockito.atLeast(minNumberOfInvokations))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testAbfsIteratorWithoutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    ListingSupport listngSupport = Mockito.spy(getFileSystem().getAbfsStore());\n+    RemoteIterator<FileStatus> fsItr = new AbfsListStatusRemoteIterator(\n+        getFileSystem().getFileStatus(testDir), listngSupport);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should be instance of \"\n+            + \"AbfsListStatusRemoteIterator by default\")\n+        .isInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+    int minNumberOfInvokations = TEST_FILES_NUMBER / 10;\n+    verify(listngSupport, Mockito.atLeast(minNumberOfInvokations))\n+        .listStatus(any(Path.class), nullable(String.class),\n+            anyList(), anyBoolean(),\n+            nullable(String.class));\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabled() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    while (fsItr.hasNext()) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testWithAbfsIteratorDisabledWithoutHasNext() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    setEnableAbfsIterator(false);\n+    final List<String> fileNames = createFilesUnderDirectory(TEST_FILES_NUMBER,\n+        testDir, \"testListPath\");\n+\n+    RemoteIterator<FileStatus> fsItr =\n+        getFileSystem().listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr)\n+        .describedAs(\"RemoteIterator should not be instance of \"\n+            + \"AbfsListStatusRemoteIterator when it is disabled\")\n+        .isNotInstanceOf(AbfsListStatusRemoteIterator.class);\n+    int itrCount = 0;\n+    for (int i = 0; i < TEST_FILES_NUMBER; i++) {\n+      FileStatus fileStatus = fsItr.next();\n+      String pathStr = fileStatus.getPath().toString();\n+      fileNames.remove(pathStr);\n+      itrCount++;\n+    }\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+            \"next() should throw NoSuchElementException since next has been \"\n+                + \"called \" + TEST_FILES_NUMBER + \" times\")\n+        .isInstanceOf(NoSuchElementException.class);\n+    Assertions.assertThat(itrCount)\n+        .describedAs(\"Number of iterations should be equal to the files \"\n+            + \"created\")\n+        .isEqualTo(TEST_FILES_NUMBER);\n+    Assertions.assertThat(fileNames.size())\n+        .describedAs(\"After removing every iterm found from the iterator, \"\n+            + \"there should be no more elements in the fileNames\")\n+        .isEqualTo(0);\n+  }\n+\n+  @Test\n+  public void testNextWhenNoMoreElementsPresent() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+            getFileSystem().getAbfsStore());\n+    fsItr = Mockito.spy(fsItr);\n+    Mockito.doReturn(false).when(fsItr).hasNext();\n+\n+    RemoteIterator<FileStatus> finalFsItr = fsItr;\n+    Assertions.assertThatThrownBy(() -> finalFsItr.next())\n+        .describedAs(\n+        \"next() should throw NoSuchElementException if hasNext() return \"\n+            + \"false\")\n+        .isInstanceOf(NoSuchElementException.class);\n+  }\n+\n+  @Test\n+  public void testHasNextForEmptyDir() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = getFileSystem()\n+        .listStatusIterator(testDir);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns false for empty directory\")\n+        .isFalse();\n+  }\n+\n+  @Test\n+  public void testHasNextForFile() throws Exception {\n+    final AzureBlobFileSystem fs = getFileSystem();\n+    String testFileName = \"testFile\";\n+    Path testFile = new Path(testFileName);\n+    getFileSystem().create(testFile);\n+    setPageSize(10);\n+    RemoteIterator<FileStatus> fsItr = fs.listStatusIterator(testFile);\n+    Assertions.assertThat(fsItr.hasNext())\n+        .describedAs(\"hasNext returns true for file\").isTrue();\n+    Assertions.assertThat(fsItr.next().getPath().toString())\n+        .describedAs(\"next returns the file itself\")\n+        .endsWith(testFileName);\n+  }\n+\n+  @Test\n+  public void testIOException() throws Exception {\n+    Path testDir = createTestDirectory();\n+    setPageSize(10);\n+    getFileSystem().mkdirs(testDir);\n+\n+    String exceptionMessage = \"test exception\";\n+    ListingSupport lsSupport =getMockListingSupport(exceptionMessage);\n+    RemoteIterator fsItr =\n+        new AbfsListStatusRemoteIterator(getFileSystem().getFileStatus(testDir),\n+        lsSupport);\n+\n+    Assertions.assertThatThrownBy(() -> fsItr.next())\n+        .describedAs(\n+        \"When ioException is not null and queue is empty exception should be \"\n+            + \"thrown\")\n+        .isInstanceOf(IOException.class)\n+        .hasMessage(exceptionMessage);\n+  }\n+\n+  @Test\n+  public void testNonExistingPath() throws Throwable {\n+    Path nonExistingDir = new Path(\"nonExistingPath\");\n+    Assertions.assertThatThrownBy(\n+        () -> getFileSystem().listStatusIterator(nonExistingDir)).describedAs(\n+        \"test the listStatusIterator call on a path which is not \"\n+            + \"present should result in FileNotFoundException\")\n+        .isInstanceOf(FileNotFoundException.class);\n+  }\n+\n+  private ListingSupport getMockListingSupport(String exceptionMessage) {\n+    return new ListingSupport() {\n+      @Override\n+      public FileStatus[] listStatus(Path path) throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public FileStatus[] listStatus(Path path, String startFrom)\n+          throws IOException {\n+        return null;\n+      }\n+\n+      @Override\n+      public String listStatus(Path path, String startFrom,\n+          List<FileStatus> fileStatuses, boolean fetchAll, String continuation)\n+          throws IOException {\n+        throw new IOException(exceptionMessage);\n+      }\n+    };\n+  }\n+\n+  private Path createTestDirectory() throws IOException {\n+    String testDirectoryName = \"testDirectory\" + System.currentTimeMillis();\n+    Path testDirectory = new Path(testDirectoryName);\n+    getFileSystem().mkdirs(testDirectory);\n+    return testDirectory;\n+  }\n+\n+  private void setEnableAbfsIterator(boolean shouldEnable) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setEnableAbfsListIterator(shouldEnable);\n+  }\n+\n+  private void setPageSize(int pageSize) throws IOException {\n+    AzureBlobFileSystemStore abfsStore = getAbfsStore(getFileSystem());\n+    abfsStore.getAbfsConfiguration().setListMaxResults(pageSize);\n+  }\n+\n+  private List<String> createFilesUnderDirectory(int numFiles, Path rootPath,\n+      String filenamePrefix)\n+      throws ExecutionException, InterruptedException, IOException {\n+    final List<Future<Void>> tasks = new ArrayList<>();\n+    final List<String> fileNames = new ArrayList<>();\n+    ExecutorService es = Executors.newFixedThreadPool(10);\n+    for (int i = 0; i < numFiles; i++) {\n+      final Path filePath = new Path(rootPath, filenamePrefix + i);\n+      Callable<Void> callable = () -> {\n+        getFileSystem().create(filePath);\n+        fileNames.add(makeQualified(filePath).toString());\n+        return null;\n+      };\n+      tasks.add(es.submit(callable));\n+    }\n+    for (Future<Void> task : tasks) {\n+      task.get();\n+    }\n+    es.shutdownNow();", "originalCommit": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcyNjA2Mg==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r568726062", "bodyText": "Done", "author": "bilaharith", "createdAt": "2021-02-02T16:07:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk5MDU5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "9b8053c7a32cce97aab5b256452132b4a397c2e9", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\nindex 5e6034827e4..6d5e4cf3bce 100644\n--- a/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/test/java/org/apache/hadoop/fs/azurebfs/ITestAbfsListStatusRemoteIterator.java\n\n@@ -53,7 +53,6 @@\n   private static final int TEST_FILES_NUMBER = 1000;\n \n   public ITestAbfsListStatusRemoteIterator() throws Exception {\n-    super();\n   }\n \n   @Test\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk5MzM1Mw==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r567993353", "bodyText": "I can't help thinking this a bit of an abuse of a queue to mix object types in there -but to do it in any other way within java would be pretty convoluted (new class, essentially), so let's go with what is here. Just need to make sure there's test coverage for the IOE path", "author": "steveloughran", "createdAt": "2021-02-01T17:09:53Z", "path": "hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.hadoop.fs.azurebfs.services;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.TimeUnit;\n+import javax.activation.UnsupportedDataTypeException;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.hadoop.fs.RemoteIterator;\n+\n+public class AbfsListStatusRemoteIterator\n+    implements RemoteIterator<FileStatus> {\n+\n+  private static final Logger LOG = LoggerFactory\n+      .getLogger(AbfsListStatusRemoteIterator.class);\n+\n+  private static final boolean FETCH_ALL_FALSE = false;\n+  private static final int MAX_QUEUE_SIZE = 10;\n+  private static final long POLL_WAIT_TIME_IN_MS = 250;\n+\n+  private final FileStatus fileStatus;\n+  private final ListingSupport listingSupport;\n+  private final ArrayBlockingQueue<Object> iteratorsQueue;\n+\n+  private volatile boolean isAsyncInProgress = false;\n+  private boolean isIterationComplete = false;\n+  private String continuation;\n+  private Iterator<FileStatus> currIterator;\n+\n+  public AbfsListStatusRemoteIterator(final FileStatus fileStatus,\n+      final ListingSupport listingSupport) {\n+    this.fileStatus = fileStatus;\n+    this.listingSupport = listingSupport;\n+    iteratorsQueue = new ArrayBlockingQueue<>(MAX_QUEUE_SIZE);\n+    currIterator = Collections.emptyIterator();\n+    fetchBatchesAsync();\n+  }\n+\n+  @Override\n+  public boolean hasNext() throws IOException {\n+    if (currIterator.hasNext()) {\n+      return true;\n+    }\n+    currIterator = getNextIterator();\n+    return currIterator.hasNext();\n+  }\n+\n+  @Override\n+  public FileStatus next() throws IOException {\n+    if (!this.hasNext()) {\n+      throw new NoSuchElementException();\n+    }\n+    return currIterator.next();\n+  }\n+\n+  private Iterator<FileStatus> getNextIterator() throws IOException {\n+    fetchBatchesAsync();\n+    try {\n+      Object obj = null;\n+      while (obj == null\n+          && (!isIterationComplete || !iteratorsQueue.isEmpty())) {\n+        obj = iteratorsQueue.poll(POLL_WAIT_TIME_IN_MS, TimeUnit.MILLISECONDS);\n+      }\n+      if (obj == null) {\n+        return Collections.emptyIterator();\n+      } else if (obj instanceof Iterator) {", "originalCommit": "5970d6ec245c2bfb273435733de5b76f2ddcb22b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODcyNTcxOA==", "url": "https://github.com/apache/hadoop/pull/2548#discussion_r568725718", "bodyText": "It is added", "author": "bilaharith", "createdAt": "2021-02-02T16:07:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Nzk5MzM1Mw=="}], "type": "inlineReview", "revised_code": {"commit": "9b8053c7a32cce97aab5b256452132b4a397c2e9", "chunk": "diff --git a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\nindex 42eddf53ae8..0c664fc2fbb 100644\n--- a/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n+++ b/hadoop-tools/hadoop-azure/src/main/java/org/apache/hadoop/fs/azurebfs/services/AbfsListStatusRemoteIterator.java\n\n@@ -146,7 +146,7 @@ private void addNextBatchIteratorToQueue()\n     continuation = listingSupport\n         .listStatus(fileStatus.getPath(), null, fileStatuses, FETCH_ALL_FALSE,\n             continuation);\n-    if(!fileStatuses.isEmpty()) {\n+    if (!fileStatuses.isEmpty()) {\n       iteratorsQueue.put(fileStatuses.iterator());\n     }\n     synchronized (this) {\n"}}, {"oid": "9b8053c7a32cce97aab5b256452132b4a397c2e9", "url": "https://github.com/apache/hadoop/commit/9b8053c7a32cce97aab5b256452132b4a397c2e9", "message": "Addressing review comments", "committedDate": "2021-02-02T15:00:50Z", "type": "commit"}, {"oid": "919245daaa42c9b46903f198f8eba58d21226998", "url": "https://github.com/apache/hadoop/commit/919245daaa42c9b46903f198f8eba58d21226998", "message": "To ignore the findbug warning related to continuation", "committedDate": "2021-02-03T11:37:36Z", "type": "commit"}, {"oid": "51bd08a71719310ad11b22f107fd5a4378d27271", "url": "https://github.com/apache/hadoop/commit/51bd08a71719310ad11b22f107fd5a4378d27271", "message": "Fixing javadoc issues", "committedDate": "2021-02-03T11:41:30Z", "type": "commit"}, {"oid": "b01659a20c2a26fdf45a19e073dc2eb8b76d6f6a", "url": "https://github.com/apache/hadoop/commit/b01659a20c2a26fdf45a19e073dc2eb8b76d6f6a", "message": "findbugs fix", "committedDate": "2021-02-03T14:27:55Z", "type": "commit"}]}