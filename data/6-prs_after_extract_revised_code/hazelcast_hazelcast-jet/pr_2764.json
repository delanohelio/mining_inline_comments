{"pr_number": 2764, "pr_title": "Re-assign InputSplits on members for LocalFileSystem", "pr_createdAt": "2020-12-28T19:00:23Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2764", "timeline": [{"oid": "cd22fdc89af3256e8866183f4551828e8d02c24d", "url": "https://github.com/hazelcast/hazelcast-jet/commit/cd22fdc89af3256e8866183f4551828e8d02c24d", "message": "re-assign input splits on members if all the input paths are of the local file system", "committedDate": "2020-12-28T18:23:44Z", "type": "commit"}, {"oid": "98803a2e7816fa3553854ad512bbfa8b34c98690", "url": "https://github.com/hazelcast/hazelcast-jet/commit/98803a2e7816fa3553854ad512bbfa8b34c98690", "message": "fix tests", "committedDate": "2020-12-28T18:47:00Z", "type": "commit"}, {"oid": "60621a44994efff22c7b53e606efa84b0a72c78c", "url": "https://github.com/hazelcast/hazelcast-jet/commit/60621a44994efff22c7b53e606efa84b0a72c78c", "message": "add since tag for HadoopSources.SHARED_LOCAL_FS", "committedDate": "2020-12-28T19:02:54Z", "type": "commit"}, {"oid": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "url": "https://github.com/hazelcast/hazelcast-jet/commit/257fc7e81fac91d8de12125d2ba95c6da7b22301", "message": "sink test fix", "committedDate": "2020-12-28T19:27:38Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTE2MjU4NQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551162585", "bodyText": "This is a change in the Hadoop connector behavior, right? Maybe we should default to true, which is current behavior.", "author": "frant-hartm", "createdAt": "2021-01-04T07:59:14Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java", "diffHunk": "@@ -62,12 +62,30 @@\n      *\n      * <pre>{@code\n      *     Configuration conf = new Configuration();\n-     *     conf.set(HadoopSources.COPY_ON_READ, \"false\");\n+     *     conf.setBoolean(HadoopSources.COPY_ON_READ, false);\n      *     BatchSource<Entry<K, V>> source = HadoopSources.inputFormat(conf);\n      * }</pre>\n      */\n     public static final String COPY_ON_READ = \"jet.source.copyonread\";\n \n+    /**\n+     * When reading files from local file system using Hadoop, each processor\n+     * reads files from its own local file system. If the local file system\n+     * is shared between members, e.g multiple members on a machine, you should\n+     * configure this property as {@code true}.\n+     * <p>\n+     * Here is how you can configure the source. Default value is {@code false}:", "originalCommit": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc3NDc4OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551774788", "bodyText": "yes this is a behavior change but I'll argue that previous behaviour was wrong so we shouldn't try to keep it as default.", "author": "gurbuzali", "createdAt": "2021-01-05T08:12:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTE2MjU4NQ=="}], "type": "inlineReview", "revised_code": {"commit": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java\nindex 41ee105fa..7fee95151 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java\n\n@@ -71,7 +71,7 @@ public final class HadoopSources {\n     /**\n      * When reading files from local file system using Hadoop, each processor\n      * reads files from its own local file system. If the local file system\n-     * is shared between members, e.g multiple members on a machine, you should\n+     * is shared between members, e.g NFS mounted filesystem, you should\n      * configure this property as {@code true}.\n      * <p>\n      * Here is how you can configure the source. Default value is {@code false}:\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc0OTMyMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551749321", "bodyText": "AFAIK we don't recommend running multiple members on a single machine, so the javadoc should give a better example, e.g. NFS mounted filesystem or similar.", "author": "frant-hartm", "createdAt": "2021-01-05T07:00:06Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java", "diffHunk": "@@ -62,12 +62,30 @@\n      *\n      * <pre>{@code\n      *     Configuration conf = new Configuration();\n-     *     conf.set(HadoopSources.COPY_ON_READ, \"false\");\n+     *     conf.setBoolean(HadoopSources.COPY_ON_READ, false);\n      *     BatchSource<Entry<K, V>> source = HadoopSources.inputFormat(conf);\n      * }</pre>\n      */\n     public static final String COPY_ON_READ = \"jet.source.copyonread\";\n \n+    /**\n+     * When reading files from local file system using Hadoop, each processor\n+     * reads files from its own local file system. If the local file system\n+     * is shared between members, e.g multiple members on a machine, you should", "originalCommit": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc3NDg1NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551774854", "bodyText": "\ud83d\udc4d", "author": "gurbuzali", "createdAt": "2021-01-05T08:12:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc0OTMyMQ=="}], "type": "inlineReview", "revised_code": {"commit": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java\nindex 41ee105fa..7fee95151 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/HadoopSources.java\n\n@@ -71,7 +71,7 @@ public final class HadoopSources {\n     /**\n      * When reading files from local file system using Hadoop, each processor\n      * reads files from its own local file system. If the local file system\n-     * is shared between members, e.g multiple members on a machine, you should\n+     * is shared between members, e.g NFS mounted filesystem, you should\n      * configure this property as {@code true}.\n      * <p>\n      * Here is how you can configure the source. Default value is {@code false}:\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1MDE5OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551750199", "bodyText": "This still happens on the coordinator node, the reassign must be in get(int) method.", "author": "frant-hartm", "createdAt": "2021-01-05T07:03:09Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java", "diffHunk": "@@ -206,7 +214,7 @@ private Supplier(\n         ) {\n             this.configuration = configuration;\n             this.projectionFn = projectionFn;\n-            this.assignedSplits = assignedSplits;\n+            this.assignedSplits = reAssignSplits(assignedSplits);", "originalCommit": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc3NTgwOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551775809", "bodyText": "\ud83d\udc4d", "author": "gurbuzali", "createdAt": "2021-01-05T08:14:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1MDE5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\nindex f07bd0088..ba47b7ca0 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n\n@@ -214,49 +217,58 @@ public final class ReadHadoopNewApiP<K, V, R> extends AbstractProcessor {\n         ) {\n             this.configuration = configuration;\n             this.projectionFn = projectionFn;\n-            this.assignedSplits = reAssignSplits(assignedSplits);\n+            this.assignedSplits = assignedSplits;\n         }\n \n         @Nonnull\n         @Override\n         public List<Processor> get(int count) {\n-            Map<Integer, List<IndexedInputSplit>> processorToSplits = Util.distributeObjects(count, assignedSplits);\n-\n-            return processorToSplits\n+            List<InputSplit> inputSplits;\n+            if (shouldSplitOnMembers(configuration)) {\n+                inputSplits = uncheckCall(() -> getSplits(configuration));\n+            } else {\n+                inputSplits = assignedSplits.stream().map(IndexedInputSplit::getNewSplit).collect(toList());\n+            }\n+            return Util.distributeObjects(count, inputSplits)\n                     .values().stream()\n-                    .map(splits -> {\n-                                List<InputSplit> mappedSplits = splits\n-                                        .stream()\n-                                        .map(IndexedInputSplit::getNewSplit)\n-                                        .collect(toList());\n-                                return new ReadHadoopNewApiP<>(configuration, mappedSplits, projectionFn);\n-                            }\n-                    ).collect(toList());\n+                    .map(splits -> new ReadHadoopNewApiP<>(configuration, splits, projectionFn))\n+                    .collect(toList());\n         }\n+    }\n \n-        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits) {\n-            // If the local file system is marked as shared, no re-assign\n-            if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n-                return assignedSplits;\n-            }\n-            try {\n-                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n-                Job job = Job.getInstance(configuration);\n-                Path[] inputPaths = FileInputFormat.getInputPaths(job);\n-                for (Path inputPath : inputPaths) {\n-                    if (!(inputPath.getFileSystem(configuration) instanceof LocalFileSystem)) {\n-                        return assignedSplits;\n-                    }\n-                }\n-\n-                // re-assign the splits\n-                int[] index = new int[1];\n-                List<InputSplit> splits = getSplits(configuration);\n-                return splits.stream().map(split -> new IndexedInputSplit(index[0]++, split)).collect(toList());\n-            } catch (Exception e) {\n-                throw ExceptionUtil.sneakyThrow(e);\n+    /**\n+     * If all the input paths are of LocalFileSystem and not marked as shared\n+     * (see {@link HadoopSources#SHARED_LOCAL_FS}), split the input paths on\n+     * members.\n+     */\n+    private static boolean shouldSplitOnMembers(Configuration configuration) {\n+        // If the local file system is marked as shared, don't split on members\n+        if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+            return false;\n+        }\n+        // Local file system is not marked as shared, throw exception if\n+        // there are local file system and shared file system in the inputs.\n+        Job job = uncheckCall(() -> Job.getInstance(configuration));\n+        Path[] inputPaths = FileInputFormat.getInputPaths(job);\n+        boolean hasLocalFileSystem = false;\n+        boolean hasSharedFileSystem = false;\n+        for (Path inputPath : inputPaths) {\n+            if (isLocalFileSystem(inputPath, configuration)) {\n+                hasLocalFileSystem = true;\n+            } else {\n+                hasSharedFileSystem = true;\n             }\n         }\n+        if (hasLocalFileSystem && hasSharedFileSystem) {\n+            throw new IllegalArgumentException(\n+                    \"LocalFileSystem should be marked as shared when used with other shared file systems\");\n+        }\n+        return hasLocalFileSystem;\n+    }\n+\n+    private static boolean isLocalFileSystem(Path inputPath, Configuration configuration) {\n+        FileSystem fileSystem = uncheckCall(() -> inputPath.getFileSystem(configuration));\n+        return fileSystem instanceof LocalFileSystem || fileSystem instanceof RawLocalFileSystem;\n     }\n \n     private static final class HadoopFileTraverser<K, V, R> implements FileTraverser<R> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1MDkwMQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551750901", "bodyText": "Maybe just use a regular for instead of stream().map(...) - mutating in map is a code smell.", "author": "frant-hartm", "createdAt": "2021-01-05T07:05:30Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java", "diffHunk": "@@ -225,6 +233,30 @@ private Supplier(\n                             }\n                     ).collect(toList());\n         }\n+\n+        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits) {\n+            // If the local file system is marked as shared, no re-assign\n+            if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+                return assignedSplits;\n+            }\n+            try {\n+                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n+                Job job = Job.getInstance(configuration);\n+                Path[] inputPaths = FileInputFormat.getInputPaths(job);\n+                for (Path inputPath : inputPaths) {\n+                    if (!(inputPath.getFileSystem(configuration) instanceof LocalFileSystem)) {\n+                        return assignedSplits;\n+                    }\n+                }\n+\n+                // re-assign the splits\n+                int[] index = new int[1];", "originalCommit": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\nindex f07bd0088..ba47b7ca0 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n\n@@ -214,49 +217,58 @@ public final class ReadHadoopNewApiP<K, V, R> extends AbstractProcessor {\n         ) {\n             this.configuration = configuration;\n             this.projectionFn = projectionFn;\n-            this.assignedSplits = reAssignSplits(assignedSplits);\n+            this.assignedSplits = assignedSplits;\n         }\n \n         @Nonnull\n         @Override\n         public List<Processor> get(int count) {\n-            Map<Integer, List<IndexedInputSplit>> processorToSplits = Util.distributeObjects(count, assignedSplits);\n-\n-            return processorToSplits\n+            List<InputSplit> inputSplits;\n+            if (shouldSplitOnMembers(configuration)) {\n+                inputSplits = uncheckCall(() -> getSplits(configuration));\n+            } else {\n+                inputSplits = assignedSplits.stream().map(IndexedInputSplit::getNewSplit).collect(toList());\n+            }\n+            return Util.distributeObjects(count, inputSplits)\n                     .values().stream()\n-                    .map(splits -> {\n-                                List<InputSplit> mappedSplits = splits\n-                                        .stream()\n-                                        .map(IndexedInputSplit::getNewSplit)\n-                                        .collect(toList());\n-                                return new ReadHadoopNewApiP<>(configuration, mappedSplits, projectionFn);\n-                            }\n-                    ).collect(toList());\n+                    .map(splits -> new ReadHadoopNewApiP<>(configuration, splits, projectionFn))\n+                    .collect(toList());\n         }\n+    }\n \n-        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits) {\n-            // If the local file system is marked as shared, no re-assign\n-            if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n-                return assignedSplits;\n-            }\n-            try {\n-                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n-                Job job = Job.getInstance(configuration);\n-                Path[] inputPaths = FileInputFormat.getInputPaths(job);\n-                for (Path inputPath : inputPaths) {\n-                    if (!(inputPath.getFileSystem(configuration) instanceof LocalFileSystem)) {\n-                        return assignedSplits;\n-                    }\n-                }\n-\n-                // re-assign the splits\n-                int[] index = new int[1];\n-                List<InputSplit> splits = getSplits(configuration);\n-                return splits.stream().map(split -> new IndexedInputSplit(index[0]++, split)).collect(toList());\n-            } catch (Exception e) {\n-                throw ExceptionUtil.sneakyThrow(e);\n+    /**\n+     * If all the input paths are of LocalFileSystem and not marked as shared\n+     * (see {@link HadoopSources#SHARED_LOCAL_FS}), split the input paths on\n+     * members.\n+     */\n+    private static boolean shouldSplitOnMembers(Configuration configuration) {\n+        // If the local file system is marked as shared, don't split on members\n+        if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+            return false;\n+        }\n+        // Local file system is not marked as shared, throw exception if\n+        // there are local file system and shared file system in the inputs.\n+        Job job = uncheckCall(() -> Job.getInstance(configuration));\n+        Path[] inputPaths = FileInputFormat.getInputPaths(job);\n+        boolean hasLocalFileSystem = false;\n+        boolean hasSharedFileSystem = false;\n+        for (Path inputPath : inputPaths) {\n+            if (isLocalFileSystem(inputPath, configuration)) {\n+                hasLocalFileSystem = true;\n+            } else {\n+                hasSharedFileSystem = true;\n             }\n         }\n+        if (hasLocalFileSystem && hasSharedFileSystem) {\n+            throw new IllegalArgumentException(\n+                    \"LocalFileSystem should be marked as shared when used with other shared file systems\");\n+        }\n+        return hasLocalFileSystem;\n+    }\n+\n+    private static boolean isLocalFileSystem(Path inputPath, Configuration configuration) {\n+        FileSystem fileSystem = uncheckCall(() -> inputPath.getFileSystem(configuration));\n+        return fileSystem instanceof LocalFileSystem || fileSystem instanceof RawLocalFileSystem;\n     }\n \n     private static final class HadoopFileTraverser<K, V, R> implements FileTraverser<R> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1MTk1Nw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551751957", "bodyText": "Ha! It's correct here in the ReadHadoopOldApiP", "author": "frant-hartm", "createdAt": "2021-01-05T07:08:37Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopOldApiP.java", "diffHunk": "@@ -148,20 +140,91 @@ public void init(@Nonnull Context context) throws Exception {\n         @Override\n         @Nonnull\n         public List<Processor> get(int count) {\n-            Map<Integer, List<IndexedInputSplit>> processorToSplits = Util.distributeObjects(count, assignedSplits);\n-            InputFormat inputFormat = jobConf.getInputFormat();\n-            Processor noopProcessor = Processors.noopP().get();\n-\n+            List<IndexedInputSplit> reAssignedSplits = reAssignSplits(assignedSplits, count);", "originalCommit": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopOldApiP.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopOldApiP.java\nindex 4508eaac3..dcf21bb14 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopOldApiP.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopOldApiP.java\n\n@@ -140,42 +146,51 @@ public final class ReadHadoopOldApiP<K, V, R> extends AbstractProcessor {\n         @Override\n         @Nonnull\n         public List<Processor> get(int count) {\n-            List<IndexedInputSplit> reAssignedSplits = reAssignSplits(assignedSplits, count);\n-            Map<Integer, List<IndexedInputSplit>> processorToSplits = Util.distributeObjects(count, reAssignedSplits);\n-            return processorToSplits\n+            List<InputSplit> inputSplits;\n+            if (shouldSplitOnMembers(jobConf)) {\n+                inputSplits = uncheckCall(() -> asList(jobConf.getInputFormat().getSplits(jobConf, count)));\n+            } else {\n+                inputSplits = assignedSplits.stream().map(IndexedInputSplit::getOldSplit).collect(toList());\n+            }\n+            return Util.distributeObjects(count, inputSplits)\n                     .values().stream()\n-                    .map(splits -> {\n-                        List<InputSplit> mappedSplits = splits\n-                                .stream()\n-                                .map(IndexedInputSplit::getOldSplit)\n-                                .collect(toList());\n-                        return new ReadHadoopOldApiP<>(jobConf, mappedSplits, projectionFn);\n-                    })\n+                    .map(splits -> new ReadHadoopOldApiP<>(jobConf, splits, projectionFn))\n                     .collect(toList());\n         }\n+    }\n \n-        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits, int count) {\n-            // If the local file system is marked as shared, no re-assign\n-            if (jobConf.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n-                return assignedSplits;\n-            }\n-            try {\n-                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n-                Path[] inputPaths = FileInputFormat.getInputPaths(jobConf);\n-                for (Path inputPath : inputPaths) {\n-                    if (!(inputPath.getFileSystem(jobConf) instanceof LocalFileSystem)) {\n-                        return assignedSplits;\n-                    }\n-                }\n-\n-                // re-assign the splits\n-                int[] index = new int[1];\n-                InputSplit[] splits = jobConf.getInputFormat().getSplits(jobConf, count);\n-                return Arrays.stream(splits).map(split -> new IndexedInputSplit(index[0]++, split)).collect(toList());\n-            } catch (Exception e) {\n-                throw ExceptionUtil.sneakyThrow(e);\n+    /**\n+     * If all the input paths are of LocalFileSystem and not marked as shared\n+     * (see {@link HadoopSources#SHARED_LOCAL_FS}), split the input paths on\n+     * members.\n+     */\n+    private static boolean shouldSplitOnMembers(JobConf jobConf) {\n+        // If the local file system is marked as shared, don't split on members\n+        if (jobConf.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+            return false;\n+        }\n+        // Local file system is not marked as shared, throw exception if\n+        // there are local file system and shared file system in the inputs.\n+        Path[] inputPaths = FileInputFormat.getInputPaths(jobConf);\n+        boolean hasLocalFileSystem = false;\n+        boolean hasSharedFileSystem = false;\n+        for (Path inputPath : inputPaths) {\n+            if (isLocalFileSystem(inputPath, jobConf)) {\n+                hasLocalFileSystem = true;\n+            } else {\n+                hasSharedFileSystem = true;\n             }\n         }\n+        if (hasLocalFileSystem && hasSharedFileSystem) {\n+            throw new IllegalArgumentException(\n+                    \"LocalFileSystem should be marked as shared when used with other shared file systems\");\n+        }\n+        return hasLocalFileSystem;\n+    }\n+\n+    private static boolean isLocalFileSystem(Path inputPath, JobConf jobConf) {\n+        FileSystem fileSystem = uncheckCall(() -> inputPath.getFileSystem(jobConf));\n+        return fileSystem instanceof LocalFileSystem || fileSystem instanceof RawLocalFileSystem;\n     }\n \n     private static final class HadoopFileTraverser<K, V, R> implements FileTraverser<R> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1MzQ5Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551753492", "bodyText": "The shared FS flag is set to false, maybe we should always reassign and forbid non-local FS & shared=false combination.\nAlso we can avoid assigning the splits in meta supplier if we assign them here.", "author": "frant-hartm", "createdAt": "2021-01-05T07:13:33Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java", "diffHunk": "@@ -225,6 +233,30 @@ private Supplier(\n                             }\n                     ).collect(toList());\n         }\n+\n+        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits) {\n+            // If the local file system is marked as shared, no re-assign\n+            if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+                return assignedSplits;\n+            }\n+            try {\n+                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n+                Job job = Job.getInstance(configuration);", "originalCommit": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc4MTgwMg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551781802", "bodyText": "I thought SHARED_LOCAL_FS property as a way to pass sharedFileSystem parameter from file source builder to hadoop implementation. it is false by default on file source builder. if it is explicitly set to true we don't do the re-assign, if it is not set then we check the filesystem and if all the inputs are local we re-assign.\nI don't have a strong opinion here, let's discuss it", "author": "gurbuzali", "createdAt": "2021-01-05T08:27:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1MzQ5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\nindex f07bd0088..ba47b7ca0 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n\n@@ -214,49 +217,58 @@ public final class ReadHadoopNewApiP<K, V, R> extends AbstractProcessor {\n         ) {\n             this.configuration = configuration;\n             this.projectionFn = projectionFn;\n-            this.assignedSplits = reAssignSplits(assignedSplits);\n+            this.assignedSplits = assignedSplits;\n         }\n \n         @Nonnull\n         @Override\n         public List<Processor> get(int count) {\n-            Map<Integer, List<IndexedInputSplit>> processorToSplits = Util.distributeObjects(count, assignedSplits);\n-\n-            return processorToSplits\n+            List<InputSplit> inputSplits;\n+            if (shouldSplitOnMembers(configuration)) {\n+                inputSplits = uncheckCall(() -> getSplits(configuration));\n+            } else {\n+                inputSplits = assignedSplits.stream().map(IndexedInputSplit::getNewSplit).collect(toList());\n+            }\n+            return Util.distributeObjects(count, inputSplits)\n                     .values().stream()\n-                    .map(splits -> {\n-                                List<InputSplit> mappedSplits = splits\n-                                        .stream()\n-                                        .map(IndexedInputSplit::getNewSplit)\n-                                        .collect(toList());\n-                                return new ReadHadoopNewApiP<>(configuration, mappedSplits, projectionFn);\n-                            }\n-                    ).collect(toList());\n+                    .map(splits -> new ReadHadoopNewApiP<>(configuration, splits, projectionFn))\n+                    .collect(toList());\n         }\n+    }\n \n-        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits) {\n-            // If the local file system is marked as shared, no re-assign\n-            if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n-                return assignedSplits;\n-            }\n-            try {\n-                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n-                Job job = Job.getInstance(configuration);\n-                Path[] inputPaths = FileInputFormat.getInputPaths(job);\n-                for (Path inputPath : inputPaths) {\n-                    if (!(inputPath.getFileSystem(configuration) instanceof LocalFileSystem)) {\n-                        return assignedSplits;\n-                    }\n-                }\n-\n-                // re-assign the splits\n-                int[] index = new int[1];\n-                List<InputSplit> splits = getSplits(configuration);\n-                return splits.stream().map(split -> new IndexedInputSplit(index[0]++, split)).collect(toList());\n-            } catch (Exception e) {\n-                throw ExceptionUtil.sneakyThrow(e);\n+    /**\n+     * If all the input paths are of LocalFileSystem and not marked as shared\n+     * (see {@link HadoopSources#SHARED_LOCAL_FS}), split the input paths on\n+     * members.\n+     */\n+    private static boolean shouldSplitOnMembers(Configuration configuration) {\n+        // If the local file system is marked as shared, don't split on members\n+        if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+            return false;\n+        }\n+        // Local file system is not marked as shared, throw exception if\n+        // there are local file system and shared file system in the inputs.\n+        Job job = uncheckCall(() -> Job.getInstance(configuration));\n+        Path[] inputPaths = FileInputFormat.getInputPaths(job);\n+        boolean hasLocalFileSystem = false;\n+        boolean hasSharedFileSystem = false;\n+        for (Path inputPath : inputPaths) {\n+            if (isLocalFileSystem(inputPath, configuration)) {\n+                hasLocalFileSystem = true;\n+            } else {\n+                hasSharedFileSystem = true;\n             }\n         }\n+        if (hasLocalFileSystem && hasSharedFileSystem) {\n+            throw new IllegalArgumentException(\n+                    \"LocalFileSystem should be marked as shared when used with other shared file systems\");\n+        }\n+        return hasLocalFileSystem;\n+    }\n+\n+    private static boolean isLocalFileSystem(Path inputPath, Configuration configuration) {\n+        FileSystem fileSystem = uncheckCall(() -> inputPath.getFileSystem(configuration));\n+        return fileSystem instanceof LocalFileSystem || fileSystem instanceof RawLocalFileSystem;\n     }\n \n     private static final class HadoopFileTraverser<K, V, R> implements FileTraverser<R> {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1NzMxOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551757318", "bodyText": "Can this ever be RawLocalFileSystem?", "author": "frant-hartm", "createdAt": "2021-01-05T07:25:38Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java", "diffHunk": "@@ -225,6 +233,30 @@ private Supplier(\n                             }\n                     ).collect(toList());\n         }\n+\n+        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits) {\n+            // If the local file system is marked as shared, no re-assign\n+            if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+                return assignedSplits;\n+            }\n+            try {\n+                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n+                Job job = Job.getInstance(configuration);\n+                Path[] inputPaths = FileInputFormat.getInputPaths(job);\n+                for (Path inputPath : inputPaths) {\n+                    if (!(inputPath.getFileSystem(configuration) instanceof LocalFileSystem)) {", "originalCommit": "257fc7e81fac91d8de12125d2ba95c6da7b22301", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc5OTYxOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2764#discussion_r551799618", "bodyText": "I don't think so but we can add that check too just to be on the safe side", "author": "gurbuzali", "createdAt": "2021-01-05T09:03:23Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTc1NzMxOA=="}], "type": "inlineReview", "revised_code": {"commit": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\nindex f07bd0088..ba47b7ca0 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/ReadHadoopNewApiP.java\n\n@@ -214,49 +217,58 @@ public final class ReadHadoopNewApiP<K, V, R> extends AbstractProcessor {\n         ) {\n             this.configuration = configuration;\n             this.projectionFn = projectionFn;\n-            this.assignedSplits = reAssignSplits(assignedSplits);\n+            this.assignedSplits = assignedSplits;\n         }\n \n         @Nonnull\n         @Override\n         public List<Processor> get(int count) {\n-            Map<Integer, List<IndexedInputSplit>> processorToSplits = Util.distributeObjects(count, assignedSplits);\n-\n-            return processorToSplits\n+            List<InputSplit> inputSplits;\n+            if (shouldSplitOnMembers(configuration)) {\n+                inputSplits = uncheckCall(() -> getSplits(configuration));\n+            } else {\n+                inputSplits = assignedSplits.stream().map(IndexedInputSplit::getNewSplit).collect(toList());\n+            }\n+            return Util.distributeObjects(count, inputSplits)\n                     .values().stream()\n-                    .map(splits -> {\n-                                List<InputSplit> mappedSplits = splits\n-                                        .stream()\n-                                        .map(IndexedInputSplit::getNewSplit)\n-                                        .collect(toList());\n-                                return new ReadHadoopNewApiP<>(configuration, mappedSplits, projectionFn);\n-                            }\n-                    ).collect(toList());\n+                    .map(splits -> new ReadHadoopNewApiP<>(configuration, splits, projectionFn))\n+                    .collect(toList());\n         }\n+    }\n \n-        private List<IndexedInputSplit> reAssignSplits(List<IndexedInputSplit> assignedSplits) {\n-            // If the local file system is marked as shared, no re-assign\n-            if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n-                return assignedSplits;\n-            }\n-            try {\n-                // If any of the input paths do not belong to LocalFileSystem, no re-assign\n-                Job job = Job.getInstance(configuration);\n-                Path[] inputPaths = FileInputFormat.getInputPaths(job);\n-                for (Path inputPath : inputPaths) {\n-                    if (!(inputPath.getFileSystem(configuration) instanceof LocalFileSystem)) {\n-                        return assignedSplits;\n-                    }\n-                }\n-\n-                // re-assign the splits\n-                int[] index = new int[1];\n-                List<InputSplit> splits = getSplits(configuration);\n-                return splits.stream().map(split -> new IndexedInputSplit(index[0]++, split)).collect(toList());\n-            } catch (Exception e) {\n-                throw ExceptionUtil.sneakyThrow(e);\n+    /**\n+     * If all the input paths are of LocalFileSystem and not marked as shared\n+     * (see {@link HadoopSources#SHARED_LOCAL_FS}), split the input paths on\n+     * members.\n+     */\n+    private static boolean shouldSplitOnMembers(Configuration configuration) {\n+        // If the local file system is marked as shared, don't split on members\n+        if (configuration.getBoolean(HadoopSources.SHARED_LOCAL_FS, false)) {\n+            return false;\n+        }\n+        // Local file system is not marked as shared, throw exception if\n+        // there are local file system and shared file system in the inputs.\n+        Job job = uncheckCall(() -> Job.getInstance(configuration));\n+        Path[] inputPaths = FileInputFormat.getInputPaths(job);\n+        boolean hasLocalFileSystem = false;\n+        boolean hasSharedFileSystem = false;\n+        for (Path inputPath : inputPaths) {\n+            if (isLocalFileSystem(inputPath, configuration)) {\n+                hasLocalFileSystem = true;\n+            } else {\n+                hasSharedFileSystem = true;\n             }\n         }\n+        if (hasLocalFileSystem && hasSharedFileSystem) {\n+            throw new IllegalArgumentException(\n+                    \"LocalFileSystem should be marked as shared when used with other shared file systems\");\n+        }\n+        return hasLocalFileSystem;\n+    }\n+\n+    private static boolean isLocalFileSystem(Path inputPath, Configuration configuration) {\n+        FileSystem fileSystem = uncheckCall(() -> inputPath.getFileSystem(configuration));\n+        return fileSystem instanceof LocalFileSystem || fileSystem instanceof RawLocalFileSystem;\n     }\n \n     private static final class HadoopFileTraverser<K, V, R> implements FileTraverser<R> {\n"}}, {"oid": "b63e680c05f0f4dcd55412a483ea515ca86e8b15", "url": "https://github.com/hazelcast/hazelcast-jet/commit/b63e680c05f0f4dcd55412a483ea515ca86e8b15", "message": "review comments", "committedDate": "2021-01-05T12:40:12Z", "type": "commit"}, {"oid": "d713ae7433e426883952aa4ed5a85470511db012", "url": "https://github.com/hazelcast/hazelcast-jet/commit/d713ae7433e426883952aa4ed5a85470511db012", "message": "shared -> remote", "committedDate": "2021-01-05T15:03:12Z", "type": "commit"}]}