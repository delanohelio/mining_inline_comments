{"pr_number": 2753, "pr_title": "Improve CSV reading performance in SQL", "pr_createdAt": "2020-12-11T16:01:41Z", "pr_url": "https://github.com/hazelcast/hazelcast-jet/pull/2753", "timeline": [{"oid": "a85245aba2cb59e573cfdb7969f051e50873bc36", "url": "https://github.com/hazelcast/hazelcast-jet/commit/a85245aba2cb59e573cfdb7969f051e50873bc36", "message": "Improve CSV reading performance in SQL\n\nInstead of reading into memory-heavy LinkedHashMap, read CSVs internally\ninto String[].", "committedDate": "2020-12-11T15:54:10Z", "type": "commit"}, {"oid": "bff559c8fc476db3d06c1dc150beef5b47208e34", "url": "https://github.com/hazelcast/hazelcast-jet/commit/bff559c8fc476db3d06c1dc150beef5b47208e34", "message": "Fix checkstyle", "committedDate": "2020-12-11T16:03:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1NzIxNw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542157217", "bodyText": "I think you could avoid projection if header == stringArrayFieldList.", "author": "gierlachg", "createdAt": "2020-12-14T07:11:48Z", "path": "extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java", "diffHunk": "@@ -47,18 +53,49 @@\n )\n public class CsvReadFileFnProvider implements ReadFileFnProvider {\n \n+    @SuppressWarnings(\"unchecked\")\n     @Nonnull\n     @Override\n     public <T> FunctionEx<Path, Stream<T>> createReadFileFn(@Nonnull FileFormat<T> format) {\n         CsvFileFormat<T> csvFileFormat = (CsvFileFormat<T>) format;\n         Class<?> formatClazz = csvFileFormat.clazz(); // Format is not Serializable\n \n         return path -> {\n-            ObjectReader reader = new CsvMapper().readerFor(formatClazz != null ? formatClazz : Map.class)\n-                                                 .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n-                                                 .with(CsvSchema.emptySchema().withHeader());\n             FileInputStream fis = new FileInputStream(path.toFile());\n-            return StreamSupport.<T>stream(Spliterators.spliteratorUnknownSize(reader.readValues(fis), ORDERED), false)\n+            MappingIterator<T> iterator;\n+            Function<T, T> projection = r -> r;\n+            if (formatClazz == String[].class) {\n+                ObjectReader reader = new CsvMapper().enable(Feature.WRAP_AS_ARRAY)\n+                                                     .readerFor(String[].class)\n+                                                     .with(CsvSchema.emptySchema().withSkipFirstDataRow(false));\n+                iterator = reader.readValues(fis);\n+                if (!iterator.hasNext()) {\n+                    throw new JetException(\"Header row missing in \" + path);\n+                }\n+                String[] header = (String[]) iterator.next();\n+                List<String> fieldList = csvFileFormat.stringArrayFieldList();\n+                if (fieldList != null) {\n+                    int[] simpleFieldMap = createSimpleFieldMap(fieldList, header);", "originalCommit": "bff559c8fc476db3d06c1dc150beef5b47208e34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjMwMTI2Mw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542301263", "bodyText": "fixed", "author": "viliam-durina", "createdAt": "2020-12-14T11:09:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1NzIxNw=="}], "type": "inlineReview", "revised_code": {"commit": "ce994cc7afd6db9ba292a1663e1db21fd886c348", "chunk": "diff --git a/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java b/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\nindex a5339246e7..b0c75b9d44 100644\n--- a/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\n+++ b/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\n\n@@ -75,18 +75,7 @@ public class CsvReadFileFnProvider implements ReadFileFnProvider {\n                 String[] header = (String[]) iterator.next();\n                 List<String> fieldList = csvFileFormat.stringArrayFieldList();\n                 if (fieldList != null) {\n-                    int[] simpleFieldMap = createSimpleFieldMap(fieldList, header);\n-\n-                    projection = row0 -> {\n-                        String[] inputRow = (String[]) row0;\n-                        String[] projectedRow = new String[simpleFieldMap.length];\n-                        for (int i = 0; i < simpleFieldMap.length; i++) {\n-                            if (simpleFieldMap[i] >= 0) {\n-                                projectedRow[i] = inputRow[simpleFieldMap[i]];\n-                            }\n-                        }\n-                        return (T) projectedRow;\n-                    };\n+                    projection = (Function<T, T>) createFieldProjection(header, fieldList);\n                 }\n             } else {\n                 iterator = new CsvMapper().readerFor(formatClazz != null ? formatClazz : Map.class)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1ODE0Ng==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542158146", "bodyText": "Hadoop variant needs exactly same logic, I guess it could be somehow shared.", "author": "gierlachg", "createdAt": "2020-12-14T07:14:10Z", "path": "extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java", "diffHunk": "@@ -47,18 +53,49 @@\n )\n public class CsvReadFileFnProvider implements ReadFileFnProvider {\n \n+    @SuppressWarnings(\"unchecked\")\n     @Nonnull\n     @Override\n     public <T> FunctionEx<Path, Stream<T>> createReadFileFn(@Nonnull FileFormat<T> format) {\n         CsvFileFormat<T> csvFileFormat = (CsvFileFormat<T>) format;\n         Class<?> formatClazz = csvFileFormat.clazz(); // Format is not Serializable\n \n         return path -> {\n-            ObjectReader reader = new CsvMapper().readerFor(formatClazz != null ? formatClazz : Map.class)\n-                                                 .withoutFeatures(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES)\n-                                                 .with(CsvSchema.emptySchema().withHeader());\n             FileInputStream fis = new FileInputStream(path.toFile());\n-            return StreamSupport.<T>stream(Spliterators.spliteratorUnknownSize(reader.readValues(fis), ORDERED), false)\n+            MappingIterator<T> iterator;\n+            Function<T, T> projection = r -> r;\n+            if (formatClazz == String[].class) {\n+                ObjectReader reader = new CsvMapper().enable(Feature.WRAP_AS_ARRAY)\n+                                                     .readerFor(String[].class)\n+                                                     .with(CsvSchema.emptySchema().withSkipFirstDataRow(false));\n+                iterator = reader.readValues(fis);", "originalCommit": "bff559c8fc476db3d06c1dc150beef5b47208e34", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ce994cc7afd6db9ba292a1663e1db21fd886c348", "chunk": "diff --git a/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java b/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\nindex a5339246e7..b0c75b9d44 100644\n--- a/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\n+++ b/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\n\n@@ -75,18 +75,7 @@ public class CsvReadFileFnProvider implements ReadFileFnProvider {\n                 String[] header = (String[]) iterator.next();\n                 List<String> fieldList = csvFileFormat.stringArrayFieldList();\n                 if (fieldList != null) {\n-                    int[] simpleFieldMap = createSimpleFieldMap(fieldList, header);\n-\n-                    projection = row0 -> {\n-                        String[] inputRow = (String[]) row0;\n-                        String[] projectedRow = new String[simpleFieldMap.length];\n-                        for (int i = 0; i < simpleFieldMap.length; i++) {\n-                            if (simpleFieldMap[i] >= 0) {\n-                                projectedRow[i] = inputRow[simpleFieldMap[i]];\n-                            }\n-                        }\n-                        return (T) projectedRow;\n-                    };\n+                    projection = (Function<T, T>) createFieldProjection(header, fieldList);\n                 }\n             } else {\n                 iterator = new CsvMapper().readerFor(formatClazz != null ? formatClazz : Map.class)\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1ODQ3NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542158474", "bodyText": "We could use a test, proving that projection works.", "author": "gierlachg", "createdAt": "2020-12-14T07:14:56Z", "path": "extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/CsvFileFormatTest.java", "diffHunk": "@@ -33,7 +33,6 @@\n \n     @Test\n     public void shouldReadCsvFile() {\n-", "originalCommit": "bff559c8fc476db3d06c1dc150beef5b47208e34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjczNDAxOA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542734018", "bodyText": "Added a unit test for the Util.createFieldProjection() method.", "author": "viliam-durina", "createdAt": "2020-12-14T20:16:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1ODQ3NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMzAyNA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543113024", "bodyText": "I agree there should be some tests in the file connector for this. It is user facing API and there is non trivial amount of new code here. I pushed some.", "author": "frant-hartm", "createdAt": "2020-12-15T07:39:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1ODQ3NA=="}], "type": "inlineReview", "revised_code": {"commit": "0e8eedec80108039af44871fc1ee9948e08de167", "chunk": "diff --git a/extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/CsvFileFormatTest.java b/extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/CsvFileFormatTest.java\nindex 38bb4ab9dc..620ee06af5 100644\n--- a/extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/CsvFileFormatTest.java\n+++ b/extensions/hadoop/src/test/java/com/hazelcast/jet/hadoop/file/CsvFileFormatTest.java\n\n@@ -28,6 +28,7 @@ import java.io.CharConversionException;\n import java.util.Map;\n \n import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.util.Lists.newArrayList;\n \n public class CsvFileFormatTest extends BaseFileFormatTest {\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1OTMzNg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542159336", "bodyText": "Does it make sense to have clazz & stringArrayFieldList at the same time? Maybe, both should be final and we should have 2 constructors setting clazz in one and stringArrayFieldList in the other?", "author": "gierlachg", "createdAt": "2020-12-14T07:16:56Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java", "diffHunk": "@@ -34,6 +35,7 @@\n     public static final String FORMAT_CSV = \"csv\";\n \n     private Class<T> clazz;\n+    private List<String> stringArrayFieldList;", "originalCommit": "bff559c8fc476db3d06c1dc150beef5b47208e34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcyMTY5NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542721694", "bodyText": "I followed the style already in the class, with a mutable clazz.", "author": "viliam-durina", "createdAt": "2020-12-14T20:05:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1OTMzNg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExNDU1OA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543114558", "bodyText": "We originaly had a final clazz, changed it with the SQL file connector. now looking at all the places maybe we could go back to final clazz and always provide a class (either Map, instead of null), TreeNode for json etc. This way we could avoid the cases if null then this class..", "author": "frant-hartm", "createdAt": "2020-12-15T07:42:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE1OTMzNg=="}], "type": "inlineReview", "revised_code": {"commit": "1f7265495ef3f81ecd7bc02e41a48110d5179698", "chunk": "diff --git a/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java b/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java\nindex 6c445fdcd1..9f3e227eed 100644\n--- a/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java\n+++ b/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/CsvFileFormat.java\n\n@@ -34,75 +34,48 @@ public class CsvFileFormat<T> implements FileFormat<T> {\n      */\n     public static final String FORMAT_CSV = \"csv\";\n \n-    private Class<T> clazz;\n-    private List<String> stringArrayFieldList;\n+    private final Class<T> clazz;\n+    private final List<String> fieldNames;\n \n     /**\n      * Creates {@link CsvFileFormat}. See {@link FileFormat#csv} for more\n      * details.\n      */\n-    CsvFileFormat() {\n+    CsvFileFormat(@Nonnull Class<T> clazz) {\n+        this.clazz = clazz;\n+        this.fieldNames = null;\n     }\n \n     /**\n-     * Specifies class that data will be deserialized into.\n-     * If parameter is {@code null} data is deserialized into\n-     * {@code Map<String, String>}.\n-     *\n-     * @param clazz type of the object to deserialize CSV into\n+     * Creates {@link CsvFileFormat}. See {@link FileFormat#csv} for more\n+     * details.\n      */\n-    @Nonnull\n-    public CsvFileFormat<T> withClass(@Nullable Class<T> clazz) {\n-        this.clazz = clazz;\n-        return this;\n+    @SuppressWarnings(\"unchecked\")\n+    CsvFileFormat(@Nullable List<String> fieldNames) {\n+        this.clazz = (Class<T>) String[].class;\n+        this.fieldNames = fieldNames;\n     }\n \n-    /**\n-     * This setting is only applied when the class (as set with {@link\n-     * #withClass} is {@code String[]}. It specifies which column should be at\n-     * which index in the resulting string array. It is useful if the files\n-     * have different field order or don't have the same set of columns.\n-     * <p>\n-     * For example, if the argument is {@code [surname, name]}, then the format\n-     * will always return items of type String[2] where at index 0 is the\n-     * {@code surname} column and at index 1 is the {@code name} column,\n-     * regardless of the actual columns found in a particular file. If some\n-     * file doesn't have some field, the value at its index will always be 0.\n-     * <p>\n-     * If the given list is {@code null}, the length and order of the string\n-     * array will match the order found in each file. It can be different for\n-     * each file. If it's an empty array, a zero-length array will be returned.\n-     *\n-     * @param fieldList list of fields in the desired order for {@code\n-     *      String[]} class\n-     */\n     @Nonnull\n-    public CsvFileFormat<T> withStringArrayFieldList(@Nullable List<String> fieldList) {\n-        this.stringArrayFieldList = fieldList;\n-        return this;\n+    @Override\n+    public String format() {\n+        return FORMAT_CSV;\n     }\n \n     /**\n      * Returns the class Jet will deserialize data into.\n-     * Null if not set.\n      */\n-    @Nullable\n+    @Nonnull\n     public Class<T> clazz() {\n         return clazz;\n     }\n \n-    @Nonnull\n-    @Override\n-    public String format() {\n-        return FORMAT_CSV;\n-    }\n-\n     /**\n      * Return the desired list of fields that is used with {@code String[]}\n      * class.\n      */\n     @Nullable\n-    public List<String> stringArrayFieldList() {\n-        return stringArrayFieldList;\n+    public List<String> fieldNames() {\n+        return fieldNames;\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDQwNQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542160405", "bodyText": "I'm not sure i like formatForSample & formatForData. Maybe just implement resolveMetadata in subclasses?", "author": "gierlachg", "createdAt": "2020-12-14T07:19:32Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/AvroMetadataResolver.java", "diffHunk": "@@ -33,7 +33,7 @@\n     private static final FileFormat<Map<String, String>> FORMAT = FileFormat.avro();\n \n     @Override\n-    protected FileFormat<?> format() {\n+    protected FileFormat<?> formatForSample() {", "originalCommit": "bff559c8fc476db3d06c1dc150beef5b47208e34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxMDg5Mg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542710892", "bodyText": "done in 3772e38", "author": "viliam-durina", "createdAt": "2020-12-14T19:55:02Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDQwNQ=="}], "type": "inlineReview", "revised_code": {"commit": "3772e38e13cd59129667b4c7c85661e7e52ebacd", "chunk": "diff --git a/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/AvroMetadataResolver.java b/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/AvroMetadataResolver.java\nindex 4d52235296..ff4928e2ee 100644\n--- a/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/AvroMetadataResolver.java\n+++ b/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/AvroMetadataResolver.java\n\n@@ -33,17 +31,20 @@ final class AvroMetadataResolver extends MetadataResolver<GenericRecord> {\n     private static final FileFormat<Map<String, String>> FORMAT = FileFormat.avro();\n \n     @Override\n-    protected FileFormat<?> formatForSample() {\n+    protected FileFormat<?> sampleFormat() {\n         return FORMAT;\n     }\n \n     @Override\n-    protected List<MappingField> resolveFieldsFromSample(GenericRecord record) {\n-        return AvroResolver.resolveFields(record.getSchema());\n+    Metadata resolveMetadata(List<MappingField> resolvedFields, Map<String, ?> options) {\n+        return new Metadata(\n+                toFields(resolvedFields),\n+                toProcessorMetaSupplier(options, FORMAT),\n+                AvroQueryTarget::new);\n     }\n \n     @Override\n-    protected SupplierEx<QueryTarget> queryTargetSupplier(List<MappingField> resolvedFields) {\n-        return AvroQueryTarget::new;\n+    protected List<MappingField> resolveFieldsFromSample(GenericRecord record) {\n+        return AvroResolver.resolveFields(record.getSchema());\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDcxOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542160719", "bodyText": "Why distinct is needed here? Maybe it should be part of validation?", "author": "gierlachg", "createdAt": "2020-12-14T07:20:14Z", "path": "hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/CsvMetadataResolver.java", "diffHunk": "@@ -42,7 +50,16 @@\n     }\n \n     @Override\n-    protected SupplierEx<QueryTarget> queryTargetSupplier() {\n-        return CsvQueryTarget::new;\n+    protected SupplierEx<QueryTarget> queryTargetSupplier(List<MappingField> resolvedFields) {\n+        List<String> fieldMap = createFieldList(resolvedFields);\n+        return () -> new CsvQueryTarget(fieldMap);\n+    }\n+\n+    @Nonnull\n+    private static List<String> createFieldList(List<MappingField> resolvedFields) {\n+        return resolvedFields.stream()\n+                      .map(f -> f.externalName() != null ? f.externalName() : f.name())\n+                      .distinct()", "originalCommit": "bff559c8fc476db3d06c1dc150beef5b47208e34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxNTEyMw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542715123", "bodyText": "You could theoretically add a mapping with two columns pointing to the same external name:\nCREATE MAPPING my_file (\n  col1 INT EXTERNAL NAME col1,\n  col1_again INT EXTERNAL NAME col1\n) ...\n\nWill add a test for that.", "author": "viliam-durina", "createdAt": "2020-12-14T19:58:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDcxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "3772e38e13cd59129667b4c7c85661e7e52ebacd", "chunk": "diff --git a/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/CsvMetadataResolver.java b/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/CsvMetadataResolver.java\nindex 5bb87352ad..52b5f1f3a5 100644\n--- a/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/CsvMetadataResolver.java\n+++ b/hazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/CsvMetadataResolver.java\n\n@@ -49,12 +52,6 @@ final class CsvMetadataResolver extends MetadataResolver<Map<String, String>> {\n         return CsvResolver.resolveFields(entry.keySet());\n     }\n \n-    @Override\n-    protected SupplierEx<QueryTarget> queryTargetSupplier(List<MappingField> resolvedFields) {\n-        List<String> fieldMap = createFieldList(resolvedFields);\n-        return () -> new CsvQueryTarget(fieldMap);\n-    }\n-\n     @Nonnull\n     private static List<String> createFieldList(List<MappingField> resolvedFields) {\n         return resolvedFields.stream()\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDk5MA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542160990", "bodyText": "Is res[index] == -1 condition needed?", "author": "gierlachg", "createdAt": "2020-12-14T07:20:56Z", "path": "extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java", "diffHunk": "@@ -68,4 +105,17 @@\n     public String format() {\n         return CsvFileFormat.FORMAT_CSV;\n     }\n+\n+    private static int[] createSimpleFieldMap(List<String> fieldList, String[] actualHeader) {\n+        int[] res = new int[fieldList.size()];\n+        Arrays.fill(res, -1);\n+        for (int i = 0; i < actualHeader.length; i++) {\n+            int index = fieldList.indexOf(actualHeader[i]);\n+            // if the header is present in the file and we didn't encounter it yet, store its index\n+            if (index >= 0 && res[index] == -1) {", "originalCommit": "bff559c8fc476db3d06c1dc150beef5b47208e34", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjcxMzIwOQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r542713209", "bodyText": "Yes, that's to ensure that if a duplicate header is found, the first one is used, not the last one. We don't overwrite index for a column that already has an index.", "author": "viliam-durina", "createdAt": "2020-12-14T19:57:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjE2MDk5MA=="}], "type": "inlineReview", "revised_code": {"commit": "ce994cc7afd6db9ba292a1663e1db21fd886c348", "chunk": "diff --git a/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java b/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\nindex a5339246e7..b0c75b9d44 100644\n--- a/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\n+++ b/extensions/csv/src/main/java/com/hazelcast/jet/csv/impl/CsvReadFileFnProvider.java\n\n@@ -105,17 +94,4 @@ public class CsvReadFileFnProvider implements ReadFileFnProvider {\n     public String format() {\n         return CsvFileFormat.FORMAT_CSV;\n     }\n-\n-    private static int[] createSimpleFieldMap(List<String> fieldList, String[] actualHeader) {\n-        int[] res = new int[fieldList.size()];\n-        Arrays.fill(res, -1);\n-        for (int i = 0; i < actualHeader.length; i++) {\n-            int index = fieldList.indexOf(actualHeader[i]);\n-            // if the header is present in the file and we didn't encounter it yet, store its index\n-            if (index >= 0 && res[index] == -1) {\n-                res[index] = i;\n-            }\n-        }\n-        return res;\n-    }\n }\n"}}, {"oid": "ce994cc7afd6db9ba292a1663e1db21fd886c348", "url": "https://github.com/hazelcast/hazelcast-jet/commit/ce994cc7afd6db9ba292a1663e1db21fd886c348", "message": "Finish the change in Hadoop module", "committedDate": "2020-12-14T19:42:07Z", "type": "commit"}, {"oid": "3772e38e13cd59129667b4c7c85661e7e52ebacd", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3772e38e13cd59129667b4c7c85661e7e52ebacd", "message": "Move more logic to subclasses", "committedDate": "2020-12-14T19:54:28Z", "type": "commit"}, {"oid": "201b483d5652e1fa925c4501b449e6cd6e5222cd", "url": "https://github.com/hazelcast/hazelcast-jet/commit/201b483d5652e1fa925c4501b449e6cd6e5222cd", "message": "Add test for duplicate external name", "committedDate": "2020-12-14T20:02:52Z", "type": "commit"}, {"oid": "49357355c5163935190cb639ac2f0e96a20701f7", "url": "https://github.com/hazelcast/hazelcast-jet/commit/49357355c5163935190cb639ac2f0e96a20701f7", "message": "Revert pom.xml", "committedDate": "2020-12-14T20:03:22Z", "type": "commit"}, {"oid": "1cf8a9cbe0ca35ed39f8847148a1544428aa599f", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1cf8a9cbe0ca35ed39f8847148a1544428aa599f", "message": "Add test for Util.createFieldProjection", "committedDate": "2020-12-14T20:16:02Z", "type": "commit"}, {"oid": "3eab14a181beb56b4562f7cf3a2ef96c3d5f2e62", "url": "https://github.com/hazelcast/hazelcast-jet/commit/3eab14a181beb56b4562f7cf3a2ef96c3d5f2e62", "message": "Fix style", "committedDate": "2020-12-14T20:17:29Z", "type": "commit"}, {"oid": "0e8eedec80108039af44871fc1ee9948e08de167", "url": "https://github.com/hazelcast/hazelcast-jet/commit/0e8eedec80108039af44871fc1ee9948e08de167", "message": "Add CsvFileFormatTest for remapping functionality", "committedDate": "2020-12-15T07:33:44Z", "type": "commit"}, {"oid": "197fa3d8e1dc2e752fd373dfa23867752953a614", "url": "https://github.com/hazelcast/hazelcast-jet/commit/197fa3d8e1dc2e752fd373dfa23867752953a614", "message": "Format", "committedDate": "2020-12-15T07:40:05Z", "type": "commit"}, {"oid": "438654d10a8b987cdf57247b2d07d4ed72702469", "url": "https://github.com/hazelcast/hazelcast-jet/commit/438654d10a8b987cdf57247b2d07d4ed72702469", "message": "Merge remote-tracking branch 'viliam/csv-performance' into csv-performance", "committedDate": "2020-12-15T07:40:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMjI1OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543112259", "bodyText": "Maybe use org.apache.hadoop.conf.Configuration#setStrings(String, String[])", "author": "frant-hartm", "createdAt": "2020-12-15T07:38:17Z", "path": "extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java", "diffHunk": "@@ -197,7 +199,13 @@ public String format() {\n \n             Class<?> clazz = csvFileFormat.clazz();\n             if (clazz != null) {\n-                job.getConfiguration().set(CSV_INPUT_FORMAT_BEAN_CLASS, clazz.getCanonicalName());\n+                job.getConfiguration().set(CSV_INPUT_FORMAT_BEAN_CLASS, clazz.getName());\n+            }\n+            List<String> fieldList = csvFileFormat.stringArrayFieldList();\n+            if (fieldList != null) {\n+                for (int i = 0; i < fieldList.size(); i++) {\n+                    job.getConfiguration().set(CSV_INPUT_FORMAT_FIELD_LIST_PREFIX + i, fieldList.get(i));", "originalCommit": "0e8eedec80108039af44871fc1ee9948e08de167", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzYzMjM4OQ==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543632389", "bodyText": "Looked good, but it trivially joins the strings using \",\" and the uses String.split(\",\"). Though not common, a field name can contain a ,, especially in CSV when headers are sometimes typed in Excel...", "author": "viliam-durina", "createdAt": "2020-12-15T19:37:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMjI1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "1f7265495ef3f81ecd7bc02e41a48110d5179698", "chunk": "diff --git a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java\nindex 0d3c6c1d93..cf5cbb98b2 100644\n--- a/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java\n+++ b/extensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java\n\n@@ -196,12 +221,8 @@ public class HadoopFileSourceFactory implements FileSourceFactory {\n             CsvFileFormat<T> csvFileFormat = (CsvFileFormat<T>) format;\n             job.setInputFormatClass(CsvInputFormat.class);\n             job.getConfiguration().setBoolean(COPY_ON_READ, Boolean.FALSE);\n-\n-            Class<?> clazz = csvFileFormat.clazz();\n-            if (clazz != null) {\n-                job.getConfiguration().set(CSV_INPUT_FORMAT_BEAN_CLASS, clazz.getName());\n-            }\n-            List<String> fieldList = csvFileFormat.stringArrayFieldList();\n+            job.getConfiguration().set(CSV_INPUT_FORMAT_BEAN_CLASS, csvFileFormat.clazz().getName());\n+            List<String> fieldList = csvFileFormat.fieldNames();\n             if (fieldList != null) {\n                 for (int i = 0; i < fieldList.size(); i++) {\n                     job.getConfiguration().set(CSV_INPUT_FORMAT_FIELD_LIST_PREFIX + i, fieldList.get(i));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMzM1Nw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543113357", "bodyText": "The false condition here isn't covered by tests.", "author": "frant-hartm", "createdAt": "2020-12-15T07:40:22Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java", "diffHunk": "@@ -548,4 +550,51 @@ public static String formatJobDuration(long durationMs) {\n         String textUpToHours = String.format(\"%02d:%02d:%02d.%03d\", hours, minutes, seconds, millis);\n         return sign + (durationMs > 0 ? durationMs + \"d \" : \"\") + textUpToHours;\n     }\n+\n+    /**\n+     * Given a list of input field names and a list of output field names\n+     * creates a projection to map between these.\n+     * <p>\n+     * For example, if input names are {@code [surname, name, address]} and\n+     * output names are {@code [name, surname, age]}, then the function,\n+     * applied to {@code [Smith, John, New York]} will return {@code [John,\n+     * Smith, (null)]}. That is, it will map the fields from the input order to\n+     * output order. The output field named {@code age} is missing in input, so\n+     * the value for it is {@code null} for any input.\n+     *\n+     * @param inputFields the input headers\n+     * @param outputFields the output headers\n+     * @return the indices to map input to output\n+     */\n+    @Nonnull\n+    public static Function<String[], String[]> createFieldProjection(\n+            @Nonnull String[] inputFields,\n+            @Nonnull List<String> outputFields\n+    ) {\n+        if (outputFields.equals(asList(inputFields))) {\n+            // shortcut - the mapping is an identity\n+            return i -> i;\n+        }\n+        int[] simpleFieldMap = new int[outputFields.size()];\n+        Arrays.fill(simpleFieldMap, -1);\n+        for (int i = 0; i < inputFields.length; i++) {\n+            int index = outputFields.indexOf(inputFields[i]);\n+            // if the inputFields is present in the file and we didn't encounter it yet, store its index\n+            if (index >= 0 && simpleFieldMap[index] == -1) {", "originalCommit": "0e8eedec80108039af44871fc1ee9948e08de167", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzY0MjYxNg==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543642616", "bodyText": "Both conditions are covered in integration tests. I added unit test coverage, if that's what you mean.", "author": "viliam-durina", "createdAt": "2020-12-15T19:53:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExMzM1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "f0d32b2827ae82a07e164fc155c7fda74d07d5c4", "chunk": "diff --git a/hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java b/hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java\nindex 5a1b241df3..973a48bc0c 100644\n--- a/hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java\n+++ b/hazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java\n\n@@ -551,6 +562,44 @@ public final class Util {\n         return sign + (durationMs > 0 ? durationMs + \"d \" : \"\") + textUpToHours;\n     }\n \n+    /**\n+     * Assigns given partitions to given {@code members}.\n+     * Set of partitions belonging to non-members are assigned to\n+     * {@code members} in a round robin fashion.\n+     */\n+    public static Map<Address, List<Integer>> assignPartitions(\n+            Collection<Address> members0,\n+            Map<Address, List<Integer>> partitionsByOwner\n+    ) {\n+        assert !members0.isEmpty();\n+\n+        LinkedHashSet<Address> members = new LinkedHashSet<>(members0);\n+\n+        Iterator<Address> iterator = members.iterator();\n+\n+        Map<Address, List<Integer>> partitionsByMember = new HashMap<>();\n+        for (Entry<Address, List<Integer>> entry : partitionsByOwner.entrySet()) {\n+            Address partitionOwner = entry.getKey();\n+            List<Integer> partitions = entry.getValue();\n+\n+            Address target;\n+            if (members.contains(partitionOwner)) {\n+                target = partitionOwner;\n+            } else {\n+                if (!iterator.hasNext()) {\n+                    iterator = members.iterator();\n+                }\n+                target = iterator.next();\n+            }\n+\n+            partitionsByMember.merge(target, new ArrayList<>(partitions), (existing, incoming) -> {\n+                existing.addAll(incoming);\n+                return existing;\n+            });\n+        }\n+        return partitionsByMember;\n+    }\n+\n     /**\n      * Given a list of input field names and a list of output field names\n      * creates a projection to map between these.\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExNTY3NA==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543115674", "bodyText": "I find the double negation less readable.", "author": "frant-hartm", "createdAt": "2020-12-15T07:44:36Z", "path": "hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java", "diffHunk": "@@ -98,7 +98,7 @@\n      */\n     public FileSourceBuilder(@Nonnull String path) {\n         this.path = requireNonNull(path, \"path must not be null\");\n-        if (!(Paths.get(path).isAbsolute() || hasHadoopPrefix(path))) {\n+        if (!hasHadoopPrefix(path) && !Paths.get(path).isAbsolute()) {", "originalCommit": "0e8eedec80108039af44871fc1ee9948e08de167", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzY0NDY4Nw==", "url": "https://github.com/hazelcast/hazelcast-jet/pull/2753#discussion_r543644687", "bodyText": "You can't read it aloud with the parenthesis, but no dispute against taste (proti gustu \u017eiaden di\u0161put\u00e1t :) ), reverting", "author": "viliam-durina", "createdAt": "2020-12-15T19:56:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzExNTY3NA=="}], "type": "inlineReview", "revised_code": {"commit": "84f4de3ad0f29bf241049d8fd92ea8e21d12452c", "chunk": "diff --git a/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java b/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java\nindex fcbebfa6d3..16b727d0fb 100644\n--- a/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java\n+++ b/hazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java\n\n@@ -89,14 +63,7 @@ public class FileSourceBuilder<T> {\n     private boolean useHadoop;\n     private boolean sharedFileSystem;\n \n-    /**\n-     * Creates a new file source builder with the given path. The path\n-     * must point to a directory. All files in the directory are\n-     * processed. The directory is not processed recursively.\n-     *\n-     * @param path path pointing to a directory to read files from\n-     */\n-    public FileSourceBuilder(@Nonnull String path) {\n+    FileSourceBuilder(@Nonnull String path) {\n         this.path = requireNonNull(path, \"path must not be null\");\n         if (!hasHadoopPrefix(path) && !Paths.get(path).isAbsolute()) {\n             throw new IllegalArgumentException(\"Provided path must be absolute. path: \" + path);\n"}}, {"oid": "84f4de3ad0f29bf241049d8fd92ea8e21d12452c", "url": "https://github.com/hazelcast/hazelcast-jet/commit/84f4de3ad0f29bf241049d8fd92ea8e21d12452c", "message": "Merge branch 'master' into csv-performance\n\n# Conflicts:\n#\thazelcast-jet-core/src/main/java/com/hazelcast/jet/pipeline/file/FileSourceBuilder.java\n#\thazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/MetadataResolver.java", "committedDate": "2020-12-15T19:45:55Z", "type": "commit"}, {"oid": "97cd5c683bb658a5dcf22cc6db26aa497a8c3b35", "url": "https://github.com/hazelcast/hazelcast-jet/commit/97cd5c683bb658a5dcf22cc6db26aa497a8c3b35", "message": "Fix linter errer", "committedDate": "2020-12-15T19:52:15Z", "type": "commit"}, {"oid": "785be0ca6e46a0dca7c3d5c329da32c8e018ee2e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/785be0ca6e46a0dca7c3d5c329da32c8e018ee2e", "message": "Improve unit test coverage", "committedDate": "2020-12-15T19:52:32Z", "type": "commit"}, {"oid": "5e3a8033dac9bdf38f8aa57828722e6ae3942efa", "url": "https://github.com/hazelcast/hazelcast-jet/commit/5e3a8033dac9bdf38f8aa57828722e6ae3942efa", "message": "Use different condition style", "committedDate": "2020-12-15T19:56:55Z", "type": "commit"}, {"oid": "30a16c804422c2549a5945b18498e5f725736842", "url": "https://github.com/hazelcast/hazelcast-jet/commit/30a16c804422c2549a5945b18498e5f725736842", "message": "Fix indentation", "committedDate": "2020-12-15T20:59:42Z", "type": "commit"}, {"oid": "f0d32b2827ae82a07e164fc155c7fda74d07d5c4", "url": "https://github.com/hazelcast/hazelcast-jet/commit/f0d32b2827ae82a07e164fc155c7fda74d07d5c4", "message": "Merge branch 'master' into csv-performance\n\n# Conflicts:\n#\textensions/hadoop/src/main/java/com/hazelcast/jet/hadoop/impl/HadoopFileSourceFactory.java\n#\thazelcast-jet-core/src/main/java/com/hazelcast/jet/impl/util/Util.java\n#\thazelcast-jet-core/src/test/java/com/hazelcast/jet/impl/util/UtilTest.java\n#\thazelcast-jet-sql/src/main/java/com/hazelcast/jet/sql/impl/connector/file/JsonMetadataResolver.java\n#\thazelcast-jet-sql/src/test/java/com/hazelcast/jet/sql/impl/connector/file/SqlCsvTest.java", "committedDate": "2021-01-13T16:06:33Z", "type": "commit"}, {"oid": "981e69db77acf85a5f77791d3300d0117bccf13e", "url": "https://github.com/hazelcast/hazelcast-jet/commit/981e69db77acf85a5f77791d3300d0117bccf13e", "message": "Formatting", "committedDate": "2021-01-14T08:25:33Z", "type": "commit"}, {"oid": "1f7265495ef3f81ecd7bc02e41a48110d5179698", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1f7265495ef3f81ecd7bc02e41a48110d5179698", "message": "Refactor CSV file format API", "committedDate": "2021-01-14T12:20:34Z", "type": "commit"}, {"oid": "1d0554f74a73f5499ae9256216e1537a42e0d974", "url": "https://github.com/hazelcast/hazelcast-jet/commit/1d0554f74a73f5499ae9256216e1537a42e0d974", "message": "Merge pull request #2 from gierlachg/refactor\n\nRefactor CSV file format API", "committedDate": "2021-01-14T13:55:42Z", "type": "commit"}]}