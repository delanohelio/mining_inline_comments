{"pr_number": 4782, "pr_title": "chore(broker): handle out of disk space in broker", "pr_createdAt": "2020-06-22T06:26:24Z", "pr_url": "https://github.com/camunda-cloud/zeebe/pull/4782", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MTUyMQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444151521", "bodyText": "Maybe Space instead of Buffer", "author": "Zelldon", "createdAt": "2020-06-23T11:26:03Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java", "diffHunk": "@@ -440,6 +440,17 @@ public Builder withMaxEntrySize(final MemorySize maxEntrySize) {\n       return this;\n     }\n \n+    /**\n+     * Set the minimum free disk space (in bytes) to leave when allocating a new segment\n+     *\n+     * @param freeDiskBuffer free disk space in bytes\n+     * @return the Raft partition group builder\n+     */\n+    public Builder withFreeDiskBuffer(final long freeDiskBuffer) {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "chunk": "diff --git a/atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java b/atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java\nindex af12f0c223..e2537ff9ab 100644\n--- a/atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java\n+++ b/atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java\n\n@@ -443,11 +444,11 @@ public class RaftPartitionGroup implements ManagedPartitionGroup {\n     /**\n      * Set the minimum free disk space (in bytes) to leave when allocating a new segment\n      *\n-     * @param freeDiskBuffer free disk space in bytes\n+     * @param freeDiskSpace free disk space in bytes\n      * @return the Raft partition group builder\n      */\n-    public Builder withFreeDiskBuffer(final long freeDiskBuffer) {\n-      config.getStorageConfig().setFreeDiskBuffer(freeDiskBuffer);\n+    public Builder withFreeDiskSpace(final long freeDiskSpace) {\n+      config.getStorageConfig().setFreeDiskSpace(freeDiskSpace);\n       return this;\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MzQ5NA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444153494", "bodyText": "This was just again reordering? Seems that there is still something wrong with my setup \ud83d\ude05", "author": "Zelldon", "createdAt": "2020-06-23T11:30:01Z", "path": "atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java", "diffHunk": "@@ -623,4 +597,31 @@ public long awaitCommit() throws Exception {\n       return commitFuture.get(30, TimeUnit.SECONDS);\n     }\n   }\n+\n+  private final class RaftSnapshotListener implements PersistedSnapshotListener {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1NTg0Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444155847", "bodyText": "IF you would add as a separate last step the disk space monitor installation then you dont need this if.", "author": "Zelldon", "createdAt": "2020-06-23T11:34:51Z", "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "diffHunk": "@@ -253,9 +258,18 @@ private AutoCloseable subscriptionAPIStep(final BrokerInfo localBroker) {\n         new SubscriptionApiCommandMessageHandlerService(localBroker, atomix);\n     partitionListeners.add(messageHandlerService);\n     scheduleActor(messageHandlerService);\n+    addDiskSpaceUsageListener(messageHandlerService);\n     return messageHandlerService;\n   }\n \n+  private void addDiskSpaceUsageListener(final DiskSpaceUsageListener diskSpaceUsageListener) {\n+    if (diskSpaceUsageMonitor == null) {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/Broker.java b/broker/src/main/java/io/zeebe/broker/Broker.java\nindex d5b225c392..2584bde8ec 100644\n--- a/broker/src/main/java/io/zeebe/broker/Broker.java\n+++ b/broker/src/main/java/io/zeebe/broker/Broker.java\n\n@@ -258,16 +259,12 @@ public final class Broker implements AutoCloseable {\n         new SubscriptionApiCommandMessageHandlerService(localBroker, atomix);\n     partitionListeners.add(messageHandlerService);\n     scheduleActor(messageHandlerService);\n-    addDiskSpaceUsageListener(messageHandlerService);\n+    diskSpaceUsageListeners.add(messageHandlerService);\n     return messageHandlerService;\n   }\n \n-  private void addDiskSpaceUsageListener(final DiskSpaceUsageListener diskSpaceUsageListener) {\n-    if (diskSpaceUsageMonitor == null) {\n-      diskSpaceUsageListeners.add(diskSpaceUsageListener);\n-    } else {\n-      diskSpaceUsageMonitor.addDiskUsageListener(diskSpaceUsageListener);\n-    }\n+  private void addDiskSpaceUsageListeners() {\n+    diskSpaceUsageListeners.forEach(diskSpaceUsageMonitor::addDiskUsageListener);\n   }\n \n   private void scheduleActor(final Actor actor) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MDM4Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444160387", "bodyText": "As I said I would felt more comfortable if we use percentage here, because I have the feeling the user need to set that setting currently in respect to there used pvc size always. If we had a percentage we would be more dynamically and then the user only needs to set it when he has really small pvcs, but even then I think it would be possible to run it. If the user uses a small pvc it might even not have such a big load or expect not a big state at all.", "author": "Zelldon", "createdAt": "2020-06-23T11:43:53Z", "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "diffHunk": "@@ -19,6 +19,9 @@\n public final class DataCfg implements ConfigurationEntry {\n   public static final String DEFAULT_DIRECTORY = \"data\";\n   private static final DataSize DEFAULT_DATA_SIZE = DataSize.ofMegabytes(512);\n+  private static final DataSize DEFAULT_LOW_FREE_DISKSPACE_WATERMARK = DataSize.ofGigabytes(1);", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java b/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java\nindex 916ac67086..095295f83e 100644\n--- a/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java\n+++ b/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java\n\n@@ -19,9 +21,9 @@ import org.springframework.util.unit.DataSize;\n public final class DataCfg implements ConfigurationEntry {\n   public static final String DEFAULT_DIRECTORY = \"data\";\n   private static final DataSize DEFAULT_DATA_SIZE = DataSize.ofMegabytes(512);\n-  private static final DataSize DEFAULT_LOW_FREE_DISKSPACE_WATERMARK = DataSize.ofGigabytes(1);\n-  private static final DataSize DEFAULT_HIGH_FREE_DISKSPACE_WATERMARK = DataSize.ofGigabytes(2);\n-  private static final Duration DEFAULT_DISK_USAGE_MONITORING_DELAY = Duration.ofSeconds(10);\n+  private static final double DEFAULT_DISK_USAGE_REPLICATION_WATERMARK = 0.9;\n+  private static final double DEFAULT_DISK_USAGE_COMMAND_WATERMARK = 0.8;\n+  private static final Duration DEFAULT_DISK_USAGE_MONITORING_DELAY = Duration.ofSeconds(1);\n \n   // Hint: do not use Collections.singletonList as this does not support replaceAll\n   private List<String> directories = Arrays.asList(DEFAULT_DIRECTORY);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MTQwMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444161402", "bodyText": "If you make this as an parameter you would be able to unit test the complete logic much easier", "author": "Zelldon", "createdAt": "2020-06-23T11:45:52Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY4NTY3Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444685672", "bodyText": "Do you mean unit testing DiskSpaceUsageMonitor ? Is it required when we have the integration test?", "author": "deepthidevaki", "createdAt": "2020-06-24T07:02:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MTQwMg=="}], "type": "inlineReview", "revised_code": {"commit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\nindex c7d4251fcc..30778efa9e 100644\n--- a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\n+++ b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\n\n@@ -21,15 +21,15 @@ public class DiskSpaceUsageMonitor extends Actor {\n \n   private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n   private boolean currentDiskAvailableStatus = true;\n-  private LongSupplier diskSpaceSupplier;\n+  private LongSupplier freeDiskSpaceSupplier;\n   private final Duration monitoringDelay;\n-  private final long minFreeDiskRequired;\n+  private final long minFreeDiskSpaceRequired;\n \n   public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n-    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n-    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    this.monitoringDelay = dataCfg.getDiskUsageMonitoringInterval();\n+    this.minFreeDiskSpaceRequired = dataCfg.getFreeDiskSpaceCommandWatermark();\n     final var directory = new File(dataCfg.getDirectories().get(0));\n-    diskSpaceSupplier = directory::getUsableSpace;\n+    freeDiskSpaceSupplier = directory::getUsableSpace;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MjA4Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444162082", "bodyText": "This variable name is a bit misleading. It should be diskFreeSpace or usable space", "author": "Zelldon", "createdAt": "2020-06-23T11:47:08Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;\n+  }\n+\n+  @Override\n+  protected void onActorStarted() {\n+    actor.runAtFixedRate(monitoringDelay, this::checkDiskUsageAndNotifyListeners);\n+  }\n+\n+  private void checkDiskUsageAndNotifyListeners() {\n+    final long diskSpaceUsage = diskSpaceSupplier.getAsLong();", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\nindex c7d4251fcc..30778efa9e 100644\n--- a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\n+++ b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\n\n@@ -21,15 +21,15 @@ public class DiskSpaceUsageMonitor extends Actor {\n \n   private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n   private boolean currentDiskAvailableStatus = true;\n-  private LongSupplier diskSpaceSupplier;\n+  private LongSupplier freeDiskSpaceSupplier;\n   private final Duration monitoringDelay;\n-  private final long minFreeDiskRequired;\n+  private final long minFreeDiskSpaceRequired;\n \n   public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n-    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n-    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    this.monitoringDelay = dataCfg.getDiskUsageMonitoringInterval();\n+    this.minFreeDiskSpaceRequired = dataCfg.getFreeDiskSpaceCommandWatermark();\n     final var directory = new File(dataCfg.getDirectories().get(0));\n-    diskSpaceSupplier = directory::getUsableSpace;\n+    freeDiskSpaceSupplier = directory::getUsableSpace;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MjkwNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444162906", "bodyText": "Maybe also rename the methods to diskSpace available; noDiskSpace available. I think it makes it more clear then below and above threshold", "author": "Zelldon", "createdAt": "2020-06-23T11:48:39Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;\n+  }\n+\n+  @Override\n+  protected void onActorStarted() {\n+    actor.runAtFixedRate(monitoringDelay, this::checkDiskUsageAndNotifyListeners);\n+  }\n+\n+  private void checkDiskUsageAndNotifyListeners() {\n+    final long diskSpaceUsage = diskSpaceSupplier.getAsLong();\n+    final boolean previousStatus = currentDiskAvailableStatus;\n+    currentDiskAvailableStatus = diskSpaceUsage >= minFreeDiskRequired;\n+    if (currentDiskAvailableStatus != previousStatus) {\n+      if (!currentDiskAvailableStatus) {\n+        LOG.debug(\n+            \"Out of disk space. Current available {} bytes. Minimum needed {} bytes.\",\n+            diskSpaceUsage,\n+            minFreeDiskRequired);\n+        diskSpaceUsageListeners.forEach(\n+            DiskSpaceUsageListener::onDiskSpaceUsageIncreasedAboveThreshold);\n+      } else {\n+        LOG.debug(\"Disk space available again. Current available {} bytes\", diskSpaceUsage);\n+        diskSpaceUsageListeners.forEach(\n+            DiskSpaceUsageListener::onDiskSpaceUsageReducedBelowThreshold);", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\nindex c7d4251fcc..30778efa9e 100644\n--- a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\n+++ b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java\n\n@@ -21,15 +21,15 @@ public class DiskSpaceUsageMonitor extends Actor {\n \n   private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n   private boolean currentDiskAvailableStatus = true;\n-  private LongSupplier diskSpaceSupplier;\n+  private LongSupplier freeDiskSpaceSupplier;\n   private final Duration monitoringDelay;\n-  private final long minFreeDiskRequired;\n+  private final long minFreeDiskSpaceRequired;\n \n   public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n-    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n-    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    this.monitoringDelay = dataCfg.getDiskUsageMonitoringInterval();\n+    this.minFreeDiskSpaceRequired = dataCfg.getFreeDiskSpaceCommandWatermark();\n     final var directory = new File(dataCfg.getDirectories().get(0));\n-    diskSpaceSupplier = directory::getUsableSpace;\n+    freeDiskSpaceSupplier = directory::getUsableSpace;\n   }\n \n   @Override\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2NDEzNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444164136", "bodyText": "So many listeners \ud83d\ude06", "author": "Zelldon", "createdAt": "2020-06-23T11:51:02Z", "path": "broker/src/main/java/io/zeebe/broker/system/partitions/ZeebePartition.java", "diffHunk": "@@ -66,7 +67,11 @@\n import org.slf4j.Logger;\n \n public final class ZeebePartition extends Actor\n-    implements RaftCommitListener, RaftRoleChangeListener, HealthMonitorable, FailureListener {\n+    implements RaftCommitListener,\n+        RaftRoleChangeListener,\n+        HealthMonitorable,\n+        FailureListener,\n+        DiskSpaceUsageListener {", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MjM1OQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448352359", "bodyText": "Just waiting for the ListenerListener interface now \ud83d\udc40", "author": "npepinpe", "createdAt": "2020-07-01T13:11:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2NDEzNg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444197878", "bodyText": "Maybe assert that we get an response", "author": "Zelldon", "createdAt": "2020-06-23T12:51:04Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.broker.test.EmbeddedBrokerRule;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.TimerIntent;\n+import io.zeebe.protocol.record.value.JobRecordValueAssert;\n+import io.zeebe.protocol.record.value.TimerRecordValueAssert;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.assertj.core.api.Assertions;\n+import org.awaitility.Awaitility;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryTest {\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final EmbeddedBrokerRule embeddedBrokerRule =\n+      new EmbeddedBrokerRule(\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(embeddedBrokerRule).around(clientRule);\n+\n+  @Test\n+  public void shouldStopAcceptingRequestWhenDiskSpaceFull() throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"test\")\n+            .send();\n+\n+    // then\n+    Assertions.assertThatThrownBy(resultFuture::join)\n+        .hasRootCauseMessage(\n+            \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\");\n+  }\n+\n+  @Test\n+  public void shouldRestartAcceptingRequestWhenDiskSpaceAvailableAgain()\n+      throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    waitUntilDiskSpaceAvailable();\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"Test\")\n+            .send();\n+\n+    // then\n+    assertThatCode(resultFuture::join).doesNotThrowAnyException();", "originalCommit": "dd6fcd629b4ef93f6531638f77fb74942691a4bb", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY4NDc4NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444684785", "bodyText": "assertThat(resultFuture.join()).isNotNull(); did not work because the response is empty for publish message.", "author": "deepthidevaki", "createdAt": "2020-06-24T07:00:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NTc2Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448365767", "bodyText": "Can we use another command then?", "author": "npepinpe", "createdAt": "2020-07-01T13:32:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3MjE1NA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448772154", "bodyText": "Why is it no good if we assert doesNotThrowAnyException? I can use deploy workflow command instead, if you insist.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:19:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0MDU5MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450840590", "bodyText": "Code shouldn't generally throw exception so it's usually a weird assertion to have. But I'm not insisting, it's more of a rule of thumb - I'd rather we assert something happened than it didn't, e.g. no exception thrown.", "author": "npepinpe", "createdAt": "2020-07-07T12:53:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}], "type": "inlineReview", "revised_code": {"commit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "chunk": "diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java\nindex 0a9013cd5f..0805a5f170 100644\n--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java\n+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java\n\n@@ -36,8 +36,7 @@ public class DiskSpaceRecoveryTest {\n   private final EmbeddedBrokerRule embeddedBrokerRule =\n       new EmbeddedBrokerRule(\n           cfg -> {\n-            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n-            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+            cfg.getData().setDiskUsageMonitoringInterval(Duration.ofSeconds(1));\n           });\n   private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n \n"}}, {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "url": "https://github.com/camunda-cloud/zeebe/commit/ef515fed93020dc76d7b339d99e86b0fc50d4514", "message": "chore(qa): add integration test", "committedDate": "2020-06-29T12:20:24Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIyNzQ2MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448227460", "bodyText": "Could you reference here the issue please", "author": "Zelldon", "createdAt": "2020-07-01T09:11:18Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.Broker;\n+import io.zeebe.broker.it.clustering.ClusteringRule;\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.client.api.response.DeploymentEvent;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.DeploymentIntent;\n+import io.zeebe.protocol.record.intent.MessageSubscriptionIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceSubscriptionIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryClusteredTest {\n+  private static final String CORRELATION_KEY = \"item-2\";\n+  private final String messageName = \"test\";\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule =\n+      new ClusteringRule(\n+          3,\n+          1,\n+          3,\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  @Test\n+  public void shouldDistributeDeploymentAfterDiskSpaceAvailableAgain() throws InterruptedException {\n+    // given\n+    final var failingBroker =\n+        clusteringRule.getBroker(clusteringRule.getLeaderForPartition(3).getNodeId());\n+    waitUntilDiskSpaceNotAvailable(failingBroker);\n+\n+    final long deploymentKey =\n+        deployWorkflow(Bpmn.createExecutableProcess(\"test\").startEvent().endEvent().done());\n+\n+    // when\n+    Awaitility.await()\n+        .timeout(Duration.ofSeconds(60))\n+        .until(\n+            () ->\n+                RecordingExporter.deploymentRecords(DeploymentIntent.DISTRIBUTE).limit(1).exists());\n+\n+    waitUntilDiskSpaceAvailable(failingBroker);\n+\n+    // then\n+    clientRule.waitUntilDeploymentIsDone(deploymentKey);\n+  }\n+\n+  @Ignore(\"Apparently a message correlation is not retried if failed\")", "originalCommit": "a28589048f8248828671adc6cb0ecec032c4fc87", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java\nindex 3bc92a81e4..1622e77689 100644\n--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java\n+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java\n\n@@ -43,8 +43,7 @@ public class DiskSpaceRecoveryClusteredTest {\n           1,\n           3,\n           cfg -> {\n-            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n-            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+            cfg.getData().setDiskUsageMonitoringInterval(Duration.ofSeconds(1));\n           });\n   private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5MTUxMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448291512", "bodyText": "Ok this test will take at least 1 minute right - wouldn't be nice to have something like zeebe-io/enhancements#5", "author": "Zelldon", "createdAt": "2020-07-01T11:12:54Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NTQ0OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448365448", "bodyText": "Is there something else we could do at all? Just wondering", "author": "npepinpe", "createdAt": "2020-07-01T13:32:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5MTUxMg=="}], "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\nindex fb0e8acab9..4176a19f2c 100644\n--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n\n@@ -29,8 +29,8 @@ import org.testcontainers.elasticsearch.ElasticsearchContainer;\n \n public class DiskSpaceRecoveryITTest {\n   static ZeebeBrokerContainer zeebeBroker;\n-  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n-  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static final Logger LOG = LoggerFactory.getLogger(DiskSpaceRecoveryITTest.class);\n+  private static final String VOLUME_NAME = \"data-DiskSpaceRecoveryITTest\";\n   private static String containerIPAddress;\n   private static Integer apiPort;\n   private static ElasticsearchContainer elastic;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMxODA0NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448318045", "bodyText": "Is there any reason not to rename the getter if we rename the property?", "author": "npepinpe", "createdAt": "2020-07-01T12:08:19Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -189,8 +189,8 @@ public boolean dynamicCompaction() {\n    *\n    * @return the percentage of disk space that must be available before log compaction is forced\n    */\n-  public double freeDiskBuffer() {\n-    return freeDiskBuffer;\n+  public long freeDiskBuffer() {", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java b/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\nindex fe0ce79823..f71dc4cf0a 100644\n--- a/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\n+++ b/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\n\n@@ -187,9 +187,9 @@ public final class RaftStorage {\n   /**\n    * Returns the percentage of disk space that must be available before log compaction is forced.\n    *\n-   * @return the percentage of disk space that must be available before log compaction is forced\n+   * @return the amount of disk space that must be available before log compaction is forced\n    */\n-  public long freeDiskBuffer() {\n+  public long freeDiskSpace() {\n     return freeDiskSpace;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyMDc1NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448320755", "bodyText": "If the close could fail, we should wrap it in a try catch to make sure we also close the disk space usage monitor.", "author": "npepinpe", "createdAt": "2020-07-01T12:13:51Z", "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "diffHunk": "@@ -271,20 +282,26 @@ private AutoCloseable topologyManagerStep(\n     return topologyManager;\n   }\n \n-  private AutoCloseable monitoringServerStep(\n-      final NetworkCfg networkCfg, final BrokerInfo localBroker) {\n+  private AutoCloseable monitoringServerStep(final DataCfg data, final BrokerInfo localBroker) {\n     healthCheckService = new BrokerHealthCheckService(localBroker, atomix);\n     springBrokerBridge.registerBrokerHealthCheckServiceSupplier(() -> healthCheckService);\n     partitionListeners.add(healthCheckService);\n     scheduleActor(healthCheckService);\n \n-    return () -> healthCheckService.close();\n+    diskSpaceUsageMonitor = new DiskSpaceUsageMonitor(data);\n+    scheduleActor(diskSpaceUsageMonitor);\n+    diskSpaceUsageListeners.forEach(l -> diskSpaceUsageMonitor.addDiskUsageListener(l));\n+    return () -> {\n+      healthCheckService.close();", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/Broker.java b/broker/src/main/java/io/zeebe/broker/Broker.java\nindex 2584bde8ec..434acfc40a 100644\n--- a/broker/src/main/java/io/zeebe/broker/Broker.java\n+++ b/broker/src/main/java/io/zeebe/broker/Broker.java\n\n@@ -282,19 +282,19 @@ public final class Broker implements AutoCloseable {\n     return topologyManager;\n   }\n \n-  private AutoCloseable monitoringServerStep(final DataCfg data, final BrokerInfo localBroker) {\n+  private AutoCloseable monitoringServerStep(final BrokerInfo localBroker) {\n     healthCheckService = new BrokerHealthCheckService(localBroker, atomix);\n     springBrokerBridge.registerBrokerHealthCheckServiceSupplier(() -> healthCheckService);\n     partitionListeners.add(healthCheckService);\n     scheduleActor(healthCheckService);\n+    return () -> healthCheckService.close();\n+  }\n \n+  private AutoCloseable diskSpaceMonitorStep(final DataCfg data) {\n     diskSpaceUsageMonitor = new DiskSpaceUsageMonitor(data);\n     scheduleActor(diskSpaceUsageMonitor);\n     diskSpaceUsageListeners.forEach(l -> diskSpaceUsageMonitor.addDiskUsageListener(l));\n-    return () -> {\n-      healthCheckService.close();\n-      diskSpaceUsageMonitor.close();\n-    };\n+    return () -> diskSpaceUsageMonitor.close();\n   }\n \n   private AutoCloseable managementRequestStep(final BrokerInfo localBroker) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNDk0OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448324948", "bodyText": "I assume this is to avoid the NoRemoteHandler errors - my question here would be, shouldn't we handle these as possible cases on the other side? Why are we expecting the service to always be there? I imagine that's a little out of scope though...just a question", "author": "npepinpe", "createdAt": "2020-07-01T12:22:16Z", "path": "broker/src/main/java/io/zeebe/broker/engine/impl/SubscriptionApiCommandMessageHandlerService.java", "diffHunk": "@@ -77,4 +82,31 @@ protected void onActorStarting() {\n                     }));\n     return future;\n   }\n+\n+  @Override\n+  public void onDiskSpaceNotAvailable() {\n+    actor.call(\n+        () -> {\n+          LOG.debug(\n+              \"Broker is out of disk space. All requests with topic {} will be rejected.\",\n+              SUBSCRIPTION_TOPIC);\n+          atomix.getCommunicationService().unsubscribe(SUBSCRIPTION_TOPIC);\n+          atomix", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2NzI0Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448767247", "bodyText": "Here it doesn't make a difference because the sender is not expecting any response. Ideally this should respond with a \"Resource exhausted\" error similar to the deployment request. But the current interface for subscription message request returns nothing. This would probably be fixed by #4786", "author": "deepthidevaki", "createdAt": "2020-07-02T06:05:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNDk0OA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNzAzNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448327036", "bodyText": "Hm, at the moment I think we do most of our validation in SystemContext#validateConfiguration. Or maybe I'm mistaken? I'm not sure if that was a conscious decision or I just thought we did that.", "author": "npepinpe", "createdAt": "2020-07-01T12:26:00Z", "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "diffHunk": "@@ -85,21 +92,67 @@ public StorageLevel getAtomixStorageLevel() {\n     return useMmap() ? StorageLevel.MAPPED : StorageLevel.DISK;\n   }\n \n+  public double getDiskUsageCommandWatermark() {\n+    return diskUsageCommandWatermark;\n+  }\n+\n+  public void setDiskUsageCommandWatermark(final double diskUsageCommandWatermark) {\n+    Preconditions.checkArgument(", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2NzU0NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448767545", "bodyText": "Didn't knew about SystemContext#validateConfiguration. I can move the validation there.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:05:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNzAzNg=="}], "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java b/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java\nindex 095295f83e..3a494a428a 100644\n--- a/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java\n+++ b/broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java\n\n@@ -97,10 +96,6 @@ public final class DataCfg implements ConfigurationEntry {\n   }\n \n   public void setDiskUsageCommandWatermark(final double diskUsageCommandWatermark) {\n-    Preconditions.checkArgument(\n-        diskUsageCommandWatermark > 0 && diskUsageCommandWatermark < 1,\n-        \"Expected diskUsageCommandWatermark to be in the range (0,1), but found %d\",\n-        diskUsageCommandWatermark);\n     this.diskUsageCommandWatermark = diskUsageCommandWatermark;\n   }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMzNDIwNw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448334207", "bodyText": "If possible we should document public interfaces \ud83d\ude42", "author": "npepinpe", "createdAt": "2020-07-01T12:39:06Z", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java", "diffHunk": "@@ -0,0 +1,15 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+public interface DiskSpaceUsageListener {", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java\nindex c6cca5531f..9fe58b7ed6 100644\n--- a/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java\n+++ b/broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java\n\n@@ -7,9 +7,15 @@\n  */\n package io.zeebe.broker.system.monitoring;\n \n+/**\n+ * Used by DiskSpaceUsageMonitor to notify listeners when disk space usage grows above (and below)\n+ * the configured threshold\n+ */\n public interface DiskSpaceUsageListener {\n \n+  /** Will be called when disk space usage grows above the threshold */\n   default void onDiskSpaceNotAvailable() {}\n \n+  /** Will be called when disk space usage goes below the threshold after it was above it. */\n   default void onDiskSpaceAvailable() {}\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448353201", "bodyText": "Can we write the current disk space and the threshold as context info?", "author": "npepinpe", "createdAt": "2020-07-01T13:13:03Z", "path": "broker/src/main/java/io/zeebe/broker/transport/commandapi/CommandApiRequestHandler.java", "diffHunk": "@@ -81,6 +82,17 @@ private void handleExecuteCommandRequest(\n       final DirectBuffer buffer,\n       final int messageOffset,\n       final int messageLength) {\n+\n+    if (!isDiskSpaceAvailable) {\n+      errorResponseWriter\n+          .resourceExhausted(\n+              String.format(\n+                  \"Cannot accept requests for partition %d. Broker is out of disk space\",", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2ODIxNg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448768216", "bodyText": "Is it useful for the clients? We log it in DiskSpaceUsageMonitor.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:07:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0Mjc3MQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450842771", "bodyText": "It's useful for us that's for sure, hard to say yet if it's useful for normal users. Do you think adding it would confuse them? What are the reasons for omitting them?", "author": "npepinpe", "createdAt": "2020-07-07T12:56:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0Nzk3Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450847972", "bodyText": "CommandApi does not now how much disk space is available or required. It only knows that there is not enough. If we want to provide this information to the users, the listener interface should be changed. Since user's can't do anything with that information, I don't think it is necessary. We log both required and available disk space in DiskSpaceUsageMonitor, which can be used by an operator.", "author": "deepthidevaki", "createdAt": "2020-07-07T13:05:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MTY4NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448361685", "bodyText": "We don't have a test for user commands? I see we have one for deployment and messages (subscription API).", "author": "npepinpe", "createdAt": "2020-07-01T13:26:32Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.Broker;\n+import io.zeebe.broker.it.clustering.ClusteringRule;\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.client.api.response.DeploymentEvent;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.DeploymentIntent;\n+import io.zeebe.protocol.record.intent.MessageSubscriptionIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceSubscriptionIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryClusteredTest {", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2ODc2NQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448768765", "bodyText": "We have it in DiskSpaceRecoveryTest with single broker.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:09:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MTY4NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MzIwOQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448363209", "bodyText": "I'm guessing this is testing left over?", "author": "npepinpe", "createdAt": "2020-07-01T13:28:53Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\nindex fb0e8acab9..4176a19f2c 100644\n--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n\n@@ -29,8 +29,8 @@ import org.testcontainers.elasticsearch.ElasticsearchContainer;\n \n public class DiskSpaceRecoveryITTest {\n   static ZeebeBrokerContainer zeebeBroker;\n-  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n-  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static final Logger LOG = LoggerFactory.getLogger(DiskSpaceRecoveryITTest.class);\n+  private static final String VOLUME_NAME = \"data-DiskSpaceRecoveryITTest\";\n   private static String containerIPAddress;\n   private static Integer apiPort;\n   private static ElasticsearchContainer elastic;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDE1OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448364158", "bodyText": "Not sure if we have to do this - stop from Testcontainers is actually more of a kill command, so it may also already be cleaning up the volumes, though we'd have to verify that.", "author": "npepinpe", "createdAt": "2020-07-01T13:30:18Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3NTI1Mw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448775253", "bodyText": "Volume should be closed explicitly. I just verified it.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:27:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDE1OA=="}], "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\nindex fb0e8acab9..4176a19f2c 100644\n--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n\n@@ -29,8 +29,8 @@ import org.testcontainers.elasticsearch.ElasticsearchContainer;\n \n public class DiskSpaceRecoveryITTest {\n   static ZeebeBrokerContainer zeebeBroker;\n-  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n-  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static final Logger LOG = LoggerFactory.getLogger(DiskSpaceRecoveryITTest.class);\n+  private static final String VOLUME_NAME = \"data-DiskSpaceRecoveryITTest\";\n   private static String containerIPAddress;\n   private static Integer apiPort;\n   private static ElasticsearchContainer elastic;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448364797", "bodyText": "I'm not a fan of doesNotThrowAnyException - can't we assert that the message was published in some way?", "author": "npepinpe", "createdAt": "2020-07-01T13:31:17Z", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "originalCommit": "ef515fed93020dc76d7b339d99e86b0fc50d4514", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3NDAxMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448374012", "bodyText": "Btw I thought we fixed that publish message doesnt return anything? Shouldn't it return a response now?", "author": "Zelldon", "createdAt": "2020-07-01T13:45:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3NTQ2MA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448375460", "bodyText": "Was added with #3820", "author": "Zelldon", "createdAt": "2020-07-01T13:47:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3MDYzOQ==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448770639", "bodyText": "It returns a type 'PublishMessageResponse'. But it is still empty.", "author": "deepthidevaki", "createdAt": "2020-07-02T06:14:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwOTM3Ng==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448909376", "bodyText": "Similar as how we return deployment keys, we should return message keys - helpful to correlate things with an exporter stream, for example. @Zelldon already opened an issue for it \ud83d\ude09 #4794\nThat said, you can still assert you get an non null PublishMessageResponse (or whatever it is) as a result, no? Wouldn't that always indicate success?", "author": "npepinpe", "createdAt": "2020-07-02T10:36:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNzgzNA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448927834", "bodyText": "assert(..).isNotNull() did not work.", "author": "deepthidevaki", "createdAt": "2020-07-02T11:14:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0MzM3Mg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450843372", "bodyText": "Hm, curious, wasn't expecting that. Well I'm fine leaving it like this, but I would propose we try to avoid it in general.", "author": "npepinpe", "createdAt": "2020-07-07T12:57:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\nindex fb0e8acab9..4176a19f2c 100644\n--- a/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n+++ b/qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java\n\n@@ -29,8 +29,8 @@ import org.testcontainers.elasticsearch.ElasticsearchContainer;\n \n public class DiskSpaceRecoveryITTest {\n   static ZeebeBrokerContainer zeebeBroker;\n-  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n-  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static final Logger LOG = LoggerFactory.getLogger(DiskSpaceRecoveryITTest.class);\n+  private static final String VOLUME_NAME = \"data-DiskSpaceRecoveryITTest\";\n   private static String containerIPAddress;\n   private static Integer apiPort;\n   private static ElasticsearchContainer elastic;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNjcyMg==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448906722", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * @return the percentage of disk space that must be available before log compaction is forced\n          \n          \n            \n               * @return the amount of disk space that must be available before log compaction is forced", "author": "npepinpe", "createdAt": "2020-07-02T10:31:06Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -189,7 +189,7 @@ public boolean dynamicCompaction() {\n    *\n    * @return the percentage of disk space that must be available before log compaction is forced", "originalCommit": "3e908944dc07b3762a4370ca610633fcae49d05d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "chunk": "diff --git a/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java b/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\nindex 8b9cfde6e5..f71dc4cf0a 100644\n--- a/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\n+++ b/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\n\n@@ -187,7 +187,7 @@ public final class RaftStorage {\n   /**\n    * Returns the percentage of disk space that must be available before log compaction is forced.\n    *\n-   * @return the percentage of disk space that must be available before log compaction is forced\n+   * @return the amount of disk space that must be available before log compaction is forced\n    */\n   public long freeDiskSpace() {\n     return freeDiskSpace;\n"}}, {"oid": "27c71401e65fada4a7b2dbb82dcc43d622a278cb", "url": "https://github.com/camunda-cloud/zeebe/commit/27c71401e65fada4a7b2dbb82dcc43d622a278cb", "message": "chore(qa): increase timeout", "committedDate": "2020-07-03T06:39:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAyNzc0OA==", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450027748", "bodyText": "This needs then probably also be changed\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * Returns the percentage of disk space that must be available before log compaction is forced.\n          \n          \n            \n               * Returns the amount of disk space that must be available before log compaction is forced.", "author": "Zelldon", "createdAt": "2020-07-06T07:17:44Z", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -187,7 +187,7 @@ public boolean dynamicCompaction() {\n   /**\n    * Returns the percentage of disk space that must be available before log compaction is forced.", "originalCommit": "cf6a16feb70194668781c9f18e9733526ebd0f67", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c491d7a819c2b520180353b9eef5ff80fe9d2d5b", "chunk": "diff --git a/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java b/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\nindex f71dc4cf0a..78674bdc3c 100644\n--- a/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\n+++ b/atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java\n\n@@ -185,7 +185,7 @@ public final class RaftStorage {\n   }\n \n   /**\n-   * Returns the percentage of disk space that must be available before log compaction is forced.\n+   * Returns the amount of disk space that must be available before log compaction is forced.\n    *\n    * @return the amount of disk space that must be available before log compaction is forced\n    */\n"}}, {"oid": "c491d7a819c2b520180353b9eef5ff80fe9d2d5b", "url": "https://github.com/camunda-cloud/zeebe/commit/c491d7a819c2b520180353b9eef5ff80fe9d2d5b", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-06T09:12:37Z", "type": "forcePushed"}, {"oid": "602bcda664eae589ec7bd7d1c54b965ab65a46c6", "url": "https://github.com/camunda-cloud/zeebe/commit/602bcda664eae589ec7bd7d1c54b965ab65a46c6", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-07T10:18:38Z", "type": "forcePushed"}, {"oid": "32a1434728701bb0df1e92ef6fcaf43bc42fcea4", "url": "https://github.com/camunda-cloud/zeebe/commit/32a1434728701bb0df1e92ef6fcaf43bc42fcea4", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-08T07:12:55Z", "type": "forcePushed"}, {"oid": "9b14bc0955df46f870fb58b34d71a0ee967306c2", "url": "https://github.com/camunda-cloud/zeebe/commit/9b14bc0955df46f870fb58b34d71a0ee967306c2", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-08T14:37:10Z", "type": "forcePushed"}, {"oid": "c1a0b019c2d29ac4cc998a20721661899da61052", "url": "https://github.com/camunda-cloud/zeebe/commit/c1a0b019c2d29ac4cc998a20721661899da61052", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-09T13:38:19Z", "type": "commit"}, {"oid": "c1a0b019c2d29ac4cc998a20721661899da61052", "url": "https://github.com/camunda-cloud/zeebe/commit/c1a0b019c2d29ac4cc998a20721661899da61052", "message": "chore(broker): handle out of disk space in broker\n* expose configuration parameters for minimum free disk space\n* When broker free disk space available is less than configured min free disk,\n  - reject client requests\n  - reject commands from other partitions\n  - pause stream processor", "committedDate": "2020-07-09T13:38:19Z", "type": "forcePushed"}]}