{"pr_number": 5399, "pr_title": "DATE_TIME should work as the primary time column for Pinot tables", "pr_createdAt": "2020-05-16T01:20:41Z", "pr_url": "https://github.com/apache/pinot/pull/5399", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjExNDI3OQ==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426114279", "bodyText": "nit: please reformat this file", "author": "haibow", "createdAt": "2020-05-16T03:45:05Z", "path": "pinot-broker/src/test/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManagerTest.java", "diffHunk": "@@ -75,85 +75,112 @@ public void testTimeBoundaryManager() {\n     ExternalView externalView = Mockito.mock(ExternalView.class);\n \n     for (TimeUnit timeUnit : TimeUnit.values()) {\n-      // Test DAILY push table\n+      // Test DAILY push table, with timeFieldSpec\n       String rawTableName = \"testTable_\" + timeUnit + \"_DAILY\";\n-      TableConfig tableConfig = getTableConfig(rawTableName, timeUnit, \"DAILY\");\n-      setSchema(rawTableName, timeUnit);\n-\n-      // Start with no segment\n-      TimeBoundaryManager timeBoundaryManager = new TimeBoundaryManager(tableConfig, _propertyStore);\n-      Set<String> onlineSegments = new HashSet<>();\n-      timeBoundaryManager.init(externalView, onlineSegments);\n-      assertNull(timeBoundaryManager.getTimeBoundaryInfo());\n-\n-      // Add the first segment should update the time boundary\n-      String segment0 = \"segment0\";\n-      onlineSegments.add(segment0);\n-      setSegmentZKMetadata(rawTableName, segment0, 2, timeUnit);\n-      timeBoundaryManager.init(externalView, onlineSegments);\n-      verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(1, TimeUnit.DAYS));\n-\n-      // Add a new segment with larger end time should update the time boundary\n-      String segment1 = \"segment1\";\n-      onlineSegments.add(segment1);\n-      setSegmentZKMetadata(rawTableName, segment1, 4, timeUnit);\n-      timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n-      verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(3, TimeUnit.DAYS));\n-\n-      // Add a new segment with smaller end time should not change the time boundary\n-      String segment2 = \"segment2\";\n-      onlineSegments.add(segment2);\n-      setSegmentZKMetadata(rawTableName, segment2, 3, timeUnit);\n-      timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n-      verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(3, TimeUnit.DAYS));\n-\n-      // Remove the segment with largest end time should update the time boundary\n-      onlineSegments.remove(segment1);\n-      timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n-      verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(2, TimeUnit.DAYS));\n-\n-      // Change segment ZK metadata without refreshing should not update the time boundary\n-      setSegmentZKMetadata(rawTableName, segment2, 5, timeUnit);\n-      timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n-      verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(2, TimeUnit.DAYS));\n-\n-      // Refresh the changed segment should update the time boundary\n-      timeBoundaryManager.refreshSegment(segment2);\n-      verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(4, TimeUnit.DAYS));\n+      TableConfig tableConfig = getTableConfig(rawTableName, \"DAILY\");\n+      setSchemaTimeFieldSpec(rawTableName, timeUnit);\n+      testDailyPushTable(rawTableName, tableConfig, timeUnit, externalView);\n \n-      // Test HOURLY push table\n+      // Test HOURLY push table, with timeFieldSpec\n       rawTableName = \"testTable_\" + timeUnit + \"_HOURLY\";\n-      tableConfig = getTableConfig(rawTableName, timeUnit, \"HOURLY\");\n-      setSchema(rawTableName, timeUnit);\n-      timeBoundaryManager = new TimeBoundaryManager(tableConfig, _propertyStore);\n-      onlineSegments = new HashSet<>();\n-      onlineSegments.add(segment0);\n-      setSegmentZKMetadata(rawTableName, segment0, 2, timeUnit);\n-      timeBoundaryManager.init(externalView, onlineSegments);\n-      long expectedTimeValue;\n-      if (timeUnit == TimeUnit.DAYS) {\n-        // Time boundary should be endTime - 1 DAY when time unit is DAYS\n-        expectedTimeValue = timeUnit.convert(1, TimeUnit.DAYS);\n-      } else {\n-        // Time boundary should be endTime - 1 HOUR when time unit is other than DAYS\n-        expectedTimeValue = timeUnit.convert(47, TimeUnit.HOURS);\n-      }\n-      verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), expectedTimeValue);\n+      tableConfig = getTableConfig(rawTableName, \"HOURLY\");\n+      setSchemaTimeFieldSpec(rawTableName, timeUnit);\n+      testHourlyPushTable(rawTableName, tableConfig, timeUnit, externalView);\n+\n+      // Test DAILY push table with dateTimeFieldSpec\n+      rawTableName = \"testTableDateTime_\" + timeUnit + \"_DAILY\";\n+      tableConfig = getTableConfig(rawTableName, \"DAILY\");\n+      setSchemaDateTimeFieldSpec(rawTableName, timeUnit);\n+      testDailyPushTable(rawTableName, tableConfig, timeUnit, externalView);\n+\n+      // Test HOURLY push table\n+      rawTableName = \"testTableDateTime_\" + timeUnit + \"_HOURLY\";\n+      tableConfig = getTableConfig(rawTableName, \"HOURLY\");\n+      setSchemaDateTimeFieldSpec(rawTableName, timeUnit);\n+      testHourlyPushTable(rawTableName, tableConfig, timeUnit, externalView);\n+    }\n+  }\n+\n+  private void testDailyPushTable(String rawTableName, TableConfig tableConfig, TimeUnit timeUnit, ExternalView externalView) {\n+    // Start with no segment\n+    TimeBoundaryManager timeBoundaryManager = new TimeBoundaryManager(tableConfig, _propertyStore);\n+    Set<String> onlineSegments = new HashSet<>();\n+    timeBoundaryManager.init(externalView, onlineSegments);\n+    assertNull(timeBoundaryManager.getTimeBoundaryInfo());\n+\n+    // Add the first segment should update the time boundary\n+    String segment0 = \"segment0\";\n+    onlineSegments.add(segment0);\n+    setSegmentZKMetadata(rawTableName, segment0, 2, timeUnit);\n+    timeBoundaryManager.init(externalView, onlineSegments);\n+    verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(1, TimeUnit.DAYS));\n+\n+    // Add a new segment with larger end time should update the time boundary\n+    String segment1 = \"segment1\";\n+    onlineSegments.add(segment1);\n+    setSegmentZKMetadata(rawTableName, segment1, 4, timeUnit);\n+    timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n+    verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(3, TimeUnit.DAYS));\n+\n+    // Add a new segment with smaller end time should not change the time boundary\n+    String segment2 = \"segment2\";\n+    onlineSegments.add(segment2);\n+    setSegmentZKMetadata(rawTableName, segment2, 3, timeUnit);\n+    timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n+    verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(3, TimeUnit.DAYS));\n+\n+    // Remove the segment with largest end time should update the time boundary\n+    onlineSegments.remove(segment1);\n+    timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n+    verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(2, TimeUnit.DAYS));\n+\n+    // Change segment ZK metadata without refreshing should not update the time boundary\n+    setSegmentZKMetadata(rawTableName, segment2, 5, timeUnit);\n+    timeBoundaryManager.onExternalViewChange(externalView, onlineSegments);\n+    verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(2, TimeUnit.DAYS));\n+\n+    // Refresh the changed segment should update the time boundary\n+    timeBoundaryManager.refreshSegment(segment2);\n+    verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), timeUnit.convert(4, TimeUnit.DAYS));\n+  }\n+\n+  private void testHourlyPushTable(String rawTableName, TableConfig tableConfig, TimeUnit timeUnit, ExternalView externalView) {\n+    TimeBoundaryManager timeBoundaryManager = new TimeBoundaryManager(tableConfig, _propertyStore);\n+    Set<String> onlineSegments = new HashSet<>();\n+    String segment0 = \"segment0\";\n+    onlineSegments.add(segment0);\n+    setSegmentZKMetadata(rawTableName, segment0, 2, timeUnit);\n+    timeBoundaryManager.init(externalView, onlineSegments);\n+    long expectedTimeValue;\n+    if (timeUnit == TimeUnit.DAYS) {\n+      // Time boundary should be endTime - 1 DAY when time unit is DAYS\n+      expectedTimeValue = timeUnit.convert(1, TimeUnit.DAYS);\n+    } else {\n+      // Time boundary should be endTime - 1 HOUR when time unit is other than DAYS\n+      expectedTimeValue = timeUnit.convert(47, TimeUnit.HOURS);\n     }\n+    verifyTimeBoundaryInfo(timeBoundaryManager.getTimeBoundaryInfo(), expectedTimeValue);\n   }\n \n-  private TableConfig getTableConfig(String rawTableName, TimeUnit timeUnit, String pushFrequency) {\n+  private TableConfig getTableConfig(String rawTableName, String pushFrequency) {\n     return new TableConfigBuilder(TableType.OFFLINE).setTableName(rawTableName).setTimeColumnName(TIME_COLUMN)\n-        .setTimeType(timeUnit.name()).setSegmentPushFrequency(pushFrequency).build();\n+        .setSegmentPushFrequency(pushFrequency).build();\n   }\n \n-  private void setSchema(String rawTableName, TimeUnit timeUnit) {\n+  private void setSchemaTimeFieldSpec(String rawTableName, TimeUnit timeUnit) {\n     ZKMetadataProvider.setSchema(_propertyStore,\n         new Schema.SchemaBuilder().setSchemaName(rawTableName)\n             .addTime(new TimeGranularitySpec(FieldSpec.DataType.LONG, timeUnit, TIME_COLUMN), null)\n             .build());\n   }\n \n+  private void setSchemaDateTimeFieldSpec(String rawTableName, TimeUnit timeUnit) {\n+    ZKMetadataProvider.setSchema(_propertyStore,\n+        new Schema.SchemaBuilder().setSchemaName(rawTableName)\n+            .addDateTime(TIME_COLUMN, FieldSpec.DataType.LONG, \"1:\"+timeUnit+\":EPOCH\", \"1:\"+timeUnit)", "originalCommit": "9cc0d14cff863b3a34e59bf19b1387528f8484ea", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-broker/src/test/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManagerTest.java b/pinot-broker/src/test/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManagerTest.java\nindex 27f2aeb244..98f5d3e492 100644\n--- a/pinot-broker/src/test/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManagerTest.java\n+++ b/pinot-broker/src/test/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManagerTest.java\n\n@@ -175,10 +175,8 @@ public class TimeBoundaryManagerTest {\n   }\n \n   private void setSchemaDateTimeFieldSpec(String rawTableName, TimeUnit timeUnit) {\n-    ZKMetadataProvider.setSchema(_propertyStore,\n-        new Schema.SchemaBuilder().setSchemaName(rawTableName)\n-            .addDateTime(TIME_COLUMN, FieldSpec.DataType.LONG, \"1:\"+timeUnit+\":EPOCH\", \"1:\"+timeUnit)\n-            .build());\n+    ZKMetadataProvider.setSchema(_propertyStore, new Schema.SchemaBuilder().setSchemaName(rawTableName)\n+        .addDateTime(TIME_COLUMN, FieldSpec.DataType.LONG, \"1:\" + timeUnit + \":EPOCH\", \"1:\" + timeUnit).build());\n   }\n \n   private void setSegmentZKMetadata(String rawTableName, String segment, int endTimeInDays, TimeUnit timeUnit) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjExNDUxMQ==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426114511", "bodyText": "Please reformat all affected files. This file has unused imports.", "author": "haibow", "createdAt": "2020-05-16T03:48:18Z", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManager.java", "diffHunk": "@@ -34,6 +34,8 @@\n import org.apache.pinot.common.utils.CommonConstants;\n import org.apache.pinot.spi.config.table.TableConfig;\n import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;", "originalCommit": "9cc0d14cff863b3a34e59bf19b1387528f8484ea", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-broker/src/main/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManager.java b/pinot-broker/src/main/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManager.java\nindex 1fb964abc2..5e4b0193cf 100644\n--- a/pinot-broker/src/main/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManager.java\n+++ b/pinot-broker/src/main/java/org/apache/pinot/broker/routing/timeboundary/TimeBoundaryManager.java\n\n@@ -36,9 +36,7 @@ import org.apache.pinot.spi.config.table.TableConfig;\n import org.apache.pinot.spi.config.table.TableType;\n import org.apache.pinot.spi.data.DateTimeFieldSpec;\n import org.apache.pinot.spi.data.DateTimeFormatSpec;\n-import org.apache.pinot.spi.data.FieldSpec;\n import org.apache.pinot.spi.data.Schema;\n-import org.apache.pinot.spi.data.TimeFieldSpec;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjExNDU1Mw==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426114553", "bodyText": "nit: s/treansformFunctions/transformFunctions", "author": "haibow", "createdAt": "2020-05-16T03:49:02Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/function/FunctionEvaluatorFactory.java", "diffHunk": "@@ -59,7 +59,8 @@ public FunctionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n       }\n     } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n \n-      // for backward compatible handling of TIME field conversion\n+      // Time conversions should be done using DateTimeFieldSpec and treansformFunctions", "originalCommit": "9cc0d14cff863b3a34e59bf19b1387528f8484ea", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-core/src/main/java/org/apache/pinot/core/data/function/FunctionEvaluatorFactory.java b/pinot-core/src/main/java/org/apache/pinot/core/data/function/FunctionEvaluatorFactory.java\nindex c19192fa34..cc8cd37208 100644\n--- a/pinot-core/src/main/java/org/apache/pinot/core/data/function/FunctionEvaluatorFactory.java\n+++ b/pinot-core/src/main/java/org/apache/pinot/core/data/function/FunctionEvaluatorFactory.java\n\n@@ -59,7 +59,7 @@ public class FunctionEvaluatorFactory {\n       }\n     } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n \n-      // Time conversions should be done using DateTimeFieldSpec and treansformFunctions\n+      // Time conversions should be done using DateTimeFieldSpec and transformFunctions\n       // But we need below lines for converting TimeFieldSpec's incoming to outgoing\n       TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n       TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjE5NzM3OA==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426197378", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                 * Deprecated in favor of addDateTime().\n          \n          \n            \n                 * @deprecated in favor of {@link #addDateTime()}.", "author": "mcvsubbu", "createdAt": "2020-05-16T22:39:45Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/Schema.java", "diffHunk": "@@ -507,10 +507,10 @@ public SchemaBuilder addMetric(String metricName, DataType dataType, Object defa\n \n     /**\n      * Add timeFieldSpec with incoming and outgoing granularity spec\n-     * TODO: This is going to be deprecated in favor of addDateTime().\n-     *  Many tests use this to construct Schema with TimeFieldSpec.\n-     *  This will continue to exist for a while, as it helps to test backward compatibility of schemas containing TimeFieldSpec\n+     * Deprecated in favor of addDateTime().", "originalCommit": "9cc0d14cff863b3a34e59bf19b1387528f8484ea", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-spi/src/main/java/org/apache/pinot/spi/data/Schema.java b/pinot-spi/src/main/java/org/apache/pinot/spi/data/Schema.java\nindex 3c39944e23..b227ad581d 100644\n--- a/pinot-spi/src/main/java/org/apache/pinot/spi/data/Schema.java\n+++ b/pinot-spi/src/main/java/org/apache/pinot/spi/data/Schema.java\n\n@@ -506,8 +506,8 @@ public final class Schema {\n     }\n \n     /**\n-     * Add timeFieldSpec with incoming and outgoing granularity spec\n-     * Deprecated in favor of addDateTime().\n+     * @deprecated in favor of {@link SchemaBuilder#addDateTime(String, DataType, String, String)}\n+     * Adds timeFieldSpec with incoming and outgoing granularity spec\n      * This will continue to exist for a while in several tests, as it helps to test backward compatibility of schemas containing TimeFieldSpec\n      */\n     @Deprecated\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjE5NzQyMg==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426197422", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * TimeFieldSpec is deprecated. Use {@link DateTimeFieldSpec} instead.\n          \n          \n            \n             * @deprecated TimeFieldSpec is deprecated. Use {@link DateTimeFieldSpec} instead.", "author": "mcvsubbu", "createdAt": "2020-05-16T22:40:12Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/TimeFieldSpec.java", "diffHunk": "@@ -28,6 +28,12 @@\n \n @SuppressWarnings(\"unused\")\n @JsonIgnoreProperties(ignoreUnknown = true)\n+@Deprecated\n+/**\n+ * TimeFieldSpec is deprecated. Use {@link DateTimeFieldSpec} instead.", "originalCommit": "9cc0d14cff863b3a34e59bf19b1387528f8484ea", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-spi/src/main/java/org/apache/pinot/spi/data/TimeFieldSpec.java b/pinot-spi/src/main/java/org/apache/pinot/spi/data/TimeFieldSpec.java\nindex e37062b426..5fefbf727f 100644\n--- a/pinot-spi/src/main/java/org/apache/pinot/spi/data/TimeFieldSpec.java\n+++ b/pinot-spi/src/main/java/org/apache/pinot/spi/data/TimeFieldSpec.java\n\n@@ -25,15 +25,13 @@ import com.google.common.base.Preconditions;\n import org.apache.pinot.spi.utils.EqualityUtils;\n import org.apache.pinot.spi.utils.JsonUtils;\n \n-\n-@SuppressWarnings(\"unused\")\n-@JsonIgnoreProperties(ignoreUnknown = true)\n-@Deprecated\n /**\n- * TimeFieldSpec is deprecated. Use {@link DateTimeFieldSpec} instead.\n+ * @deprecated Use {@link DateTimeFieldSpec} instead.\n  * This should only be used in 1) tests 2) wherever required for backward compatible handling of schemas with TimeFieldSpec\n  * https://github.com/apache/incubator-pinot/issues/2756\n  */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+@SuppressWarnings(\"unused\")\n public final class TimeFieldSpec extends FieldSpec {\n   private TimeGranularitySpec _incomingGranularitySpec;\n   private TimeGranularitySpec _outgoingGranularitySpec;\n"}}, {"oid": "118b8ba31b0145980a9d57be2392a3e9401e4625", "url": "https://github.com/apache/pinot/commit/118b8ba31b0145980a9d57be2392a3e9401e4625", "message": "Change quickstart schemas", "committedDate": "2020-05-16T22:51:55Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg2Njg5OQ==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426866899", "bodyText": "Why do we need the second part of the check? What if the schema has no DateTimeField but only TimeField?", "author": "Jackie-Jiang", "createdAt": "2020-05-18T20:09:44Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java", "diffHunk": "@@ -362,12 +362,14 @@ private void writeMetadata()\n     properties.setProperty(DIMENSIONS, config.getDimensions());\n     properties.setProperty(METRICS, config.getMetrics());\n     properties.setProperty(DATETIME_COLUMNS, config.getDateTimeColumnNames());\n-    properties.setProperty(TIME_COLUMN_NAME, config.getTimeColumnName());\n+    String timeColumnName = config.getTimeColumnName();\n+    if (timeColumnName != null && !config.getSchema().getDateTimeNames().contains(timeColumnName)) {", "originalCommit": "e0dacf8054a31507d54c5df91cd38b312c95a507", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjkyNDcwNA==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426924704", "bodyText": "Summarizing our offline discussion:\nThe second part was to avoid setting the time column name in segment.datetime.column.names and also in segment.time.column.name, which will happen if the primary time column is dateTimeFieldSpec. This happens because segment.time.column.name was serving as primary timeColumnName and also as timeFieldSpec. This worked well so far, because primary time column and timeFieldSpec were one and the same. I added that check, with the intention to stop having a record of primary time column in the segment metadata. It was not being used anywhere in Pinot.\nBut based on our chat, removing that check. As decided, the segment.time.column.name property will serve as the primary time column name. It will match with timecolumnName in tableConfig. It can be of type DATE_TIME or TIME.", "author": "npawar", "createdAt": "2020-05-18T22:23:38Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg2Njg5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java b/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java\nindex cbdadbcfc2..12e6feb402 100644\n--- a/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java\n+++ b/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java\n\n@@ -363,53 +363,51 @@ public class SegmentColumnarIndexCreator implements SegmentCreator {\n     properties.setProperty(METRICS, config.getMetrics());\n     properties.setProperty(DATETIME_COLUMNS, config.getDateTimeColumnNames());\n     String timeColumnName = config.getTimeColumnName();\n-    if (timeColumnName != null && !config.getSchema().getDateTimeNames().contains(timeColumnName)) {\n-      properties.setProperty(TIME_COLUMN_NAME, timeColumnName);\n-    }\n+    properties.setProperty(TIME_COLUMN_NAME, timeColumnName);\n     properties.setProperty(SEGMENT_TOTAL_DOCS, String.valueOf(totalDocs));\n \n     // Write time related metadata (start time, end time, time unit)\n-    ColumnIndexCreationInfo timeColumnIndexCreationInfo = indexCreationInfoMap.get(timeColumnName);\n-    if (timeColumnIndexCreationInfo != null) {\n-      long startTime;\n-      long endTime;\n-      TimeUnit timeUnit;\n-\n-      // Use start/end time in config if defined\n-      if (config.getStartTime() != null) {\n-        startTime = Long.parseLong(config.getStartTime());\n-        endTime = Long.parseLong(config.getEndTime());\n-        timeUnit = Preconditions.checkNotNull(config.getSegmentTimeUnit());\n-      } else {\n-        String startTimeStr = timeColumnIndexCreationInfo.getMin().toString();\n-        String endTimeStr = timeColumnIndexCreationInfo.getMax().toString();\n-\n-        if (config.getTimeColumnType() == SegmentGeneratorConfig.TimeColumnType.SIMPLE_DATE) {\n-          // For TimeColumnType.SIMPLE_DATE_FORMAT, convert time value into millis since epoch\n-          DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern(config.getSimpleDateFormat());\n-          startTime = dateTimeFormatter.parseMillis(startTimeStr);\n-          endTime = dateTimeFormatter.parseMillis(endTimeStr);\n-          timeUnit = TimeUnit.MILLISECONDS;\n-        } else {\n-          // by default, time column type is TimeColumnType.EPOCH\n-          startTime = Long.parseLong(startTimeStr);\n-          endTime = Long.parseLong(endTimeStr);\n+    if (timeColumnName != null) {\n+      ColumnIndexCreationInfo timeColumnIndexCreationInfo = indexCreationInfoMap.get(timeColumnName);\n+      if (timeColumnIndexCreationInfo != null) {\n+        long startTime;\n+        long endTime;\n+        TimeUnit timeUnit;\n+\n+        // Use start/end time in config if defined\n+        if (config.getStartTime() != null) {\n+          startTime = Long.parseLong(config.getStartTime());\n+          endTime = Long.parseLong(config.getEndTime());\n           timeUnit = Preconditions.checkNotNull(config.getSegmentTimeUnit());\n+        } else {\n+          String startTimeStr = timeColumnIndexCreationInfo.getMin().toString();\n+          String endTimeStr = timeColumnIndexCreationInfo.getMax().toString();\n+\n+          if (config.getTimeColumnType() == SegmentGeneratorConfig.TimeColumnType.SIMPLE_DATE) {\n+            // For TimeColumnType.SIMPLE_DATE_FORMAT, convert time value into millis since epoch\n+            DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern(config.getSimpleDateFormat());\n+            startTime = dateTimeFormatter.parseMillis(startTimeStr);\n+            endTime = dateTimeFormatter.parseMillis(endTimeStr);\n+            timeUnit = TimeUnit.MILLISECONDS;\n+          } else {\n+            // by default, time column type is TimeColumnType.EPOCH\n+            startTime = Long.parseLong(startTimeStr);\n+            endTime = Long.parseLong(endTimeStr);\n+            timeUnit = Preconditions.checkNotNull(config.getSegmentTimeUnit());\n+          }\n         }\n-      }\n \n-      if (!config.isSkipTimeValueCheck()) {\n-        Interval timeInterval =\n-            new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime), DateTimeZone.UTC);\n-        Preconditions.checkState(TimeUtils.isValidTimeInterval(timeInterval),\n-            \"Invalid segment start/end time: %s (in millis: %s/%s) for time column: %s, must be between: %s\",\n-            timeInterval, timeInterval.getStartMillis(), timeInterval.getEndMillis(), timeColumnName,\n-            TimeUtils.VALID_TIME_INTERVAL);\n-      }\n+        if (!config.isSkipTimeValueCheck()) {\n+          Interval timeInterval = new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime), DateTimeZone.UTC);\n+          Preconditions.checkState(TimeUtils.isValidTimeInterval(timeInterval),\n+              \"Invalid segment start/end time: %s (in millis: %s/%s) for time column: %s, must be between: %s\",\n+              timeInterval, timeInterval.getStartMillis(), timeInterval.getEndMillis(), timeColumnName, TimeUtils.VALID_TIME_INTERVAL);\n+        }\n \n-      properties.setProperty(SEGMENT_START_TIME, startTime);\n-      properties.setProperty(SEGMENT_END_TIME, endTime);\n-      properties.setProperty(TIME_UNIT, timeUnit);\n+        properties.setProperty(SEGMENT_START_TIME, startTime);\n+        properties.setProperty(SEGMENT_END_TIME, endTime);\n+        properties.setProperty(TIME_UNIT, timeUnit);\n+      }\n     }\n \n     for (Map.Entry<String, String> entry : config.getCustomProperties().entrySet()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg2NzgwOA==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426867808", "bodyText": "Check whether timeColumnName is null first", "author": "Jackie-Jiang", "createdAt": "2020-05-18T20:11:47Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java", "diffHunk": "@@ -362,12 +362,14 @@ private void writeMetadata()\n     properties.setProperty(DIMENSIONS, config.getDimensions());\n     properties.setProperty(METRICS, config.getMetrics());\n     properties.setProperty(DATETIME_COLUMNS, config.getDateTimeColumnNames());\n-    properties.setProperty(TIME_COLUMN_NAME, config.getTimeColumnName());\n+    String timeColumnName = config.getTimeColumnName();\n+    if (timeColumnName != null && !config.getSchema().getDateTimeNames().contains(timeColumnName)) {\n+      properties.setProperty(TIME_COLUMN_NAME, timeColumnName);\n+    }\n     properties.setProperty(SEGMENT_TOTAL_DOCS, String.valueOf(totalDocs));\n \n     // Write time related metadata (start time, end time, time unit)\n-    String timeColumn = config.getTimeColumnName();\n-    ColumnIndexCreationInfo timeColumnIndexCreationInfo = indexCreationInfoMap.get(timeColumn);\n+    ColumnIndexCreationInfo timeColumnIndexCreationInfo = indexCreationInfoMap.get(timeColumnName);", "originalCommit": "e0dacf8054a31507d54c5df91cd38b312c95a507", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java b/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java\nindex cbdadbcfc2..12e6feb402 100644\n--- a/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java\n+++ b/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/SegmentColumnarIndexCreator.java\n\n@@ -363,53 +363,51 @@ public class SegmentColumnarIndexCreator implements SegmentCreator {\n     properties.setProperty(METRICS, config.getMetrics());\n     properties.setProperty(DATETIME_COLUMNS, config.getDateTimeColumnNames());\n     String timeColumnName = config.getTimeColumnName();\n-    if (timeColumnName != null && !config.getSchema().getDateTimeNames().contains(timeColumnName)) {\n-      properties.setProperty(TIME_COLUMN_NAME, timeColumnName);\n-    }\n+    properties.setProperty(TIME_COLUMN_NAME, timeColumnName);\n     properties.setProperty(SEGMENT_TOTAL_DOCS, String.valueOf(totalDocs));\n \n     // Write time related metadata (start time, end time, time unit)\n-    ColumnIndexCreationInfo timeColumnIndexCreationInfo = indexCreationInfoMap.get(timeColumnName);\n-    if (timeColumnIndexCreationInfo != null) {\n-      long startTime;\n-      long endTime;\n-      TimeUnit timeUnit;\n-\n-      // Use start/end time in config if defined\n-      if (config.getStartTime() != null) {\n-        startTime = Long.parseLong(config.getStartTime());\n-        endTime = Long.parseLong(config.getEndTime());\n-        timeUnit = Preconditions.checkNotNull(config.getSegmentTimeUnit());\n-      } else {\n-        String startTimeStr = timeColumnIndexCreationInfo.getMin().toString();\n-        String endTimeStr = timeColumnIndexCreationInfo.getMax().toString();\n-\n-        if (config.getTimeColumnType() == SegmentGeneratorConfig.TimeColumnType.SIMPLE_DATE) {\n-          // For TimeColumnType.SIMPLE_DATE_FORMAT, convert time value into millis since epoch\n-          DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern(config.getSimpleDateFormat());\n-          startTime = dateTimeFormatter.parseMillis(startTimeStr);\n-          endTime = dateTimeFormatter.parseMillis(endTimeStr);\n-          timeUnit = TimeUnit.MILLISECONDS;\n-        } else {\n-          // by default, time column type is TimeColumnType.EPOCH\n-          startTime = Long.parseLong(startTimeStr);\n-          endTime = Long.parseLong(endTimeStr);\n+    if (timeColumnName != null) {\n+      ColumnIndexCreationInfo timeColumnIndexCreationInfo = indexCreationInfoMap.get(timeColumnName);\n+      if (timeColumnIndexCreationInfo != null) {\n+        long startTime;\n+        long endTime;\n+        TimeUnit timeUnit;\n+\n+        // Use start/end time in config if defined\n+        if (config.getStartTime() != null) {\n+          startTime = Long.parseLong(config.getStartTime());\n+          endTime = Long.parseLong(config.getEndTime());\n           timeUnit = Preconditions.checkNotNull(config.getSegmentTimeUnit());\n+        } else {\n+          String startTimeStr = timeColumnIndexCreationInfo.getMin().toString();\n+          String endTimeStr = timeColumnIndexCreationInfo.getMax().toString();\n+\n+          if (config.getTimeColumnType() == SegmentGeneratorConfig.TimeColumnType.SIMPLE_DATE) {\n+            // For TimeColumnType.SIMPLE_DATE_FORMAT, convert time value into millis since epoch\n+            DateTimeFormatter dateTimeFormatter = DateTimeFormat.forPattern(config.getSimpleDateFormat());\n+            startTime = dateTimeFormatter.parseMillis(startTimeStr);\n+            endTime = dateTimeFormatter.parseMillis(endTimeStr);\n+            timeUnit = TimeUnit.MILLISECONDS;\n+          } else {\n+            // by default, time column type is TimeColumnType.EPOCH\n+            startTime = Long.parseLong(startTimeStr);\n+            endTime = Long.parseLong(endTimeStr);\n+            timeUnit = Preconditions.checkNotNull(config.getSegmentTimeUnit());\n+          }\n         }\n-      }\n \n-      if (!config.isSkipTimeValueCheck()) {\n-        Interval timeInterval =\n-            new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime), DateTimeZone.UTC);\n-        Preconditions.checkState(TimeUtils.isValidTimeInterval(timeInterval),\n-            \"Invalid segment start/end time: %s (in millis: %s/%s) for time column: %s, must be between: %s\",\n-            timeInterval, timeInterval.getStartMillis(), timeInterval.getEndMillis(), timeColumnName,\n-            TimeUtils.VALID_TIME_INTERVAL);\n-      }\n+        if (!config.isSkipTimeValueCheck()) {\n+          Interval timeInterval = new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime), DateTimeZone.UTC);\n+          Preconditions.checkState(TimeUtils.isValidTimeInterval(timeInterval),\n+              \"Invalid segment start/end time: %s (in millis: %s/%s) for time column: %s, must be between: %s\",\n+              timeInterval, timeInterval.getStartMillis(), timeInterval.getEndMillis(), timeColumnName, TimeUtils.VALID_TIME_INTERVAL);\n+        }\n \n-      properties.setProperty(SEGMENT_START_TIME, startTime);\n-      properties.setProperty(SEGMENT_END_TIME, endTime);\n-      properties.setProperty(TIME_UNIT, timeUnit);\n+        properties.setProperty(SEGMENT_START_TIME, startTime);\n+        properties.setProperty(SEGMENT_END_TIME, endTime);\n+        properties.setProperty(TIME_UNIT, timeUnit);\n+      }\n     }\n \n     for (Map.Entry<String, String> entry : config.getCustomProperties().entrySet()) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg2OTE2Nw==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r426869167", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  if (timeFormat.equals(TimeFormat.EPOCH)) {\n          \n          \n            \n                  if (timeFormat == TimeFormat.EPOCH) {", "author": "Jackie-Jiang", "createdAt": "2020-05-18T20:14:42Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/name/NormalizedDateSegmentNameGenerator.java", "diffHunk": "@@ -60,16 +61,16 @@ public NormalizedDateSegmentNameGenerator(String tableName, @Nullable String seg\n       }\n       _outputSDF.setTimeZone(TimeZone.getTimeZone(\"UTC\"));\n \n-      // Parse input time format: 'EPOCH' or 'SIMPLE_DATE_FORMAT:<pattern>'\n-      if (Preconditions.checkNotNull(timeFormat).equals(TimeFormat.EPOCH.toString())) {\n-        _inputTimeUnit = timeType;\n+      // Parse input time format: 'EPOCH' or 'SIMPLE_DATE_FORMAT' using pattern\n+      Preconditions.checkNotNull(dateTimeFormatSpec);\n+      TimeFormat timeFormat = dateTimeFormatSpec.getTimeFormat();\n+      if (timeFormat.equals(TimeFormat.EPOCH)) {", "originalCommit": "e0dacf8054a31507d54c5df91cd38b312c95a507", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "chunk": "diff --git a/pinot-core/src/main/java/org/apache/pinot/core/segment/name/NormalizedDateSegmentNameGenerator.java b/pinot-core/src/main/java/org/apache/pinot/core/segment/name/NormalizedDateSegmentNameGenerator.java\nindex 25f583195c..75b619df85 100644\n--- a/pinot-core/src/main/java/org/apache/pinot/core/segment/name/NormalizedDateSegmentNameGenerator.java\n+++ b/pinot-core/src/main/java/org/apache/pinot/core/segment/name/NormalizedDateSegmentNameGenerator.java\n\n@@ -64,7 +64,7 @@ public class NormalizedDateSegmentNameGenerator implements SegmentNameGenerator\n       // Parse input time format: 'EPOCH' or 'SIMPLE_DATE_FORMAT' using pattern\n       Preconditions.checkNotNull(dateTimeFormatSpec);\n       TimeFormat timeFormat = dateTimeFormatSpec.getTimeFormat();\n-      if (timeFormat.equals(TimeFormat.EPOCH)) {\n+      if (timeFormat == TimeFormat.EPOCH) {\n         _inputTimeUnit = dateTimeFormatSpec.getColumnUnit();\n         _inputSDF = null;\n       } else {\n"}}, {"oid": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "url": "https://github.com/apache/pinot/commit/237ca457acb543b3e2c2305c095eb3531bd1f52c", "message": "Set primary time column into segment.time.column.name segment metadata property", "committedDate": "2020-05-18T22:15:01Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQ3OTkxMg==", "url": "https://github.com/apache/pinot/pull/5399#discussion_r427479912", "bodyText": "mention in the comment that TimeFieldSpec is deprecated", "author": "mcvsubbu", "createdAt": "2020-05-19T17:35:58Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/V1Constants.java", "diffHunk": "@@ -51,6 +51,10 @@\n       public static final String TABLE_NAME = \"segment.table.name\";\n       public static final String DIMENSIONS = \"segment.dimension.column.names\";\n       public static final String METRICS = \"segment.metric.column.names\";\n+      /**\n+       * The primary time column for the table. This will match the timeColumnName defined in the tableConfig.\n+       * In the Pinot schema, this column can be defined as either a TimeFieldSpec or DateTimeFieldSpec", "originalCommit": "237ca457acb543b3e2c2305c095eb3531bd1f52c", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "8c90413d490baa6a4e84d526460f54e184ea97f0", "chunk": "diff --git a/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/V1Constants.java b/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/V1Constants.java\nindex 37db8d8580..3dc60aa6a7 100644\n--- a/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/V1Constants.java\n+++ b/pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/V1Constants.java\n\n@@ -51,10 +51,6 @@ public class V1Constants {\n       public static final String TABLE_NAME = \"segment.table.name\";\n       public static final String DIMENSIONS = \"segment.dimension.column.names\";\n       public static final String METRICS = \"segment.metric.column.names\";\n-      /**\n-       * The primary time column for the table. This will match the timeColumnName defined in the tableConfig.\n-       * In the Pinot schema, this column can be defined as either a TimeFieldSpec or DateTimeFieldSpec\n-       */\n       public static final String TIME_COLUMN_NAME = \"segment.time.column.name\";\n       public static final String TIME_UNIT = \"segment.time.unit\";\n       public static final String SEGMENT_START_TIME = \"segment.start.time\";\n"}}, {"oid": "8c90413d490baa6a4e84d526460f54e184ea97f0", "url": "https://github.com/apache/pinot/commit/8c90413d490baa6a4e84d526460f54e184ea97f0", "message": "DATE_TIME should work as the primary time column for Pinot tables", "committedDate": "2020-05-19T22:23:08Z", "type": "commit"}, {"oid": "d77442856b0bf81d43936f85402fe751206bb9fa", "url": "https://github.com/apache/pinot/commit/d77442856b0bf81d43936f85402fe751206bb9fa", "message": "Minor tweaks", "committedDate": "2020-05-19T22:23:08Z", "type": "commit"}, {"oid": "15048bca3521a58ba483a8c266c21684c570241a", "url": "https://github.com/apache/pinot/commit/15048bca3521a58ba483a8c266c21684c570241a", "message": "Fix NormalizedDateSegmentNameGenerator", "committedDate": "2020-05-19T22:23:08Z", "type": "commit"}, {"oid": "1a409ada137aaee00d7f63417a7d657657ea54f7", "url": "https://github.com/apache/pinot/commit/1a409ada137aaee00d7f63417a7d657657ea54f7", "message": "Change quickstart schemas", "committedDate": "2020-05-19T22:23:08Z", "type": "commit"}, {"oid": "68ff4c36a2fa450d00f143543b59bd391f38c443", "url": "https://github.com/apache/pinot/commit/68ff4c36a2fa450d00f143543b59bd391f38c443", "message": "Deprecated tags and reformatting", "committedDate": "2020-05-19T22:23:08Z", "type": "commit"}, {"oid": "b85078f69c81a5afef0d2d6591d3c5c1ae53c8ce", "url": "https://github.com/apache/pinot/commit/b85078f69c81a5afef0d2d6591d3c5c1ae53c8ce", "message": "Set primary time column into segment.time.column.name segment metadata property", "committedDate": "2020-05-19T22:23:08Z", "type": "commit"}, {"oid": "2726b6ae49d377e4e9e7114d74ca4f028e25dd6e", "url": "https://github.com/apache/pinot/commit/2726b6ae49d377e4e9e7114d74ca4f028e25dd6e", "message": "comment", "committedDate": "2020-05-19T22:23:08Z", "type": "commit"}, {"oid": "2726b6ae49d377e4e9e7114d74ca4f028e25dd6e", "url": "https://github.com/apache/pinot/commit/2726b6ae49d377e4e9e7114d74ca4f028e25dd6e", "message": "comment", "committedDate": "2020-05-19T22:23:08Z", "type": "forcePushed"}]}