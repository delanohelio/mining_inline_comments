{"pr_number": 6012, "pr_title": "Configurable segment generation job parallelism for Hadoop and Spark", "pr_createdAt": "2020-09-12T22:14:57Z", "pr_url": "https://github.com/apache/pinot/pull/6012", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5MzkwOQ==", "url": "https://github.com/apache/pinot/pull/6012#discussion_r488393909", "bodyText": "Should we use min of configured parallelism and the numDataFiles?", "author": "Jackie-Jiang", "createdAt": "2020-09-15T05:27:02Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-hadoop/src/main/java/org/apache/pinot/plugin/ingestion/batch/hadoop/HadoopSegmentGenerationJobRunner.java", "diffHunk": "@@ -230,7 +230,10 @@ public void run()\n       if (hadoopTokenFileLocation != null) {\n         jobConf.set(\"mapreduce.job.credentials.binary\", hadoopTokenFileLocation);\n       }\n-      jobConf.setInt(JobContext.NUM_MAPS, numDataFiles);\n+\n+      int jobParallelism =\n+          (_spec.getSegmentCreationJobParallelism() > 0) ? _spec.getSegmentCreationJobParallelism() : numDataFiles;", "originalCommit": "6e2cf599bb8623acef91836979a6cef4ef68bc02", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODQzMjA1MA==", "url": "https://github.com/apache/pinot/pull/6012#discussion_r488432050", "bodyText": "You are right :)", "author": "xiangfu0", "createdAt": "2020-09-15T07:01:43Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5MzkwOQ=="}], "type": "inlineReview", "revised_code": {"commit": "35b7ebc43c816c3cc7439880083e10832c6224e6", "chunk": "diff --git a/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-hadoop/src/main/java/org/apache/pinot/plugin/ingestion/batch/hadoop/HadoopSegmentGenerationJobRunner.java b/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-hadoop/src/main/java/org/apache/pinot/plugin/ingestion/batch/hadoop/HadoopSegmentGenerationJobRunner.java\nindex 5272d8fb95..59beadc3d8 100644\n--- a/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-hadoop/src/main/java/org/apache/pinot/plugin/ingestion/batch/hadoop/HadoopSegmentGenerationJobRunner.java\n+++ b/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-hadoop/src/main/java/org/apache/pinot/plugin/ingestion/batch/hadoop/HadoopSegmentGenerationJobRunner.java\n\n@@ -230,9 +230,10 @@ public class HadoopSegmentGenerationJobRunner extends Configured implements Inge\n       if (hadoopTokenFileLocation != null) {\n         jobConf.set(\"mapreduce.job.credentials.binary\", hadoopTokenFileLocation);\n       }\n-\n-      int jobParallelism =\n-          (_spec.getSegmentCreationJobParallelism() > 0) ? _spec.getSegmentCreationJobParallelism() : numDataFiles;\n+      int jobParallelism = _spec.getSegmentCreationJobParallelism();\n+      if (jobParallelism <= 0 || jobParallelism > numDataFiles) {\n+        jobParallelism = numDataFiles;\n+      }\n       jobConf.setInt(JobContext.NUM_MAPS, jobParallelism);\n \n       // Pinot plugins are necessary to launch Pinot ingestion job from every mapper.\n"}}, {"oid": "35b7ebc43c816c3cc7439880083e10832c6224e6", "url": "https://github.com/apache/pinot/commit/35b7ebc43c816c3cc7439880083e10832c6224e6", "message": "Adding field 'segmentCreationJobParallelism' to allow users to set segment generation job parallelism. Default to the number of input files.", "committedDate": "2020-09-15T07:09:19Z", "type": "commit"}, {"oid": "35b7ebc43c816c3cc7439880083e10832c6224e6", "url": "https://github.com/apache/pinot/commit/35b7ebc43c816c3cc7439880083e10832c6224e6", "message": "Adding field 'segmentCreationJobParallelism' to allow users to set segment generation job parallelism. Default to the number of input files.", "committedDate": "2020-09-15T07:09:19Z", "type": "forcePushed"}]}