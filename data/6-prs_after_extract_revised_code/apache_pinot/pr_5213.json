{"pr_number": 5213, "pr_title": "Support order-by on BYTES column", "pr_createdAt": "2020-04-06T23:53:34Z", "pr_url": "https://github.com/apache/pinot/pull/5213", "timeline": [{"oid": "b5e867ae36ae02c211c83cde8693db81ad264396", "url": "https://github.com/apache/pinot/commit/b5e867ae36ae02c211c83cde8693db81ad264396", "message": "Support order-by on BYTES column\n\nIn order to support order-by on BYTES column everywhere, inside the system we should always use ByteArray (comparable) to store the BYTES value.\nCurrently BYTES value are stored as byte[], ByteArray or String in different places, which is very confusing and could cause casting errors.\n\nChanges:\n- For DisctinctCount, fix the casting issue when ordering on BYTES column\n- For selection order-by, order BYTES column using ByteArray instead of String for performance improvement\n- Inside Record, always store BYTES as ByteArray for clarity and also performance improvement (avoid expensive deepEquals and deepHashCode)\n- On broker side, store BYTES column using ByteArray instead of String for performance improvement\n- On broker side, support type compatible merges for all selection queries\n\nNo format change on the query results.\nTODO: We are still returning String for BYTES column when preserving the type. Consider changing it to byte[].", "committedDate": "2020-04-08T01:46:38Z", "type": "commit"}, {"oid": "b5e867ae36ae02c211c83cde8693db81ad264396", "url": "https://github.com/apache/pinot/commit/b5e867ae36ae02c211c83cde8693db81ad264396", "message": "Support order-by on BYTES column\n\nIn order to support order-by on BYTES column everywhere, inside the system we should always use ByteArray (comparable) to store the BYTES value.\nCurrently BYTES value are stored as byte[], ByteArray or String in different places, which is very confusing and could cause casting errors.\n\nChanges:\n- For DisctinctCount, fix the casting issue when ordering on BYTES column\n- For selection order-by, order BYTES column using ByteArray instead of String for performance improvement\n- Inside Record, always store BYTES as ByteArray for clarity and also performance improvement (avoid expensive deepEquals and deepHashCode)\n- On broker side, store BYTES column using ByteArray instead of String for performance improvement\n- On broker side, support type compatible merges for all selection queries\n\nNo format change on the query results.\nTODO: We are still returning String for BYTES column when preserving the type. Consider changing it to byte[].", "committedDate": "2020-04-08T01:46:38Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIyMjAxNg==", "url": "https://github.com/apache/pinot/pull/5213#discussion_r405222016", "bodyText": "this is needed for intermediate aggregated object like HLL?", "author": "snleee", "createdAt": "2020-04-08T02:26:16Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "diffHunk": "@@ -332,11 +330,14 @@ private IndexedTable getIndexedTable(DataSchema dataSchema, Collection<DataTable\n             function = dataTable::getString;\n             break;\n           case BYTES:\n-            // FIXME: support BYTES in DataTable instead of converting to string\n-            function = (row, col) -> BytesUtils.toByteArray(dataTable.getString(row, col));\n+            function = dataTable::getBytes;\n             break;\n-          default:\n+          case OBJECT:", "originalCommit": "b5e867ae36ae02c211c83cde8693db81ad264396", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIzOTMzMg==", "url": "https://github.com/apache/pinot/pull/5213#discussion_r405239332", "bodyText": "Yes", "author": "Jackie-Jiang", "createdAt": "2020-04-08T03:36:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIyMjAxNg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIyNDA1OQ==", "url": "https://github.com/apache/pinot/pull/5213#discussion_r405224059", "bodyText": "From IntermediateResultsBlock class, you kind of directly casted types to an object instead of casting to Number.  Can we use the same approach here?", "author": "snleee", "createdAt": "2020-04-08T02:34:25Z", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/selection/SelectionOperatorUtils.java", "diffHunk": "@@ -481,55 +510,81 @@ public static ResultTable renderResultTableWithoutOrdering(List<Serializable[]>\n   }\n \n   /**\n-   * Extract columns from the row based on the given column indices.\n-   * <p>The extracted row is used to build the {@link SelectionResults}.\n-   *\n-   * @param row selection row to be extracted.\n-   * @param columnIndices column indices.\n-   * @return selection row.\n+   * Converts a value into the given data type. (Broker side)\n+   * <p>Actual value type can be different with data type passed in, but they must be type compatible.\n    */\n-  public static Serializable[] extractColumns(Serializable[] row, int[] columnIndices,\n-      @Nullable DataSchema.ColumnDataType[] columnDataTypes) {\n-    int numColumns = columnIndices.length;\n-    Serializable[] extractedRow = new Serializable[numColumns];\n-    if (columnDataTypes == null) {\n-      for (int i = 0; i < numColumns; i++) {\n-        extractedRow[i] = row[columnIndices[i]];\n-      }\n-    } else {\n-      for (int i = 0; i < numColumns; i++) {\n-        extractedRow[i] = getFormattedValue(row[columnIndices[i]], columnDataTypes[i]);\n-      }\n-    }\n-    return extractedRow;\n-  }\n+  public static Serializable convertValueToType(Object value, DataSchema.ColumnDataType dataType) {\n+    switch (dataType) {\n+      // Single-value column\n+      case INT:\n+        return ((Number) value).intValue();", "originalCommit": "b5e867ae36ae02c211c83cde8693db81ad264396", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIzOTkxMg==", "url": "https://github.com/apache/pinot/pull/5213#discussion_r405239912", "bodyText": "We are trying to handle compatible types here (commented on line 514). This is required for cases where different segments have different schema (same column name, but different data types).\nThe long term solution should be let the query engine use the table schema instead of the schema inside each segments.", "author": "Jackie-Jiang", "createdAt": "2020-04-08T03:38:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTIyNDA1OQ=="}], "type": "inlineReview", "revised_code": null}]}