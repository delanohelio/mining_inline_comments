{"pr_number": 5542, "pr_title": "Changed the stream and metadata interface", "pr_createdAt": "2020-06-11T19:09:52Z", "pr_url": "https://github.com/apache/pinot/pull/5542", "timeline": [{"oid": "200bb75c3c862c4d106ca11697b2e01cab3fdb26", "url": "https://github.com/apache/pinot/commit/200bb75c3c862c4d106ca11697b2e01cab3fdb26", "message": "Changed the stream and metadata interface\n\nChanged the interface exposed by streams to return StreamPartitionMsgOffset\ninstead of long.\n\nAlso changed the LLCRealtimeSegmentZKMetadat class to return String instead\nof long offsets, since it is stored as a String anyway. Luckily zk metadata does\nnot generate java objects from json automatically (instead, parses the\nfields one by one via custom code).\n\nThe segment endOffset can now be null in LLCRealtimeSegmentZKMetadata. For\nbackward compatibility, we store Long.toSring(Long.MAX_VALUE) in zookeeper\nso that readers of the metadata do not get NPE if they are still running old\nversion. We will remove this workaround after we release 0.5.0\n\nThe segment completion protocol for realtime LLC segment completion will\ncontinue to use both 'offset' and 'streamPartitionOffset' elements for\none more release, and will move to use the latter completely in 0.6.0\n\nInterfaces PartitionLevelConsumer and StreamMetadataProvider (marked STABLE)\nare now deprecating the calls that use long offsets. Instead, new calls have\nbeen added that use StreamPartitionMsgOffset. Kafka Plugins have been updated\nto use the new calls, but the old methods are preserved to make sure that any\nother Kafka implementations have time to move over. These calls will be removed\nin 0.6.0\n\nThe metric to show the highest offset consumed has disappeared.\n\nTesting done:\nManually verified that LLCRealtimeClusterIntegrationTest completes segments correctly with\nold server and new controller as well as with new server and old controller, using\ncommand line starter for controller and server to start a component at a specific\nrevision after 0.4.0 release.\n\nThis PR concludes the work for this Issue\n\nIssue #5359", "committedDate": "2020-06-11T19:06:46Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2MjI5Mg==", "url": "https://github.com/apache/pinot/pull/5542#discussion_r439062292", "bodyText": "We can drop Msg, StreamPartitionOffset", "author": "kishoreg", "createdAt": "2020-06-11T20:47:37Z", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManager.java", "diffHunk": "@@ -893,20 +891,19 @@ IdealState ensureAllPartitionsConsuming(TableConfig tableConfig, PartitionLevelS\n \n             // Create a new segment to re-consume from the previous start offset\n             LLCSegmentName newLLCSegmentName = getNextLLCSegmentName(latestLLCSegmentName, currentTimeMs);\n-            long startOffset = latestSegmentZKMetadata.getStartOffset();\n+            StreamPartitionMsgOffset startOffset = offsetFactory.create(latestSegmentZKMetadata.getStartOffset());", "originalCommit": "200bb75c3c862c4d106ca11697b2e01cab3fdb26", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2OTE3MA==", "url": "https://github.com/apache/pinot/pull/5542#discussion_r439069170", "bodyText": "A bit late for this (you had your chance in PR#5360 :), it is already in the segment completion protocol, and also in config. I can probably change the class name without damaging compat (I think). I would let this be.", "author": "mcvsubbu", "createdAt": "2020-06-11T21:02:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2MjI5Mg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2MjQwNQ==", "url": "https://github.com/apache/pinot/pull/5542#discussion_r439062405", "bodyText": "LongOffset", "author": "kishoreg", "createdAt": "2020-06-11T20:47:50Z", "path": "pinot-controller/src/test/java/org/apache/pinot/controller/helix/core/realtime/PinotLLCRealtimeSegmentManagerTest.java", "diffHunk": "@@ -77,7 +79,7 @@\n \n   private static final long RANDOM_SEED = System.currentTimeMillis();\n   private static final Random RANDOM = new Random(RANDOM_SEED);\n-  static final long PARTITION_OFFSET = RANDOM.nextInt(Integer.MAX_VALUE);\n+  static final LongMsgOffset PARTITION_OFFSET = new LongMsgOffset(RANDOM.nextInt(Integer.MAX_VALUE));", "originalCommit": "200bb75c3c862c4d106ca11697b2e01cab3fdb26", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2ODQxOA==", "url": "https://github.com/apache/pinot/pull/5542#discussion_r439068418", "bodyText": "I think I can change this without affecting compat", "author": "mcvsubbu", "createdAt": "2020-06-11T21:00:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2MjQwNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA4ODYxNw==", "url": "https://github.com/apache/pinot/pull/5542#discussion_r439088617", "bodyText": "Discussed offline, we will leave it as is", "author": "mcvsubbu", "createdAt": "2020-06-11T21:48:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2MjQwNQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTA2MzY3Mg==", "url": "https://github.com/apache/pinot/pull/5542#discussion_r439063672", "bodyText": "Nicely done!", "author": "kishoreg", "createdAt": "2020-06-11T20:50:44Z", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/stream/PartitionLevelConsumer.java", "diffHunk": "@@ -31,19 +31,35 @@\n public interface PartitionLevelConsumer extends Closeable {\n \n   /**\n+   * Is here for backward compatibility for a short time.\n+   * TODO Issue 5359 remove this API once external kafka consumers implements return of StreamPartitionMsgOffset\n    * Fetch messages from the stream between the specified offsets\n    * @param startOffset\n    * @param endOffset\n    * @param timeoutMillis\n    * @return\n    * @throws java.util.concurrent.TimeoutException\n    */\n+  @Deprecated\n   MessageBatch fetchMessages(long startOffset, long endOffset, int timeoutMillis)\n       throws java.util.concurrent.TimeoutException;\n \n+  /**\n+   * Fetch messages and the per-partition high watermark from Kafka between the specified offsets.\n+   *\n+   * @param startOffset The offset of the first message desired, inclusive\n+   * @param endOffset The offset of the last message desired, exclusive, or null\n+   * @param timeoutMillis Timeout in milliseconds\n+   * @throws java.util.concurrent.TimeoutException If the operation could not be completed within {@code timeoutMillis}\n+   * milliseconds\n+   * @return An iterable containing messages fetched from the stream partition and their offsets, as well as the\n+   * high watermark for this partition.\n+   */\n   default MessageBatch fetchMessages(StreamPartitionMsgOffset startOffset, StreamPartitionMsgOffset endOffset, int timeoutMillis)", "originalCommit": "200bb75c3c862c4d106ca11697b2e01cab3fdb26", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}