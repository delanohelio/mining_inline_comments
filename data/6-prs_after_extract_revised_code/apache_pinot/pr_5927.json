{"pr_number": 5927, "pr_title": "support for local.directory.sequence.id", "pr_createdAt": "2020-08-26T12:48:55Z", "pr_url": "https://github.com/apache/pinot/pull/5927", "timeline": [{"oid": "1e927270a48458ab450faebb4b114f9414958256", "url": "https://github.com/apache/pinot/commit/1e927270a48458ab450faebb4b114f9414958256", "message": "support for local.directory.sequence.id", "committedDate": "2020-08-26T12:46:59Z", "type": "commit"}, {"oid": "64c2336df41a9d327d4641d0d61b512d24ac991a", "url": "https://github.com/apache/pinot/commit/64c2336df41a9d327d4641d0d61b512d24ac991a", "message": "add null check", "committedDate": "2020-08-26T12:51:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzU2NDExNw==", "url": "https://github.com/apache/pinot/pull/5927#discussion_r477564117", "bodyText": "expend the .*", "author": "xiangfu0", "createdAt": "2020-08-26T20:17:44Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java", "diffHunk": "@@ -29,12 +30,10 @@\n import java.io.Serializable;\n import java.net.URI;\n import java.nio.file.FileSystems;\n+import java.nio.file.Path;\n import java.nio.file.PathMatcher;\n import java.nio.file.Paths;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.UUID;\n+import java.util.*;", "originalCommit": "64c2336df41a9d327d4641d0d61b512d24ac991a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "32bcd8279b5d5debb8fdde8e00cba811f8c8623f", "chunk": "diff --git a/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java b/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java\nindex 6d53ad733e..ad96e5de22 100644\n--- a/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java\n+++ b/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java\n\n@@ -33,7 +33,12 @@ import java.nio.file.FileSystems;\n import java.nio.file.Path;\n import java.nio.file.PathMatcher;\n import java.nio.file.Paths;\n-import java.util.*;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n \n import org.apache.commons.io.FileUtils;\n import org.apache.pinot.common.utils.TarGzCompressionUtils;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzU2NjczMA==", "url": "https://github.com/apache/pinot/pull/5927#discussion_r477566730", "bodyText": "suggest to sort siblingFiles list, so rerun segment creation job will give same segments list", "author": "xiangfu0", "createdAt": "2020-08-26T20:22:52Z", "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java", "diffHunk": "@@ -200,8 +199,30 @@ public void run()\n       }\n \n       List<String> pathAndIdxList = new ArrayList<>();\n-      for (int i = 0; i < filteredFiles.size(); i++) {\n-        pathAndIdxList.add(String.format(\"%s %d\", filteredFiles.get(i), i));\n+      String localDirectorySequenceIdString = _spec.getSegmentNameGeneratorSpec().getConfigs().get(LOCAL_DIRECTORY_SEQUENCE_ID);\n+      boolean localDirectorySequenceId = false;\n+      if (localDirectorySequenceIdString != null) {\n+        localDirectorySequenceId = Boolean.parseBoolean(localDirectorySequenceIdString);\n+      }\n+      if (localDirectorySequenceId) {\n+        Map<String, List<String>> localDirIndex = new HashMap<>();\n+        for (String filteredFile : filteredFiles) {\n+          Path filteredParentPath = Paths.get(filteredFile).getParent();\n+          if (!localDirIndex.containsKey(filteredParentPath.toString())) {\n+            localDirIndex.put(filteredParentPath.toString(), new ArrayList<>());\n+          }\n+          localDirIndex.get(filteredParentPath.toString()).add(filteredFile);\n+        }\n+        for (String parentPath: localDirIndex.keySet()){\n+          List<String> siblingFiles = localDirIndex.get(parentPath);", "originalCommit": "64c2336df41a9d327d4641d0d61b512d24ac991a", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "32bcd8279b5d5debb8fdde8e00cba811f8c8623f", "chunk": "diff --git a/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java b/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java\nindex 6d53ad733e..ad96e5de22 100644\n--- a/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java\n+++ b/pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java\n\n@@ -215,6 +220,7 @@ public class SparkSegmentGenerationJobRunner implements IngestionJobRunner, Seri\n         }\n         for (String parentPath: localDirIndex.keySet()){\n           List<String> siblingFiles = localDirIndex.get(parentPath);\n+          Collections.sort(siblingFiles);\n           for (int i = 0; i < siblingFiles.size(); i++) {\n             pathAndIdxList.add(String.format(\"%s %d\", siblingFiles.get(i), i));\n           }\n"}}, {"oid": "32bcd8279b5d5debb8fdde8e00cba811f8c8623f", "url": "https://github.com/apache/pinot/commit/32bcd8279b5d5debb8fdde8e00cba811f8c8623f", "message": "Fix based on review comments", "committedDate": "2020-08-27T14:09:05Z", "type": "commit"}]}