{"pr_number": 8894, "pr_title": "KAFKA-9509: Increase timeout when consuming records to fix flaky test in MM2", "pr_createdAt": "2020-06-18T08:54:51Z", "pr_url": "https://github.com/apache/kafka/pull/8894", "timeline": [{"oid": "8a14b989dd32a9602e0b6703e348f9c413fb0b67", "url": "https://github.com/apache/kafka/commit/8a14b989dd32a9602e0b6703e348f9c413fb0b67", "message": "KAFKA-9509: add retries for mirrorClient consume records to fix flaky test", "committedDate": "2020-06-18T09:02:01Z", "type": "commit"}, {"oid": "8a14b989dd32a9602e0b6703e348f9c413fb0b67", "url": "https://github.com/apache/kafka/commit/8a14b989dd32a9602e0b6703e348f9c413fb0b67", "message": "KAFKA-9509: add retries for mirrorClient consume records to fix flaky test", "committedDate": "2020-06-18T09:02:01Z", "type": "forcePushed"}, {"oid": "1559549e83adae1c4f1f5d362b0c176a694fea4b", "url": "https://github.com/apache/kafka/commit/1559549e83adae1c4f1f5d362b0c176a694fea4b", "message": "KAFKA-9509: refactor", "committedDate": "2020-06-18T09:36:04Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjMxMzYxNA==", "url": "https://github.com/apache/kafka/pull/8894#discussion_r442313614", "bodyText": "fwiw this doesn't adhere to kafka style guide (looks like Kafka Streams to me)", "author": "ryannedolan", "createdAt": "2020-06-18T15:28:53Z", "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -207,23 +212,45 @@ public void close() {\n         backup.stop();\n     }\n \n+    // throw exception after 3 retries, and print expected error messages\n+    private void assertEqualsWithConsumeRetries(final String errorMsg,", "originalCommit": "1559549e83adae1c4f1f5d362b0c176a694fea4b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "56a2fefb59b14b2aa4cbd90ff10473fc09a3bf09", "chunk": "diff --git a/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java b/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\nindex d6a8c4cbf6..169968c320 100644\n--- a/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\n+++ b/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\n\n@@ -212,45 +207,23 @@ public class MirrorConnectorsIntegrationTest {\n         backup.stop();\n     }\n \n-    // throw exception after 3 retries, and print expected error messages\n-    private void assertEqualsWithConsumeRetries(final String errorMsg,\n-                                                final int numRecordsProduces,\n-                                                final int timeout,\n-                                                final ClusterType clusterType,\n-                                                final String... topics) throws InterruptedException {\n-        int retries = 3;\n-        while (retries-- > 0) {\n-            try {\n-                int actualNum = clusterType == ClusterType.PRIMARY ?\n-                        primary.kafka().consume(numRecordsProduces, timeout, topics).count() :\n-                        backup.kafka().consume(numRecordsProduces, timeout, topics).count();\n-                if (numRecordsProduces == actualNum)\n-                    return;\n-            } catch (Throwable e) {\n-                log.error(\"Could not find enough records with {} retries left\", retries, e);\n-            }\n-        }\n-        throw new InterruptedException(errorMsg);\n-    }\n-\n     @Test\n     public void testReplication() throws InterruptedException {\n         MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n         MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n \n-        assertEqualsWithConsumeRetries(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"primary.test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"backup.test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"backup.test-topic-1\", \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"primary.test-topic-1\", \"test-topic-1\");\n-\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n         assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n             RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n         assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjMxNDY5MQ==", "url": "https://github.com/apache/kafka/pull/8894#discussion_r442314691", "bodyText": "these are really strange side-effects to have in an assert statement. I see what you are trying to do, but this is probably not the way to do it.", "author": "ryannedolan", "createdAt": "2020-06-18T15:30:30Z", "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -207,23 +212,45 @@ public void close() {\n         backup.stop();\n     }\n \n+    // throw exception after 3 retries, and print expected error messages\n+    private void assertEqualsWithConsumeRetries(final String errorMsg,\n+                                                final int numRecordsProduces,\n+                                                final int timeout,\n+                                                final ClusterType clusterType,\n+                                                final String... topics) throws InterruptedException {\n+        int retries = 3;\n+        while (retries-- > 0) {\n+            try {\n+                int actualNum = clusterType == ClusterType.PRIMARY ?\n+                        primary.kafka().consume(numRecordsProduces, timeout, topics).count() :", "originalCommit": "1559549e83adae1c4f1f5d362b0c176a694fea4b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "56a2fefb59b14b2aa4cbd90ff10473fc09a3bf09", "chunk": "diff --git a/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java b/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\nindex d6a8c4cbf6..169968c320 100644\n--- a/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\n+++ b/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\n\n@@ -212,45 +207,23 @@ public class MirrorConnectorsIntegrationTest {\n         backup.stop();\n     }\n \n-    // throw exception after 3 retries, and print expected error messages\n-    private void assertEqualsWithConsumeRetries(final String errorMsg,\n-                                                final int numRecordsProduces,\n-                                                final int timeout,\n-                                                final ClusterType clusterType,\n-                                                final String... topics) throws InterruptedException {\n-        int retries = 3;\n-        while (retries-- > 0) {\n-            try {\n-                int actualNum = clusterType == ClusterType.PRIMARY ?\n-                        primary.kafka().consume(numRecordsProduces, timeout, topics).count() :\n-                        backup.kafka().consume(numRecordsProduces, timeout, topics).count();\n-                if (numRecordsProduces == actualNum)\n-                    return;\n-            } catch (Throwable e) {\n-                log.error(\"Could not find enough records with {} retries left\", retries, e);\n-            }\n-        }\n-        throw new InterruptedException(errorMsg);\n-    }\n-\n     @Test\n     public void testReplication() throws InterruptedException {\n         MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n         MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n \n-        assertEqualsWithConsumeRetries(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"primary.test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"backup.test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"backup.test-topic-1\", \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"primary.test-topic-1\", \"test-topic-1\");\n-\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n         assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n             RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n         assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ0NTcyOA==", "url": "https://github.com/apache/kafka/pull/8894#discussion_r442445728", "bodyText": "I'd agree with @ryannedolan here. We could use the waitForCondition in TestUtils.java instead to wait for the condition necessary instead. More details on that is here: \n  \n    \n      kafka/clients/src/test/java/org/apache/kafka/test/TestUtils.java\n    \n    \n        Lines 370 to 371\n      in\n      d8cc6fe\n    \n    \n    \n    \n\n        \n          \n           public static void waitForCondition(final TestCondition testCondition, final String conditionDetails) throws InterruptedException { \n        \n\n        \n          \n               waitForCondition(testCondition, DEFAULT_MAX_WAIT_MS, () -> conditionDetails);", "author": "skaundinya15", "createdAt": "2020-06-18T19:14:00Z", "path": "connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java", "diffHunk": "@@ -207,23 +212,45 @@ public void close() {\n         backup.stop();\n     }\n \n+    // throw exception after 3 retries, and print expected error messages\n+    private void assertEqualsWithConsumeRetries(final String errorMsg,\n+                                                final int numRecordsProduces,\n+                                                final int timeout,\n+                                                final ClusterType clusterType,\n+                                                final String... topics) throws InterruptedException {\n+        int retries = 3;\n+        while (retries-- > 0) {\n+            try {\n+                int actualNum = clusterType == ClusterType.PRIMARY ?\n+                        primary.kafka().consume(numRecordsProduces, timeout, topics).count() :\n+                        backup.kafka().consume(numRecordsProduces, timeout, topics).count();\n+                if (numRecordsProduces == actualNum)\n+                    return;\n+            } catch (Throwable e) {\n+                log.error(\"Could not find enough records with {} retries left\", retries, e);\n+            }\n+        }\n+        throw new InterruptedException(errorMsg);\n+    }\n+\n     @Test\n     public void testReplication() throws InterruptedException {\n         MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n         MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n \n-        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,", "originalCommit": "1559549e83adae1c4f1f5d362b0c176a694fea4b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "56a2fefb59b14b2aa4cbd90ff10473fc09a3bf09", "chunk": "diff --git a/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java b/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\nindex d6a8c4cbf6..169968c320 100644\n--- a/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\n+++ b/connect/mirror/src/test/java/org/apache/kafka/connect/mirror/MirrorConnectorsIntegrationTest.java\n\n@@ -212,45 +207,23 @@ public class MirrorConnectorsIntegrationTest {\n         backup.stop();\n     }\n \n-    // throw exception after 3 retries, and print expected error messages\n-    private void assertEqualsWithConsumeRetries(final String errorMsg,\n-                                                final int numRecordsProduces,\n-                                                final int timeout,\n-                                                final ClusterType clusterType,\n-                                                final String... topics) throws InterruptedException {\n-        int retries = 3;\n-        while (retries-- > 0) {\n-            try {\n-                int actualNum = clusterType == ClusterType.PRIMARY ?\n-                        primary.kafka().consume(numRecordsProduces, timeout, topics).count() :\n-                        backup.kafka().consume(numRecordsProduces, timeout, topics).count();\n-                if (numRecordsProduces == actualNum)\n-                    return;\n-            } catch (Throwable e) {\n-                log.error(\"Could not find enough records with {} retries left\", retries, e);\n-            }\n-        }\n-        throw new InterruptedException(errorMsg);\n-    }\n-\n     @Test\n     public void testReplication() throws InterruptedException {\n         MirrorClient primaryClient = new MirrorClient(mm2Config.clientConfig(\"primary\"));\n         MirrorClient backupClient = new MirrorClient(mm2Config.clientConfig(\"backup\"));\n \n-        assertEqualsWithConsumeRetries(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"primary.test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"backup.test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.PRIMARY, \"backup.test-topic-1\", \"test-topic-1\");\n-        assertEqualsWithConsumeRetries(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n-                RECORD_TRANSFER_DURATION_MS, ClusterType.BACKUP, \"primary.test-topic-1\", \"test-topic-1\");\n-\n+        assertEquals(\"Records were not produced to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\").count());\n+        assertEquals(\"Records were not produced to backup cluster.\", NUM_RECORDS_PRODUCED,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"test-topic-1\").count());\n+        assertEquals(\"Records were not replicated to primary cluster.\", NUM_RECORDS_PRODUCED,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\").count());\n+        assertEquals(\"Primary cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            primary.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"backup.test-topic-1\", \"test-topic-1\").count());\n+        assertEquals(\"Backup cluster doesn't have all records from both clusters.\", NUM_RECORDS_PRODUCED * 2,\n+            backup.kafka().consume(NUM_RECORDS_PRODUCED * 2, RECORD_TRANSFER_DURATION_MS, \"primary.test-topic-1\", \"test-topic-1\").count());\n         assertTrue(\"Heartbeats were not emitted to primary cluster.\", primary.kafka().consume(1,\n             RECORD_TRANSFER_DURATION_MS, \"heartbeats\").count() > 0);\n         assertTrue(\"Heartbeats were not emitted to backup cluster.\", backup.kafka().consume(1,\n"}}, {"oid": "56a2fefb59b14b2aa4cbd90ff10473fc09a3bf09", "url": "https://github.com/apache/kafka/commit/56a2fefb59b14b2aa4cbd90ff10473fc09a3bf09", "message": "KAFKA-9509: address reviewer's comments to increase the timeout value directly", "committedDate": "2020-06-19T02:27:46Z", "type": "commit"}, {"oid": "56a2fefb59b14b2aa4cbd90ff10473fc09a3bf09", "url": "https://github.com/apache/kafka/commit/56a2fefb59b14b2aa4cbd90ff10473fc09a3bf09", "message": "KAFKA-9509: address reviewer's comments to increase the timeout value directly", "committedDate": "2020-06-19T02:27:46Z", "type": "forcePushed"}]}