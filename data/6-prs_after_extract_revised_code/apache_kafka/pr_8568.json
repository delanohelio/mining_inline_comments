{"pr_number": 8568, "pr_title": "KAFKA-9176: Retry on getting local stores from KafkaStreams", "pr_createdAt": "2020-04-28T04:58:55Z", "pr_url": "https://github.com/apache/kafka/pull/8568", "timeline": [{"oid": "f936848a86992d779fa37703c4a4a7b83fc30727", "url": "https://github.com/apache/kafka/commit/f936848a86992d779fa37703c4a4a7b83fc30727", "message": "wrap around getting stores", "committedDate": "2020-04-28T04:49:05Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzMzNQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327335", "bodyText": "This is fix 2).", "author": "guozhangwang", "createdAt": "2020-04-28T04:59:22Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -210,16 +210,21 @@ public static void cleanStateAfterTest(final EmbeddedKafkaCluster cluster, final\n                                                             final Properties producerConfig,\n                                                             final Headers headers,\n                                                             final Time time,\n-                                                            final boolean enableTransactions)\n-        throws ExecutionException, InterruptedException {\n-        for (final KeyValue<K, V> record : records) {\n-            produceKeyValuesSynchronouslyWithTimestamp(topic,\n-                Collections.singleton(record),\n-                producerConfig,\n-                headers,\n-                time.milliseconds(),\n-                enableTransactions);\n-            time.sleep(1L);\n+                                                            final boolean enableTransactions) {\n+\n+        try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzM4Ng==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327386", "bodyText": "Those functions are not used anywhere, ditto below.", "author": "guozhangwang", "createdAt": "2020-04-28T04:59:36Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -599,13 +595,6 @@ public static void waitForCompletion(final KafkaStreams streams,\n         return waitUntilFinalKeyValueRecordsReceived(consumerConfig, topic, expectedRecords, waitTime, false);\n     }\n \n-    public static <K, V> List<KeyValueTimestamp<K, V>> waitUntilFinalKeyValueTimestampRecordsReceived(final Properties consumerConfig,", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNzEyNg==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416927126", "bodyText": "thanks for the cleanup", "author": "vvcephei", "createdAt": "2020-04-28T21:14:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzM4Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzY3MQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327671", "bodyText": "This is a minor fix, that we should retry this condition.", "author": "guozhangwang", "createdAt": "2020-04-28T05:00:29Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/OptimizedKTableIntegrationTest.java", "diffHunk": "@@ -163,8 +159,10 @@ public void shouldApplyUpdatesToStandbyStore() throws Exception {\n         // Assert that all messages in the second batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch2NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));\n \n-        // Assert that the current value in store reflects all messages being processed\n-        assertThat(newActiveStore.get(key), is(equalTo(totalNumMessages - 1)));\n+        TestUtils.retryOnExceptionWithTimeout(100, 60 * 1000, () -> {", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjMyNzg4MQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416327881", "bodyText": "This is a fix to the test itself: with caching the records are delayed sending to the sink topics.", "author": "guozhangwang", "createdAt": "2020-04-28T05:01:04Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/OptimizedKTableIntegrationTest.java", "diffHunk": "@@ -227,10 +225,11 @@ private Properties streamsConfiguration() {\n         config.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         config.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.Integer().getClass());\n         config.put(StreamsConfig.NUM_STANDBY_REPLICAS_CONFIG, 1);\n+        config.put(StreamsConfig.COMMIT_INTERVAL_MS_CONFIG, 100);\n+        config.put(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, 0);", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgwOTQ2OQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416809469", "bodyText": "OptimizedKTableIntegrationTest.shouldApplyUpdatesToStandbyStore still failed on one of the builds at this line :/\nBut, at least we got farther into the test before it failed so I'd say this is still an improvement \ud83d\ude04", "author": "ableegoldman", "createdAt": "2020-04-28T17:52:25Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/OptimizedKTableIntegrationTest.java", "diffHunk": "@@ -163,8 +159,10 @@ public void shouldApplyUpdatesToStandbyStore() throws Exception {\n         // Assert that all messages in the second batch were processed in a timely manner\n         assertThat(semaphore.tryAcquire(batch2NumMessages, 60, TimeUnit.SECONDS), is(equalTo(true)));", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgxNDE2Mw==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416814163", "bodyText": "Why do we have to check for null now?", "author": "ableegoldman", "createdAt": "2020-04-28T17:59:41Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java", "diffHunk": "@@ -158,8 +158,9 @@ public void shouldKStreamGlobalKTableLeftJoin() throws Exception {\n \n         produceGlobalTableValues();\n \n-        final ReadOnlyKeyValueStore<Long, String> replicatedStore =\n-            kafkaStreams.store(StoreQueryParameters.fromNameAndType(globalStore, QueryableStoreTypes.keyValueStore()));\n+        final ReadOnlyKeyValueStore<Long, String> replicatedStore = IntegrationTestUtils\n+            .getStore(globalStore, kafkaStreams, QueryableStoreTypes.keyValueStore());\n+        assertNotNull(replicatedStore);", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkxMDcyNQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416910725", "bodyText": "Since previously we would just throw the exception with the un-wrapped call, here asserting it is not null is equal to make sure that the store is indeed returned.", "author": "guozhangwang", "createdAt": "2020-04-28T20:45:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjgxNDE2Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyMTk3MQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416921971", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        .getStore(300000L, storeName, streams, QueryableStoreTypes.keyValueStore());\n          \n          \n            \n                        .getStore(300_000L, storeName, streams, QueryableStoreTypes.keyValueStore());", "author": "vvcephei", "createdAt": "2020-04-28T21:05:30Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java", "diffHunk": "@@ -810,21 +808,9 @@ private void writeInputData(final List<KeyValue<Long, Long>> records) throws Exc\n     }\n \n     private void verifyStateStore(final KafkaStreams streams,\n-                                  final Set<KeyValue<Long, Long>> expectedStoreContent) {\n-        ReadOnlyKeyValueStore<Long, Long> store = null;\n-\n-        final long maxWaitingTime = System.currentTimeMillis() + 300000L;\n-        while (System.currentTimeMillis() < maxWaitingTime) {\n-            try {\n-                store = streams.store(StoreQueryParameters.fromNameAndType(storeName, QueryableStoreTypes.keyValueStore()));\n-                break;\n-            } catch (final InvalidStateStoreException okJustRetry) {\n-                try {\n-                    Thread.sleep(5000L);\n-                } catch (final Exception ignore) { }\n-            }\n-        }\n-\n+                                  final Set<KeyValue<Long, Long>> expectedStoreContent) throws InterruptedException {\n+        final ReadOnlyKeyValueStore<Long, Long> store = IntegrationTestUtils\n+            .getStore(300000L, storeName, streams, QueryableStoreTypes.keyValueStore());", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0Mjk5Mg==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416942992", "bodyText": "Ack.", "author": "guozhangwang", "createdAt": "2020-04-28T21:45:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyMTk3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java\nindex 1deb7c4a05..fa65766d96 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/EosIntegrationTest.java\n\n@@ -810,7 +849,7 @@ public class EosIntegrationTest {\n     private void verifyStateStore(final KafkaStreams streams,\n                                   final Set<KeyValue<Long, Long>> expectedStoreContent) throws InterruptedException {\n         final ReadOnlyKeyValueStore<Long, Long> store = IntegrationTestUtils\n-            .getStore(300000L, storeName, streams, QueryableStoreTypes.keyValueStore());\n+            .getStore(300_000L, storeName, streams, QueryableStoreTypes.keyValueStore());\n         assertNotNull(store);\n \n         final KeyValueIterator<Long, Long> it = store.all();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNTgxMw==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416925813", "bodyText": "not a huge deal, but technically, these should have brackets.", "author": "vvcephei", "createdAt": "2020-04-28T21:12:18Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/StoreUpgradeIntegrationTest.java", "diffHunk": "@@ -337,8 +336,11 @@ public void shouldProxyKeyValueStoreToTimestampedKeyValueStoreUsingPapi() throws\n         TestUtils.waitForCondition(\n             () -> {\n                 try {\n-                    final ReadOnlyKeyValueStore<K, V> store =\n-                        kafkaStreams.store(StoreQueryParameters.fromNameAndType(STORE_NAME, QueryableStoreTypes.keyValueStore()));\n+                    final ReadOnlyKeyValueStore<K, V> store = IntegrationTestUtils.getStore(STORE_NAME, kafkaStreams, QueryableStoreTypes.keyValueStore());\n+\n+                    if (store == null)\n+                        return false;", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0MzkwNw==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416943907", "bodyText": "ack.", "author": "guozhangwang", "createdAt": "2020-04-28T21:46:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNTgxMw=="}], "type": "inlineReview", "revised_code": {"commit": "57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/StoreUpgradeIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/StoreUpgradeIntegrationTest.java\nindex d296a3dac6..9db1e6b9ba 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/StoreUpgradeIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/StoreUpgradeIntegrationTest.java\n\n@@ -338,8 +338,9 @@ public class StoreUpgradeIntegrationTest {\n                 try {\n                     final ReadOnlyKeyValueStore<K, V> store = IntegrationTestUtils.getStore(STORE_NAME, kafkaStreams, QueryableStoreTypes.keyValueStore());\n \n-                    if (store == null)\n+                    if (store == null) {\n                         return false;\n+                    }\n \n                     try (final KeyValueIterator<K, V> all = store.all()) {\n                         final List<KeyValue<K, V>> storeContent = new LinkedList<>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNjk4NQ==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416926985", "bodyText": "I guess the flush at the end makes it synchronous anyway?", "author": "vvcephei", "createdAt": "2020-04-28T21:14:22Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/utils/IntegrationTestUtils.java", "diffHunk": "@@ -269,24 +271,20 @@ public static void cleanStateAfterTest(final EmbeddedKafkaCluster cluster, final\n      * @param <K>                 Key type of the data records\n      * @param <V>                 Value type of the data records\n      */\n-    @SuppressWarnings(\"WeakerAccess\")\n     public static <K, V> void produceKeyValuesSynchronouslyWithTimestamp(final String topic,\n                                                                          final Collection<KeyValue<K, V>> records,\n                                                                          final Properties producerConfig,\n                                                                          final Headers headers,\n                                                                          final Long timestamp,\n-                                                                         final boolean enableTransactions)\n-            throws ExecutionException, InterruptedException {\n+                                                                         final boolean enableTransactions) {\n \n         try (final Producer<K, V> producer = new KafkaProducer<>(producerConfig)) {\n             if (enableTransactions) {\n                 producer.initTransactions();\n                 producer.beginTransaction();\n             }\n             for (final KeyValue<K, V> record : records) {\n-                final Future<RecordMetadata> f = producer.send(\n-                    new ProducerRecord<>(topic, null, timestamp, record.key, record.value, headers));\n-                f.get();\n+                producer.send(new ProducerRecord<>(topic, null, timestamp, record.key, record.value, headers));", "originalCommit": "f936848a86992d779fa37703c4a4a7b83fc30727", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0NDM5Mg==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416944392", "bodyText": "Previously we wait after sending each record, here we only wait once after sending all records, so it is more efficient.", "author": "guozhangwang", "createdAt": "2020-04-28T21:48:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNjk4NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjk0NzgwMA==", "url": "https://github.com/apache/kafka/pull/8568#discussion_r416947800", "bodyText": "Thanks. That's what I was asking for confirmation on. I realize now the structure of my sentence was ambiguous.\nI agree that the method contract is that the batch should be synchronously produced, not that each record should be synchronously produced, so this change looks good to me.", "author": "vvcephei", "createdAt": "2020-04-28T21:55:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjkyNjk4NQ=="}], "type": "inlineReview", "revised_code": null}, {"oid": "4bb8463e529e5e9c631c7dd05b3427d6320e98a9", "url": "https://github.com/apache/kafka/commit/4bb8463e529e5e9c631c7dd05b3427d6320e98a9", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K9176-get-store-with-exception", "committedDate": "2020-04-28T21:44:42Z", "type": "commit"}, {"oid": "57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf", "url": "https://github.com/apache/kafka/commit/57a2c39bcded8ecbdf0f443520ed7385f4ce0dbf", "message": "github comments", "committedDate": "2020-04-28T22:02:40Z", "type": "commit"}]}