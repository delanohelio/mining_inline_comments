{"pr_number": 9476, "pr_title": "MINOR: Refactor RaftClientTest to be used by other tests", "pr_createdAt": "2020-10-21T21:56:37Z", "pr_url": "https://github.com/apache/kafka/pull/9476", "timeline": [{"oid": "006c10b4999f5d379629874aa224230b83592c79", "url": "https://github.com/apache/kafka/commit/006c10b4999f5d379629874aa224230b83592c79", "message": "MINOR: Refactor RaftClientTest to be used by other tests", "committedDate": "2020-10-21T03:04:04Z", "type": "commit"}, {"oid": "5471c7864aa14ff4c671c96e2d99f70e32e18163", "url": "https://github.com/apache/kafka/commit/5471c7864aa14ff4c671c96e2d99f70e32e18163", "message": "Refactor all of the KafkaRaftClientTest", "committedDate": "2020-10-21T21:46:59Z", "type": "commit"}, {"oid": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "url": "https://github.com/apache/kafka/commit/5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "message": "Remove commentted out imports", "committedDate": "2020-10-21T21:54:44Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2MDcyMw==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509760723", "bodyText": "I think nearly every call to updateQuorumStateStore is just writing an initial state. Seems like we can introduce a more direct option to the builder.\nBy the way, one of the annoyances is needing to provide voters through the initial state and through build below. Since we always need voters, maybe we can provide it in the builder constructor. That would allow us to add helpers to construct the state. For example, we could turn this into:\nnew RaftClientTestContext.Builder(voters)\n  .initializeAsFollower(epoch, otherNodeId)\n  .build()\nSimilarly, we could probably do state assertions in the test context as well and save the need to always pass through voters (e.g. we could have context.assertFollower(epoch, leaderId) instead of the cumbersome assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState())).", "author": "hachikuji", "createdAt": "2020-10-21T22:31:06Z", "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -1729,126 +1695,156 @@ public void testLeaderGracefulShutdownTimeout() throws Exception {\n     public void testFollowerGracefulShutdown() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {", "originalCommit": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1NzAyNw==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509857027", "bodyText": "Thanks for the suggestion. I implemented this.", "author": "jsancio", "createdAt": "2020-10-22T03:24:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2MDcyMw=="}], "type": "inlineReview", "revised_code": {"commit": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\nindex 4c2ff9646e..2c57ea0a50 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n\n@@ -1697,15 +1564,11 @@ public class KafkaRaftClientTest {\n         int epoch = 5;\n         Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        RaftClientTestContext context = new RaftClientTestContext.Builder()\n-            .updateQuorumStateStore(quorumStateStore -> {\n-                assertDoesNotThrow(() -> {\n-                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-                });\n-            })\n-            .build(voters);\n+        RaftClientTestContext context = new RaftClientTestContext.Builder(voters)\n+            .withElectedLeader(epoch, otherNodeId)\n+            .build();\n \n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());\n+        context.assertElectedLeader(epoch, otherNodeId);\n \n         context.client.poll();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2NzQxMA==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509767410", "bodyText": "nit: we have assertions like this in many test cases. With a more direct api to update quorum state, we can move these assertions into that api.", "author": "hachikuji", "createdAt": "2020-10-21T22:36:45Z", "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -1729,126 +1695,156 @@ public void testLeaderGracefulShutdownTimeout() throws Exception {\n     public void testFollowerGracefulShutdown() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n+                });\n+            })\n+            .build(voters);\n \n-        client.poll();\n+        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());\n+\n+        context.client.poll();\n \n         int shutdownTimeoutMs = 5000;\n-        CompletableFuture<Void> shutdownFuture = client.shutdown(shutdownTimeoutMs);\n-        assertTrue(client.isRunning());\n+        CompletableFuture<Void> shutdownFuture = context.client.shutdown(shutdownTimeoutMs);\n+        assertTrue(context.client.isRunning());\n         assertFalse(shutdownFuture.isDone());\n \n-        client.poll();\n-        assertFalse(client.isRunning());\n+        context.client.poll();\n+        assertFalse(context.client.isRunning());\n         assertTrue(shutdownFuture.isDone());\n         assertNull(shutdownFuture.get());\n     }\n \n     @Test\n     public void testGracefulShutdownSingleMemberQuorum() throws IOException {\n-        KafkaRaftClient client = buildClient(Collections.singleton(localId));\n+        RaftClientTestContext context = RaftClientTestContext.build(Collections.singleton(LOCAL_ID));\n+\n         assertEquals(ElectionState.withElectedLeader(\n-            1, localId, Collections.singleton(localId)), quorumStateStore.readElectionState());\n-        client.poll();\n-        assertEquals(0, channel.drainSendQueue().size());\n+            1, LOCAL_ID, Collections.singleton(LOCAL_ID)), context.quorumStateStore.readElectionState());\n+        context.client.poll();\n+        assertEquals(0, context.channel.drainSendQueue().size());\n         int shutdownTimeoutMs = 5000;\n-        client.shutdown(shutdownTimeoutMs);\n-        assertTrue(client.isRunning());\n-        client.poll();\n-        assertFalse(client.isRunning());\n+        context.client.shutdown(shutdownTimeoutMs);\n+        assertTrue(context.client.isRunning());\n+        context.client.poll();\n+        assertFalse(context.client.isRunning());\n     }\n \n     @Test\n     public void testFollowerReplication() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n+                });\n+            })\n+            .build(voters);\n+\n+        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());\n \n-        pollUntilSend(client);\n+        context.pollUntilSend();\n \n-        int fetchQuorumCorrelationId = assertSentFetchRequest(epoch, 0L, 0);\n+        int fetchQuorumCorrelationId = context.assertSentFetchRequest(epoch, 0L, 0);\n         Records records = MemoryRecords.withRecords(0L, CompressionType.NONE,\n             3, new SimpleRecord(\"a\".getBytes()), new SimpleRecord(\"b\".getBytes()));\n         FetchResponseData response = fetchResponse(epoch, otherNodeId, records, 0L, Errors.NONE);\n-        deliverResponse(fetchQuorumCorrelationId, otherNodeId, response);\n+        context.deliverResponse(fetchQuorumCorrelationId, otherNodeId, response);\n \n-        client.poll();\n-        assertEquals(2L, log.endOffset().offset);\n-        assertEquals(2L, log.lastFlushedOffset());\n+        context.client.poll();\n+        assertEquals(2L, context.log.endOffset().offset);\n+        assertEquals(2L, context.log.lastFlushedOffset());\n     }\n \n     @Test\n     public void testEmptyRecordSetInFetchResponse() throws Exception {\n         int otherNodeId = 1;\n         int epoch = 5;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n+                });\n+            })\n+            .build(voters);\n+\n+        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());", "originalCommit": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg1NzEwNQ==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509857105", "bodyText": "Thanks for the suggestion. I implemented this.", "author": "jsancio", "createdAt": "2020-10-22T03:24:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc2NzQxMA=="}], "type": "inlineReview", "revised_code": {"commit": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\nindex 4c2ff9646e..2c57ea0a50 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n\n@@ -1697,15 +1564,11 @@ public class KafkaRaftClientTest {\n         int epoch = 5;\n         Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n \n-        RaftClientTestContext context = new RaftClientTestContext.Builder()\n-            .updateQuorumStateStore(quorumStateStore -> {\n-                assertDoesNotThrow(() -> {\n-                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, otherNodeId, voters));\n-                });\n-            })\n-            .build(voters);\n+        RaftClientTestContext context = new RaftClientTestContext.Builder(voters)\n+            .withElectedLeader(epoch, otherNodeId)\n+            .build();\n \n-        assertEquals(ElectionState.withElectedLeader(epoch, otherNodeId, voters), context.quorumStateStore.readElectionState());\n+        context.assertElectedLeader(epoch, otherNodeId);\n \n         context.client.poll();\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3MjE2OQ==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509772169", "bodyText": "nit: it is a tad vexing to see all the context prefixes. I guess another option might be to define RaftClientTestContext as an abstract class so that the test method can define the test behavior within the scope of a subclass.\nFor example:\nnew RaftClientTestContext(builder) {\n  void run() {\n    assertTrue(client.isShuttingDown());\n    ...\n  }\n}\nNot required, just an alternative to consider.", "author": "hachikuji", "createdAt": "2020-10-21T22:43:17Z", "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -1536,67 +1522,70 @@ public void testObserverLeaderRediscoveryAfterRequestTimeout() throws Exception\n         int otherNodeId = 2;\n         int epoch = 5;\n         Set<Integer> voters = Utils.mkSet(leaderId, otherNodeId);\n-        KafkaRaftClient client = buildClient(voters);\n-        discoverLeaderAsObserver(client, voters, leaderId, epoch);\n \n-        pollUntilSend(client);\n-        RaftRequest.Outbound fetchRequest1 = assertSentFetchRequest();\n+        RaftClientTestContext context = RaftClientTestContext.build(voters);\n+\n+        context.discoverLeaderAsObserver(voters, leaderId, epoch);\n+\n+        context.pollUntilSend();\n+        RaftRequest.Outbound fetchRequest1 = context.assertSentFetchRequest();\n         assertEquals(leaderId, fetchRequest1.destinationId());\n-        assertFetchRequestData(fetchRequest1, epoch, 0L, 0);\n+        RaftClientTestContext.assertFetchRequestData(fetchRequest1, epoch, 0L, 0);\n \n-        time.sleep(requestTimeoutMs);\n-        pollUntilSend(client);\n+        context.time.sleep(REQUEST_TIMEOUT_MS);\n+        context.pollUntilSend();\n \n         // We should retry the Fetch against the other voter since the original\n         // voter connection will be backing off.\n-        RaftRequest.Outbound fetchRequest2 = assertSentFetchRequest();\n+        RaftRequest.Outbound fetchRequest2 = context.assertSentFetchRequest();\n         assertNotEquals(leaderId, fetchRequest2.destinationId());\n         assertTrue(voters.contains(fetchRequest2.destinationId()));\n-        assertFetchRequestData(fetchRequest2, epoch, 0L, 0);\n+        RaftClientTestContext.assertFetchRequestData(fetchRequest2, epoch, 0L, 0);\n \n-        deliverResponse(fetchRequest2.correlationId, fetchRequest2.destinationId(),\n+        context.deliverResponse(fetchRequest2.correlationId, fetchRequest2.destinationId(),\n             fetchResponse(epoch, leaderId, MemoryRecords.EMPTY, 0L, Errors.FENCED_LEADER_EPOCH));\n-        client.poll();\n+        context.client.poll();\n \n-        assertEquals(ElectionState.withElectedLeader(epoch, leaderId, voters), quorumStateStore.readElectionState());\n+        assertEquals(ElectionState.withElectedLeader(epoch, leaderId, voters), context.quorumStateStore.readElectionState());\n     }\n \n     @Test\n     public void testLeaderGracefulShutdown() throws Exception {\n         int otherNodeId = 1;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n         int epoch = 1;\n-        KafkaRaftClient client = initializeAsLeader(voters, epoch);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+\n+        RaftClientTestContext context = RaftClientTestContext.initializeAsLeader(voters, epoch);\n \n         // Now shutdown\n         int shutdownTimeoutMs = 5000;\n-        CompletableFuture<Void> shutdownFuture = client.shutdown(shutdownTimeoutMs);\n+        CompletableFuture<Void> shutdownFuture = context.client.shutdown(shutdownTimeoutMs);\n \n         // We should still be running until we have had a chance to send EndQuorumEpoch\n-        assertTrue(client.isShuttingDown());\n-        assertTrue(client.isRunning());\n+        assertTrue(context.client.isShuttingDown());", "originalCommit": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc4NzIxMQ==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509787211", "bodyText": "Yeah. Let me play around with this.", "author": "jsancio", "createdAt": "2020-10-21T23:12:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3MjE2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMzMTI0OQ==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510331249", "bodyText": "I thought about this last night and hack some solutions. I wasn't very pleased with the result. Let's explore this improvement in a future PR.", "author": "jsancio", "createdAt": "2020-10-22T17:20:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTc3MjE2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\nindex 4c2ff9646e..2c57ea0a50 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n\n@@ -1523,9 +1390,9 @@ public class KafkaRaftClientTest {\n         int epoch = 5;\n         Set<Integer> voters = Utils.mkSet(leaderId, otherNodeId);\n \n-        RaftClientTestContext context = RaftClientTestContext.build(voters);\n+        RaftClientTestContext context = new RaftClientTestContext.Builder(voters).build();\n \n-        context.discoverLeaderAsObserver(voters, leaderId, epoch);\n+        context.discoverLeaderAsObserver(leaderId, epoch);\n \n         context.pollUntilSend();\n         RaftRequest.Outbound fetchRequest1 = context.assertSentFetchRequest();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDI2NQ==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509840265", "bodyText": "@hachikuji is this a bug? Shouldn't the leader (LOCAL_ID) always be a voter (the second argument for this function)?", "author": "jsancio", "createdAt": "2020-10-22T02:21:10Z", "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -90,470 +76,480 @@\n import static org.junit.jupiter.api.Assertions.assertTrue;\n \n public class KafkaRaftClientTest {\n-    private static final TopicPartition METADATA_PARTITION = new TopicPartition(\"metadata\", 0);\n-\n-    private final int localId = 0;\n-    private final int electionTimeoutMs = 10000;\n-    private final int electionBackoffMaxMs = 100;\n-    private final int fetchTimeoutMs = 50000;   // fetch timeout is usually larger than election timeout\n-    private final int retryBackoffMs = 50;\n-    private final int requestTimeoutMs = 5000;\n-    private final int fetchMaxWaitMs = 0;\n-\n-    private final MockTime time = new MockTime();\n-    private final MockLog log = new MockLog(METADATA_PARTITION);\n-    private final MockNetworkChannel channel = new MockNetworkChannel();\n-    private final Random random = Mockito.spy(new Random(1));\n-    private final QuorumStateStore quorumStateStore = new MockQuorumStateStore();\n-\n-    @AfterEach\n-    public void cleanUp() throws IOException {\n-        quorumStateStore.clear();\n-    }\n-\n-    private InetSocketAddress mockAddress(int id) {\n-        return new InetSocketAddress(\"localhost\", 9990 + id);\n-    }\n-\n-    private KafkaRaftClient buildClient(Set<Integer> voters) throws IOException {\n-        return buildClient(voters, new Metrics(time));\n-    }\n-\n-    private KafkaRaftClient buildClient(Set<Integer> voters, Metrics metrics) throws IOException {\n-        LogContext logContext = new LogContext();\n-        QuorumState quorum = new QuorumState(localId, voters, electionTimeoutMs, fetchTimeoutMs,\n-            quorumStateStore, time, logContext, random);\n-\n-        Map<Integer, InetSocketAddress> voterAddresses = voters.stream().collect(Collectors.toMap(\n-            Function.identity(),\n-            this::mockAddress\n-        ));\n-\n-        KafkaRaftClient client = new KafkaRaftClient(channel, log, quorum, time, metrics,\n-            new MockFuturePurgatory<>(time), new MockFuturePurgatory<>(time), voterAddresses,\n-            electionBackoffMaxMs, retryBackoffMs, requestTimeoutMs, fetchMaxWaitMs, logContext, random);\n-\n-        client.initialize();\n-\n-        return client;\n-    }\n-\n     @Test\n     public void testInitializeSingleMemberQuorum() throws IOException {\n-        buildClient(Collections.singleton(localId));\n-        assertEquals(ElectionState.withElectedLeader(1, localId, Collections.singleton(localId)),\n-            quorumStateStore.readElectionState());\n+        RaftClientTestContext context = RaftClientTestContext.build(Collections.singleton(LOCAL_ID));\n+        assertEquals(\n+            ElectionState.withElectedLeader(1, LOCAL_ID, Collections.singleton(LOCAL_ID)),\n+            context.quorumStateStore.readElectionState()\n+        );\n     }\n \n     @Test\n     public void testInitializeAsLeaderFromStateStoreSingleMemberQuorum() throws Exception {\n         // Start off as leader. We should still bump the epoch after initialization\n \n         int initialEpoch = 2;\n-        Set<Integer> voters = Collections.singleton(localId);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(initialEpoch, localId, voters));\n-\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(1L, log.endOffset().offset);\n-        assertEquals(initialEpoch + 1, log.lastFetchedEpoch());\n-        assertEquals(new LeaderAndEpoch(OptionalInt.of(localId), initialEpoch + 1),\n-            client.currentLeaderAndEpoch());\n-        assertEquals(ElectionState.withElectedLeader(initialEpoch + 1, localId, voters),\n-            quorumStateStore.readElectionState());\n+        Set<Integer> voters = Collections.singleton(LOCAL_ID);\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(\n+                        ElectionState.withElectedLeader(initialEpoch, LOCAL_ID, voters)\n+                    );\n+                });\n+            })\n+            .build(voters);\n+\n+        assertEquals(1L, context.log.endOffset().offset);\n+        assertEquals(initialEpoch + 1, context.log.lastFetchedEpoch());\n+        assertEquals(new LeaderAndEpoch(OptionalInt.of(LOCAL_ID), initialEpoch + 1),\n+            context.client.currentLeaderAndEpoch());\n+        assertEquals(ElectionState.withElectedLeader(initialEpoch + 1, LOCAL_ID, voters),\n+            context.quorumStateStore.readElectionState());\n     }\n \n     @Test\n     public void testInitializeAsLeaderFromStateStore() throws Exception {\n-        Set<Integer> voters = Utils.mkSet(localId, 1);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, 1);\n         int epoch = 2;\n \n-        Mockito.doReturn(0).when(random).nextInt(electionTimeoutMs);\n-        quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, localId, voters));\n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(0L, log.endOffset().offset);\n-        assertEquals(ElectionState.withUnknownLeader(epoch, voters), quorumStateStore.readElectionState());\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateRandom(random -> {\n+                Mockito.doReturn(0).when(random).nextInt(RaftClientTestContext.ELECTION_TIMEOUT_MS);\n+            })\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, LOCAL_ID, voters));\n+                });\n+            })\n+            .build(voters);\n+\n \n-        time.sleep(electionTimeoutMs);\n-        pollUntilSend(client);\n-        assertSentVoteRequest(epoch + 1, 0, 0L);\n+        assertEquals(0L, context.log.endOffset().offset);\n+        assertEquals(ElectionState.withUnknownLeader(epoch, voters), context.quorumStateStore.readElectionState());\n+\n+        context.time.sleep(RaftClientTestContext.ELECTION_TIMEOUT_MS);\n+        context.pollUntilSend();\n+        context.assertSentVoteRequest(epoch + 1, 0, 0L);\n     }\n \n     @Test\n     public void testInitializeAsCandidateFromStateStore() throws Exception {\n         // Need 3 node to require a 2-node majority\n-        Set<Integer> voters = Utils.mkSet(localId, 1, 2);\n-        quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(2, localId, voters));\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, 1, 2);\n+\n+        RaftClientTestContext context = new RaftClientTestContext.Builder()\n+            .updateQuorumStateStore(quorumStateStore -> {\n+                assertDoesNotThrow(() -> {\n+                    quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(2, LOCAL_ID, voters));\n+                });\n+            })\n+            .build(voters);\n \n-        KafkaRaftClient client = buildClient(voters);\n-        assertEquals(0L, log.endOffset().offset);\n+        assertEquals(0L, context.log.endOffset().offset);\n \n         // Send out vote requests.\n-        client.poll();\n+        context.client.poll();\n \n-        List<RaftRequest.Outbound> voteRequests = collectVoteRequests(2, 0, 0);\n+        List<RaftRequest.Outbound> voteRequests = context.collectVoteRequests(2, 0, 0);\n         assertEquals(2, voteRequests.size());\n     }\n \n     @Test\n     public void testInitializeAsCandidateAndBecomeLeader() throws Exception {\n         final int otherNodeId = 1;\n-        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n-        KafkaRaftClient client = buildClient(voters);\n+        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+        RaftClientTestContext context = RaftClientTestContext.build(voters);\n \n-        assertEquals(ElectionState.withUnknownLeader(0, voters), quorumStateStore.readElectionState());\n-        time.sleep(2 * electionTimeoutMs);\n+        assertEquals(ElectionState.withUnknownLeader(0, voters), context.quorumStateStore.readElectionState());\n+        context.time.sleep(2 * RaftClientTestContext.ELECTION_TIMEOUT_MS);\n \n-        pollUntilSend(client);\n-        assertEquals(ElectionState.withVotedCandidate(1, localId, voters), quorumStateStore.readElectionState());\n+        context.pollUntilSend();\n+        assertEquals(ElectionState.withVotedCandidate(1, LOCAL_ID, voters), context.quorumStateStore.readElectionState());\n \n-        int correlationId = assertSentVoteRequest(1, 0, 0L);\n-        deliverResponse(correlationId, otherNodeId, voteResponse(true, Optional.empty(), 1));\n+        int correlationId = context.assertSentVoteRequest(1, 0, 0L);\n+        context.deliverResponse(correlationId, otherNodeId, RaftClientTestContext.voteResponse(true, Optional.empty(), 1));\n \n         // Become leader after receiving the vote\n-        client.poll();\n-        assertEquals(ElectionState.withElectedLeader(1, localId, voters), quorumStateStore.readElectionState());\n-        long electionTimestamp = time.milliseconds();\n+        context.client.poll();\n+        assertEquals(ElectionState.withElectedLeader(1, LOCAL_ID, voters), context.quorumStateStore.readElectionState());\n+        long electionTimestamp = context.time.milliseconds();\n \n         // Leader change record appended\n-        assertEquals(1L, log.endOffset().offset);\n-        assertEquals(1L, log.lastFlushedOffset());\n+        assertEquals(1L, context.log.endOffset().offset);\n+        assertEquals(1L, context.log.lastFlushedOffset());\n \n         // Send BeginQuorumEpoch to voters\n-        client.poll();\n-        assertSentBeginQuorumEpochRequest(1);\n+        context.client.poll();\n+        context.assertSentBeginQuorumEpochRequest(1);\n \n-        Records records = log.read(0, Isolation.UNCOMMITTED).records;\n+        Records records = context.log.read(0, Isolation.UNCOMMITTED).records;\n         RecordBatch batch = records.batches().iterator().next();\n         assertTrue(batch.isControlBatch());\n \n         Record record = batch.iterator().next();\n         assertEquals(electionTimestamp, record.timestamp());\n-        verifyLeaderChangeMessage(localId, Collections.singletonList(otherNodeId),\n-            record.key(), record.value());\n+        RaftClientTestContext.verifyLeaderChangeMessage(LOCAL_ID, Collections.singletonList(otherNodeId), record.key(), record.value());", "originalCommit": "5ce5150fec4a3d795a0e43dbdcf4f90dcbdd8c4f", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDgzNA==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r509840834", "bodyText": "This is what the LeaderChangeMessage says:\n      {\"name\": \"VotedIds\", \"type\": \"[]int32\", \"versions\": \"0+\",\n       \"about\": \"The IDs of the voters who voted for the current leader\"},", "author": "jsancio", "createdAt": "2020-10-22T02:23:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDI2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5NTA5Ng==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510395096", "bodyText": "Yeah, that's fair. It looks like the code current just includes all followers. I guess we need to carry over the voters into the LeaderState if we want to implement the description above. Let's open a separate sub-task for https://issues.apache.org/jira/browse/KAFKA-9876 and decide what we want to do there.", "author": "hachikuji", "createdAt": "2020-10-22T19:10:04Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDI2NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQyMTk2NA==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510421964", "bodyText": "Done. https://issues.apache.org/jira/browse/KAFKA-10634", "author": "jsancio", "createdAt": "2020-10-22T19:59:58Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg0MDI2NQ=="}], "type": "inlineReview", "revised_code": {"commit": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\nindex 4c2ff9646e..2c57ea0a50 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n\n@@ -78,11 +77,8 @@ import static org.junit.jupiter.api.Assertions.assertTrue;\n public class KafkaRaftClientTest {\n     @Test\n     public void testInitializeSingleMemberQuorum() throws IOException {\n-        RaftClientTestContext context = RaftClientTestContext.build(Collections.singleton(LOCAL_ID));\n-        assertEquals(\n-            ElectionState.withElectedLeader(1, LOCAL_ID, Collections.singleton(LOCAL_ID)),\n-            context.quorumStateStore.readElectionState()\n-        );\n+        RaftClientTestContext context = new RaftClientTestContext.Builder(Collections.singleton(LOCAL_ID)).build();\n+        context.assertElectedLeader(1, LOCAL_ID);\n     }\n \n     @Test\n"}}, {"oid": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "url": "https://github.com/apache/kafka/commit/8f200afd8fa571bbc43c7e567e5d53c44cf33506", "message": "Avoid the need to repeat the voter set", "committedDate": "2020-10-22T03:23:52Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM4NzMxMA==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510387310", "bodyText": "I'm somewhat inclined to add the local id to the builder rather than making it constant. It makes the builder a bit more self-contained.\nOn a similar note, it would be nice to push the other static config values into the builder as well.", "author": "hachikuji", "createdAt": "2020-10-22T18:56:44Z", "path": "raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.BeginQuorumEpochRequestData;\n+import org.apache.kafka.common.message.BeginQuorumEpochResponseData;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData.ReplicaState;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData;\n+import org.apache.kafka.common.message.EndQuorumEpochRequestData;\n+import org.apache.kafka.common.message.EndQuorumEpochResponseData;\n+import org.apache.kafka.common.message.FetchRequestData;\n+import org.apache.kafka.common.message.FetchResponseData;\n+import org.apache.kafka.common.message.LeaderChangeMessage.Voter;\n+import org.apache.kafka.common.message.LeaderChangeMessage;\n+import org.apache.kafka.common.message.VoteRequestData;\n+import org.apache.kafka.common.message.VoteResponseData;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.ApiMessage;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.record.ControlRecordType;\n+import org.apache.kafka.common.record.ControlRecordUtils;\n+import org.apache.kafka.common.record.MemoryRecords;\n+import org.apache.kafka.common.record.Record;\n+import org.apache.kafka.common.record.Records;\n+import org.apache.kafka.common.record.SimpleRecord;\n+import org.apache.kafka.common.requests.BeginQuorumEpochResponse;\n+import org.apache.kafka.common.requests.DescribeQuorumResponse;\n+import org.apache.kafka.common.requests.VoteResponse;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.test.TestUtils;\n+import org.mockito.Mockito;\n+import static org.apache.kafka.raft.RaftUtil.hasValidTopicPartition;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+final class RaftClientTestContext {\n+    private static final int FETCH_MAX_WAIT_MS = 0;\n+\n+    static final TopicPartition METADATA_PARTITION = new TopicPartition(\"metadata\", 0);\n+    static final int LOCAL_ID = 0;", "originalCommit": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ0OTUwOA==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510449508", "bodyText": "Okay. I made it possible to easily add support of this in the future without breaking the existing tests.\nWe can make this changeable in the Builder as we need it.", "author": "jsancio", "createdAt": "2020-10-22T20:52:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM4NzMxMA=="}], "type": "inlineReview", "revised_code": {"commit": "6db5a627ed3fa91f8de65586bb973c389e98948a", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java b/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java\nindex ca8a9f0313..8769ade296 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java\n\n@@ -56,8 +56,11 @@ import org.apache.kafka.common.record.MemoryRecords;\n import org.apache.kafka.common.record.Record;\n import org.apache.kafka.common.record.Records;\n import org.apache.kafka.common.record.SimpleRecord;\n+import org.apache.kafka.common.requests.BeginQuorumEpochRequest;\n import org.apache.kafka.common.requests.BeginQuorumEpochResponse;\n import org.apache.kafka.common.requests.DescribeQuorumResponse;\n+import org.apache.kafka.common.requests.EndQuorumEpochRequest;\n+import org.apache.kafka.common.requests.VoteRequest;\n import org.apache.kafka.common.requests.VoteResponse;\n import org.apache.kafka.common.utils.LogContext;\n import org.apache.kafka.common.utils.MockTime;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5MDgxOQ==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510390819", "bodyText": "nit: this indentation looks kind of funky", "author": "hachikuji", "createdAt": "2020-10-22T19:02:45Z", "path": "raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java", "diffHunk": "@@ -0,0 +1,648 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft;\n+\n+import java.io.IOException;\n+import java.net.InetSocketAddress;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.OptionalInt;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.BeginQuorumEpochRequestData;\n+import org.apache.kafka.common.message.BeginQuorumEpochResponseData;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData.ReplicaState;\n+import org.apache.kafka.common.message.DescribeQuorumResponseData;\n+import org.apache.kafka.common.message.EndQuorumEpochRequestData;\n+import org.apache.kafka.common.message.EndQuorumEpochResponseData;\n+import org.apache.kafka.common.message.FetchRequestData;\n+import org.apache.kafka.common.message.FetchResponseData;\n+import org.apache.kafka.common.message.LeaderChangeMessage.Voter;\n+import org.apache.kafka.common.message.LeaderChangeMessage;\n+import org.apache.kafka.common.message.VoteRequestData;\n+import org.apache.kafka.common.message.VoteResponseData;\n+import org.apache.kafka.common.metrics.Metrics;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.ApiMessage;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.record.ControlRecordType;\n+import org.apache.kafka.common.record.ControlRecordUtils;\n+import org.apache.kafka.common.record.MemoryRecords;\n+import org.apache.kafka.common.record.Record;\n+import org.apache.kafka.common.record.Records;\n+import org.apache.kafka.common.record.SimpleRecord;\n+import org.apache.kafka.common.requests.BeginQuorumEpochResponse;\n+import org.apache.kafka.common.requests.DescribeQuorumResponse;\n+import org.apache.kafka.common.requests.VoteResponse;\n+import org.apache.kafka.common.utils.LogContext;\n+import org.apache.kafka.common.utils.MockTime;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.test.TestUtils;\n+import org.mockito.Mockito;\n+import static org.apache.kafka.raft.RaftUtil.hasValidTopicPartition;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+final class RaftClientTestContext {\n+    private static final int FETCH_MAX_WAIT_MS = 0;\n+\n+    static final TopicPartition METADATA_PARTITION = new TopicPartition(\"metadata\", 0);\n+    static final int LOCAL_ID = 0;\n+\n+    static final int ELECTION_BACKOFF_MAX_MS = 100;\n+    static final int ELECTION_TIMEOUT_MS = 10000;\n+    // fetch timeout is usually larger than election timeout\n+    static final int FETCH_TIMEOUT_MS = 50000;\n+    static final int REQUEST_TIMEOUT_MS = 5000;\n+    static final int RETRY_BACKOFF_MS = 50;\n+\n+    private final QuorumStateStore quorumStateStore;\n+    private final Random random;\n+\n+    final KafkaRaftClient client;\n+    final Metrics metrics;\n+    final MockLog log;\n+    final MockNetworkChannel channel;\n+    final MockTime time;\n+    final Set<Integer> voters;\n+\n+    public static final class Builder {\n+        private final QuorumStateStore quorumStateStore = new MockQuorumStateStore();\n+        private final Random random = Mockito.spy(new Random(1));\n+        private final MockLog log = new MockLog(METADATA_PARTITION);\n+        private final Set<Integer> voters;\n+\n+        Builder(Set<Integer> voters) {\n+            this.voters = voters;\n+        }\n+\n+        Builder withElectedLeader(int epoch, int leaderId) throws IOException {\n+            quorumStateStore.writeElectionState(ElectionState.withElectedLeader(epoch, leaderId, voters));\n+            return this;\n+        }\n+\n+        Builder withUnknownLeader(int epoch) throws IOException {\n+            quorumStateStore.writeElectionState(ElectionState.withUnknownLeader(epoch, voters));\n+            return this;\n+        }\n+\n+        Builder withVotedCandidate(int epoch, int votedId) throws IOException {\n+            quorumStateStore.writeElectionState(ElectionState.withVotedCandidate(epoch, votedId, voters));\n+            return this;\n+        }\n+\n+        Builder updateRandom(Consumer<Random> consumer) {\n+            consumer.accept(random);\n+            return this;\n+        }\n+\n+        Builder updateLog(Consumer<MockLog> consumer) {\n+            consumer.accept(log);\n+            return this;\n+        }\n+\n+        RaftClientTestContext build() throws IOException {\n+            MockTime time = new MockTime();\n+            Metrics metrics = new Metrics(time);\n+            MockNetworkChannel channel = new MockNetworkChannel();\n+            LogContext logContext = new LogContext();\n+            QuorumState quorum = new QuorumState(LOCAL_ID, voters, ELECTION_TIMEOUT_MS, FETCH_TIMEOUT_MS,\n+                    quorumStateStore, time, logContext, random);\n+\n+            Map<Integer, InetSocketAddress> voterAddresses = voters.stream().collect(Collectors.toMap(\n+                        Function.identity(),\n+                        RaftClientTestContext::mockAddress\n+                        ));", "originalCommit": "8f200afd8fa571bbc43c7e567e5d53c44cf33506", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ0ODY5NA==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510448694", "bodyText": "Done.", "author": "jsancio", "createdAt": "2020-10-22T20:50:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5MDgxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "6db5a627ed3fa91f8de65586bb973c389e98948a", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java b/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java\nindex ca8a9f0313..8769ade296 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/RaftClientTestContext.java\n\n@@ -56,8 +56,11 @@ import org.apache.kafka.common.record.MemoryRecords;\n import org.apache.kafka.common.record.Record;\n import org.apache.kafka.common.record.Records;\n import org.apache.kafka.common.record.SimpleRecord;\n+import org.apache.kafka.common.requests.BeginQuorumEpochRequest;\n import org.apache.kafka.common.requests.BeginQuorumEpochResponse;\n import org.apache.kafka.common.requests.DescribeQuorumResponse;\n+import org.apache.kafka.common.requests.EndQuorumEpochRequest;\n+import org.apache.kafka.common.requests.VoteRequest;\n import org.apache.kafka.common.requests.VoteResponse;\n import org.apache.kafka.common.utils.LogContext;\n import org.apache.kafka.common.utils.MockTime;\n"}}, {"oid": "6db5a627ed3fa91f8de65586bb973c389e98948a", "url": "https://github.com/apache/kafka/commit/6db5a627ed3fa91f8de65586bb973c389e98948a", "message": "Don't assume that each context has the same configuration", "committedDate": "2020-10-22T20:50:01Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ4ODkwMg==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510488902", "bodyText": "The pattern I had in mind was a little different. I was thinking something like this:\n        int localId = 0;\n        int otherNodeId = 1;\n        int epoch = 2;\n        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n\n        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n          .withVotedCandidate(epoch, otherNodeId)\n          .build()\nThen we don't have the awkwardness of the partial reliance on the static LOCAL_ID. I like this better because the ids have to be explicitly declared in each test case, which makes it easier to follow.", "author": "hachikuji", "createdAt": "2020-10-22T22:15:42Z", "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java", "diffHunk": "@@ -278,13 +265,13 @@ public void testEndQuorumStartsNewElectionAfterBackoffIfReceivedFromVotedCandida\n             .withVotedCandidate(epoch, otherNodeId)", "originalCommit": "6db5a627ed3fa91f8de65586bb973c389e98948a", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ5ODQzMw==", "url": "https://github.com/apache/kafka/pull/9476#discussion_r510498433", "bodyText": "Makes sense. I implemented this suggestion.", "author": "jsancio", "createdAt": "2020-10-22T22:42:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ4ODkwMg=="}], "type": "inlineReview", "revised_code": {"commit": "47c94de723519691fa9749cc21d9ef1dc65fe85f", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\nindex cdd03b3d94..80e9285596 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientTest.java\n\n@@ -257,11 +265,12 @@ public class KafkaRaftClientTest {\n \n     @Test\n     public void testEndQuorumStartsNewElectionAfterBackoffIfReceivedFromVotedCandidate() throws Exception {\n+        int localId = 0;\n         int otherNodeId = 1;\n         int epoch = 2;\n-        Set<Integer> voters = Utils.mkSet(LOCAL_ID, otherNodeId);\n+        Set<Integer> voters = Utils.mkSet(localId, otherNodeId);\n \n-        RaftClientTestContext context = new RaftClientTestContext.Builder(voters)\n+        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n             .withVotedCandidate(epoch, otherNodeId)\n             .build();\n \n"}}, {"oid": "47c94de723519691fa9749cc21d9ef1dc65fe85f", "url": "https://github.com/apache/kafka/commit/47c94de723519691fa9749cc21d9ef1dc65fe85f", "message": "Remove LOCAL_ID and make it configurable in the Builder", "committedDate": "2020-10-22T22:41:20Z", "type": "commit"}]}