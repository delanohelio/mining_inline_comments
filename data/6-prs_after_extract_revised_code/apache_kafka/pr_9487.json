{"pr_number": 9487, "pr_title": "KAFKA-9331: Add a streams specific uncaught exception handler", "pr_createdAt": "2020-10-23T20:45:51Z", "pr_url": "https://github.com/apache/kafka/pull/9487", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3ODExNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518478117", "bodyText": "I had a little trouble following the Handler class. Some trivial things -- eg the handler in the StreamThread is named streamsUncaughtExceptionHandler but it's actually not a StreamsUncaughtExceptionHandler. Also the usage of the return value; IIUC it's supposed to indicate whether to use the new handler or fall back on the old one. To me it sounds like if handle returns true that means we should handle it, ie we should not rethrow the exception, but this looks like the opposite of what we do now. Honestly either interpretation is ok with me, as long as it's documented somewhere\nDo we really need the Handler in the first place though? It's already pretty confusing that we have to deal with two types of handlers (old and new) so I'd prefer not to add a third unless it's really necessary. It seems like we can just inline the logic of whether to invoke the new handler or rethrow the exception, which would also clear up the confusion around the meaning of the return value. But I might be missing something here -- WDYT?", "author": "ableegoldman", "createdAt": "2020-11-06T01:55:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -567,10 +589,34 @@ void runLoop() {\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final Exception e) {\n+                if (this.streamsUncaughtExceptionHandler.handle(e)) {", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgzNzI1MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518837250", "bodyText": "We could do the logic inline how ever this does make it slightly simpler. Also we only expose the streamsUncaughtExceptionHandler to the user and @vvcephei had a problem with the wrapping that again with the same type. So we introduced a wrapper class. if we renamed it from Handler to streamsUncaughtExceptionHandlerWrapper would that make it more clear?", "author": "wcarlson5", "createdAt": "2020-11-06T15:46:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3ODExNw=="}], "type": "inlineReview", "revised_code": {"commit": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\nindex d3a0bbc22d..604454ea1b 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n\n@@ -590,7 +592,17 @@ public class StreamThread extends Thread {\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n             } catch (final Exception e) {\n-                if (this.streamsUncaughtExceptionHandler.handle(e)) {\n+                if (newHandler) {\n+                    if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+                        log.error(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                                \"The old handler will be ignored as long as a new handler is set.\");\n+                    }\n+                    if (this.streamsUncaughtExceptionHandler.handle(e) != StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) {\n+                        throw e;\n+                    } else {\n+                        sendShutdownRequest(AssignorError.SHUTDOWN_REQUESTED);\n+                    }\n+                } else {\n                     throw e;\n                 }\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3OTUyNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518479524", "bodyText": "Seems like we can just pass in a Runnable with KafkaStreams::closeToError instead of adding a whole ShutdownErrorHook functional interface", "author": "ableegoldman", "createdAt": "2020-11-06T01:59:50Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -282,6 +283,17 @@ public boolean isRunning() {\n     private final Admin adminClient;\n     private final InternalTopologyBuilder builder;\n \n+    private Handler streamsUncaughtExceptionHandler;\n+    private ShutdownErrorHook shutdownErrorHook;\n+    private AtomicInteger assignmentErrorCode;\n+    public interface ShutdownErrorHook {\n+        void shutdown();\n+    }", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg0Mjc0Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518842747", "bodyText": "Yes we can", "author": "wcarlson5", "createdAt": "2020-11-06T15:55:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ3OTUyNA=="}], "type": "inlineReview", "revised_code": {"commit": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\nindex d3a0bbc22d..604454ea1b 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n\n@@ -283,15 +285,13 @@ public class StreamThread extends Thread {\n     private final Admin adminClient;\n     private final InternalTopologyBuilder builder;\n \n-    private Handler streamsUncaughtExceptionHandler;\n+\n+    private boolean newHandler;\n+    private StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler;\n     private ShutdownErrorHook shutdownErrorHook;\n     private AtomicInteger assignmentErrorCode;\n     public interface ShutdownErrorHook {\n-        void shutdown();\n-    }\n-    @FunctionalInterface\n-    public interface Handler {\n-        boolean handle(Throwable throwable);\n+        void shutdown(Duration duration);\n     }\n \n     public static StreamThread create(final InternalTopologyBuilder builder,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MTg4Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518481887", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            \"The all clients in this app will now begin to shutdown\");\n          \n          \n            \n                            \"All clients in this app will now begin to shutdown\");", "author": "ableegoldman", "createdAt": "2020-11-06T02:07:58Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -567,10 +589,34 @@ void runLoop() {\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final Exception e) {\n+                if (this.streamsUncaughtExceptionHandler.handle(e)) {\n+                    throw e;\n+                }\n             }\n         }\n     }\n \n+    /**\n+     * Sets the streams uncaught exception handler.\n+     *\n+     * @param streamsUncaughtExceptionHandler the user handler wrapped in shell to execute the action\n+     */\n+    public void setStreamsUncaughtExceptionHandler(final Handler streamsUncaughtExceptionHandler) {\n+        this.streamsUncaughtExceptionHandler = streamsUncaughtExceptionHandler;\n+    }\n+\n+    public void shutdownToError() {\n+        shutdownErrorHook.shutdown();\n+    }\n+\n+    public void sendShutdownRequest(final AssignorError assignorError) {\n+        log.warn(\"Detected that shutdown was requested. \" +\n+                \"The all clients in this app will now begin to shutdown\");", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\nindex d3a0bbc22d..604454ea1b 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n\n@@ -590,7 +592,17 @@ public class StreamThread extends Thread {\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n             } catch (final Exception e) {\n-                if (this.streamsUncaughtExceptionHandler.handle(e)) {\n+                if (newHandler) {\n+                    if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+                        log.error(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                                \"The old handler will be ignored as long as a new handler is set.\");\n+                    }\n+                    if (this.streamsUncaughtExceptionHandler.handle(e) != StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse.SHUTDOWN_APPLICATION) {\n+                        throw e;\n+                    } else {\n+                        sendShutdownRequest(AssignorError.SHUTDOWN_REQUESTED);\n+                    }\n+                } else {\n                     throw e;\n                 }\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MjgzMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518482832", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                log.error(\"Exception in global stream thread cause the application to attempt to shutdown.\" +\n          \n          \n            \n                                        \" This action will succeed only if there is at least one StreamThread running on ths client.\" +\n          \n          \n            \n                                        \" Currently there is no running threads so will now close the client.\");\n          \n          \n            \n                                log.error(\"Exception in global thread caused the application to attempt to shutdown.\" +\n          \n          \n            \n                                        \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n          \n          \n            \n                                        \" Currently there are no running threads so will now close the client.\");", "author": "ableegoldman", "createdAt": "2020-11-06T02:11:28Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +373,84 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamThread.Handler handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                        \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private boolean handleStreamsUncaughtExceptionDefaultWrapper(final Throwable throwable) {\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            return true;\n+        }\n+        return handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+    }\n+\n+    private boolean handleStreamsUncaughtException(final Throwable e,\n+                                                   final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(e);\n+        if (Thread.getDefaultUncaughtExceptionHandler() != null) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \\\" + action + \\\".\" +\n+                        \" The streams client is going to shut down now. \", e);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (e instanceof Error) {\n+                    log.error(\"This option requires running threads to shut down the application.\" +\n+                            \"but the uncaught exception was an Error, which means this runtime is no \" +\n+                            \"longer in a well-defined state. Attempting to send the shutdown command anyway.\", e);\n+                }\n+                if (Thread.currentThread().equals(globalStreamThread) && threads.stream().noneMatch(StreamThread::isRunning)) {\n+                    log.error(\"Exception in global stream thread cause the application to attempt to shutdown.\" +\n+                            \" This action will succeed only if there is at least one StreamThread running on ths client.\" +\n+                            \" Currently there is no running threads so will now close the client.\");", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\nindex 295f257f74..c71e3b7b3b 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n\n@@ -368,13 +369,13 @@ public class KafkaStreams implements AutoCloseable {\n                 }\n             } else {\n                 throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n-                    \"Current state is: \" + state);\n+                        \"Current state is: \" + state);\n             }\n         }\n     }\n \n     /**\n-     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n      * throws an unexpected exception.\n      * These might be exceptions indicating rare bugs in Kafka Streams, or they\n      * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518483194", "bodyText": "Should this be logged at error?", "author": "ableegoldman", "createdAt": "2020-11-06T02:12:42Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -996,6 +1082,62 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            log.info(\"Can not transition to error from state \" + state());", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgzODQyMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518838421", "bodyText": "In the normal close method the corresponding log is also info. As multiple thread will be calling this at once I would rather not flood the logs with error unnecessarily.", "author": "wcarlson5", "createdAt": "2020-11-06T15:48:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODkxMzUxNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518913514", "bodyText": "Gotcha. In that case maybe we shouldn't log anything here at all? Or just reword it to clarify that this is expected (eg \"Skipping shutdown since we are already in ERROR\") since \"Can not transition...\" kind of sounds like something went wrong", "author": "ableegoldman", "createdAt": "2020-11-06T17:57:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODkzODg1Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518938852", "bodyText": "That is a good idea, Ill change the log", "author": "wcarlson5", "createdAt": "2020-11-06T18:47:09Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4MzE5NA=="}], "type": "inlineReview", "revised_code": {"commit": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\nindex 295f257f74..c71e3b7b3b 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n\n@@ -1084,9 +1071,10 @@ public class KafkaStreams implements AutoCloseable {\n \n     private void closeToError() {\n         if (!setState(State.ERROR)) {\n-            log.info(\"Can not transition to error from state \" + state());\n+            // if transition failed, it means it was either in PENDING_SHUTDOWN\n+            // or NOT_RUNNING already; just check that all threads have been stopped\n+            log.info(\"Can not close to error\");\n         } else {\n-            log.info(\"Transitioning to ERROR state\");\n             stateDirCleaner.shutdownNow();\n             if (rocksDBMetricsRecordingService != null) {\n                 rocksDBMetricsRecordingService.shutdownNow();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NDI3MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518484271", "bodyText": "Looks like we call setState(ERROR) three times in this method, is that intentional?", "author": "ableegoldman", "createdAt": "2020-11-06T02:16:48Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -996,6 +1082,62 @@ private boolean close(final long timeoutMs) {\n         }\n     }\n \n+    private void closeToError() {\n+        if (!setState(State.ERROR)) {\n+            log.info(\"Can not transition to error from state \" + state());\n+        } else {\n+            log.info(\"Transitioning to ERROR state\");\n+            stateDirCleaner.shutdownNow();\n+            if (rocksDBMetricsRecordingService != null) {\n+                rocksDBMetricsRecordingService.shutdownNow();\n+            }\n+\n+            // wait for all threads to join in a separate thread;\n+            // save the current thread so that if it is a stream thread\n+            // we don't attempt to join it and cause a deadlock\n+            final Thread shutdownThread = new Thread(() -> {\n+                // notify all the threads to stop; avoid deadlocks by stopping any\n+                // further state reports from the thread since we're shutting down\n+                for (final StreamThread thread : threads) {\n+                    thread.shutdown();\n+                }\n+\n+                for (final StreamThread thread : threads) {\n+                    try {\n+                        if (!thread.isRunning()) {\n+                            thread.join();\n+                        }\n+                    } catch (final InterruptedException ex) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                }\n+\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.shutdown();\n+                }\n+\n+                if (globalStreamThread != null && !globalStreamThread.stillRunning()) {\n+                    try {\n+                        globalStreamThread.join();\n+                    } catch (final InterruptedException e) {\n+                        Thread.currentThread().interrupt();\n+                    }\n+                    globalStreamThread = null;\n+                }\n+\n+                adminClient.close();\n+\n+                streamsMetrics.removeAllClientLevelMetrics();\n+                metrics.close();\n+                setState(State.ERROR);\n+            }, \"kafka-streams-close-thread\");\n+\n+            shutdownThread.setDaemon(true);\n+            shutdownThread.start();\n+            setState(State.ERROR);", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODgzODU4Ng==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518838586", "bodyText": "No, I hadn't seen that", "author": "wcarlson5", "createdAt": "2020-11-06T15:49:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NDI3MQ=="}], "type": "inlineReview", "revised_code": {"commit": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\nindex 295f257f74..c71e3b7b3b 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n\n@@ -1084,9 +1071,10 @@ public class KafkaStreams implements AutoCloseable {\n \n     private void closeToError() {\n         if (!setState(State.ERROR)) {\n-            log.info(\"Can not transition to error from state \" + state());\n+            // if transition failed, it means it was either in PENDING_SHUTDOWN\n+            // or NOT_RUNNING already; just check that all threads have been stopped\n+            log.info(\"Can not close to error\");\n         } else {\n-            log.info(\"Transitioning to ERROR state\");\n             stateDirCleaner.shutdownNow();\n             if (rocksDBMetricsRecordingService != null) {\n                 rocksDBMetricsRecordingService.shutdownNow();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTI4MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518485280", "bodyText": "It probably doesn't matter too much since handleRebalanceComplete doesn't do anything that important at the mometn, but it seems like we should call it before shutting down, not after.", "author": "ableegoldman", "createdAt": "2020-11-06T02:20:24Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java", "diffHunk": "@@ -60,6 +60,11 @@ public void onPartitionsAssigned(final Collection<TopicPartition> partitions) {\n         }  else if (assignmentErrorCode.get() == AssignorError.ASSIGNMENT_ERROR.code()) {\n             log.error(\"Received error code {}\", AssignorError.ASSIGNMENT_ERROR);\n             throw new TaskAssignmentException(\"Hit an unexpected exception during task assignment phase of rebalance\");\n+        } else if (assignmentErrorCode.get() == AssignorError.SHUTDOWN_REQUESTED.code()) {\n+            log.error(\"A Kafka Streams client in this Kafka Streams application is requesting to shutdown the application\");\n+            streamThread.shutdownToError();\n+            taskManager.handleRebalanceComplete();", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg0MDEyMQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518840121", "bodyText": "We can do that, it doesn't seem make difference which order it is called. However if it is not called it will get stuck continually rebalancing. We return because setting the state to partitions assigned will cause an error", "author": "wcarlson5", "createdAt": "2020-11-06T15:51:21Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTI4MA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI4ODY3OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r523288678", "bodyText": "For the same reason I had to add to the other cases as the close from the new handler will not finish otherwise", "author": "wcarlson5", "createdAt": "2020-11-13T23:49:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTI4MA=="}], "type": "inlineReview", "revised_code": {"commit": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java\nindex dc7f5f17a5..1a8a5f57ac 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsRebalanceListener.java\n\n@@ -61,9 +61,8 @@ public class StreamsRebalanceListener implements ConsumerRebalanceListener {\n             log.error(\"Received error code {}\", AssignorError.ASSIGNMENT_ERROR);\n             throw new TaskAssignmentException(\"Hit an unexpected exception during task assignment phase of rebalance\");\n         } else if (assignmentErrorCode.get() == AssignorError.SHUTDOWN_REQUESTED.code()) {\n-            log.error(\"A Kafka Streams client in this Kafka Streams application is requesting to shutdown the application\");\n+            log.error(\"An application is requesting Shutdown\");\n             streamThread.shutdownToError();\n-            taskManager.handleRebalanceComplete();\n             return;\n         } else if (assignmentErrorCode.get() != AssignorError.NONE.code()) {\n             log.error(\"Received unknown error code {}\", assignmentErrorCode.get());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTc0OQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518485749", "bodyText": "This should probably stay final so we don't accidentally change it ever", "author": "ableegoldman", "createdAt": "2020-11-06T02:22:02Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ReferenceContainer.java", "diffHunk": "@@ -30,7 +30,7 @@\n     public Admin adminClient;\n     public TaskManager taskManager;\n     public StreamsMetadataState streamsMetadataState;\n-    public final AtomicInteger assignmentErrorCode = new AtomicInteger();\n+    public AtomicInteger assignmentErrorCode = new AtomicInteger();", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODg0MDYwMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518840602", "bodyText": "I was changing it intentionally but I think I can get away with not", "author": "wcarlson5", "createdAt": "2020-11-06T15:52:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4NTc0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "5d08b9f24021198581a7271f98a0a7db3d7d4c0b", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ReferenceContainer.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ReferenceContainer.java\nindex 9dd8c275e1..fbf65e50f4 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ReferenceContainer.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/assignment/ReferenceContainer.java\n\n@@ -30,7 +30,7 @@ public class ReferenceContainer {\n     public Admin adminClient;\n     public TaskManager taskManager;\n     public StreamsMetadataState streamsMetadataState;\n-    public AtomicInteger assignmentErrorCode = new AtomicInteger();\n+    public final AtomicInteger assignmentErrorCode = new AtomicInteger();\n     public final AtomicLong nextScheduledRebalanceMs = new AtomicLong(Long.MAX_VALUE);\n     public Time time;\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODQ4ODU3Nw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r518488577", "bodyText": "This cast makes me kind of uncomfortable...either the assignmentErrorCode that we have in the AssignmentInfo is conceptually the same as the one we're adding to the SubscriptionInfo (in which case it should be the same type), or it's not the same, in which case we should use a different variable to track it.\nPersonally I think it's probably simpler to keep them the same, and just add an int errorCode field to the Subscription instead of a byte shutdownRequested field. But it's your choice", "author": "ableegoldman", "createdAt": "2020-11-06T02:32:29Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java", "diffHunk": "@@ -255,8 +255,9 @@ public ByteBuffer subscriptionUserData(final Set<String> topics) {\n             taskManager.processId(),\n             userEndPoint,\n             taskManager.getTaskOffsetSums(),\n-            uniqueField)\n-                .encode();\n+            uniqueField,\n+            (byte) assignmentErrorCode.get()", "originalCommit": "0fab427b4a8e8e9caff419d026add8c0dc44eb77", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "3f2b8b2cf7885c81f0bf737b29a0646895f1aa9b", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java\nindex f8f9818e12..e9079cd956 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamsPartitionAssignor.java\n\n@@ -256,7 +256,7 @@ public class StreamsPartitionAssignor implements ConsumerPartitionAssignor, Conf\n             userEndPoint,\n             taskManager.getTaskOffsetSums(),\n             uniqueField,\n-            (byte) assignmentErrorCode.get()\n+            assignmentErrorCode.get()\n         ).encode();\n     }\n \n"}}, {"oid": "c170379a33e35b56d0dea2158f9ff9f1b52ba914", "url": "https://github.com/apache/kafka/commit/c170379a33e35b56d0dea2158f9ff9f1b52ba914", "message": "Still has a problem with actually shutting down the application", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "8c20e715e172202dfa8d229af20f1fd95e85e9c8", "url": "https://github.com/apache/kafka/commit/8c20e715e172202dfa8d229af20f1fd95e85e9c8", "message": "in progress", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "1e86e6c37bc9a423efb301c963cfc146d98c0b7b", "url": "https://github.com/apache/kafka/commit/1e86e6c37bc9a423efb301c963cfc146d98c0b7b", "message": "needed to stop the rebalance", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "a969ca55572bc041cdbc907aa5b43cf676ac0eb3", "url": "https://github.com/apache/kafka/commit/a969ca55572bc041cdbc907aa5b43cf676ac0eb3", "message": "Still has a problem with actually shutting down the application", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "cde16becd223ee64b5c59f8e458641d2f37c9e04", "url": "https://github.com/apache/kafka/commit/cde16becd223ee64b5c59f8e458641d2f37c9e04", "message": "style", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "a70d7b8a5c8df0f585a0e825067328d95cb8b644", "url": "https://github.com/apache/kafka/commit/a70d7b8a5c8df0f585a0e825067328d95cb8b644", "message": "added old handler logic back to global stream threads", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "769e471050e905313f071fb7fff4e72d9caa3801", "url": "https://github.com/apache/kafka/commit/769e471050e905313f071fb7fff4e72d9caa3801", "message": "fixed mem error", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "07dbf7dc4d1db8988d2a98b586c789d9337ee20f", "url": "https://github.com/apache/kafka/commit/07dbf7dc4d1db8988d2a98b586c789d9337ee20f", "message": "style and system test msgs", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "8cf9c891f6f61ac83ff3077e40c26e2f998e4f78", "url": "https://github.com/apache/kafka/commit/8cf9c891f6f61ac83ff3077e40c26e2f998e4f78", "message": "java doc changes", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "a4a95594eabeafb6e8f6a2eaa953cb77264726dd", "url": "https://github.com/apache/kafka/commit/a4a95594eabeafb6e8f6a2eaa953cb77264726dd", "message": "refactor and address comments", "committedDate": "2020-11-17T18:23:41Z", "type": "commit"}, {"oid": "96f0e8fe7d840de9576d974994a62e36a010dbf1", "url": "https://github.com/apache/kafka/commit/96f0e8fe7d840de9576d974994a62e36a010dbf1", "message": "incremented version number in probing test", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "cd377bae8a9ba7ba1aa5463e47b954985b11f2f4", "url": "https://github.com/apache/kafka/commit/cd377bae8a9ba7ba1aa5463e47b954985b11f2f4", "message": "address comments", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "5d08b9f24021198581a7271f98a0a7db3d7d4c0b", "url": "https://github.com/apache/kafka/commit/5d08b9f24021198581a7271f98a0a7db3d7d4c0b", "message": "Address comments and clean up named", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "256600903ebc08ab486a034e31905093ec457cca", "url": "https://github.com/apache/kafka/commit/256600903ebc08ab486a034e31905093ec457cca", "message": "change log statement", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "c4718d6673e295727a22cc9361b0dac8e5a8a3d2", "url": "https://github.com/apache/kafka/commit/c4718d6673e295727a22cc9361b0dac8e5a8a3d2", "message": "added tag and make logic better", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "527373b4b5d4d70dc180f825fe6de8ce1663987b", "url": "https://github.com/apache/kafka/commit/527373b4b5d4d70dc180f825fe6de8ce1663987b", "message": "address comments", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "e426f49dce4fbf3d9cc1f4fe51a1329ad5883288", "url": "https://github.com/apache/kafka/commit/e426f49dce4fbf3d9cc1f4fe51a1329ad5883288", "message": "typo", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "9747f6be998f08f1c5061983d13affd065c90811", "url": "https://github.com/apache/kafka/commit/9747f6be998f08f1c5061983d13affd065c90811", "message": "add test", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "48dbafc48759cf5e133ebc8f3e07120c088e42ca", "url": "https://github.com/apache/kafka/commit/48dbafc48759cf5e133ebc8f3e07120c088e42ca", "message": "Made so tests can no longer swallow", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "f07aba83e3037253a8bf3966308cd1e7fe8c0073", "url": "https://github.com/apache/kafka/commit/f07aba83e3037253a8bf3966308cd1e7fe8c0073", "message": "removed indent", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "0236aa86ba071dbeab8bf0d517cf9c13e949c65e", "url": "https://github.com/apache/kafka/commit/0236aa86ba071dbeab8bf0d517cf9c13e949c65e", "message": "address comments", "committedDate": "2020-11-17T18:23:42Z", "type": "commit"}, {"oid": "3f2b8b2cf7885c81f0bf737b29a0646895f1aa9b", "url": "https://github.com/apache/kafka/commit/3f2b8b2cf7885c81f0bf737b29a0646895f1aa9b", "message": "address comments", "committedDate": "2020-11-17T18:23:43Z", "type": "commit"}, {"oid": "56f94913ab0c3a53ffdff86d83e81c7c3c92317f", "url": "https://github.com/apache/kafka/commit/56f94913ab0c3a53ffdff86d83e81c7c3c92317f", "message": "remove byte", "committedDate": "2020-11-17T18:23:43Z", "type": "commit"}, {"oid": "2cf792c124cf199ebc5948909f0df8e54aa6d2e4", "url": "https://github.com/apache/kafka/commit/2cf792c124cf199ebc5948909f0df8e54aa6d2e4", "message": "fixed flaky test sometime causing buf underflow", "committedDate": "2020-11-17T19:20:09Z", "type": "commit"}, {"oid": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "url": "https://github.com/apache/kafka/commit/1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "message": "couple of comments", "committedDate": "2020-11-17T19:51:35Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNjU1NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525636554", "bodyText": "I think it makes more sense to transition to ERROR in this case than to NOT_RUNNING. But let's put this on file with the other FSM-related work planned for following PRs", "author": "ableegoldman", "createdAt": "2020-11-18T01:32:09Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -366,6 +377,90 @@ public void setUncaughtExceptionHandler(final Thread.UncaughtExceptionHandler eh\n         }\n     }\n \n+    /**\n+     * Set the handler invoked when an {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread}\n+     * throws an unexpected exception.\n+     * These might be exceptions indicating rare bugs in Kafka Streams, or they\n+     * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor\n+     * logic.\n+     * The handler will execute on the thread that produced the exception.\n+     * In order to get the thread that threw the exception, Thread.currentThread().\n+     * <p>\n+     * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any\n+     * thread that encounters such an exception.\n+     *\n+     * @param streamsUncaughtExceptionHandler the uncaught exception handler of type {@link StreamsUncaughtExceptionHandler} for all internal threads\n+     * @throws IllegalStateException if this {@code KafkaStreams} instance is not in state {@link State#CREATED CREATED}.\n+     * @throws NullPointerException if streamsUncaughtExceptionHandler is null.\n+     */\n+    public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final Consumer<Throwable> handler = exception -> handleStreamsUncaughtException(exception, streamsUncaughtExceptionHandler);\n+        synchronized (stateLock) {\n+            if (state == State.CREATED) {\n+                Objects.requireNonNull(streamsUncaughtExceptionHandler);\n+                for (final StreamThread thread : threads) {\n+                    thread.setStreamsUncaughtExceptionHandler(handler);\n+                }\n+                if (globalStreamThread != null) {\n+                    globalStreamThread.setUncaughtExceptionHandler(handler);\n+                }\n+            } else {\n+                throw new IllegalStateException(\"Can only set UncaughtExceptionHandler in CREATED state. \" +\n+                    \"Current state is: \" + state);\n+            }\n+        }\n+    }\n+\n+    private void defaultStreamsUncaughtExceptionHandler(final Throwable throwable) {\n+        if (oldHandler) {\n+            if (throwable instanceof RuntimeException) {\n+                throw (RuntimeException) throwable;\n+            } else if (throwable instanceof Error) {\n+                throw (Error) throwable;\n+            } else {\n+                throw new RuntimeException(\"Unexpected checked exception caught in the uncaught exception handler\", throwable);\n+            }\n+        } else {\n+            handleStreamsUncaughtException(throwable, t -> SHUTDOWN_CLIENT);\n+        }\n+    }\n+\n+    private void handleStreamsUncaughtException(final Throwable throwable,\n+                                                final StreamsUncaughtExceptionHandler streamsUncaughtExceptionHandler) {\n+        final StreamsUncaughtExceptionHandler.StreamThreadExceptionResponse action = streamsUncaughtExceptionHandler.handle(throwable);\n+        if (oldHandler) {\n+            log.warn(\"Stream's new uncaught exception handler is set as well as the deprecated old handler.\" +\n+                    \"The old handler will be ignored as long as a new handler is set.\");\n+        }\n+        switch (action) {\n+            case SHUTDOWN_CLIENT:\n+                log.error(\"Encountered the following exception during processing \" +\n+                        \"and the registered exception handler opted to \" + action + \".\" +\n+                        \" The streams client is going to shut down now. \", throwable);\n+                close(Duration.ZERO);\n+                break;\n+            case SHUTDOWN_APPLICATION:\n+                if (throwable instanceof Error) {\n+                    log.error(\"This option requires running threads to shut down the application.\" +\n+                            \"but the uncaught exception was an Error, which means this runtime is no \" +\n+                            \"longer in a well-defined state. Attempting to send the shutdown command anyway.\", throwable);\n+                }\n+                if (Thread.currentThread().equals(globalStreamThread) && threads.stream().noneMatch(StreamThread::isRunning)) {\n+                    log.error(\"Exception in global thread caused the application to attempt to shutdown.\" +\n+                            \" This action will succeed only if there is at least one StreamThread running on this client.\" +\n+                            \" Currently there are no running threads so will now close the client.\");\n+                    close(Duration.ZERO);", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY4MDg3NA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525680874", "bodyText": "I am on the fence about this. I do think its would be consistent to be not running but also it did shutdown cleanly. We made this choice when ERROR still meant all threads had died and that is not true now. In the end I just went with what we had in the KIP rather than try to change it. Though I could be swayed to leave this in ERROR.", "author": "wcarlson5", "createdAt": "2020-11-18T02:46:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNjU1NA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTcwMTY5MQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525701691", "bodyText": "That's fair. I guess I was thinking less about the inherent meaning of ERROR vs NOT_RUNNING, and more about not behaving differently in this special case. ie if there are still StreamThreads running when a user selects SHUTDOWN_APPLICATION, then we ultimately transition to ERROR. So it strikes me as a bit odd to transition to NOT_RUNNING just because we didn't happen to have any threads left.", "author": "ableegoldman", "createdAt": "2020-11-18T03:06:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNjU1NA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MDA4OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525640088", "bodyText": "Why do we shut down the global thread only after all stream threads have completed their shutdown? Seems like it would be more efficient to send the shutdown signal to everyone first, and then wait for all the threads to join. Can you try this out in the followup PR?", "author": "ableegoldman", "createdAt": "2020-11-18T01:43:12Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -932,56 +1028,62 @@ public synchronized boolean close(final long timeout, final TimeUnit timeUnit) {\n         return close(timeoutMs);\n     }\n \n-    private boolean close(final long timeoutMs) {\n-        if (!setState(State.PENDING_SHUTDOWN)) {\n-            // if transition failed, it means it was either in PENDING_SHUTDOWN\n-            // or NOT_RUNNING already; just check that all threads have been stopped\n-            log.info(\"Already in the pending shutdown state, wait to complete shutdown\");\n-        } else {\n-            stateDirCleaner.shutdownNow();\n-            if (rocksDBMetricsRecordingService != null) {\n-                rocksDBMetricsRecordingService.shutdownNow();\n-            }\n+    private Thread shutdownHelper(final boolean error) {\n+        stateDirCleaner.shutdownNow();\n+        if (rocksDBMetricsRecordingService != null) {\n+            rocksDBMetricsRecordingService.shutdownNow();\n+        }\n \n-            // wait for all threads to join in a separate thread;\n-            // save the current thread so that if it is a stream thread\n-            // we don't attempt to join it and cause a deadlock\n-            final Thread shutdownThread = new Thread(() -> {\n-                // notify all the threads to stop; avoid deadlocks by stopping any\n-                // further state reports from the thread since we're shutting down\n-                for (final StreamThread thread : threads) {\n-                    thread.shutdown();\n-                }\n+        // wait for all threads to join in a separate thread;\n+        // save the current thread so that if it is a stream thread\n+        // we don't attempt to join it and cause a deadlock\n+        return new Thread(() -> {\n+            // notify all the threads to stop; avoid deadlocks by stopping any\n+            // further state reports from the thread since we're shutting down\n+            for (final StreamThread thread : threads) {\n+                thread.shutdown();\n+            }\n \n-                for (final StreamThread thread : threads) {\n-                    try {\n-                        if (!thread.isRunning()) {\n-                            thread.join();\n-                        }\n-                    } catch (final InterruptedException ex) {\n-                        Thread.currentThread().interrupt();\n+            for (final StreamThread thread : threads) {\n+                try {\n+                    if (!thread.isRunning()) {\n+                        thread.join();\n                     }\n+                } catch (final InterruptedException ex) {\n+                    Thread.currentThread().interrupt();\n                 }\n+            }\n \n-                if (globalStreamThread != null) {\n-                    globalStreamThread.shutdown();\n-                }\n+            if (globalStreamThread != null) {\n+                globalStreamThread.shutdown();\n+            }", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY3ODIzNA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525678234", "bodyText": "You are right I think. I just copied from the normal close method because I knew it worked. In a follow up we can maybe change both of these. Do you think that there should be a ak ticket to track it?", "author": "wcarlson5", "createdAt": "2020-11-18T02:44:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MDA4OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY5Mjk2MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525692960", "bodyText": "Eh, I wouldn't bother with an AK ticket if this will be tackled in the next PR. I'll just make a list of all the minor followup work somewhere to keep track", "author": "ableegoldman", "createdAt": "2020-11-18T02:59:37Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY0MDA4OA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525650632", "bodyText": "I just realized that this is going to be a problem with the way the ERROR state is being used. IF we closeToError then we transition to ERROR and shut down, however ERROR -> PENDING_SHUTDOWN is still an allowed transition so there's nothing to prevent the shutdown from being triggered again when a user calls close(). And note that a lot of users most likely have a state listener at the moment which does exactly that, ie when it sees a transition to ERROR it immediately invokes close (because that's what you should do with the current semantics)\nJust another thing that I think we can fix with some minor rewiring of the FSM.", "author": "ableegoldman", "createdAt": "2020-11-18T02:14:15Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -932,56 +1028,62 @@ public synchronized boolean close(final long timeout, final TimeUnit timeUnit) {\n         return close(timeoutMs);\n     }\n \n-    private boolean close(final long timeoutMs) {\n-        if (!setState(State.PENDING_SHUTDOWN)) {\n-            // if transition failed, it means it was either in PENDING_SHUTDOWN\n-            // or NOT_RUNNING already; just check that all threads have been stopped\n-            log.info(\"Already in the pending shutdown state, wait to complete shutdown\");\n-        } else {\n-            stateDirCleaner.shutdownNow();\n-            if (rocksDBMetricsRecordingService != null) {\n-                rocksDBMetricsRecordingService.shutdownNow();\n-            }\n+    private Thread shutdownHelper(final boolean error) {\n+        stateDirCleaner.shutdownNow();\n+        if (rocksDBMetricsRecordingService != null) {\n+            rocksDBMetricsRecordingService.shutdownNow();\n+        }\n \n-            // wait for all threads to join in a separate thread;\n-            // save the current thread so that if it is a stream thread\n-            // we don't attempt to join it and cause a deadlock\n-            final Thread shutdownThread = new Thread(() -> {\n-                // notify all the threads to stop; avoid deadlocks by stopping any\n-                // further state reports from the thread since we're shutting down\n-                for (final StreamThread thread : threads) {\n-                    thread.shutdown();\n-                }\n+        // wait for all threads to join in a separate thread;\n+        // save the current thread so that if it is a stream thread\n+        // we don't attempt to join it and cause a deadlock\n+        return new Thread(() -> {\n+            // notify all the threads to stop; avoid deadlocks by stopping any\n+            // further state reports from the thread since we're shutting down\n+            for (final StreamThread thread : threads) {\n+                thread.shutdown();\n+            }\n \n-                for (final StreamThread thread : threads) {\n-                    try {\n-                        if (!thread.isRunning()) {\n-                            thread.join();\n-                        }\n-                    } catch (final InterruptedException ex) {\n-                        Thread.currentThread().interrupt();\n+            for (final StreamThread thread : threads) {\n+                try {\n+                    if (!thread.isRunning()) {\n+                        thread.join();\n                     }\n+                } catch (final InterruptedException ex) {\n+                    Thread.currentThread().interrupt();\n                 }\n+            }\n \n-                if (globalStreamThread != null) {\n-                    globalStreamThread.shutdown();\n-                }\n+            if (globalStreamThread != null) {\n+                globalStreamThread.shutdown();\n+            }\n \n-                if (globalStreamThread != null && !globalStreamThread.stillRunning()) {\n-                    try {\n-                        globalStreamThread.join();\n-                    } catch (final InterruptedException e) {\n-                        Thread.currentThread().interrupt();\n-                    }\n-                    globalStreamThread = null;\n+            if (globalStreamThread != null && !globalStreamThread.stillRunning()) {\n+                try {\n+                    globalStreamThread.join();\n+                } catch (final InterruptedException e) {\n+                    Thread.currentThread().interrupt();\n                 }\n+                globalStreamThread = null;\n+            }\n \n-                adminClient.close();\n+            adminClient.close();\n \n-                streamsMetrics.removeAllClientLevelMetrics();\n-                metrics.close();\n+            streamsMetrics.removeAllClientLevelMetrics();\n+            metrics.close();\n+            if (!error) {\n                 setState(State.NOT_RUNNING);\n-            }, \"kafka-streams-close-thread\");\n+            }\n+        }, \"kafka-streams-close-thread\");\n+    }\n+\n+    private boolean close(final long timeoutMs) {\n+        if (!setState(State.PENDING_SHUTDOWN)) {", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY4MTY0Mg==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525681642", "bodyText": "This is currently the plan to remove that transition. It is pretty much the only change we plan to make to the FSM.", "author": "wcarlson5", "createdAt": "2020-11-18T02:47:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTczNDQxNw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525734417", "bodyText": "WDYT about having both NOT_RUNNING and ERROR go through PENDING_SHUTDOWN, rather than just transitioning directly and permanently to ERROR? At a high level I think it just makes sense for ERROR and NOT_RUNNING to be symmetric. Also any benefit to having an intermediate PENDING_SHUTDOWN for the NOT_RUNNING case presumably applies to the ERROR case as well. eg, it indicates whether Streams has completed its shutdown or not: users know that an app in PENDING_SHUTDOWN should never be killed, its only safe to do so once it reaches NOT_RUNNING. We should provide the same functionality and only transition to ERROR after the shutdown is complete", "author": "ableegoldman", "createdAt": "2020-11-18T03:30:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjIxMTQwOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r526211409", "bodyText": "I do think that Error should not have direct transition. However I don't like using PENDING_SHUTDOWN , mostly because we can already distinguish between the two states and it would be best to inform right away. Also it could be a problem if we went to set Error and some how it went from PENDING_SHUTDOWN to NOT_RUNNING. I am in favor of adding something like PENDING_ERROR just to be more precise.", "author": "wcarlson5", "createdAt": "2020-11-18T16:08:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ3NzI1OA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r526477258", "bodyText": "Sounds reasonable", "author": "ableegoldman", "createdAt": "2020-11-18T22:53:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1MDYzMg=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1ODYzOQ==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525658639", "bodyText": "Hm ok this might be a problem. Since this is thrown from another catch block and not from the try block, it won't be caught by the catch block below and will slip through the exception handler.", "author": "ableegoldman", "createdAt": "2020-11-18T02:23:10Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java", "diffHunk": "@@ -311,6 +314,8 @@ public void run() {\n                 \"Updating global state failed. You can restart KafkaStreams to recover from this error.\",\n                 recoverableException", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY4Njg0Mw==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525686843", "bodyText": "like in stream thread we can just add a call to the handler", "author": "wcarlson5", "createdAt": "2020-11-18T02:53:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY1ODYzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "35dc69a461be58624c13ce4a252ed483d1f4c65d", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java\nindex c83f94beca..a16c4a572f 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/GlobalStreamThread.java\n\n@@ -310,10 +310,11 @@ public class GlobalStreamThread extends Thread {\n                 \"Updating global state failed due to inconsistent local state. Will attempt to clean up the local state. You can restart KafkaStreams to recover from this error.\",\n                 recoverableException\n             );\n-            throw new StreamsException(\n-                \"Updating global state failed. You can restart KafkaStreams to recover from this error.\",\n+            final StreamsException e = new StreamsException(\n+                \"Updating global state failed. You can restart KafkaStreams to launch a new GlobalStreamThread to recover from this error.\",\n                 recoverableException\n             );\n+            this.streamsUncaughtExceptionHandler.accept(e);\n         } catch (final Exception e) {\n             this.streamsUncaughtExceptionHandler.accept(e);\n         } finally {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTY2MzY0MA==", "url": "https://github.com/apache/kafka/pull/9487#discussion_r525663640", "bodyText": "We should remember to update the wording here when we add the REPLACE_THREAD functionality", "author": "ableegoldman", "createdAt": "2020-11-18T02:28:30Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -559,18 +552,51 @@ void runLoop() {\n                 }\n             } catch (final TaskCorruptedException e) {\n                 log.warn(\"Detected the states of tasks \" + e.corruptedTaskWithChangelogs() + \" are corrupted. \" +\n-                             \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n+                        \"Will close the task as dirty and re-create and bootstrap from scratch.\", e);\n                 try {\n                     taskManager.handleCorruption(e.corruptedTaskWithChangelogs());\n                 } catch (final TaskMigratedException taskMigrated) {\n                     handleTaskMigrated(taskMigrated);\n                 }\n             } catch (final TaskMigratedException e) {\n                 handleTaskMigrated(e);\n+            } catch (final UnsupportedVersionException e) {\n+                final String errorMessage = e.getMessage();\n+                if (errorMessage != null &&\n+                        errorMessage.startsWith(\"Broker unexpectedly doesn't support requireStable flag on version \")) {\n+\n+                    log.error(\"Shutting down because the Kafka cluster seems to be on a too old version. \" +", "originalCommit": "1b8913c5afbdc5fa41ad7702eea90093bdb1f253", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "35dc69a461be58624c13ce4a252ed483d1f4c65d", "url": "https://github.com/apache/kafka/commit/35dc69a461be58624c13ce4a252ed483d1f4c65d", "message": "respond to exception", "committedDate": "2020-11-18T03:39:02Z", "type": "commit"}]}