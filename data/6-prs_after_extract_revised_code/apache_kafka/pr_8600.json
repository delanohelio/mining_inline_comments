{"pr_number": 8600, "pr_title": "KAFKA-9928: Fix flaky GlobalKTableEOSIntegrationTest", "pr_createdAt": "2020-05-01T21:04:28Z", "pr_url": "https://github.com/apache/kafka/pull/8600", "timeline": [{"oid": "e0d5f566078db5b4ad463142978c8cbd2af23974", "url": "https://github.com/apache/kafka/commit/e0d5f566078db5b4ad463142978c8cbd2af23974", "message": "KAFKA-9928: Fix flaky GlobalKTableEOSIntegrationTest", "committedDate": "2020-05-01T21:03:21Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODczNzgzNQ==", "url": "https://github.com/apache/kafka/pull/8600#discussion_r418737835", "bodyText": "This might be the actually fix. Not sure why we set retries to one, but if we would loose input data, we would never complete the result and the test would time out. (Maybe not relevant for aborted message, but same below)", "author": "mjsax", "createdAt": "2020-05-01T21:05:53Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java", "diffHunk": "@@ -304,59 +382,64 @@ private void startStreams() {\n \n     private void produceTopicValues(final String topic) {\n         IntegrationTestUtils.produceKeyValuesSynchronously(\n-                topic,\n-                Arrays.asList(\n-                        new KeyValue<>(\"a\", 1L),\n-                        new KeyValue<>(\"b\", 2L),\n-                        new KeyValue<>(\"c\", 3L),\n-                        new KeyValue<>(\"d\", 4L),\n-                        new KeyValue<>(\"e\", 5L)),\n-                TestUtils.producerConfig(\n-                        CLUSTER.bootstrapServers(),\n-                        StringSerializer.class,\n-                        LongSerializer.class,\n-                        new Properties()),\n-                mockTime);\n+            topic,\n+            Arrays.asList(\n+                new KeyValue<>(\"a\", 1L),\n+                new KeyValue<>(\"b\", 2L),\n+                new KeyValue<>(\"c\", 3L),\n+                new KeyValue<>(\"d\", 4L),\n+                new KeyValue<>(\"e\", 5L)\n+            ),\n+            TestUtils.producerConfig(\n+                CLUSTER.bootstrapServers(),\n+                StringSerializer.class,\n+                LongSerializer.class,\n+                new Properties()\n+            ),\n+            mockTime\n+        );\n     }\n \n     private void produceAbortedMessages() throws Exception {\n         final Properties properties = new Properties();\n         properties.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, \"someid\");\n-        properties.put(ProducerConfig.RETRIES_CONFIG, 1);", "originalCommit": "e0d5f566078db5b4ad463142978c8cbd2af23974", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1c1d325a1567f7d6f78e8406ca5f606f97fceda4", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java\nindex 2f816af30d..8f57399b82 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/GlobalKTableEOSIntegrationTest.java\n\n@@ -444,18 +444,21 @@ public class GlobalKTableEOSIntegrationTest {\n \n     private void produceGlobalTableValues() {\n         IntegrationTestUtils.produceKeyValuesSynchronously(\n-                globalTableTopic,\n-                Arrays.asList(\n-                        new KeyValue<>(1L, \"F\"),\n-                        new KeyValue<>(2L, \"G\"),\n-                        new KeyValue<>(3L, \"H\"),\n-                        new KeyValue<>(4L, \"I\"),\n-                        new KeyValue<>(5L, \"J\")),\n-                TestUtils.producerConfig(\n-                        CLUSTER.bootstrapServers(),\n-                        LongSerializer.class,\n-                        StringSerializer.class,\n-                        new Properties()),\n-                mockTime);\n+            globalTableTopic,\n+            Arrays.asList(\n+                new KeyValue<>(1L, \"F\"),\n+                new KeyValue<>(2L, \"G\"),\n+                new KeyValue<>(3L, \"H\"),\n+                new KeyValue<>(4L, \"I\"),\n+                new KeyValue<>(5L, \"J\")\n+            ),\n+            TestUtils.producerConfig(\n+                CLUSTER.bootstrapServers(),\n+                LongSerializer.class,\n+                StringSerializer.class,\n+                new Properties()\n+            ),\n+            mockTime\n+        );\n     }\n }\n"}}, {"oid": "1c1d325a1567f7d6f78e8406ca5f606f97fceda4", "url": "https://github.com/apache/kafka/commit/1c1d325a1567f7d6f78e8406ca5f606f97fceda4", "message": "fix formatting", "committedDate": "2020-05-01T21:07:08Z", "type": "commit"}, {"oid": "dbec61df84780f0033d0c170fc065bec1b0c5891", "url": "https://github.com/apache/kafka/commit/dbec61df84780f0033d0c170fc065bec1b0c5891", "message": "Use supplier to provide error message", "committedDate": "2020-05-01T21:23:22Z", "type": "commit"}, {"oid": "df27f9ef06369c82b4ea37722ae8be89ff24729a", "url": "https://github.com/apache/kafka/commit/df27f9ef06369c82b4ea37722ae8be89ff24729a", "message": "Another try to fix flakiness (plus some cleanup)", "committedDate": "2020-05-04T04:55:10Z", "type": "commit"}, {"oid": "ab2e6a445b177130be2b69e2fe0464e3e31904d4", "url": "https://github.com/apache/kafka/commit/ab2e6a445b177130be2b69e2fe0464e3e31904d4", "message": "Improve wait condition", "committedDate": "2020-05-05T05:38:05Z", "type": "commit"}]}