{"pr_number": 8030, "pr_title": "KAFKA-9492; Ignore record errors in ProduceResponse for older versions", "pr_createdAt": "2020-02-01T16:57:21Z", "pr_url": "https://github.com/apache/kafka/pull/8030", "timeline": [{"oid": "4e7132184b0e242d772193bc02522ca188c12f43", "url": "https://github.com/apache/kafka/commit/4e7132184b0e242d772193bc02522ca188c12f43", "message": "KAFKA-9492; Ignore record errors in ProduceResponse for older versions", "committedDate": "2020-02-01T16:55:41Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg2Mjc3OA==", "url": "https://github.com/apache/kafka/pull/8030#discussion_r373862778", "bodyText": "Maybe this should be in ProduceResponseTest? We started writing this type of test in dedicated classes as this class was getting too large.", "author": "ijuma", "createdAt": "2020-02-02T17:41:46Z", "path": "clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java", "diffHunk": "@@ -653,6 +654,33 @@ public void produceResponseVersionTest() {\n         assertEquals(\"Response data does not match\", responseData, v2Response.responses());\n     }\n \n+    @Test\n+    public void produceResponseRecordErrorsTest() {", "originalCommit": "4e7132184b0e242d772193bc02522ca188c12f43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYyNjIyNA==", "url": "https://github.com/apache/kafka/pull/8030#discussion_r374626224", "bodyText": "@ijuma Thanks for the review. I have moved this test and the other two produce response tests to ProduceResponseTest.", "author": "rajinisivaram", "createdAt": "2020-02-04T11:52:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzg2Mjc3OA=="}], "type": "inlineReview", "revised_code": {"commit": "2585cc329ad15ec0b3a1e760018a6a4bf08917bd", "chunk": "diff --git a/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java b/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java\nindex 30ba426d95..6ce9405100 100644\n--- a/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java\n+++ b/clients/src/test/java/org/apache/kafka/common/requests/RequestResponseTest.java\n\n@@ -603,84 +602,6 @@ public class RequestResponseTest {\n         assertEquals(RecordBatch.NO_TIMESTAMP, partitionResponse.logAppendTime);\n     }\n \n-    @Test\n-    public void produceResponseV5Test() {\n-        Map<TopicPartition, ProduceResponse.PartitionResponse> responseData = new HashMap<>();\n-        TopicPartition tp0 = new TopicPartition(\"test\", 0);\n-        responseData.put(tp0, new ProduceResponse.PartitionResponse(Errors.NONE,\n-                10000, RecordBatch.NO_TIMESTAMP, 100));\n-\n-        ProduceResponse v5Response = new ProduceResponse(responseData, 10);\n-        short version = 5;\n-\n-        ByteBuffer buffer = v5Response.serialize(ApiKeys.PRODUCE, version, 0);\n-        buffer.rewind();\n-\n-        ResponseHeader.parse(buffer, ApiKeys.PRODUCE.responseHeaderVersion(version)); // throw away.\n-\n-        Struct deserializedStruct = ApiKeys.PRODUCE.parseResponse(version, buffer);\n-\n-        ProduceResponse v5FromBytes = (ProduceResponse) AbstractResponse.parseResponse(ApiKeys.PRODUCE,\n-                deserializedStruct, version);\n-\n-        assertEquals(1, v5FromBytes.responses().size());\n-        assertTrue(v5FromBytes.responses().containsKey(tp0));\n-        ProduceResponse.PartitionResponse partitionResponse = v5FromBytes.responses().get(tp0);\n-        assertEquals(100, partitionResponse.logStartOffset);\n-        assertEquals(10000, partitionResponse.baseOffset);\n-        assertEquals(10, v5FromBytes.throttleTimeMs());\n-        assertEquals(responseData, v5Response.responses());\n-    }\n-\n-    @Test\n-    public void produceResponseVersionTest() {\n-        Map<TopicPartition, ProduceResponse.PartitionResponse> responseData = new HashMap<>();\n-        responseData.put(new TopicPartition(\"test\", 0), new ProduceResponse.PartitionResponse(Errors.NONE,\n-                10000, RecordBatch.NO_TIMESTAMP, 100));\n-        ProduceResponse v0Response = new ProduceResponse(responseData);\n-        ProduceResponse v1Response = new ProduceResponse(responseData, 10);\n-        ProduceResponse v2Response = new ProduceResponse(responseData, 10);\n-        assertEquals(\"Throttle time must be zero\", 0, v0Response.throttleTimeMs());\n-        assertEquals(\"Throttle time must be 10\", 10, v1Response.throttleTimeMs());\n-        assertEquals(\"Throttle time must be 10\", 10, v2Response.throttleTimeMs());\n-        assertEquals(\"Should use schema version 0\", ApiKeys.PRODUCE.responseSchema((short) 0),\n-                v0Response.toStruct((short) 0).schema());\n-        assertEquals(\"Should use schema version 1\", ApiKeys.PRODUCE.responseSchema((short) 1),\n-                v1Response.toStruct((short) 1).schema());\n-        assertEquals(\"Should use schema version 2\", ApiKeys.PRODUCE.responseSchema((short) 2),\n-                v2Response.toStruct((short) 2).schema());\n-        assertEquals(\"Response data does not match\", responseData, v0Response.responses());\n-        assertEquals(\"Response data does not match\", responseData, v1Response.responses());\n-        assertEquals(\"Response data does not match\", responseData, v2Response.responses());\n-    }\n-\n-    @Test\n-    public void produceResponseRecordErrorsTest() {\n-        Map<TopicPartition, ProduceResponse.PartitionResponse> responseData = new HashMap<>();\n-        TopicPartition tp = new TopicPartition(\"test\", 0);\n-        ProduceResponse.PartitionResponse partResponse = new ProduceResponse.PartitionResponse(Errors.NONE,\n-                10000, RecordBatch.NO_TIMESTAMP, 100,\n-                Collections.singletonList(new ProduceResponse.RecordError(3, \"Record error\")),\n-                \"Produce failed\");\n-        responseData.put(tp, partResponse);\n-\n-        for (short ver = 0; ver <= PRODUCE.latestVersion(); ver++) {\n-            ProduceResponse response = new ProduceResponse(responseData);\n-            Struct struct = response.toStruct(ver);\n-            assertEquals(\"Should use schema version \" + ver, ApiKeys.PRODUCE.responseSchema(ver), struct.schema());\n-            ProduceResponse.PartitionResponse deserialized = new ProduceResponse(struct).responses().get(tp);\n-            if (ver >= 8) {\n-                assertEquals(1, deserialized.recordErrors.size());\n-                assertEquals(3, deserialized.recordErrors.get(0).batchIndex);\n-                assertEquals(\"Record error\", deserialized.recordErrors.get(0).message);\n-                assertEquals(\"Produce failed\", deserialized.errorMessage);\n-            } else {\n-                assertEquals(0, deserialized.recordErrors.size());\n-                assertEquals(null, deserialized.errorMessage);\n-            }\n-        }\n-    }\n-\n     @Test\n     public void fetchResponseVersionTest() {\n         LinkedHashMap<TopicPartition, FetchResponse.PartitionData<MemoryRecords>> responseData = new LinkedHashMap<>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDE5MTEzMg==", "url": "https://github.com/apache/kafka/pull/8030#discussion_r374191132", "bodyText": "Should we convert the type of LOG_APPEND_TIME_KEY_NAME from long to Field.Int64? the benefit of using Field.Int64 is shown below.\n\nremove the duplicate code of converting LOG_APPEND_TIME_KEY_NAME  to Field.Int64\nuse more readable method - getOrElse", "author": "chia7712", "createdAt": "2020-02-03T16:07:17Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/ProduceResponse.java", "diffHunk": "@@ -222,7 +222,8 @@ public ProduceResponse(Struct struct) {\n                 int partition = partRespStruct.get(PARTITION_ID);\n                 Errors error = Errors.forCode(partRespStruct.get(ERROR_CODE));\n                 long offset = partRespStruct.getLong(BASE_OFFSET_KEY_NAME);\n-                long logAppendTime = partRespStruct.getLong(LOG_APPEND_TIME_KEY_NAME);\n+                long logAppendTime = partRespStruct.hasField(LOG_APPEND_TIME_KEY_NAME) ?", "originalCommit": "4e7132184b0e242d772193bc02522ca188c12f43", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDYyNzQzNQ==", "url": "https://github.com/apache/kafka/pull/8030#discussion_r374627435", "bodyText": "@chia7712 Thanks for the review. As @hachikuji mentioned, we can convert to use the generated classes, so will leave that for a separate PR.", "author": "rajinisivaram", "createdAt": "2020-02-04T11:55:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDE5MTEzMg=="}], "type": "inlineReview", "revised_code": null}, {"oid": "2585cc329ad15ec0b3a1e760018a6a4bf08917bd", "url": "https://github.com/apache/kafka/commit/2585cc329ad15ec0b3a1e760018a6a4bf08917bd", "message": "Address review comment", "committedDate": "2020-02-04T11:48:14Z", "type": "commit"}]}