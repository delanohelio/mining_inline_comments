{"pr_number": 9553, "pr_title": "KAFKA-10427:  Fetch snapshot", "pr_createdAt": "2020-11-03T18:59:48Z", "pr_url": "https://github.com/apache/kafka/pull/9553", "timeline": [{"oid": "514a043e6044f5eab52f21671a53bf8f513264f1", "url": "https://github.com/apache/kafka/commit/514a043e6044f5eab52f21671a53bf8f513264f1", "message": "Implement FetchSnapshot response handling", "committedDate": "2020-11-23T17:59:30Z", "type": "forcePushed"}, {"oid": "277e6a5c59d8e1e52324720fd262badd247ad3e7", "url": "https://github.com/apache/kafka/commit/277e6a5c59d8e1e52324720fd262badd247ad3e7", "message": "KAFKA-10427: Basic fetch snapshot implementation", "committedDate": "2020-12-08T02:14:58Z", "type": "commit"}, {"oid": "e64837768e79c3b78de2d5741cdbcbeb10b72737", "url": "https://github.com/apache/kafka/commit/e64837768e79c3b78de2d5741cdbcbeb10b72737", "message": "Implement FetchSnapshot response handling", "committedDate": "2020-12-08T02:14:58Z", "type": "commit"}, {"oid": "4ea3c9b4fe4a1e2528d322291665d0365dbc304e", "url": "https://github.com/apache/kafka/commit/4ea3c9b4fe4a1e2528d322291665d0365dbc304e", "message": "Include leader epoch in the FetchSnapshot request", "committedDate": "2020-12-08T02:14:58Z", "type": "commit"}, {"oid": "460992277664c781c08627514d8391bbad8cf5af", "url": "https://github.com/apache/kafka/commit/460992277664c781c08627514d8391bbad8cf5af", "message": "Fix FetchSnapsot request and response class", "committedDate": "2020-12-08T02:39:40Z", "type": "commit"}, {"oid": "460992277664c781c08627514d8391bbad8cf5af", "url": "https://github.com/apache/kafka/commit/460992277664c781c08627514d8391bbad8cf5af", "message": "Fix FetchSnapsot request and response class", "committedDate": "2020-12-08T02:39:40Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzk5MzE1Ng==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r537993156", "bodyText": "Fix this logic to be more conservative. It should be a fatal error if one is negative and the other is positive.", "author": "jsancio", "createdAt": "2020-12-08T02:51:09Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1037,6 +1047,14 @@ private boolean handleFetchResponse(\n                     logger.info(\"Truncated to offset {} from Fetch response from leader {}\",\n                         truncationOffset, quorum.leaderIdOrNil());\n                 });\n+            } else if (partitionResponse.snapshotId().epoch() >= 0 && partitionResponse.snapshotId().endOffset() >= 0) {", "originalCommit": "460992277664c781c08627514d8391bbad8cf5af", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "a96d16abfbd21a424fc3da78fbf69b6dc1630bac", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f4672bc1e5..f026b78726 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1047,8 +1047,29 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n                     logger.info(\"Truncated to offset {} from Fetch response from leader {}\",\n                         truncationOffset, quorum.leaderIdOrNil());\n                 });\n-            } else if (partitionResponse.snapshotId().epoch() >= 0 && partitionResponse.snapshotId().endOffset() >= 0) {\n+            } else if (partitionResponse.snapshotId().epoch() >= 0 ||\n+                       partitionResponse.snapshotId().endOffset() >= 0) {\n                 // The leader is asking us to fetch a snapshot\n+\n+                if (partitionResponse.snapshotId().epoch() < 0) {\n+                    throw new KafkaException(\n+                        String.format(\n+                            \"The leader sent a snapshot id with a valid end offset %s but with an invalid epoch %s\",\n+                            partitionResponse.snapshotId().endOffset(),\n+                            partitionResponse.snapshotId().epoch()\n+                        )\n+                    );\n+                }\n+                if (partitionResponse.snapshotId().endOffset() < 0) {\n+                    throw new KafkaException(\n+                        String.format(\n+                            \"The leader sent a snapshot id with a valid epoch %s but with an invalid end offset %s\",\n+                            partitionResponse.snapshotId().epoch(),\n+                            partitionResponse.snapshotId().endOffset()\n+                        )\n+                    );\n+                }\n+\n                 OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n                     partitionResponse.snapshotId().endOffset(),\n                     partitionResponse.snapshotId().epoch()\n"}}, {"oid": "a96d16abfbd21a424fc3da78fbf69b6dc1630bac", "url": "https://github.com/apache/kafka/commit/a96d16abfbd21a424fc3da78fbf69b6dc1630bac", "message": "Implement better snapshot id validation in fetch response", "committedDate": "2020-12-08T03:06:43Z", "type": "commit"}, {"oid": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "url": "https://github.com/apache/kafka/commit/79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "message": "Improve documentation", "committedDate": "2020-12-08T06:05:17Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODA2MDM5Nw==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r538060397", "bodyText": "The follower needs to update the log start offset and log end offset after it has successfully fetched a snapshot. I want to implement this part in this JIRA: https://issues.apache.org/jira/browse/KAFKA-10820", "author": "jsancio", "createdAt": "2020-12-08T06:08:51Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1101,6 +1140,174 @@ private DescribeQuorumResponseData handleDescribeQuorumRequest(\n         );\n     }\n \n+    private FetchSnapshotResponseData handleFetchSnapshotRequest(\n+        RaftRequest.Inbound requestMetadata\n+    ) throws IOException {\n+        FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+        }\n+\n+        Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            // The Raft client assumes that there is only one topic partition.\n+            TopicPartition unknownTopicPartition = new TopicPartition(\n+                data.topics().get(0).name(),\n+                data.topics().get(0).partitions().get(0).partition()\n+            );\n+\n+            return FetchSnapshotResponse.singleton(\n+                unknownTopicPartition,\n+                responsePartitionSnapshot -> {\n+                    return responsePartitionSnapshot\n+                        .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code());\n+                }\n+            );\n+        }\n+\n+        FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+        Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n+                partitionSnapshot.currentLeaderEpoch()\n+        );\n+        if (leaderValidation.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(leaderValidation.get().code());\n+                }\n+            );\n+        }\n+\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n+            partitionSnapshot.snapshotId().endOffset(),\n+            partitionSnapshot.snapshotId().epoch()\n+        );\n+        Optional<RawSnapshotReader> snapshotOpt = log.readSnapshot(snapshotId);\n+        if (!snapshotOpt.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code());\n+                }\n+            );\n+        }\n+\n+        try (RawSnapshotReader snapshot = snapshotOpt.get()) {\n+            int maxSnapshotSize;\n+            try {\n+                maxSnapshotSize = Math.toIntExact(snapshot.sizeInBytes());\n+            } catch (ArithmeticException e) {\n+                maxSnapshotSize = Integer.MAX_VALUE;\n+            }\n+\n+            // TODO: Make sure that we also limit based on the fetch max bytes configuration\n+            ByteBuffer buffer = ByteBuffer.allocate(Math.min(data.maxBytes(), maxSnapshotSize));\n+            snapshot.read(buffer, partitionSnapshot.position());\n+            buffer.flip();\n+\n+            long snapshotSize = snapshot.sizeInBytes();\n+\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    addQuorumLeader(responsePartitionSnapshot)\n+                        .snapshotId()\n+                        .setEndOffset(snapshotId.offset)\n+                        .setEpoch(snapshotId.epoch);\n+\n+                    return responsePartitionSnapshot\n+                        .setSize(snapshotSize)\n+                        .setPosition(partitionSnapshot.position())\n+                        .setBytes(buffer);\n+                }\n+            );\n+        }\n+    }\n+\n+    private boolean handleFetchSnapshotResponse(\n+        RaftResponse.Inbound responseMetadata,\n+        long currentTimeMs\n+    ) throws IOException {\n+        FetchSnapshotResponseData data = (FetchSnapshotResponseData) responseMetadata.data;\n+        Errors topLevelError = Errors.forCode(data.errorCode());\n+        if (topLevelError != Errors.NONE) {\n+            // TODO: check what values this expression returns\n+            return handleTopLevelError(topLevelError, responseMetadata);\n+        }\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return false;\n+        }\n+\n+        Optional<FetchSnapshotResponseData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotResponse\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            return false;\n+        }\n+\n+        FetchSnapshotResponseData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+\n+        FetchSnapshotResponseData.LeaderIdAndEpoch currentLeaderIdAndEpoch = partitionSnapshot.currentLeader();\n+        OptionalInt responseLeaderId = optionalLeaderId(currentLeaderIdAndEpoch.leaderId());\n+        int responseEpoch = currentLeaderIdAndEpoch.leaderEpoch();\n+        Errors error = Errors.forCode(partitionSnapshot.errorCode());\n+\n+        Optional<Boolean> handled = maybeHandleCommonResponse(\n+            error, responseLeaderId, responseEpoch, currentTimeMs);\n+        if (handled.isPresent()) {\n+            // TODO: check what values this expression returns\n+            return handled.get();\n+        }\n+\n+        FollowerState state = quorum.followerStateOrThrow();\n+\n+        if (Errors.forCode(partitionSnapshot.errorCode()) == Errors.SNAPSHOT_NOT_FOUND ||\n+            partitionSnapshot.snapshotId().endOffset() < 0 ||\n+            partitionSnapshot.snapshotId().epoch() < 0) {\n+\n+            /* The leader deleted the snapshot before the follower could download it. Start over by\n+             * reseting the fetching snapshot state and sending another fetch request.\n+             */\n+            state.setFetchingSnapshot(Optional.empty());\n+            state.resetFetchTimeout(currentTimeMs);\n+            return true;\n+        }\n+\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n+            partitionSnapshot.snapshotId().endOffset(),\n+            partitionSnapshot.snapshotId().epoch()\n+        );\n+\n+        RawSnapshotWriter snapshot;\n+        if (state.fetchingSnapshot().isPresent()) {\n+            snapshot = state.fetchingSnapshot().get();\n+        } else {\n+            throw new IllegalStateException(\"Received unexpected fetch snapshot response: \" + partitionSnapshot);\n+        }\n+\n+        if (!snapshot.snapshotId().equals(snapshotId)) {\n+            throw new IllegalStateException(String.format(\"Received fetch snapshot response with an invalid id. Expected %s; Received %s\", snapshot.snapshotId(), snapshotId));\n+        }\n+        if (snapshot.sizeInBytes() != partitionSnapshot.position()) {\n+            throw new IllegalStateException(String.format(\"Received fetch snapshot response with an invalid position. Expected %s; Received %s\", snapshot.sizeInBytes(), partitionSnapshot.position()));\n+        }\n+\n+        snapshot.append(partitionSnapshot.bytes());\n+\n+        if (snapshot.sizeInBytes() == partitionSnapshot.size()) {\n+            // Finished fetching the snapshot.\n+            snapshot.freeze();\n+            state.setFetchingSnapshot(Optional.empty());", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1146,7 +1141,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n         FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n \n         if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n-            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+            return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n         }\n \n         Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM4OTc5Ng==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547389796", "bodyText": "nit: maybe withTopLevelError?", "author": "hachikuji", "createdAt": "2020-12-22T16:57:40Z", "path": "clients/src/main/java/org/apache/kafka/common/requests/FetchSnapshotResponse.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.common.requests;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.UnaryOperator;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.message.FetchSnapshotResponseData;\n+import org.apache.kafka.common.protocol.ApiKeys;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.protocol.Message;\n+\n+final public class FetchSnapshotResponse extends AbstractResponse {\n+    public final FetchSnapshotResponseData data;\n+\n+    public FetchSnapshotResponse(FetchSnapshotResponseData data) {\n+        super(ApiKeys.FETCH_SNAPSHOT);\n+\n+        this.data = data;\n+    }\n+\n+    @Override\n+    public Map<Errors, Integer> errorCounts() {\n+        Map<Errors, Integer> errors = new HashMap<>();\n+\n+        Errors topLevelError = Errors.forCode(data.errorCode());\n+        if (topLevelError != Errors.NONE) {\n+            errors.put(topLevelError, 1);\n+        }\n+\n+        for (FetchSnapshotResponseData.TopicSnapshot topicResponse : data.topics()) {\n+            for (FetchSnapshotResponseData.PartitionSnapshot partitionResponse : topicResponse.partitions()) {\n+                errors.compute(Errors.forCode(partitionResponse.errorCode()),\n+                    (error, count) -> count == null ? 1 : count + 1);\n+            }\n+        }\n+\n+        return errors;\n+    }\n+\n+    @Override\n+    public int throttleTimeMs() {\n+        return data.throttleTimeMs();\n+    }\n+\n+    @Override\n+    protected Message data() {\n+        return data;\n+    }\n+\n+    /**\n+     * Creates a FetchSnapshotResponseData with a top level error.\n+     *\n+     * @param error the top level error\n+     * @return the created fetch snapshot response data\n+     */\n+    public static FetchSnapshotResponseData withTopError(Errors error) {", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/clients/src/main/java/org/apache/kafka/common/requests/FetchSnapshotResponse.java b/clients/src/main/java/org/apache/kafka/common/requests/FetchSnapshotResponse.java\nindex de0dab1d9e..b503292f5e 100644\n--- a/clients/src/main/java/org/apache/kafka/common/requests/FetchSnapshotResponse.java\n+++ b/clients/src/main/java/org/apache/kafka/common/requests/FetchSnapshotResponse.java\n\n@@ -71,7 +71,7 @@ final public class FetchSnapshotResponse extends AbstractResponse {\n      * @param error the top level error\n      * @return the created fetch snapshot response data\n      */\n-    public static FetchSnapshotResponseData withTopError(Errors error) {\n+    public static FetchSnapshotResponseData withTopLevelError(Errors error) {\n         return new FetchSnapshotResponseData().setErrorCode(error.code());\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5MTY4Ng==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547391686", "bodyText": "Maybe we could add a default no-op implementation to EpochState?", "author": "hachikuji", "createdAt": "2020-12-22T17:01:29Z", "path": "raft/src/main/java/org/apache/kafka/raft/LeaderState.java", "diffHunk": "@@ -287,4 +287,7 @@ public String name() {\n         return \"Leader\";\n     }\n \n+    @Override\n+    public void close() {}", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ4MzQ1Mg==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547483452", "bodyText": "I prefer to have each of the epoch states explicitly opt out of this close method. This makes it clear that this state doesn't have any resource that it wishes to clean/close during a transition. Instead of future code changes forgetting to override this method. What do you think?", "author": "jsancio", "createdAt": "2020-12-22T20:05:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5MTY4Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5Mjk5NA==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547392994", "bodyText": "Isn't this already done by buildFetchResponse?", "author": "hachikuji", "createdAt": "2020-12-22T17:04:16Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -941,6 +949,8 @@ private FetchResponseData tryCompleteFetchRequest(\n     ) {\n         Optional<Errors> errorOpt = validateLeaderOnlyRequest(request.currentLeaderEpoch());\n         if (errorOpt.isPresent()) {\n+            // TODO: The replica should return what information it knows about the current epoch and", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ3MjI2Ng==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547472266", "bodyText": "Yes. This was a note to me to confirm this as it wasn't clear to me when I first read the code.", "author": "jsancio", "createdAt": "2020-12-22T19:39:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5Mjk5NA=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -949,8 +949,6 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n     ) {\n         Optional<Errors> errorOpt = validateLeaderOnlyRequest(request.currentLeaderEpoch());\n         if (errorOpt.isPresent()) {\n-            // TODO: The replica should return what information it knows about the current epoch and\n-            // leader.\n             return buildEmptyFetchResponse(errorOpt.get(), Optional.empty());\n         }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NDc1NQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547394755", "bodyText": "Hmm.. The leader has sent a bad response. I think logging an error and retrying might be better than crashing the followers.", "author": "hachikuji", "createdAt": "2020-12-22T17:07:54Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1037,6 +1047,35 @@ private boolean handleFetchResponse(\n                     logger.info(\"Truncated to offset {} from Fetch response from leader {}\",\n                         truncationOffset, quorum.leaderIdOrNil());\n                 });\n+            } else if (partitionResponse.snapshotId().epoch() >= 0 ||\n+                       partitionResponse.snapshotId().endOffset() >= 0) {\n+                // The leader is asking us to fetch a snapshot\n+\n+                if (partitionResponse.snapshotId().epoch() < 0) {\n+                    throw new KafkaException(", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ3NTk3OA==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547475978", "bodyText": "Yeah. I am not sure. If these exception are thrown then it means that the epoch is \"valid\" but the end offset is not \"valid\" or vice versa. I think this could happen because of either a buggy remote replica or corrupted data in the remote replica.\nI guess you can argue that it is safe to keep retrying.\nIn the case that the Fetch never succeed do we want to transition to the candidate the state? If so, let me add a test that confirms that.", "author": "jsancio", "createdAt": "2020-12-22T19:48:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NDc1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU0ODgzMQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547548831", "bodyText": "Hmm.. I would rather not handle this case specially by transitioning to a candidate. It's not a crazy idea, but I think we should attempt that in a separate PR and consider errors more holistically.\nI would suggest that we log an error saying that the remote replica seemed to return an invalid response and just keep fetching. Then a user can see the log message and restart the remote replica.", "author": "hachikuji", "createdAt": "2020-12-22T23:04:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NDc1NQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1NjczOA==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547556738", "bodyText": "I would suggest that we log an error saying that the remote replica seemed to return an invalid response and just keep fetching. Then a user can see the log message and restart the remote replica.\n\nYeah. This is what I implemented and added a test for it. In other words.\n\nLog an error message\nTell the raft client that the response was handle successfully but the fetch timer was not reset\n\nIn practice this results in the follower continuing to send Fetch requests. After fetchTimeoutMs the follower will transition to candidate as the existing client code does. See https://github.com/apache/kafka/pull/9553/files#diff-86474ad1438150630c21b29a3da2f6dd79d1357e33ac034f00e5fcef0f2e889cR350\nLet me know if this is what you were thinking.", "author": "jsancio", "createdAt": "2020-12-22T23:31:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NDc1NQ=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1052,30 +1050,27 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n                 // The leader is asking us to fetch a snapshot\n \n                 if (partitionResponse.snapshotId().epoch() < 0) {\n-                    throw new KafkaException(\n-                        String.format(\n-                            \"The leader sent a snapshot id with a valid end offset %s but with an invalid epoch %s\",\n-                            partitionResponse.snapshotId().endOffset(),\n-                            partitionResponse.snapshotId().epoch()\n-                        )\n+                    logger.error(\n+                        \"The leader sent a snapshot id with a valid end offset {} but with an invalid epoch {}\",\n+                        partitionResponse.snapshotId().endOffset(),\n+                        partitionResponse.snapshotId().epoch()\n                     );\n-                }\n-                if (partitionResponse.snapshotId().endOffset() < 0) {\n-                    throw new KafkaException(\n-                        String.format(\n-                            \"The leader sent a snapshot id with a valid epoch %s but with an invalid end offset %s\",\n-                            partitionResponse.snapshotId().epoch(),\n-                            partitionResponse.snapshotId().endOffset()\n-                        )\n+                    return false;\n+                } else if (partitionResponse.snapshotId().endOffset() < 0) {\n+                    logger.error(\n+                        \"The leader sent a snapshot id with a valid epoch {} but with an invalid end offset {}\",\n+                        partitionResponse.snapshotId().epoch(),\n+                        partitionResponse.snapshotId().endOffset()\n+                    );\n+                    return false;\n+                } else {\n+                    OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n+                        partitionResponse.snapshotId().endOffset(),\n+                        partitionResponse.snapshotId().epoch()\n                     );\n-                }\n-\n-                OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n-                    partitionResponse.snapshotId().endOffset(),\n-                    partitionResponse.snapshotId().epoch()\n-                );\n \n-                state.setFetchingSnapshot(Optional.of(log.createSnapshot(snapshotId)));\n+                    state.setFetchingSnapshot(Optional.of(log.createSnapshot(snapshotId)));\n+                }\n             } else {\n                 Records records = (Records) partitionResponse.recordSet();\n                 if (records.sizeInBytes() > 0) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NjAzNQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547396035", "bodyText": "nit: I guess you could use leaderValidation.ifPresent", "author": "hachikuji", "createdAt": "2020-12-22T17:10:25Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1101,6 +1140,174 @@ private DescribeQuorumResponseData handleDescribeQuorumRequest(\n         );\n     }\n \n+    private FetchSnapshotResponseData handleFetchSnapshotRequest(\n+        RaftRequest.Inbound requestMetadata\n+    ) throws IOException {\n+        FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+        }\n+\n+        Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            // The Raft client assumes that there is only one topic partition.\n+            TopicPartition unknownTopicPartition = new TopicPartition(\n+                data.topics().get(0).name(),\n+                data.topics().get(0).partitions().get(0).partition()\n+            );\n+\n+            return FetchSnapshotResponse.singleton(\n+                unknownTopicPartition,\n+                responsePartitionSnapshot -> {\n+                    return responsePartitionSnapshot\n+                        .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code());\n+                }\n+            );\n+        }\n+\n+        FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+        Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n+                partitionSnapshot.currentLeaderEpoch()\n+        );\n+        if (leaderValidation.isPresent()) {", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQyNDM3NA==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547424374", "bodyText": "Hmm. I don't think so. ifPresent returns void and this part of the code wants to return a FetchSnapshotResponseData if there was a validation error. We can do a map followed by a isPresent and get but I think this is more consistent with the rest of the code.", "author": "jsancio", "createdAt": "2020-12-22T18:09:35Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NjAzNQ=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1146,7 +1141,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n         FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n \n         if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n-            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+            return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n         }\n \n         Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5Njg2OQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547396869", "bodyText": "Is it worth validating that partitionSnapshot.position() is non-negative?", "author": "hachikuji", "createdAt": "2020-12-22T17:12:11Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1101,6 +1140,174 @@ private DescribeQuorumResponseData handleDescribeQuorumRequest(\n         );\n     }\n \n+    private FetchSnapshotResponseData handleFetchSnapshotRequest(\n+        RaftRequest.Inbound requestMetadata\n+    ) throws IOException {\n+        FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+        }\n+\n+        Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            // The Raft client assumes that there is only one topic partition.\n+            TopicPartition unknownTopicPartition = new TopicPartition(\n+                data.topics().get(0).name(),\n+                data.topics().get(0).partitions().get(0).partition()\n+            );\n+\n+            return FetchSnapshotResponse.singleton(\n+                unknownTopicPartition,\n+                responsePartitionSnapshot -> {\n+                    return responsePartitionSnapshot\n+                        .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code());\n+                }\n+            );\n+        }\n+\n+        FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+        Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n+                partitionSnapshot.currentLeaderEpoch()\n+        );\n+        if (leaderValidation.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(leaderValidation.get().code());\n+                }\n+            );\n+        }\n+\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n+            partitionSnapshot.snapshotId().endOffset(),\n+            partitionSnapshot.snapshotId().epoch()\n+        );\n+        Optional<RawSnapshotReader> snapshotOpt = log.readSnapshot(snapshotId);\n+        if (!snapshotOpt.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code());\n+                }\n+            );\n+        }\n+\n+        try (RawSnapshotReader snapshot = snapshotOpt.get()) {\n+            int maxSnapshotSize;\n+            try {\n+                maxSnapshotSize = Math.toIntExact(snapshot.sizeInBytes());\n+            } catch (ArithmeticException e) {\n+                maxSnapshotSize = Integer.MAX_VALUE;\n+            }\n+\n+            // TODO: Make sure that we also limit based on the fetch max bytes configuration\n+            ByteBuffer buffer = ByteBuffer.allocate(Math.min(data.maxBytes(), maxSnapshotSize));\n+            snapshot.read(buffer, partitionSnapshot.position());", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQzNzgxNg==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547437816", "bodyText": "Good catch. In the KIP we added POSITION_OUT_OF_RANGE which I am not using any where in this PR.", "author": "jsancio", "createdAt": "2020-12-22T18:30:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5Njg2OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU1NDQxNg==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547554416", "bodyText": "Done.", "author": "jsancio", "createdAt": "2020-12-22T23:23:49Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5Njg2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1146,7 +1141,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n         FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n \n         if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n-            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+            return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n         }\n \n         Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5ODg1Nw==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547398857", "bodyText": "Address TODO?", "author": "hachikuji", "createdAt": "2020-12-22T17:15:47Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1101,6 +1140,174 @@ private DescribeQuorumResponseData handleDescribeQuorumRequest(\n         );\n     }\n \n+    private FetchSnapshotResponseData handleFetchSnapshotRequest(\n+        RaftRequest.Inbound requestMetadata\n+    ) throws IOException {\n+        FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+        }\n+\n+        Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            // The Raft client assumes that there is only one topic partition.\n+            TopicPartition unknownTopicPartition = new TopicPartition(\n+                data.topics().get(0).name(),\n+                data.topics().get(0).partitions().get(0).partition()\n+            );\n+\n+            return FetchSnapshotResponse.singleton(\n+                unknownTopicPartition,\n+                responsePartitionSnapshot -> {\n+                    return responsePartitionSnapshot\n+                        .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code());\n+                }\n+            );\n+        }\n+\n+        FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+        Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n+                partitionSnapshot.currentLeaderEpoch()\n+        );\n+        if (leaderValidation.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(leaderValidation.get().code());\n+                }\n+            );\n+        }\n+\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n+            partitionSnapshot.snapshotId().endOffset(),\n+            partitionSnapshot.snapshotId().epoch()\n+        );\n+        Optional<RawSnapshotReader> snapshotOpt = log.readSnapshot(snapshotId);\n+        if (!snapshotOpt.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code());\n+                }\n+            );\n+        }\n+\n+        try (RawSnapshotReader snapshot = snapshotOpt.get()) {\n+            int maxSnapshotSize;\n+            try {\n+                maxSnapshotSize = Math.toIntExact(snapshot.sizeInBytes());\n+            } catch (ArithmeticException e) {\n+                maxSnapshotSize = Integer.MAX_VALUE;\n+            }\n+\n+            // TODO: Make sure that we also limit based on the fetch max bytes configuration\n+            ByteBuffer buffer = ByteBuffer.allocate(Math.min(data.maxBytes(), maxSnapshotSize));\n+            snapshot.read(buffer, partitionSnapshot.position());\n+            buffer.flip();\n+\n+            long snapshotSize = snapshot.sizeInBytes();\n+\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    addQuorumLeader(responsePartitionSnapshot)\n+                        .snapshotId()\n+                        .setEndOffset(snapshotId.offset)\n+                        .setEpoch(snapshotId.epoch);\n+\n+                    return responsePartitionSnapshot\n+                        .setSize(snapshotSize)\n+                        .setPosition(partitionSnapshot.position())\n+                        .setBytes(buffer);\n+                }\n+            );\n+        }\n+    }\n+\n+    private boolean handleFetchSnapshotResponse(\n+        RaftResponse.Inbound responseMetadata,\n+        long currentTimeMs\n+    ) throws IOException {\n+        FetchSnapshotResponseData data = (FetchSnapshotResponseData) responseMetadata.data;\n+        Errors topLevelError = Errors.forCode(data.errorCode());\n+        if (topLevelError != Errors.NONE) {\n+            // TODO: check what values this expression returns", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ4MTIxMQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547481211", "bodyText": "Done. Excuse the noise.", "author": "jsancio", "createdAt": "2020-12-22T20:00:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5ODg1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1146,7 +1141,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n         FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n \n         if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n-            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+            return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n         }\n \n         Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5OTc4MQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547399781", "bodyText": "A log message would probably be helpful. It's probably worth doing one full pass over the logic here to see where we could add extra logging.", "author": "hachikuji", "createdAt": "2020-12-22T17:17:36Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1101,6 +1140,174 @@ private DescribeQuorumResponseData handleDescribeQuorumRequest(\n         );\n     }\n \n+    private FetchSnapshotResponseData handleFetchSnapshotRequest(\n+        RaftRequest.Inbound requestMetadata\n+    ) throws IOException {\n+        FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+        }\n+\n+        Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            // The Raft client assumes that there is only one topic partition.\n+            TopicPartition unknownTopicPartition = new TopicPartition(\n+                data.topics().get(0).name(),\n+                data.topics().get(0).partitions().get(0).partition()\n+            );\n+\n+            return FetchSnapshotResponse.singleton(\n+                unknownTopicPartition,\n+                responsePartitionSnapshot -> {\n+                    return responsePartitionSnapshot\n+                        .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code());\n+                }\n+            );\n+        }\n+\n+        FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+        Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n+                partitionSnapshot.currentLeaderEpoch()\n+        );\n+        if (leaderValidation.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(leaderValidation.get().code());\n+                }\n+            );\n+        }\n+\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n+            partitionSnapshot.snapshotId().endOffset(),\n+            partitionSnapshot.snapshotId().epoch()\n+        );\n+        Optional<RawSnapshotReader> snapshotOpt = log.readSnapshot(snapshotId);\n+        if (!snapshotOpt.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code());\n+                }\n+            );\n+        }\n+\n+        try (RawSnapshotReader snapshot = snapshotOpt.get()) {\n+            int maxSnapshotSize;\n+            try {\n+                maxSnapshotSize = Math.toIntExact(snapshot.sizeInBytes());\n+            } catch (ArithmeticException e) {\n+                maxSnapshotSize = Integer.MAX_VALUE;\n+            }\n+\n+            // TODO: Make sure that we also limit based on the fetch max bytes configuration\n+            ByteBuffer buffer = ByteBuffer.allocate(Math.min(data.maxBytes(), maxSnapshotSize));\n+            snapshot.read(buffer, partitionSnapshot.position());\n+            buffer.flip();\n+\n+            long snapshotSize = snapshot.sizeInBytes();\n+\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    addQuorumLeader(responsePartitionSnapshot)\n+                        .snapshotId()\n+                        .setEndOffset(snapshotId.offset)\n+                        .setEpoch(snapshotId.epoch);\n+\n+                    return responsePartitionSnapshot\n+                        .setSize(snapshotSize)\n+                        .setPosition(partitionSnapshot.position())\n+                        .setBytes(buffer);\n+                }\n+            );\n+        }\n+    }\n+\n+    private boolean handleFetchSnapshotResponse(\n+        RaftResponse.Inbound responseMetadata,\n+        long currentTimeMs\n+    ) throws IOException {\n+        FetchSnapshotResponseData data = (FetchSnapshotResponseData) responseMetadata.data;\n+        Errors topLevelError = Errors.forCode(data.errorCode());\n+        if (topLevelError != Errors.NONE) {\n+            // TODO: check what values this expression returns\n+            return handleTopLevelError(topLevelError, responseMetadata);\n+        }\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return false;\n+        }\n+\n+        Optional<FetchSnapshotResponseData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotResponse\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            return false;\n+        }\n+\n+        FetchSnapshotResponseData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+\n+        FetchSnapshotResponseData.LeaderIdAndEpoch currentLeaderIdAndEpoch = partitionSnapshot.currentLeader();\n+        OptionalInt responseLeaderId = optionalLeaderId(currentLeaderIdAndEpoch.leaderId());\n+        int responseEpoch = currentLeaderIdAndEpoch.leaderEpoch();\n+        Errors error = Errors.forCode(partitionSnapshot.errorCode());\n+\n+        Optional<Boolean> handled = maybeHandleCommonResponse(\n+            error, responseLeaderId, responseEpoch, currentTimeMs);\n+        if (handled.isPresent()) {\n+            // TODO: check what values this expression returns\n+            return handled.get();\n+        }\n+\n+        FollowerState state = quorum.followerStateOrThrow();\n+\n+        if (Errors.forCode(partitionSnapshot.errorCode()) == Errors.SNAPSHOT_NOT_FOUND ||\n+            partitionSnapshot.snapshotId().endOffset() < 0 ||\n+            partitionSnapshot.snapshotId().epoch() < 0) {\n+\n+            /* The leader deleted the snapshot before the follower could download it. Start over by", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1146,7 +1141,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n         FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n \n         if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n-            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+            return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n         }\n \n         Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwMTMyOQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547401329", "bodyText": "Can we move this logic to pollFollower somehow?", "author": "hachikuji", "createdAt": "2020-12-22T17:20:53Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1629,16 +1872,29 @@ private long pollFollowerAsVoter(FollowerState state, long currentTimeMs) throws\n             transitionToCandidate(currentTimeMs);\n             return 0L;\n         } else {\n-            long backoffMs = maybeSendRequest(\n-                currentTimeMs,\n-                state.leaderId(),\n-                this::buildFetchRequest\n-            );\n+            long backoffMs;\n+            if (state.fetchingSnapshot().isPresent()) {", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ4MTc4OA==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547481788", "bodyText": "I cleaned this up by moving it to a method we can reuse. Let me know if that addresses your concern.", "author": "jsancio", "createdAt": "2020-12-22T20:01:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwMTMyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1872,23 +1875,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n             transitionToCandidate(currentTimeMs);\n             return 0L;\n         } else {\n-            long backoffMs;\n-            if (state.fetchingSnapshot().isPresent()) {\n-                RawSnapshotWriter snapshot = state.fetchingSnapshot().get();\n-                long snapshotSize = snapshot.sizeInBytes();\n-\n-                backoffMs = maybeSendRequest(\n-                    currentTimeMs,\n-                    state.leaderId(),\n-                    () -> buildFetchSnapshotRequest(snapshot.snapshotId(), snapshotSize)\n-                );\n-            } else {\n-                backoffMs = maybeSendRequest(\n-                    currentTimeMs,\n-                    state.leaderId(),\n-                    this::buildFetchRequest\n-                );\n-            }\n+            long backoffMs = maybeSendFetchOrFetchSnapshot(state, currentTimeMs);\n \n             return Math.min(backoffMs, state.remainingFetchTimeMs(currentTimeMs));\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwMTg5OQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547401899", "bodyText": "I guess you're still planning to implement these?", "author": "hachikuji", "createdAt": "2020-12-22T17:22:09Z", "path": "raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java", "diffHunk": "@@ -0,0 +1,765 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements. See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ *\n+ *    http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.kafka.raft;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.Set;\n+import org.apache.kafka.common.TopicPartition;\n+import org.apache.kafka.common.memory.MemoryPool;\n+import org.apache.kafka.common.message.FetchResponseData;\n+import org.apache.kafka.common.message.FetchSnapshotRequestData;\n+import org.apache.kafka.common.message.FetchSnapshotResponseData;\n+import org.apache.kafka.common.protocol.Errors;\n+import org.apache.kafka.common.record.CompressionType;\n+import org.apache.kafka.common.requests.FetchSnapshotRequest;\n+import org.apache.kafka.common.requests.FetchSnapshotResponse;\n+import org.apache.kafka.common.utils.Utils;\n+import org.apache.kafka.raft.internals.StringSerde;\n+import org.apache.kafka.snapshot.RawSnapshotReader;\n+import org.apache.kafka.snapshot.RawSnapshotWriter;\n+import org.apache.kafka.snapshot.SnapshotWriter;\n+import org.apache.kafka.snapshot.SnapshotWriterTest;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Disabled;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+final public class KafkaRaftClientSnapshotTest {\n+    @Test\n+    public void testMissingFetchSnapshotRequest() throws Exception {\n+        int localId = 0;\n+        int epoch = 2;\n+        Set<Integer> voters = Utils.mkSet(localId, localId + 1);\n+\n+        RaftClientTestContext context = RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n+\n+        context.deliverRequest(\n+            fetchSnapshotRequest(\n+                context.metadataPartition,\n+                epoch,\n+                new OffsetAndEpoch(0, 0),\n+                Integer.MAX_VALUE,\n+                0\n+            )\n+        );\n+\n+        context.client.poll();\n+\n+        FetchSnapshotResponseData.PartitionSnapshot response =  context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n+        assertEquals(Errors.SNAPSHOT_NOT_FOUND, Errors.forCode(response.errorCode()));\n+    }\n+\n+    @Test\n+    public void testUnknownFetchSnapshotRequest() throws Exception {\n+        int localId = 0;\n+        Set<Integer> voters = Utils.mkSet(localId, localId + 1);\n+        int epoch = 2;\n+        TopicPartition topicPartition = new TopicPartition(\"unknown\", 0);\n+\n+        RaftClientTestContext context = RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n+\n+        context.deliverRequest(\n+            fetchSnapshotRequest(\n+                topicPartition,\n+                epoch,\n+                new OffsetAndEpoch(0, 0),\n+                Integer.MAX_VALUE,\n+                0\n+            )\n+        );\n+\n+        context.client.poll();\n+\n+        FetchSnapshotResponseData.PartitionSnapshot response =  context.assertSentFetchSnapshotResponse(topicPartition).get();\n+        assertEquals(Errors.UNKNOWN_TOPIC_OR_PARTITION, Errors.forCode(response.errorCode()));\n+    }\n+\n+    @Test\n+    public void testFetchSnapshotRequestAsLeader() throws Exception {\n+        int localId = 0;\n+        Set<Integer> voters = Utils.mkSet(localId, localId + 1);\n+        int epoch = 2;\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(0, 0);\n+        List<String> records = Arrays.asList(\"foo\", \"bar\");\n+\n+        RaftClientTestContext context = RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n+\n+        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(snapshotId)) {\n+            snapshot.append(records);\n+            snapshot.freeze();\n+        }\n+\n+        try (RawSnapshotReader snapshot = context.log.readSnapshot(snapshotId).get()) {\n+            context.deliverRequest(\n+                fetchSnapshotRequest(\n+                    context.metadataPartition,\n+                    epoch,\n+                    snapshotId,\n+                    Integer.MAX_VALUE,\n+                    0\n+                )\n+            );\n+\n+            context.client.poll();\n+\n+            FetchSnapshotResponseData.PartitionSnapshot response =  context\n+                .assertSentFetchSnapshotResponse(context.metadataPartition)\n+                .get();\n+\n+            assertEquals(Errors.NONE, Errors.forCode(response.errorCode()));\n+            assertEquals(snapshot.sizeInBytes(), response.size());\n+            assertEquals(0, response.position());\n+            assertEquals(snapshot.sizeInBytes(), response.bytes().remaining());\n+\n+            ByteBuffer buffer = ByteBuffer.allocate(Math.toIntExact(snapshot.sizeInBytes()));\n+            snapshot.read(buffer, 0);\n+            buffer.flip();\n+\n+            assertEquals(buffer.slice(), response.bytes());\n+        }\n+    }\n+\n+    @Test\n+    public void testPartialFetchSnapshotRequestAsLeader() throws Exception {\n+        int localId = 0;\n+        Set<Integer> voters = Utils.mkSet(localId, localId + 1);\n+        int epoch = 2;\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(0, 0);\n+        List<String> records = Arrays.asList(\"foo\", \"bar\");\n+\n+        RaftClientTestContext context = RaftClientTestContext.initializeAsLeader(localId, voters, epoch);\n+\n+        try (SnapshotWriter<String> snapshot = context.client.createSnapshot(snapshotId)) {\n+            snapshot.append(records);\n+            snapshot.freeze();\n+        }\n+\n+        try (RawSnapshotReader snapshot = context.log.readSnapshot(snapshotId).get()) {\n+            // Fetch half of the snapshot\n+            context.deliverRequest(\n+                fetchSnapshotRequest(\n+                    context.metadataPartition,\n+                    epoch,\n+                    snapshotId,\n+                    Math.toIntExact(snapshot.sizeInBytes() / 2),\n+                    0\n+                )\n+            );\n+\n+            context.client.poll();\n+\n+            FetchSnapshotResponseData.PartitionSnapshot response = context\n+                .assertSentFetchSnapshotResponse(context.metadataPartition)\n+                .get();\n+\n+            assertEquals(Errors.NONE, Errors.forCode(response.errorCode()));\n+            assertEquals(snapshot.sizeInBytes(), response.size());\n+            assertEquals(0, response.position());\n+            assertEquals(snapshot.sizeInBytes() / 2, response.bytes().remaining());\n+\n+            ByteBuffer snapshotBuffer = ByteBuffer.allocate(Math.toIntExact(snapshot.sizeInBytes()));\n+            snapshot.read(snapshotBuffer, 0);\n+            snapshotBuffer.flip();\n+\n+            ByteBuffer responseBuffer = ByteBuffer.allocate(Math.toIntExact(snapshot.sizeInBytes()));\n+            responseBuffer.put(response.bytes());\n+\n+            ByteBuffer expectedBytes = snapshotBuffer.duplicate();\n+            expectedBytes.limit(Math.toIntExact(snapshot.sizeInBytes() / 2));\n+\n+            assertEquals(expectedBytes, responseBuffer.duplicate().flip());\n+\n+            // Fetch the remainder of the snapshot\n+            context.deliverRequest(\n+                fetchSnapshotRequest(\n+                    context.metadataPartition,\n+                    epoch,\n+                    snapshotId,\n+                    Integer.MAX_VALUE,\n+                    responseBuffer.position()\n+                )\n+            );\n+\n+            context.client.poll();\n+\n+            response = context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n+            assertEquals(Errors.NONE, Errors.forCode(response.errorCode()));\n+            assertEquals(snapshot.sizeInBytes(), response.size());\n+            assertEquals(responseBuffer.position(), response.position());\n+            assertEquals(snapshot.sizeInBytes() - (snapshot.sizeInBytes() / 2), response.bytes().remaining());\n+\n+            responseBuffer.put(response.bytes());\n+            assertEquals(snapshotBuffer, responseBuffer.flip());\n+        }\n+    }\n+\n+    @Test\n+    public void testFetchSnapshotRequestAsFollower() throws IOException {\n+        int localId = 0;\n+        int leaderId = localId + 1;\n+        Set<Integer> voters = Utils.mkSet(localId, leaderId);\n+        int epoch = 2;\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(0, 0);\n+\n+        RaftClientTestContext context = new RaftClientTestContext.Builder(localId, voters)\n+            .withElectedLeader(epoch, leaderId)\n+            .build();\n+\n+        context.deliverRequest(\n+            fetchSnapshotRequest(\n+                context.metadataPartition,\n+                epoch,\n+                snapshotId,\n+                Integer.MAX_VALUE,\n+                0\n+            )\n+        );\n+\n+        context.client.poll();\n+\n+        FetchSnapshotResponseData.PartitionSnapshot response =  context.assertSentFetchSnapshotResponse(context.metadataPartition).get();\n+        assertEquals(Errors.NOT_LEADER_OR_FOLLOWER, Errors.forCode(response.errorCode()));\n+        assertEquals(epoch, response.currentLeader().leaderEpoch());\n+        assertEquals(leaderId, response.currentLeader().leaderId());\n+    }\n+\n+    @Disabled\n+    @Test\n+    public void testFetchSnapshotRequestWithOlderEpoch() throws IOException {\n+        assertTrue(false);", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ4NTAyMw==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547485023", "bodyText": "Yes. Doing that now...", "author": "jsancio", "createdAt": "2020-12-22T20:08:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwMTg5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java\nindex e8c375ea2f..86de6c0a04 100644\n--- a/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java\n+++ b/raft/src/test/java/org/apache/kafka/raft/KafkaRaftClientSnapshotTest.java\n\n@@ -596,6 +596,12 @@ final public class KafkaRaftClientSnapshotTest {\n         assertTrue(false);\n     }\n \n+    @Disabled\n+    @Test\n+    public void testFetchSnapshotResponseWithInvalidId() throws Exception {\n+        assertTrue(false);\n+    }\n+\n     private static FetchSnapshotRequestData fetchSnapshotRequest(\n         TopicPartition topicPartition,\n         int epoch,\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwNDkyNQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547404925", "bodyText": "Just checking my understanding. This patch adds the logic to respond to the snapshot id from a fetch response and to handle send/handle snapshots when needed. However, since it does not contain the logic to set the snapshot id in the fetch request handler, none of this logic will get exercised by the simulation test. Is that right?", "author": "hachikuji", "createdAt": "2020-12-22T17:28:15Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1101,6 +1140,174 @@ private DescribeQuorumResponseData handleDescribeQuorumRequest(\n         );\n     }\n \n+    private FetchSnapshotResponseData handleFetchSnapshotRequest(", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQxMjc0Ng==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547412746", "bodyText": "Correct. I am handling this case in https://issues.apache.org/jira/browse/KAFKA-10761. I think that after implementing that issue we should have an end-to-end working Raft Client with snapshot support that we test in the simulations.", "author": "jsancio", "createdAt": "2020-12-22T17:44:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwNDkyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1146,7 +1141,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n         FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n \n         if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n-            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+            return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n         }\n \n         Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ0NjY4OA==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547446688", "bodyText": "I created this issue: https://issues.apache.org/jira/browse/KAFKA-10884\nWe can fix this for Raft Client's implementation of both Fetch and FetchSnapshot at the same time.", "author": "jsancio", "createdAt": "2020-12-22T18:50:41Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1101,6 +1140,174 @@ private DescribeQuorumResponseData handleDescribeQuorumRequest(\n         );\n     }\n \n+    private FetchSnapshotResponseData handleFetchSnapshotRequest(\n+        RaftRequest.Inbound requestMetadata\n+    ) throws IOException {\n+        FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n+\n+        if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n+            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+        }\n+\n+        Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n+            .forTopicPartition(data, log.topicPartition());\n+        if (!partitionSnapshotOpt.isPresent()) {\n+            // The Raft client assumes that there is only one topic partition.\n+            TopicPartition unknownTopicPartition = new TopicPartition(\n+                data.topics().get(0).name(),\n+                data.topics().get(0).partitions().get(0).partition()\n+            );\n+\n+            return FetchSnapshotResponse.singleton(\n+                unknownTopicPartition,\n+                responsePartitionSnapshot -> {\n+                    return responsePartitionSnapshot\n+                        .setErrorCode(Errors.UNKNOWN_TOPIC_OR_PARTITION.code());\n+                }\n+            );\n+        }\n+\n+        FetchSnapshotRequestData.PartitionSnapshot partitionSnapshot = partitionSnapshotOpt.get();\n+        Optional<Errors> leaderValidation = validateLeaderOnlyRequest(\n+                partitionSnapshot.currentLeaderEpoch()\n+        );\n+        if (leaderValidation.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(leaderValidation.get().code());\n+                }\n+            );\n+        }\n+\n+        OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n+            partitionSnapshot.snapshotId().endOffset(),\n+            partitionSnapshot.snapshotId().epoch()\n+        );\n+        Optional<RawSnapshotReader> snapshotOpt = log.readSnapshot(snapshotId);\n+        if (!snapshotOpt.isPresent()) {\n+            return FetchSnapshotResponse.singleton(\n+                log.topicPartition(),\n+                responsePartitionSnapshot -> {\n+                    return addQuorumLeader(responsePartitionSnapshot)\n+                        .setErrorCode(Errors.SNAPSHOT_NOT_FOUND.code());\n+                }\n+            );\n+        }\n+\n+        try (RawSnapshotReader snapshot = snapshotOpt.get()) {\n+            int maxSnapshotSize;\n+            try {\n+                maxSnapshotSize = Math.toIntExact(snapshot.sizeInBytes());\n+            } catch (ArithmeticException e) {\n+                maxSnapshotSize = Integer.MAX_VALUE;\n+            }\n+\n+            // TODO: Make sure that we also limit based on the fetch max bytes configuration", "originalCommit": "79fed6115ce20aedee3cea0cc9a4a8c5ba1bcca2", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex f5cb42a689..5b29ef9178 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1146,7 +1141,7 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n         FetchSnapshotRequestData data = (FetchSnapshotRequestData) requestMetadata.data;\n \n         if (data.topics().size() != 1 && data.topics().get(0).partitions().size() != 1) {\n-            return FetchSnapshotResponse.withTopError(Errors.INVALID_REQUEST);\n+            return FetchSnapshotResponse.withTopLevelError(Errors.INVALID_REQUEST);\n         }\n \n         Optional<FetchSnapshotRequestData.PartitionSnapshot> partitionSnapshotOpt = FetchSnapshotRequest\n"}}, {"oid": "33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "url": "https://github.com/apache/kafka/commit/33be3a4be9b8f558e1d0cd0dadc8c98ee82eeb26", "message": "Add position out of range error", "committedDate": "2020-12-22T20:15:38Z", "type": "commit"}, {"oid": "2393cf75bb0f3854ae10d629c09207a5c0675640", "url": "https://github.com/apache/kafka/commit/2393cf75bb0f3854ae10d629c09207a5c0675640", "message": "Add the remaining tests", "committedDate": "2020-12-22T23:20:14Z", "type": "commit"}, {"oid": "61de910301b0add34289f4421e8d7d6bed5d9f6e", "url": "https://github.com/apache/kafka/commit/61de910301b0add34289f4421e8d7d6bed5d9f6e", "message": "Merge remote-tracking branch 'upstream/trunk' into kafka-10427-fetch-snapshot", "committedDate": "2020-12-23T00:00:27Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDYxOQ==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547574619", "bodyText": "Returning false seemed more appropriate. That ensures we will get a backoff before the next retry.", "author": "hachikuji", "createdAt": "2020-12-23T00:40:51Z", "path": "raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java", "diffHunk": "@@ -1055,14 +1055,14 @@ private boolean handleFetchResponse(\n                         partitionResponse.snapshotId().endOffset(),\n                         partitionResponse.snapshotId().epoch()\n                     );\n-                    return false;\n+                    return true;", "originalCommit": "2393cf75bb0f3854ae10d629c09207a5c0675640", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU5MTM4Mw==", "url": "https://github.com/apache/kafka/pull/9553#discussion_r547591383", "bodyText": "Done.", "author": "jsancio", "createdAt": "2020-12-23T01:32:08Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzU3NDYxOQ=="}], "type": "inlineReview", "revised_code": {"commit": "cad8284a4333fffb5b15c09b0d71a0a38a8cd7c1", "chunk": "diff --git a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\nindex 246ac1f337..241e08cf7d 100644\n--- a/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n+++ b/raft/src/main/java/org/apache/kafka/raft/KafkaRaftClient.java\n\n@@ -1055,14 +1071,14 @@ public class KafkaRaftClient<T> implements RaftClient<T> {\n                         partitionResponse.snapshotId().endOffset(),\n                         partitionResponse.snapshotId().epoch()\n                     );\n-                    return true;\n+                    return false;\n                 } else if (partitionResponse.snapshotId().endOffset() < 0) {\n                     logger.error(\n                         \"The leader sent a snapshot id with a valid epoch {} but with an invalid end offset {}\",\n                         partitionResponse.snapshotId().epoch(),\n                         partitionResponse.snapshotId().endOffset()\n                     );\n-                    return true;\n+                    return false;\n                 } else {\n                     OffsetAndEpoch snapshotId = new OffsetAndEpoch(\n                         partitionResponse.snapshotId().endOffset(),\n"}}, {"oid": "cad8284a4333fffb5b15c09b0d71a0a38a8cd7c1", "url": "https://github.com/apache/kafka/commit/cad8284a4333fffb5b15c09b0d71a0a38a8cd7c1", "message": "Invalid snapshot should back off instead of reporting success", "committedDate": "2020-12-23T01:30:48Z", "type": "commit"}, {"oid": "22133d1166394ea4ffbf111aeb8eb063c2182cd8", "url": "https://github.com/apache/kafka/commit/22133d1166394ea4ffbf111aeb8eb063c2182cd8", "message": "Add missing parsing code", "committedDate": "2020-12-23T18:09:54Z", "type": "commit"}]}