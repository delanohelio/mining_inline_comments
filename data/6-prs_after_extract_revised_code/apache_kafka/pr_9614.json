{"pr_number": 9614, "pr_title": "KAFKA-10500: Add failed-stream-threads metric for adding + removing stream threads", "pr_createdAt": "2020-11-18T18:12:29Z", "pr_url": "https://github.com/apache/kafka/pull/9614", "timeline": [{"oid": "17843bfd0d471356e91cce82cb466806c63b853c", "url": "https://github.com/apache/kafka/commit/17843bfd0d471356e91cce82cb466806c63b853c", "message": "adding failed stream metric", "committedDate": "2020-11-17T21:17:03Z", "type": "commit"}, {"oid": "b32c64d8892438dc305ad4c51f455ee4e6347e46", "url": "https://github.com/apache/kafka/commit/b32c64d8892438dc305ad4c51f455ee4e6347e46", "message": "adding testing", "committedDate": "2020-11-18T17:22:23Z", "type": "commit"}, {"oid": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db", "url": "https://github.com/apache/kafka/commit/845b1750959d4cf69d8ce905d79b6a6c89c6c2db", "message": "Merge branch 'trunk' into thread_metrics", "committedDate": "2020-11-18T18:14:14Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526331025", "bodyText": "We also need to verify that the metric works when there is a failed stream thread. Options are (1) to create a custom processor now and (IIRC) run the test suite twice, once with failing stream threads and once without to confirm that the metric works. I'm not sure if the custom processor will let us just fail one stream thread right before closing the app. Or (2) wait until add/remove stream threads is implemented and remove threads and test the metric after removing some threads before closing the app. WDYT?", "author": "lct45", "createdAt": "2020-11-18T18:37:29Z", "path": "streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java", "diffHunk": "@@ -377,7 +378,7 @@ private void shouldAddMetricsOnAllLevels(final String builtInMetricsVersion) thr\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-\n+        verifyFailedStreamThreadsSensor(0.0);", "originalCommit": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1Mjc5Ng==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526352796", "bodyText": "I think you should try using the custom processor. You can find an example in StreamsUncaughtExceptionHandlerIntegrationTest.java", "author": "wcarlson5", "createdAt": "2020-11-18T19:12:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkzNTU4Ng==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526935586", "bodyText": "I would put the test whether the metric is recorded correctly in StreamThreadTest. An example for such a test is shouldLogAndRecordSkippedRecordsForInvalidTimestamps(). I do not think an integration test is needed. The test regarding the existence of the metric, i.e., checkMetricByName(listMetricThread, FAILED_STREAM_THREADS, 1); should stay here.", "author": "cadonna", "createdAt": "2020-11-19T14:37:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzcyNDMzOA==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r527724338", "bodyText": "After looking at both test classes, I think it actually might make the most sense to put the test for this metric in StreamsUncaughtExceptionHandlerIntegrationTest, since the metric is so closely aligned with the exception handler anyways and the setup works nicely with what we're trying to test with the metric. From the size + complexity of the other test classes, I think creating an overloaded processor for one test out of 20+ tests seems tricky.", "author": "lct45", "createdAt": "2020-11-20T14:22:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjMzMTAyNQ=="}], "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java b/streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java\nindex 481b0f2f0b..72d65fce47 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/integration/MetricsIntegrationTest.java\n\n@@ -378,7 +378,7 @@ public class MetricsIntegrationTest {\n             builtInMetricsVersion\n         );\n         checkCacheMetrics(builtInMetricsVersion);\n-        verifyFailedStreamThreadsSensor(0.0);\n+\n         closeApplication();\n \n         checkMetricsDeregistration();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0NzM1OQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526347359", "bodyText": "This seems wrong. There are a few duplicate calls here", "author": "wcarlson5", "createdAt": "2020-11-18T19:03:38Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1070,6 +1070,10 @@ private Thread shutdownHelper(final boolean error) {\n             adminClient.close();\n \n             streamsMetrics.removeAllClientLevelMetrics();", "originalCommit": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1NTgzOA==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526355838", "bodyText": "Ahh, got mixed up when I rebased trunk", "author": "lct45", "createdAt": "2020-11-18T19:17:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0NzM1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "44db7af16b663dba85e2d126947e239f475f63fe", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\nindex fac4173a4e..a7b32dfbaf 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n\n@@ -1069,12 +1069,10 @@ public class KafkaStreams implements AutoCloseable {\n \n             adminClient.close();\n \n-            streamsMetrics.removeAllClientLevelMetrics();\n-            metrics.close();\n             streamsMetrics.removeAllClientLevelMetrics();\n             streamsMetrics.removeAllClientLevelSensors();\n-\n             metrics.close();\n+\n             if (!error) {\n                 setState(State.NOT_RUNNING);\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM0ODU3OA==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526348578", "bodyText": "We probably don't want to skip this log. Can you move the sensor in here?", "author": "wcarlson5", "createdAt": "2020-11-18T19:05:45Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -219,6 +220,8 @@ State setState(final State newState) {\n             } else if (!state.isValidTransition(newState)) {\n                 log.error(\"Unexpected state transition from {} to {}\", oldState, newState);\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n+            } else if (newState == State.DEAD) {\n+                failedStreamThreadSensor.record();\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);", "originalCommit": "845b1750959d4cf69d8ce905d79b6a6c89c6c2db", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "44db7af16b663dba85e2d126947e239f475f63fe", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\nindex d6f6d90e30..1f0002e401 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n\n@@ -220,10 +219,11 @@ public class StreamThread extends Thread {\n             } else if (!state.isValidTransition(newState)) {\n                 log.error(\"Unexpected state transition from {} to {}\", oldState, newState);\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n-            } else if (newState == State.DEAD) {\n-                failedStreamThreadSensor.record();\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);\n+                if (newState == State.DEAD) {\n+                    failedStreamThreadSensor.record();\n+                }\n             }\n \n             state = newState;\n"}}, {"oid": "44db7af16b663dba85e2d126947e239f475f63fe", "url": "https://github.com/apache/kafka/commit/44db7af16b663dba85e2d126947e239f475f63fe", "message": "Walker's updates", "committedDate": "2020-11-18T22:38:25Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg4MDQxMg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526880412", "bodyText": "Could you please add a public method to StreamsMetricsImpl named removeAllClientLevelSensorsAndMetrics() that calls removeAllClientLevelMetrics() and removeAllClientLevelSensors() and make the latter two methods private?", "author": "cadonna", "createdAt": "2020-11-19T13:29:31Z", "path": "streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java", "diffHunk": "@@ -1070,7 +1070,9 @@ private Thread shutdownHelper(final boolean error) {\n             adminClient.close();\n \n             streamsMetrics.removeAllClientLevelMetrics();\n+            streamsMetrics.removeAllClientLevelSensors();", "originalCommit": "44db7af16b663dba85e2d126947e239f475f63fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\nindex a7b32dfbaf..71701f52b5 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/KafkaStreams.java\n\n@@ -1069,10 +1069,8 @@ public class KafkaStreams implements AutoCloseable {\n \n             adminClient.close();\n \n-            streamsMetrics.removeAllClientLevelMetrics();\n-            streamsMetrics.removeAllClientLevelSensors();\n+            streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n             metrics.close();\n-\n             if (!error) {\n                 setState(State.NOT_RUNNING);\n             }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg4NjM2OQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526886369", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads so far for a given Kafka Streams client\";\n          \n          \n            \n                private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads since the start of the Kafka Streams client\";", "author": "cadonna", "createdAt": "2020-11-19T13:33:43Z", "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "diffHunk": "@@ -60,6 +65,7 @@ private ClientMetrics() {}\n         \"The description of the topology executed in the Kafka Streams client\";\n     private static final String STATE_DESCRIPTION = \"The state of the Kafka Streams client\";\n     private static final String ALIVE_STREAM_THREADS_DESCRIPTION = \"The current number of alive stream threads that are running or participating in rebalance\";\n+    private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads so far for a given Kafka Streams client\";", "originalCommit": "44db7af16b663dba85e2d126947e239f475f63fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java b/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java\nindex eb535bbba8..242a547fb0 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java\n\n@@ -65,7 +65,7 @@ public class ClientMetrics {\n         \"The description of the topology executed in the Kafka Streams client\";\n     private static final String STATE_DESCRIPTION = \"The state of the Kafka Streams client\";\n     private static final String ALIVE_STREAM_THREADS_DESCRIPTION = \"The current number of alive stream threads that are running or participating in rebalance\";\n-    private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads so far for a given Kafka Streams client\";\n+    private static final String FAILED_STREAM_THREADS_DESCRIPTION = \"The number of failed stream threads since the start of the Kafka Streams client\";\n \n     public static String version() {\n         return VERSION_FROM_FILE;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NTQ0Nw==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526895447", "bodyText": "nit: I like to insert a blank line after the call to test to visually separate setup, call, and verification.", "author": "cadonna", "createdAt": "2020-11-19T13:42:11Z", "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "diffHunk": "@@ -99,6 +121,27 @@ public void shouldAddAliveStreamThreadsMetric() {\n         );\n     }\n \n+    @Test\n+    public void shouldGetFailedStreamThreadsSensor() {\n+        final String name = \"failed-stream-threads\";\n+        final String description = \"The number of failed stream threads so far for a given Kafka Streams client\";\n+        expect(streamsMetrics.clientLevelSensor(name, RecordingLevel.INFO)).andReturn(expectedSensor);\n+        expect(streamsMetrics.clientLevelTagMap()).andReturn(tagMap);\n+        StreamsMetricsImpl.addSumMetricToSensor(\n+            expectedSensor,\n+            CLIENT_LEVEL_GROUP,\n+            tagMap,\n+            name,\n+            false,\n+            description\n+        );\n+        replay(StreamsMetricsImpl.class, streamsMetrics);\n+\n+        final Sensor sensor = ClientMetrics.failedStreamThreadSensor(streamsMetrics);", "originalCommit": "44db7af16b663dba85e2d126947e239f475f63fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java b/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java\nindex b953134f13..6dc465cf1a 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java\n\n@@ -124,7 +124,7 @@ public class ClientMetricsTest {\n     @Test\n     public void shouldGetFailedStreamThreadsSensor() {\n         final String name = \"failed-stream-threads\";\n-        final String description = \"The number of failed stream threads so far for a given Kafka Streams client\";\n+        final String description = \"The number of failed stream threads since the start of the Kafka Streams client\";\n         expect(streamsMetrics.clientLevelSensor(name, RecordingLevel.INFO)).andReturn(expectedSensor);\n         expect(streamsMetrics.clientLevelTagMap()).andReturn(tagMap);\n         StreamsMetricsImpl.addSumMetricToSensor(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NzEzNQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526897135", "bodyText": "Unit tests for this method are missing.", "author": "cadonna", "createdAt": "2020-11-19T13:44:38Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,", "originalCommit": "44db7af16b663dba85e2d126947e239f475f63fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\nindex dbd48d4685..8ecb2a1602 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n\n@@ -223,7 +223,7 @@ public class StreamsMetricsImpl implements StreamsMetrics {\n             final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n             return Optional.ofNullable(metrics.getSensor(fullSensorName))\n                 .orElseGet(() -> {\n-                    clientLevelSensors.computeIfAbsent(key, ignored -> new LinkedList<>()).push(fullSensorName);\n+                    clientLevelSensors.push(fullSensorName);\n                     return metrics.sensor(fullSensorName, recordingLevel, parents);\n                 });\n         }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjg5NzIzNA==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526897234", "bodyText": "Unit tests for this method are missing. Please also consider my comment in class KafkaStreams for these unit tests.", "author": "cadonna", "createdAt": "2020-11-19T13:44:46Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -253,6 +268,16 @@ public final void removeAllClientLevelMetrics() {\n         }\n     }\n \n+    public final void removeAllClientLevelSensors() {", "originalCommit": "44db7af16b663dba85e2d126947e239f475f63fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\nindex dbd48d4685..8ecb2a1602 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n\n@@ -260,7 +260,12 @@ public class StreamsMetricsImpl implements StreamsMetrics {\n         return tagMap;\n     }\n \n-    public final void removeAllClientLevelMetrics() {\n+    public final void removeAllClientLevelSensorsAndMetrics() {\n+        removeAllClientLevelSensors();\n+        removeAllClientLevelMetrics();\n+    }\n+\n+    private final void removeAllClientLevelMetrics() {\n         synchronized (clientLevelMetrics) {\n             while (!clientLevelMetrics.isEmpty()) {\n                 metrics.removeMetric(clientLevelMetrics.pop());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkwOTkyNw==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526909927", "bodyText": "Here you should just need a queue as for clientLevelMetrics. We need a map for the other levels because there can be multiple objects for each level, e.g., there might be multiple stream thread and each one manages its sensors under a key in the map. However, there is only one client on client level.", "author": "cadonna", "createdAt": "2020-11-19T14:02:40Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -93,6 +93,7 @@ public int hashCode() {\n \n     private final Version version;\n     private final Deque<MetricName> clientLevelMetrics = new LinkedList<>();\n+    private final Map<String, Deque<String>> clientLevelSensors = new HashMap<>();", "originalCommit": "44db7af16b663dba85e2d126947e239f475f63fe", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\nindex dbd48d4685..8ecb2a1602 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n\n@@ -93,7 +93,7 @@ public class StreamsMetricsImpl implements StreamsMetrics {\n \n     private final Version version;\n     private final Deque<MetricName> clientLevelMetrics = new LinkedList<>();\n-    private final Map<String, Deque<String>> clientLevelSensors = new HashMap<>();\n+    private final Deque<String> clientLevelSensors = new LinkedList<>();\n     private final Map<String, Deque<String>> threadLevelSensors = new HashMap<>();\n     private final Map<String, Deque<String>> taskLevelSensors = new HashMap<>();\n     private final Map<String, Deque<String>> nodeLevelSensors = new HashMap<>();\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkxNDY2OA==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r526914668", "bodyText": "Not every dead stream thread is a failed stream thread. You should record this metric where the uncaught exception handler is called because there we now that a stream thread died unexpectedly.", "author": "cadonna", "createdAt": "2020-11-19T14:09:34Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java", "diffHunk": "@@ -221,6 +221,9 @@ State setState(final State newState) {\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);\n+                if (newState == State.DEAD) {\n+                    failedStreamThreadSensor.record();\n+                }", "originalCommit": "44db7af16b663dba85e2d126947e239f475f63fe", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzExNzY4NQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r527117685", "bodyText": "Would that just be in run() of the GlobalStreamThread then?", "author": "lct45", "createdAt": "2020-11-19T18:46:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkxNDY2OA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzEyMjc3Mg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r527122772", "bodyText": "No, that would be in StreamThread#runLoop().", "author": "cadonna", "createdAt": "2020-11-19T18:54:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjkxNDY2OA=="}], "type": "inlineReview", "revised_code": {"commit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\nindex 1f0002e401..8e348db0c0 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/StreamThread.java\n\n@@ -221,9 +222,6 @@ public class StreamThread extends Thread {\n                 throw new StreamsException(logPrefix + \"Unexpected state transition from \" + oldState + \" to \" + newState);\n             } else {\n                 log.info(\"State transition from {} to {}\", oldState, newState);\n-                if (newState == State.DEAD) {\n-                    failedStreamThreadSensor.record();\n-                }\n             }\n \n             state = newState;\n"}}, {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "url": "https://github.com/apache/kafka/commit/f6db8cdd4e9f880bf34baf471212b980f8da7092", "message": "Updated testing and fixes", "committedDate": "2020-11-23T16:20:23Z", "type": "commit"}, {"oid": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "url": "https://github.com/apache/kafka/commit/f6db8cdd4e9f880bf34baf471212b980f8da7092", "message": "Updated testing and fixes", "committedDate": "2020-11-23T16:20:23Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMwODk0Ng==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529308946", "bodyText": "You can inline the value of variable key here and remove key.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n          \n          \n            \n                        final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;", "author": "cadonna", "createdAt": "2020-11-24T09:00:03Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        final String key = CLIENT_LEVEL_GROUP;\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\nindex 8ecb2a1602..16c9621acf 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n\n@@ -218,14 +218,14 @@ public class StreamsMetricsImpl implements StreamsMetrics {\n     public final Sensor clientLevelSensor(final String sensorName,\n                                           final RecordingLevel recordingLevel,\n                                           final Sensor... parents) {\n-        final String key = CLIENT_LEVEL_GROUP;\n         synchronized (clientLevelSensors) {\n-            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n-            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n-                .orElseGet(() -> {\n-                    clientLevelSensors.push(fullSensorName);\n-                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n-                });\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);\n+            if (sensor == null) {\n+                clientLevelSensors.push(fullSensorName);\n+                return metrics.sensor(fullSensorName, recordingLevel, parents);\n+            }\n+            return sensor;\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMxMzAyMg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529313022", "bodyText": "Although, we use this in other methods, I think the following is a bit simpler to read:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        return Optional.ofNullable(metrics.getSensor(fullSensorName))\n          \n          \n            \n                            .orElseGet(() -> {\n          \n          \n            \n                                clientLevelSensors.push(fullSensorName);\n          \n          \n            \n                                return metrics.sensor(fullSensorName, recordingLevel, parents);\n          \n          \n            \n                            });\n          \n          \n            \n                    final Sensor sensor = metrics.getSensor(fullSensorName);\n          \n          \n            \n                    if (sensor == null) {\n          \n          \n            \n                        clientLevelSensors.push(fullSensorName);\n          \n          \n            \n                        return metrics.sensor(fullSensorName, recordingLevel, parents);\n          \n          \n            \n                    }\n          \n          \n            \n                    return sensor;", "author": "cadonna", "createdAt": "2020-11-24T09:03:22Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        final String key = CLIENT_LEVEL_GROUP;\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n+            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n+                .orElseGet(() -> {\n+                    clientLevelSensors.push(fullSensorName);\n+                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n+                });", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\nindex 8ecb2a1602..16c9621acf 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n\n@@ -218,14 +218,14 @@ public class StreamsMetricsImpl implements StreamsMetrics {\n     public final Sensor clientLevelSensor(final String sensorName,\n                                           final RecordingLevel recordingLevel,\n                                           final Sensor... parents) {\n-        final String key = CLIENT_LEVEL_GROUP;\n         synchronized (clientLevelSensors) {\n-            final String fullSensorName = key + SENSOR_NAME_DELIMITER + sensorName;\n-            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n-                .orElseGet(() -> {\n-                    clientLevelSensors.push(fullSensorName);\n-                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n-                });\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);\n+            if (sensor == null) {\n+                clientLevelSensors.push(fullSensorName);\n+                return metrics.sensor(fullSensorName, recordingLevel, parents);\n+            }\n+            return sensor;\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMxNzM5OA==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529317398", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n          \n          \n            \n                        SENSOR_NAME_1,\n          \n          \n            \n                        recordingLevel\n          \n          \n            \n                    );\n          \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);", "author": "cadonna", "createdAt": "2020-11-24T09:07:08Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -577,6 +579,38 @@ public void shouldGetExistingCacheLevelSensor() {\n         assertThat(actualSensor, is(equalToObject(sensor)));\n     }\n \n+    @Test\n+    public void shouldGetNewClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetNewSensorTest(metrics, recordingLevel);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );\n+\n+        verify(metrics);\n+        assertThat(actualSensor, is(equalToObject(sensor)));\n+    }\n+\n+    @Test\n+    public void shouldGetExistingClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetExistingSensorTest(metrics);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\nindex 981beda15c..facdc2694f 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n\n@@ -586,10 +586,7 @@ public class StreamsMetricsImplTest {\n         setupGetNewSensorTest(metrics, recordingLevel);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n \n-        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n-            SENSOR_NAME_1,\n-            recordingLevel\n-        );\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);\n \n         verify(metrics);\n         assertThat(actualSensor, is(equalToObject(sensor)));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMyMjk2Ng==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529322966", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n          \n          \n            \n                        SENSOR_NAME_1,\n          \n          \n            \n                        recordingLevel\n          \n          \n            \n                    );\n          \n          \n            \n                    final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);", "author": "cadonna", "createdAt": "2020-11-24T09:11:37Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -577,6 +579,38 @@ public void shouldGetExistingCacheLevelSensor() {\n         assertThat(actualSensor, is(equalToObject(sensor)));\n     }\n \n+    @Test\n+    public void shouldGetNewClientLevelSensor() {\n+        final Metrics metrics = mock(Metrics.class);\n+        final RecordingLevel recordingLevel = RecordingLevel.INFO;\n+        setupGetNewSensorTest(metrics, recordingLevel);\n+        final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n+\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n+            SENSOR_NAME_1,\n+            recordingLevel\n+        );", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\nindex 981beda15c..facdc2694f 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n\n@@ -586,10 +586,7 @@ public class StreamsMetricsImplTest {\n         setupGetNewSensorTest(metrics, recordingLevel);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n \n-        final Sensor actualSensor = streamsMetrics.clientLevelSensor(\n-            SENSOR_NAME_1,\n-            recordingLevel\n-        );\n+        final Sensor actualSensor = streamsMetrics.clientLevelSensor(SENSOR_NAME_1, recordingLevel);\n \n         verify(metrics);\n         assertThat(actualSensor, is(equalToObject(sensor)));\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMzOTI3Mg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529339272", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(0));\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(1));\n          \n          \n            \n            \n          \n          \n            \n                    expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    replay(metrics);\n          \n          \n            \n            \n          \n          \n            \n                    streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n          \n          \n            \n                    verify(metrics);\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(0));\n          \n          \n            \n                    metrics.removeSensor(sensorKeys.getValues().get(1));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n          \n          \n            \n                    replay(metrics);\n          \n          \n            \n            \n          \n          \n            \n                    streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n          \n          \n            \n            \n          \n          \n            \n                    verify(metrics);", "author": "cadonna", "createdAt": "2020-11-24T09:24:34Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,17 +663,20 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n \n-        streamsMetrics.removeAllClientLevelMetrics();\n+        metrics.removeSensor(sensorKeys.getValues().get(0));\n+        metrics.removeSensor(sensorKeys.getValues().get(1));\n+\n+        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n+        replay(metrics);\n \n+        streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n         verify(metrics);", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\nindex 981beda15c..facdc2694f 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n\n@@ -671,12 +665,11 @@ public class StreamsMetricsImplTest {\n \n         metrics.removeSensor(sensorKeys.getValues().get(0));\n         metrics.removeSensor(sensorKeys.getValues().get(1));\n-\n         expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n         expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n         replay(metrics);\n-\n         streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n+\n         verify(metrics);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTMzOTU4Mg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529339582", "bodyText": "Please remove this empty line.", "author": "cadonna", "createdAt": "2020-11-24T09:24:48Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,17 +663,20 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n ", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\nindex 981beda15c..facdc2694f 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n\n@@ -671,12 +665,11 @@ public class StreamsMetricsImplTest {\n \n         metrics.removeSensor(sensorKeys.getValues().get(0));\n         metrics.removeSensor(sensorKeys.getValues().get(1));\n-\n         expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n         expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n         replay(metrics);\n-\n         streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n+\n         verify(metrics);\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM0MDk3Ng==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529340976", "bodyText": "Please remove empty line.", "author": "cadonna", "createdAt": "2020-11-24T09:25:52Z", "path": "streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java", "diffHunk": "@@ -99,6 +121,29 @@ public void shouldAddAliveStreamThreadsMetric() {\n         );\n     }\n \n+    @Test\n+    public void shouldGetFailedStreamThreadsSensor() {\n+        final String name = \"failed-stream-threads\";\n+        final String description = \"The number of failed stream threads since the start of the Kafka Streams client\";\n+        expect(streamsMetrics.clientLevelSensor(name, RecordingLevel.INFO)).andReturn(expectedSensor);\n+        expect(streamsMetrics.clientLevelTagMap()).andReturn(tagMap);\n+        StreamsMetricsImpl.addSumMetricToSensor(\n+            expectedSensor,\n+            CLIENT_LEVEL_GROUP,\n+            tagMap,\n+            name,\n+            false,\n+            description\n+        );\n+", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java b/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java\nindex 6dc465cf1a..d86cd83f45 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/internals/metrics/ClientMetricsTest.java\n\n@@ -135,7 +135,6 @@ public class ClientMetricsTest {\n             false,\n             description\n         );\n-\n         replay(StreamsMetricsImpl.class, streamsMetrics);\n \n         final Sensor sensor = ClientMetrics.failedStreamThreadSensor(streamsMetrics);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM2Mzc5Ng==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529363796", "bodyText": "You can remove these lines. They are dead code.", "author": "cadonna", "createdAt": "2020-11-24T09:44:03Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {\n+        final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n+        final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n+        final StreamsMetricsImpl streamsMetrics =\n+            new StreamsMetricsImpl(metrics, CLIENT_ID, StreamsConfig.METRICS_LATEST, mockTime);\n+        final StreamThread thread = new StreamThread(\n+            mockTime,\n+            config,\n+            null,\n+            consumer,\n+            consumer,\n+            null,\n+            null,\n+            taskManager,\n+            streamsMetrics,\n+            internalTopologyBuilder,\n+            CLIENT_ID,\n+            new LogContext(\"\"),\n+            new AtomicInteger(),\n+            new AtomicLong(Long.MAX_VALUE),\n+            null,\n+            e -> { }\n+        ) {\n+            @Override\n+            void runOnce() {\n+                setState(StreamThread.State.PENDING_SHUTDOWN);\n+                if (shouldFail) {\n+                    throw new StreamsException(Thread.currentThread().getName());\n+                }\n+            }\n+        };\n+        expect(taskManager.activeTaskMap()).andReturn(Collections.emptyMap());\n+        expect(taskManager.standbyTaskMap()).andReturn(Collections.emptyMap());\n+\n+        taskManager.process(anyInt(), anyObject());\n+        EasyMock.expectLastCall().andThrow(new StreamsException(Thread.currentThread().getName()));\n+", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\nindex 95743beaea..e7ce9a3cf1 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n\n@@ -2441,12 +2440,16 @@ public class StreamThreadTest {\n     }\n \n     @Test\n-    public void shouldCountFailedStreamThread() {\n-        verifyFailedStreamThread(false);\n-        verifyFailedStreamThread(true);\n+    public void shouldNotRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(false);\n     }\n \n-    public void verifyFailedStreamThread(final boolean shouldFail) {\n+    @Test\n+    public void shouldRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(true);\n+    }\n+\n+    public void runAndVerifyFailedStreamThreadRecording(final boolean shouldFail) {\n         final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n         final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n         final StreamsMetricsImpl streamsMetrics =\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM2OTMxMw==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529369313", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            \n          \n          \n            \n                    EasyMock.replay(taskManager);\n          \n          \n            \n            \n          \n          \n            \n                    thread.updateThreadMetadata(\"metadata\");\n          \n          \n            \n                    thread.setState(StreamThread.State.STARTING);\n          \n          \n            \n                    thread.runLoop();\n          \n          \n            \n            \n          \n          \n            \n                    final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n          \n          \n            \n            \n          \n          \n            \n                    assertEquals(shouldFail ? 1.0 : 0.0, failedThreads.metricValue());\n          \n          \n            \n                    EasyMock.replay(taskManager);\n          \n          \n            \n                    thread.updateThreadMetadata(\"metadata\");\n          \n          \n            \n                    thread.setState(StreamThread.State.STARTING);\n          \n          \n            \n                    \n          \n          \n            \n                    thread.runLoop();\n          \n          \n            \n            \n          \n          \n            \n                    final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n          \n          \n            \n                    assertThat(failedThreads.metricValue(), is(shouldFail ? 1.0 : 0.0));", "author": "cadonna", "createdAt": "2020-11-24T09:48:30Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {\n+        final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n+        final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n+        final StreamsMetricsImpl streamsMetrics =\n+            new StreamsMetricsImpl(metrics, CLIENT_ID, StreamsConfig.METRICS_LATEST, mockTime);\n+        final StreamThread thread = new StreamThread(\n+            mockTime,\n+            config,\n+            null,\n+            consumer,\n+            consumer,\n+            null,\n+            null,\n+            taskManager,\n+            streamsMetrics,\n+            internalTopologyBuilder,\n+            CLIENT_ID,\n+            new LogContext(\"\"),\n+            new AtomicInteger(),\n+            new AtomicLong(Long.MAX_VALUE),\n+            null,\n+            e -> { }\n+        ) {\n+            @Override\n+            void runOnce() {\n+                setState(StreamThread.State.PENDING_SHUTDOWN);\n+                if (shouldFail) {\n+                    throw new StreamsException(Thread.currentThread().getName());\n+                }\n+            }\n+        };\n+        expect(taskManager.activeTaskMap()).andReturn(Collections.emptyMap());\n+        expect(taskManager.standbyTaskMap()).andReturn(Collections.emptyMap());\n+\n+        taskManager.process(anyInt(), anyObject());\n+        EasyMock.expectLastCall().andThrow(new StreamsException(Thread.currentThread().getName()));\n+\n+        EasyMock.replay(taskManager);\n+\n+        thread.updateThreadMetadata(\"metadata\");\n+        thread.setState(StreamThread.State.STARTING);\n+        thread.runLoop();\n+\n+        final Metric failedThreads = StreamsTestUtils.getMetricByName(metrics.metrics(), \"failed-stream-threads\", \"stream-metrics\");\n+\n+        assertEquals(shouldFail ? 1.0 : 0.0, failedThreads.metricValue());", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\nindex 95743beaea..e7ce9a3cf1 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n\n@@ -2441,12 +2440,16 @@ public class StreamThreadTest {\n     }\n \n     @Test\n-    public void shouldCountFailedStreamThread() {\n-        verifyFailedStreamThread(false);\n-        verifyFailedStreamThread(true);\n+    public void shouldNotRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(false);\n     }\n \n-    public void verifyFailedStreamThread(final boolean shouldFail) {\n+    @Test\n+    public void shouldRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(true);\n+    }\n+\n+    public void runAndVerifyFailedStreamThreadRecording(final boolean shouldFail) {\n         final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n         final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n         final StreamsMetricsImpl streamsMetrics =\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDM2Mg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529384362", "bodyText": "I would rename this method to runAndVerifyFailedStreamThreadRecording().", "author": "cadonna", "createdAt": "2020-11-24T09:59:55Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }\n+\n+    public void verifyFailedStreamThread(final boolean shouldFail) {", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\nindex 95743beaea..e7ce9a3cf1 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n\n@@ -2441,12 +2440,16 @@ public class StreamThreadTest {\n     }\n \n     @Test\n-    public void shouldCountFailedStreamThread() {\n-        verifyFailedStreamThread(false);\n-        verifyFailedStreamThread(true);\n+    public void shouldNotRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(false);\n     }\n \n-    public void verifyFailedStreamThread(final boolean shouldFail) {\n+    @Test\n+    public void shouldRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(true);\n+    }\n+\n+    public void runAndVerifyFailedStreamThreadRecording(final boolean shouldFail) {\n         final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n         final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n         final StreamsMetricsImpl streamsMetrics =\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTM4NDY5Nw==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r529384697", "bodyText": "Could you please specify two separate unit tests? One could be named shouldRecordFailedStreamThread() and the other shouldNotRecordFailedStreamThread().", "author": "cadonna", "createdAt": "2020-11-24T10:00:15Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java", "diffHunk": "@@ -2438,6 +2440,60 @@ public void shouldConstructAdminMetrics() {\n         assertEquals(testMetricName, adminClientMetrics.get(testMetricName).metricName());\n     }\n \n+    @Test\n+    public void shouldCountFailedStreamThread() {\n+        verifyFailedStreamThread(false);\n+        verifyFailedStreamThread(true);\n+    }", "originalCommit": "f6db8cdd4e9f880bf34baf471212b980f8da7092", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "e395ba706e59f13af996c83177e5846878adb3e8", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\nindex 95743beaea..e7ce9a3cf1 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/StreamThreadTest.java\n\n@@ -2441,12 +2440,16 @@ public class StreamThreadTest {\n     }\n \n     @Test\n-    public void shouldCountFailedStreamThread() {\n-        verifyFailedStreamThread(false);\n-        verifyFailedStreamThread(true);\n+    public void shouldNotRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(false);\n     }\n \n-    public void verifyFailedStreamThread(final boolean shouldFail) {\n+    @Test\n+    public void shouldRecordFailedStreamThread() {\n+        runAndVerifyFailedStreamThreadRecording(true);\n+    }\n+\n+    public void runAndVerifyFailedStreamThreadRecording(final boolean shouldFail) {\n         final Consumer<byte[], byte[]> consumer = EasyMock.createNiceMock(Consumer.class);\n         final TaskManager taskManager = EasyMock.createNiceMock(TaskManager.class);\n         final StreamsMetricsImpl streamsMetrics =\n"}}, {"oid": "e395ba706e59f13af996c83177e5846878adb3e8", "url": "https://github.com/apache/kafka/commit/e395ba706e59f13af996c83177e5846878adb3e8", "message": "Review clean up", "committedDate": "2020-11-24T15:51:08Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxODA5Mw==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533018093", "bodyText": "nit: missing empty line", "author": "mjsax", "createdAt": "2020-12-01T01:44:44Z", "path": "streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java", "diffHunk": "@@ -125,4 +131,16 @@ public static void addNumAliveStreamThreadMetric(final StreamsMetricsImpl stream\n             stateProvider\n         );\n     }\n+    public static Sensor failedStreamThreadSensor(final StreamsMetricsImpl streamsMetrics) {", "originalCommit": "e395ba706e59f13af996c83177e5846878adb3e8", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "fc6cf529d9e4becb5871913a34711a37dd6916dc", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java b/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java\nindex 242a547fb0..209d2b9da1 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/internals/metrics/ClientMetrics.java\n\n@@ -131,6 +131,7 @@ public class ClientMetrics {\n             stateProvider\n         );\n     }\n+\n     public static Sensor failedStreamThreadSensor(final StreamsMetricsImpl streamsMetrics) {\n         final Sensor sensor = streamsMetrics.clientLevelSensor(FAILED_STREAM_THREADS, RecordingLevel.INFO);\n         addSumMetricToSensor(\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533020449", "bodyText": "Should we rewrite this the same way threadLevelSensor is written (ie, using orElseGet) for consistency?", "author": "mjsax", "createdAt": "2020-12-01T01:51:48Z", "path": "streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java", "diffHunk": "@@ -214,6 +215,20 @@ public RocksDBMetricsRecordingTrigger rocksDBMetricsRecordingTrigger() {\n         }\n     }\n \n+    public final Sensor clientLevelSensor(final String sensorName,\n+                                          final RecordingLevel recordingLevel,\n+                                          final Sensor... parents) {\n+        synchronized (clientLevelSensors) {\n+            final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n+            final Sensor sensor = metrics.getSensor(fullSensorName);", "originalCommit": "e395ba706e59f13af996c83177e5846878adb3e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE0ODMzNQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533148335", "bodyText": "I requested this. See my comment #9614 (comment)", "author": "cadonna", "createdAt": "2020-12-01T08:22:27Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU3MDUzNQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533570535", "bodyText": "I'm good either way (:", "author": "lct45", "createdAt": "2020-12-01T16:57:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYzOTkyMg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533639922", "bodyText": "I am fine either way, too, but I prefer consistency... So should we rewrite the other method as a side cleanup?", "author": "mjsax", "createdAt": "2020-12-01T18:43:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzY0MTU0MA==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533641540", "bodyText": "I am fine with consistency and clean-up, but I would like to have the clean-up in a separate PR.", "author": "cadonna", "createdAt": "2020-12-01T18:46:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI1NjYwNQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r534256605", "bodyText": "I changed it back for consistency and will open up a fix PR to update both of them to the new syntax", "author": "lct45", "createdAt": "2020-12-02T15:28:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMDQ0OQ=="}], "type": "inlineReview", "revised_code": {"commit": "c5df6eb31efe029519f633de1cded887306edb29", "chunk": "diff --git a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\nindex 16c9621acf..a05dbd9d2f 100644\n--- a/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n+++ b/streams/src/main/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImpl.java\n\n@@ -220,12 +220,11 @@ public class StreamsMetricsImpl implements StreamsMetrics {\n                                           final Sensor... parents) {\n         synchronized (clientLevelSensors) {\n             final String fullSensorName = CLIENT_LEVEL_GROUP + SENSOR_NAME_DELIMITER + sensorName;\n-            final Sensor sensor = metrics.getSensor(fullSensorName);\n-            if (sensor == null) {\n-                clientLevelSensors.push(fullSensorName);\n-                return metrics.sensor(fullSensorName, recordingLevel, parents);\n-            }\n-            return sensor;\n+            return Optional.ofNullable(metrics.getSensor(fullSensorName))\n+                .orElseGet(() -> {\n+                    clientLevelSensors.push(fullSensorName);\n+                    return metrics.sensor(fullSensorName, recordingLevel, parents);\n+                });\n         }\n     }\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMzM1Nw==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533023357", "bodyText": "Why did we change this from andStubReturn(null) to andReturn(mock(KafkaMetric.class))?", "author": "mjsax", "createdAt": "2020-12-01T02:00:40Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -629,16 +657,18 @@ private void setupRemoveSensorsTest(final Metrics metrics,\n     }\n \n     @Test\n-    public void shouldRemoveClientLevelMetrics() {\n+    public void shouldRemoveClientLevelMetricsAndSensors() {\n         final Metrics metrics = niceMock(Metrics.class);\n         final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION, time);\n-        addSensorsOnAllLevels(metrics, streamsMetrics);\n+        final Capture<String> sensorKeys = addSensorsOnAllLevels(metrics, streamsMetrics);\n         resetToDefault(metrics);\n-        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n-        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n-        replay(metrics);\n \n-        streamsMetrics.removeAllClientLevelMetrics();\n+        metrics.removeSensor(sensorKeys.getValues().get(0));\n+        metrics.removeSensor(sensorKeys.getValues().get(1));\n+        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));", "originalCommit": "e395ba706e59f13af996c83177e5846878adb3e8", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4NTYzOQ==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533585639", "bodyText": "Must've been an accidental change when trying to get the test to work. shouldRemoveStateStoreLevelSensors uses andReturn(mock(KafkaMetric.class)) so that's where it came from, but this test works with andStubReturn(null) so I changed it back to that", "author": "lct45", "createdAt": "2020-12-01T17:19:11Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMzM1Nw=="}], "type": "inlineReview", "revised_code": {"commit": "fc6cf529d9e4becb5871913a34711a37dd6916dc", "chunk": "diff --git a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\nindex facdc2694f..42743bce4c 100644\n--- a/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n+++ b/streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java\n\n@@ -665,8 +664,8 @@ public class StreamsMetricsImplTest {\n \n         metrics.removeSensor(sensorKeys.getValues().get(0));\n         metrics.removeSensor(sensorKeys.getValues().get(1));\n-        expect(metrics.removeMetric(metricName1)).andReturn(mock(KafkaMetric.class));\n-        expect(metrics.removeMetric(metricName2)).andReturn(mock(KafkaMetric.class));\n+        expect(metrics.removeMetric(metricName1)).andStubReturn(null);\n+        expect(metrics.removeMetric(metricName2)).andStubReturn(null);\n         replay(metrics);\n         streamsMetrics.removeAllClientLevelSensorsAndMetrics();\n \n"}}, {"oid": "fc6cf529d9e4becb5871913a34711a37dd6916dc", "url": "https://github.com/apache/kafka/commit/fc6cf529d9e4becb5871913a34711a37dd6916dc", "message": "Fixes from Matthias's comments", "committedDate": "2020-12-01T17:17:06Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzU4NjU4Mg==", "url": "https://github.com/apache/kafka/pull/9614#discussion_r533586582", "bodyText": "This wasn't being used so I went ahead and took it out", "author": "lct45", "createdAt": "2020-12-01T17:20:30Z", "path": "streams/src/test/java/org/apache/kafka/streams/processor/internals/metrics/StreamsMetricsImplTest.java", "diffHunk": "@@ -619,8 +647,7 @@ public void shouldProvideCorrectStrings() {\n     }\n \n     private void setupRemoveSensorsTest(final Metrics metrics,\n-                                        final String level,\n-                                        final RecordingLevel recordingLevel) {", "originalCommit": "fc6cf529d9e4becb5871913a34711a37dd6916dc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "c5df6eb31efe029519f633de1cded887306edb29", "url": "https://github.com/apache/kafka/commit/c5df6eb31efe029519f633de1cded887306edb29", "message": "updated consistency", "committedDate": "2020-12-02T15:27:37Z", "type": "commit"}]}