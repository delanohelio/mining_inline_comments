{"pr_number": 9354, "pr_title": "KAFKA-10134 Follow-up: Set the re-join flag in heartbeat failure", "pr_createdAt": "2020-09-29T23:39:09Z", "pr_url": "https://github.com/apache/kafka/pull/9354", "timeline": [{"oid": "52a2029211ee6395140064f4db1403c6084cdb7b", "url": "https://github.com/apache/kafka/commit/52a2029211ee6395140064f4db1403c6084cdb7b", "message": "set the re-join flag in hb failure", "committedDate": "2020-09-29T23:38:07Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MzUyNw==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497383527", "bodyText": "@dajac I feel this patch can fix https://issues.apache.org/jira/browse/KAFKA-8266\nThe test case in https://issues.apache.org/jira/browse/KAFKA-8266 restarts all brokers to activate new configs. However, the data of group (__consumer_offsets) may get lost if all brokers are killed too quick (the log folder is changed when restarting broker so the restarting broker has to fetch data from other brokers). The heartbeat of running consumer will encounter UNKNOWN_MEMBER_ID in sending heartbeat request since the group data is gone. Without this patch, the heartbeat thread is disabled and the state is in UNJOINED but the rejoinNeeded is still false. In short, the consumer is not going to rejoin group so we can't see expected error.", "author": "chia7712", "createdAt": "2020-09-30T09:49:50Z", "path": "clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java", "diffHunk": "@@ -948,7 +948,7 @@ private synchronized void resetStateAndRejoin() {\n     synchronized void resetGenerationOnResponseError(ApiKeys api, Errors error) {\n         log.debug(\"Resetting generation after encountering {} from {} response and requesting re-join\", error, api);\n \n-        resetState();\n+        resetStateAndRejoin();", "originalCommit": "52a2029211ee6395140064f4db1403c6084cdb7b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzY5OTY1Mw==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497699653", "bodyText": "Nice find! I analyzed the logs and I was actually trying to find out why the consumer was not rejoining. The logs coincides with what you described. It may be due to this as you pointed out.", "author": "dajac", "createdAt": "2020-09-30T17:58:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MzUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzcwOTU1MA==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497709550", "bodyText": "@chia7712 @dajac I think this bug is only introduced recently in this PR: #8834. If your tests is executed before it then maybe there are other issues yet to be discovered.", "author": "guozhangwang", "createdAt": "2020-09-30T18:16:28Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MzUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzcyMTk1MA==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497721950", "bodyText": "That test became flaky quite recently. Time wise, that could coincides. I will try to run the test without #8834 to check tomorrow.", "author": "dajac", "createdAt": "2020-09-30T18:38:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MzUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzk2MTgxNg==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497961816", "bodyText": "It seems that we would rejoin on FENCED_INSTANCE_ID as well, is that intentional? \n  \n    \n      kafka/clients/src/main/java/org/apache/kafka/clients/consumer/internals/AbstractCoordinator.java\n    \n    \n         Line 1106\n      in\n      bd462df\n    \n    \n    \n    \n\n        \n          \n           error == Errors.FENCED_INSTANCE_ID) {", "author": "abbccdda", "createdAt": "2020-10-01T03:19:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MzUyNw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU3NjM3OA==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r498576378", "bodyText": "That is fine since in the outer caller FENCED_INSTANCE_ID would be treated as fatal, in line 1386.", "author": "guozhangwang", "createdAt": "2020-10-02T00:46:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzM4MzUyNw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzk2MDYwMw==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497960603", "bodyText": "Could we remove this print statement?", "author": "abbccdda", "createdAt": "2020-10-01T03:13:50Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -1934,12 +1933,20 @@ public void testReturnRecordsDuringRebalance() {\n         fetches1.put(tp0, new FetchInfo(3, 1));\n         client.respondFrom(fetchResponse(fetches1), node);\n \n-        records = consumer.poll(Duration.ZERO);\n+        // now complete teh rebalance\n+        client.respondFrom(syncGroupResponse(Arrays.asList(tp0, t3p0), Errors.NONE), coordinator);\n+\n+        AtomicInteger count = new AtomicInteger(0);\n+        TestUtils.waitForCondition(() -> {\n+            ConsumerRecords<String, String> recs = consumer.poll(Duration.ofMillis(100L));\n+            System.out.println(\"count \" + count.addAndGet(recs.count()));", "originalCommit": "52a2029211ee6395140064f4db1403c6084cdb7b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "34cd77113701ff54ef1c90cde12497e5c01132ca", "chunk": "diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\nindex a0efa70e0b..e86331c36b 100644\n--- a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\n+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\n\n@@ -1933,14 +1932,13 @@ public class KafkaConsumerTest {\n         fetches1.put(tp0, new FetchInfo(3, 1));\n         client.respondFrom(fetchResponse(fetches1), node);\n \n-        // now complete teh rebalance\n+        // now complete the rebalance\n         client.respondFrom(syncGroupResponse(Arrays.asList(tp0, t3p0), Errors.NONE), coordinator);\n \n         AtomicInteger count = new AtomicInteger(0);\n         TestUtils.waitForCondition(() -> {\n             ConsumerRecords<String, String> recs = consumer.poll(Duration.ofMillis(100L));\n-            System.out.println(\"count \" + count.addAndGet(recs.count()));\n-            return consumer.assignment().equals(Utils.mkSet(tp0, t3p0)) && count.get() == 1;\n+            return consumer.assignment().equals(Utils.mkSet(tp0, t3p0)) && count.addAndGet(recs.count()) == 1;\n \n         }, \"Does not complete rebalance in time\");\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzk2MDYxOA==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497960618", "bodyText": "s/teh/the", "author": "abbccdda", "createdAt": "2020-10-01T03:13:58Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -1934,12 +1933,20 @@ public void testReturnRecordsDuringRebalance() {\n         fetches1.put(tp0, new FetchInfo(3, 1));\n         client.respondFrom(fetchResponse(fetches1), node);\n \n-        records = consumer.poll(Duration.ZERO);\n+        // now complete teh rebalance", "originalCommit": "52a2029211ee6395140064f4db1403c6084cdb7b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "34cd77113701ff54ef1c90cde12497e5c01132ca", "chunk": "diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\nindex a0efa70e0b..e86331c36b 100644\n--- a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\n+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\n\n@@ -1933,14 +1932,13 @@ public class KafkaConsumerTest {\n         fetches1.put(tp0, new FetchInfo(3, 1));\n         client.respondFrom(fetchResponse(fetches1), node);\n \n-        // now complete teh rebalance\n+        // now complete the rebalance\n         client.respondFrom(syncGroupResponse(Arrays.asList(tp0, t3p0), Errors.NONE), coordinator);\n \n         AtomicInteger count = new AtomicInteger(0);\n         TestUtils.waitForCondition(() -> {\n             ConsumerRecords<String, String> recs = consumer.poll(Duration.ofMillis(100L));\n-            System.out.println(\"count \" + count.addAndGet(recs.count()));\n-            return consumer.assignment().equals(Utils.mkSet(tp0, t3p0)) && count.get() == 1;\n+            return consumer.assignment().equals(Utils.mkSet(tp0, t3p0)) && count.addAndGet(recs.count()) == 1;\n \n         }, \"Does not complete rebalance in time\");\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzk2MDY2Ng==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r497960666", "bodyText": "Same here", "author": "abbccdda", "createdAt": "2020-10-01T03:14:12Z", "path": "clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java", "diffHunk": "@@ -1948,10 +1955,14 @@ public void testReturnRecordsDuringRebalance() {\n         fetches1.put(t3p0, new FetchInfo(0, 100));\n         client.respondFrom(fetchResponse(fetches1), node);\n \n-        records = consumer.poll(Duration.ZERO);\n+        count.set(0);\n+        TestUtils.waitForCondition(() -> {\n+            ConsumerRecords<String, String> recs = consumer.poll(Duration.ofMillis(100L));\n+            System.out.println(\"count2 \" + count.addAndGet(recs.count()));", "originalCommit": "52a2029211ee6395140064f4db1403c6084cdb7b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5ODU3NjQ2NQ==", "url": "https://github.com/apache/kafka/pull/9354#discussion_r498576465", "bodyText": "Ah, thanks!", "author": "guozhangwang", "createdAt": "2020-10-02T00:46:26Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzk2MDY2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "34cd77113701ff54ef1c90cde12497e5c01132ca", "chunk": "diff --git a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\nindex a0efa70e0b..e86331c36b 100644\n--- a/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\n+++ b/clients/src/test/java/org/apache/kafka/clients/consumer/KafkaConsumerTest.java\n\n@@ -1958,8 +1956,7 @@ public class KafkaConsumerTest {\n         count.set(0);\n         TestUtils.waitForCondition(() -> {\n             ConsumerRecords<String, String> recs = consumer.poll(Duration.ofMillis(100L));\n-            System.out.println(\"count2 \" + count.addAndGet(recs.count()));\n-            return count.get() == 101;\n+            return count.addAndGet(recs.count()) == 101;\n \n         }, \"Does not complete rebalance in time\");\n \n"}}, {"oid": "425da87e98faea6852433144084d3d78db504c80", "url": "https://github.com/apache/kafka/commit/425da87e98faea6852433144084d3d78db504c80", "message": "Merge branch 'trunk' of https://github.com/apache/kafka into K10134-require-rejoin-in-heartbeat-error", "committedDate": "2020-10-01T23:18:24Z", "type": "commit"}, {"oid": "34cd77113701ff54ef1c90cde12497e5c01132ca", "url": "https://github.com/apache/kafka/commit/34cd77113701ff54ef1c90cde12497e5c01132ca", "message": "github comments", "committedDate": "2020-10-02T00:55:46Z", "type": "commit"}]}