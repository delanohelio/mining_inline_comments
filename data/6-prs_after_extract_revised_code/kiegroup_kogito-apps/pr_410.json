{"pr_number": 410, "pr_title": "KOGITO-2914: connect Trusty service and Explainability service", "pr_createdAt": "2020-08-24T17:26:33Z", "pr_url": "https://github.com/kiegroup/kogito-apps/pull/410", "timeline": [{"oid": "cca107bc75784f06a6cb838fa0bb60d3d9f8e816", "url": "https://github.com/kiegroup/kogito-apps/commit/cca107bc75784f06a6cb838fa0bb60d3d9f8e816", "message": "KOGITO-2914: first stub of explainability DTOs with properties", "committedDate": "2020-08-20T16:42:40Z", "type": "commit"}, {"oid": "7ad286e23ab5584214aebb8cadc5c34b44cad276", "url": "https://github.com/kiegroup/kogito-apps/commit/7ad286e23ab5584214aebb8cadc5c34b44cad276", "message": "KOGITO-2914: use tracing-typedvalue-api and improve explainability DTOs", "committedDate": "2020-08-21T12:43:35Z", "type": "commit"}, {"oid": "e99f8c422a1063bb17c3075874ead3e6940e2ecd", "url": "https://github.com/kiegroup/kogito-apps/commit/e99f8c422a1063bb17c3075874ead3e6940e2ecd", "message": "KOGITO-2914: use typedvalue-api", "committedDate": "2020-08-24T08:34:50Z", "type": "commit"}, {"oid": "a4a0f887fc1b31aafac212ab740738e403fc6cb6", "url": "https://github.com/kiegroup/kogito-apps/commit/a4a0f887fc1b31aafac212ab740738e403fc6cb6", "message": "KOGITO-3086 - kogito remote prediction provider", "committedDate": "2020-08-24T08:35:55Z", "type": "commit"}, {"oid": "b5effbf4915fdfec39fbd7acc00ca5c1798b20b3", "url": "https://github.com/kiegroup/kogito-apps/commit/b5effbf4915fdfec39fbd7acc00ca5c1798b20b3", "message": "KOGITO-3086 - added predict API model objects", "committedDate": "2020-08-24T08:35:55Z", "type": "commit"}, {"oid": "2c4b324d38ea9a1cf6a9829fa7d558260897b34d", "url": "https://github.com/kiegroup/kogito-apps/commit/2c4b324d38ea9a1cf6a9829fa7d558260897b34d", "message": "KOGITO-3086 - added missing vertx dep in POM", "committedDate": "2020-08-24T08:35:55Z", "type": "commit"}, {"oid": "8ff62c2396592496e6ab4d4e509a41193ee2413d", "url": "https://github.com/kiegroup/kogito-apps/commit/8ff62c2396592496e6ab4d4e509a41193ee2413d", "message": "KOGITO-3086 - make LimeExplainer API async", "committedDate": "2020-08-24T08:35:55Z", "type": "commit"}, {"oid": "517b5b0b1066557550815a12fef8841617938e1a", "url": "https://github.com/kiegroup/kogito-apps/commit/517b5b0b1066557550815a12fef8841617938e1a", "message": "KOGITO-3086 - fail in case of empty (linearized) features", "committedDate": "2020-08-24T08:35:56Z", "type": "commit"}, {"oid": "dbd84821b388394567f9c3e181e664f7acc68399", "url": "https://github.com/kiegroup/kogito-apps/commit/dbd84821b388394567f9c3e181e664f7acc68399", "message": "KOGITO-3086 - plugging dto/request with expl-service impl", "committedDate": "2020-08-24T08:36:36Z", "type": "commit"}, {"oid": "24598be536c08a027e00d64535fb08cf55713d50", "url": "https://github.com/kiegroup/kogito-apps/commit/24598be536c08a027e00d64535fb08cf55713d50", "message": "KOGITO-3086 - in RKPP get the service url from the request", "committedDate": "2020-08-24T08:36:36Z", "type": "commit"}, {"oid": "41380ec06feed7a0c47dff769a86877b83eeecea", "url": "https://github.com/kiegroup/kogito-apps/commit/41380ec06feed7a0c47dff769a86877b83eeecea", "message": "KOGITO-2914: first stub of explainability DTOs with properties", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "12a79d04e7bbec4d7b7b37d51a4b908647873017", "url": "https://github.com/kiegroup/kogito-apps/commit/12a79d04e7bbec4d7b7b37d51a4b908647873017", "message": "KOGITO-2914: use tracing-typedvalue-api and improve explainability DTOs", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "a349ab4edfa27d0e1ffd229cd38476d253a04069", "url": "https://github.com/kiegroup/kogito-apps/commit/a349ab4edfa27d0e1ffd229cd38476d253a04069", "message": "KOGITO-2914: use typedvalue-api", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "e913f408ff344fca93353c37d66f6ee600d4b014", "url": "https://github.com/kiegroup/kogito-apps/commit/e913f408ff344fca93353c37d66f6ee600d4b014", "message": "KOGITO-3086 - kogito remote prediction provider", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "5ae3783034db7d50af53dddfc52177a97a7f4c76", "url": "https://github.com/kiegroup/kogito-apps/commit/5ae3783034db7d50af53dddfc52177a97a7f4c76", "message": "KOGITO-3086 - added predict API model objects", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "317933b97a601e26874a16a0d74a578820400c04", "url": "https://github.com/kiegroup/kogito-apps/commit/317933b97a601e26874a16a0d74a578820400c04", "message": "KOGITO-3086 - added missing vertx dep in POM", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "87b32ce63137803ce4dfb85b80db03594d813a69", "url": "https://github.com/kiegroup/kogito-apps/commit/87b32ce63137803ce4dfb85b80db03594d813a69", "message": "KOGITO-3086 - make LimeExplainer API async", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "25cc6585d2ff2880b018faceb6da9cae5c80935f", "url": "https://github.com/kiegroup/kogito-apps/commit/25cc6585d2ff2880b018faceb6da9cae5c80935f", "message": "KOGITO-3086 - fail in case of empty (linearized) features", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "127da32a58068a22c554e7b7c4a84623249c9588", "url": "https://github.com/kiegroup/kogito-apps/commit/127da32a58068a22c554e7b7c4a84623249c9588", "message": "KOGITO-3086 - plugging dto/request with expl-service impl", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "5690e8fd14a9b1d040dd2e601b368a12b8129c07", "url": "https://github.com/kiegroup/kogito-apps/commit/5690e8fd14a9b1d040dd2e601b368a12b8129c07", "message": "KOGITO-3086 - in RKPP get the service url from the request", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "44079831610e9e985b211935d3275e2efa8648a7", "url": "https://github.com/kiegroup/kogito-apps/commit/44079831610e9e985b211935d3275e2efa8648a7", "message": "KOGITO-2914: add DecisionInput to persistence models", "committedDate": "2020-08-24T15:04:31Z", "type": "commit"}, {"oid": "564aea31e111e63044a126b5b47caf71f4641acf", "url": "https://github.com/kiegroup/kogito-apps/commit/564aea31e111e63044a126b5b47caf71f4641acf", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914", "committedDate": "2020-08-24T15:57:33Z", "type": "commit"}, {"oid": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "url": "https://github.com/kiegroup/kogito-apps/commit/5041a4994ddecfb6f2d5da83853c32c577de2eba", "message": "KOGITO-2914: working loop between trusty and explainability services (some stubbed parts yet)", "committedDate": "2020-08-24T17:23:38Z", "type": "commit"}, {"oid": "5fa703c099a80579a271ce579e69e935a560f5ca", "url": "https://github.com/kiegroup/kogito-apps/commit/5fa703c099a80579a271ce579e69e935a560f5ca", "message": "[KOGITO-2914] missing license", "committedDate": "2020-08-24T17:48:14Z", "type": "commit"}, {"oid": "538a5e3069b771f60fdf5245486d5a0bd5d06c15", "url": "https://github.com/kiegroup/kogito-apps/commit/538a5e3069b771f60fdf5245486d5a0bd5d06c15", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914", "committedDate": "2020-08-24T17:48:23Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475820708", "bodyText": "I think the URL should not be in the dto (at least for the scenarios we will support in this first release). The URL to be used is going to be injected by the operator with an enviroment variable. wdyt?", "author": "r00ta", "createdAt": "2020-08-24T18:43:15Z", "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java", "diffHunk": "@@ -16,26 +16,50 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityRequestDto {\n \n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    public ExplainabilityRequestDto(){\n+    @JsonProperty(\"serviceUrl\")\n+    private String serviceUrl;", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjMxMjkyMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476312921", "bodyText": "In general it is not correct to have this value injected by the operator because explainable-service (like job-service) needs to know who to call and this is not (or should not be) hard-coded.\nI'm fine to have a fallback value provisioned by the operator but we cannot get rid of this parameter.", "author": "danielezonca", "createdAt": "2020-08-25T09:31:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzEzMjE3Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r477132172", "bodyText": "Hi @danielezonca @kostola , following this architecture, who, where and how this serviceUrl should be set?", "author": "r00ta", "createdAt": "2020-08-26T08:37:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzEzODQ4OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r477138488", "bodyText": "This value contains KogitoApp host, it is injected inside ConfigBean ( template ) by the operator  ( link ).\nThe flow is:\n\nKogito has its own URL\nTraceEvent contains this value\nThis value is send to Expl-service\nExpl-service interact with Kogito using it", "author": "danielezonca", "createdAt": "2020-08-26T08:47:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMDcwOA=="}], "type": "inlineReview", "revised_code": {"commit": "5416e7cbedfd25943ab1f45dab230e3ff6d94ced", "chunk": "diff --git a/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java b/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java\nindex e7c30e89f..29b657032 100644\n--- a/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java\n+++ b/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityRequestDto.java\n\n@@ -31,6 +31,12 @@ public class ExplainabilityRequestDto {\n     @JsonProperty(\"serviceUrl\")\n     private String serviceUrl;\n \n+    @JsonProperty(\"modelName\")\n+    private String modelName;\n+\n+    @JsonProperty(\"modelNamespace\")\n+    private String modelNamespace;\n+\n     @JsonProperty(\"inputs\")\n     private Map<String, TypedValue> inputs;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMTQ5Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475821496", "bodyText": "Create a dedicated object for this to avoid Map<Map<>> that is not very informative? imo it's better to encapsulate it in a separated object in general since it will be easier to add properties in the future", "author": "r00ta", "createdAt": "2020-08-24T18:44:40Z", "path": "explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java", "diffHunk": "@@ -16,23 +16,33 @@\n \n package org.kie.kogito.explainability.api;\n \n+import java.util.Map;\n+\n import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n import com.fasterxml.jackson.annotation.JsonProperty;\n \n @JsonIgnoreProperties(ignoreUnknown = true)\n public class ExplainabilityResultDto {\n+\n     @JsonProperty(\"executionId\")\n     private String executionId;\n \n-    // TODO: add properties\n+    @JsonProperty(\"saliency\")\n+    private Map<String, Map<String, Double>> saliency;", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjMxMzU3OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476313579", "bodyText": "Yes @kostola is already working on this \ud83d\udc4d\nLet's keep this comment opened until the change is pushed", "author": "danielezonca", "createdAt": "2020-08-25T09:33:03Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMTQ5Ng=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5NDYwMg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476694602", "bodyText": "Introduced SaliencyDto", "author": "danielezonca", "createdAt": "2020-08-25T19:43:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyMTQ5Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "chunk": "diff --git a/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java b/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java\nindex bb9605bdc..01bbaeba7 100644\n--- a/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java\n+++ b/explainability/explainability-api/src/main/java/org/kie/kogito/explainability/api/ExplainabilityResultDto.java\n\n@@ -28,21 +28,21 @@ public class ExplainabilityResultDto {\n     private String executionId;\n \n     @JsonProperty(\"saliency\")\n-    private Map<String, Map<String, Double>> saliency;\n+    private Map<String, SaliencyDto> saliencies;\n \n-    public ExplainabilityResultDto() {\n+    private ExplainabilityResultDto() {\n     }\n \n-    public ExplainabilityResultDto(String executionId, Map<String, Map<String, Double>> saliency) {\n+    public ExplainabilityResultDto(String executionId, Map<String, SaliencyDto> saliencies) {\n         this.executionId = executionId;\n-        this.saliency = saliency;\n+        this.saliencies = saliencies;\n     }\n \n     public String getExecutionId() {\n         return executionId;\n     }\n \n-    public Map<String, Map<String, Double>> getSaliency() {\n-        return saliency;\n+    public Map<String, SaliencyDto> getSaliencies() {\n+        return saliencies;\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODUzOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475828539", "bodyText": "I'm not sure about this reaction to these exceptions. Let's assume that something bad happens and we catch the exception, we would anyway produce an (kind of empty?) explaination and display it right? If something bad happens, I think we should make it transparent to the user somehow (or even leave the explaination as \"not available\" or something) and not showing him wrong information", "author": "r00ta", "createdAt": "2020-08-24T18:57:40Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -75,17 +77,23 @@ public static double impactScore(PredictionProvider model, Prediction prediction\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput)).get();\n+        } catch (InterruptedException | ExecutionException e) {\n+            predictionOutputs = Collections.emptyList();", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI0Nzg3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478247873", "bodyText": "Done, now the error is propagated", "author": "danielezonca", "createdAt": "2020-08-27T08:30:20Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyODUzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "c2217030d4f8e8febeadd8720185df80a1da8088", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\nindex b807afcec..a6e4d608c 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n\n@@ -79,9 +84,10 @@ public class ExplainabilityMetrics {\n         PredictionInput predictionInput = new PredictionInput(copy);\n         List<PredictionOutput> predictionOutputs;\n         try {\n-            predictionOutputs = model.predict(List.of(predictionInput)).get();\n-        } catch (InterruptedException | ExecutionException e) {\n-            predictionOutputs = Collections.emptyList();\n+            predictionOutputs = model.predict(List.of(predictionInput)).get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction \" + e.getMessage(), e);\n+            throw new IllegalStateException(\"Impossible to obtain prediction \" + e.getMessage(), e);\n         }\n         double impact = 0d;\n         for (PredictionOutput predictionOutput : predictionOutputs) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyOTk5Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475829992", "bodyText": "move to TOP_FEATURE_THRESHOLD constant or something?", "author": "r00ta", "createdAt": "2020-08-24T19:00:27Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java", "diffHunk": "@@ -53,41 +55,53 @@ private void assertStable(PredictionProvider model, List<Feature> featureList) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n             PredictionInput input = new PredictionInput(featureList);\n-            List<PredictionOutput> predictionOutputs = model.predict(List.of(input));\n-            Prediction prediction = new Prediction(input, predictionOutputs.get(0));\n-            List<Saliency> saliencies = new LinkedList<>();\n-            for (int i = 0; i < 100; i++) {\n-                Map<String, Saliency> saliencyMap = limeExplainer.explain(prediction, model);\n-                saliencies.addAll(saliencyMap.values());\n+            List<PredictionOutput> predictionOutputs;\n+            try {\n+                predictionOutputs = model.predict(List.of(input)).get();\n+            } catch (InterruptedException | ExecutionException e) {\n+                predictionOutputs = Collections.emptyList();\n             }\n-            // check that the topmost important feature is stable\n-            List<String> names = new LinkedList<>();\n-            saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n-            Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n-            boolean topFeature = false;\n-            for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n-                if (entry.getValue() >= 0.9) {\n-                    topFeature = true;\n-                    break;\n+            for (PredictionOutput predictionOutput : predictionOutputs) {\n+                Prediction prediction = new Prediction(input, predictionOutput);\n+                List<Saliency> saliencies = new LinkedList<>();\n+                for (int i = 0; i < 100; i++) {\n+                    Map<String, Saliency> saliencyMap = null;\n+                    try {\n+                        saliencyMap = limeExplainer.explain(prediction, model).get();\n+                    } catch (InterruptedException | ExecutionException e) {\n+                        saliencyMap = Collections.emptyMap();\n+                    }\n+                    saliencies.addAll(saliencyMap.values());\n                 }\n-            }\n-            assertTrue(topFeature);\n+                // check that the topmost important feature is stable\n+                List<String> names = new LinkedList<>();\n+                saliencies.stream().map(s -> s.getPositiveFeatures(1)).forEach(f -> names.add(f.get(0).getFeature().getName()));\n+                Map<String, Long> frequencyMap = names.stream().collect(Collectors.groupingBy(Function.identity(), Collectors.counting()));\n+                boolean topFeature = false;\n+                for (Map.Entry<String, Long> entry : frequencyMap.entrySet()) {\n+                    if (entry.getValue() >= 0.9) {", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI2MzAwNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478263005", "bodyText": "Done", "author": "danielezonca", "createdAt": "2020-08-27T08:55:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgyOTk5Mg=="}], "type": "inlineReview", "revised_code": {"commit": "c2217030d4f8e8febeadd8720185df80a1da8088", "chunk": "diff --git a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java\nindex bdbca2546..647ea53f9 100644\n--- a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java\n+++ b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeStabilityTest.java\n\n@@ -49,28 +51,32 @@ class LimeStabilityTest {\n         assertStable(sumSkipModel, featureList);\n     }\n \n-    private void assertStable(PredictionProvider model, List<Feature> featureList) {\n+    @Test\n+    @Disabled(\"fails with LIME dataset not separable for output 'spam' of type 'boolean' with 'Value{true}' ({1.0=32})\")\n+    void testStabilityWithTextData() throws InterruptedException, ExecutionException, TimeoutException {\n+        PredictionProvider sumSkipModel = TestUtils.getDummyTextClassifier();\n+        List<Feature> featureList = new LinkedList<>();\n+        for (int i = 0; i < 4; i++) {\n+            featureList.add(TestUtils.getMockedTextFeature(\"foo \" + i));\n+        }\n+        featureList.add(TestUtils.getMockedTextFeature(\"money\"));\n+        assertStable(sumSkipModel, featureList);\n+    }\n+\n+    private void assertStable(PredictionProvider model, List<Feature> featureList) throws InterruptedException, ExecutionException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n             PredictionInput input = new PredictionInput(featureList);\n-            List<PredictionOutput> predictionOutputs;\n-            try {\n-                predictionOutputs = model.predict(List.of(input)).get();\n-            } catch (InterruptedException | ExecutionException e) {\n-                predictionOutputs = Collections.emptyList();\n-            }\n+            List<PredictionOutput> predictionOutputs = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n             for (PredictionOutput predictionOutput : predictionOutputs) {\n                 Prediction prediction = new Prediction(input, predictionOutput);\n                 List<Saliency> saliencies = new LinkedList<>();\n                 for (int i = 0; i < 100; i++) {\n-                    Map<String, Saliency> saliencyMap = null;\n-                    try {\n-                        saliencyMap = limeExplainer.explain(prediction, model).get();\n-                    } catch (InterruptedException | ExecutionException e) {\n-                        saliencyMap = Collections.emptyMap();\n-                    }\n+                    Map<String, Saliency> saliencyMap = limeExplainer.explain(prediction, model)\n+                            .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n                     saliencies.addAll(saliencyMap.values());\n                 }\n                 // check that the topmost important feature is stable\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMDIzMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475830230", "bodyText": "disable the test instead of commenting?", "author": "r00ta", "createdAt": "2020-08-24T19:00:53Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java", "diffHunk": "@@ -38,41 +38,41 @@ void testSamplingEmptyDataset() {\n         SampleWeighter.getSampleWeights(targetInput, trainingSet);\n     }\n \n-    @Test\n-    void testSamplingNonEmptyDataset() {\n-        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n-        List<Feature> features = new LinkedList<>();\n-        for (int i = 0; i < 5; i++) {\n-            features.add(TestUtils.getMockedNumericFeature());\n-        }\n-        // create a dataset whose samples values decrease as the dataset grows (starting from 1)\n-        for (int i = 0; i < 10; i++) {\n-            int finalI = i;\n-            Pair<double[], Double> doubles = new Pair<>() {\n-                @Override\n-                public double[] getLeft() {\n-                    double[] vector = new double[features.size()];\n-                    Arrays.fill(vector, 1d / (1d + finalI));\n-                    return vector;\n-                }\n-\n-                @Override\n-                public Double getRight() {\n-                    return 0d;\n-                }\n-\n-                @Override\n-                public Double setValue(Double aDouble) {\n-                    return 0d;\n-                }\n-            };\n-            trainingSet.add(doubles);\n-        }\n-        PredictionInput targetInput = new PredictionInput(features);\n-        double[] weights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n-        // check that weights decrease with the distance from the 1 vector (the target instance)\n-        for (int i = 0; i < weights.length - 1; i++) {\n-            assertTrue(weights[i] > weights[i + 1]);\n-        }\n-    }\n+//    @Test", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI0ODAzOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478248039", "bodyText": "Restored", "author": "danielezonca", "createdAt": "2020-08-27T08:30:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMDIzMA=="}], "type": "inlineReview", "revised_code": {"commit": "de1d89b35d77e657d62f0fab17d7af67d394ef3d", "chunk": "diff --git a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java\nindex 1e066ba06..c10abfe99 100644\n--- a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java\n+++ b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/SampleWeighterTest.java\n\n@@ -38,41 +38,41 @@ class SampleWeighterTest {\n         SampleWeighter.getSampleWeights(targetInput, trainingSet);\n     }\n \n-//    @Test\n-//    void testSamplingNonEmptyDataset() {\n-//        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n-//        List<Feature> features = new LinkedList<>();\n-//        for (int i = 0; i < 5; i++) {\n-//            features.add(TestUtils.getMockedNumericFeature());\n-//        }\n-//        // create a dataset whose samples values decrease as the dataset grows (starting from 1)\n-//        for (int i = 0; i < 10; i++) {\n-//            int finalI = i;\n-//            Pair<double[], Double> doubles = new Pair<>() {\n-//                @Override\n-//                public double[] getLeft() {\n-//                    double[] vector = new double[features.size()];\n-//                    Arrays.fill(vector, 1d / (1d + finalI));\n-//                    return vector;\n-//                }\n-//\n-//                @Override\n-//                public Double getRight() {\n-//                    return 0d;\n-//                }\n-//\n-//                @Override\n-//                public Double setValue(Double aDouble) {\n-//                    return 0d;\n-//                }\n-//            };\n-//            trainingSet.add(doubles);\n-//        }\n-//        PredictionInput targetInput = new PredictionInput(features);\n-//        double[] weights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n-//        // check that weights decrease with the distance from the 1 vector (the target instance)\n-//        for (int i = 0; i < weights.length - 1; i++) {\n-//            assertTrue(weights[i] > weights[i + 1]);\n-//        }\n-//    }\n+    @Test\n+    void testSamplingNonEmptyDataset() {\n+        Collection<Pair<double[], Double>> trainingSet = new LinkedList<>();\n+        List<Feature> features = new LinkedList<>();\n+        for (int i = 0; i < 5; i++) {\n+            features.add(TestUtils.getMockedNumericFeature());\n+        }\n+        // create a dataset whose samples values decrease as the dataset grows (starting from 1)\n+        for (int i = 0; i < 10; i++) {\n+            int finalI = i;\n+            Pair<double[], Double> doubles = new Pair<>() {\n+                @Override\n+                public double[] getLeft() {\n+                    double[] vector = new double[features.size()];\n+                    Arrays.fill(vector, 1d / (1d + finalI));\n+                    return vector;\n+                }\n+\n+                @Override\n+                public Double getRight() {\n+                    return 0d;\n+                }\n+\n+                @Override\n+                public Double setValue(Double aDouble) {\n+                    return 0d;\n+                }\n+            };\n+            trainingSet.add(doubles);\n+        }\n+        PredictionInput targetInput = new PredictionInput(features);\n+        double[] weights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+        // check that weights decrease with the distance from the 1 vector (the target instance)\n+        for (int i = 0; i < weights.length - 1; i++) {\n+            assertTrue(weights[i] > weights[i + 1]);\n+        }\n+    }\n }\n\\ No newline at end of file\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMTM2Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475831366", "bodyText": "remove this log or make it more informative like processing explainability for execution id xyz?", "author": "r00ta", "createdAt": "2020-08-24T19:03:07Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI2Mjk0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478262946", "bodyText": "Fixed :)", "author": "danielezonca", "createdAt": "2020-08-27T08:55:13Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMTM2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\nindex 63d539fc5..e423dc7d7 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n\n@@ -33,6 +33,8 @@ import javax.inject.Inject;\n import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n import org.kie.kogito.explainability.model.Feature;\n import org.kie.kogito.explainability.model.FeatureImportance;\n import org.kie.kogito.explainability.model.Output;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMjIzNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475832236", "bodyText": "should't this call the expl lib?", "author": "r00ta", "createdAt": "2020-08-24T19:04:54Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI1NTE2Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478255167", "bodyText": "It was a WIP, fixed :)", "author": "danielezonca", "createdAt": "2020-08-27T08:42:29Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMjIzNg=="}], "type": "inlineReview", "revised_code": {"commit": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\nindex 63d539fc5..e423dc7d7 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n\n@@ -33,6 +33,8 @@ import javax.inject.Inject;\n import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n import org.kie.kogito.explainability.model.Feature;\n import org.kie.kogito.explainability.model.FeatureImportance;\n import org.kie.kogito.explainability.model.Output;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzIxMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833211", "bodyText": "why check isDone?", "author": "r00ta", "createdAt": "2020-08-24T19:06:48Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5NTg1Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476695856", "bodyText": "This check was wrong, code changed", "author": "danielezonca", "createdAt": "2020-08-25T19:46:05Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzIxMQ=="}], "type": "inlineReview", "revised_code": {"commit": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\nindex 63d539fc5..e423dc7d7 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n\n@@ -33,6 +33,8 @@ import javax.inject.Inject;\n import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n import org.kie.kogito.explainability.model.Feature;\n import org.kie.kogito.explainability.model.FeatureImportance;\n import org.kie.kogito.explainability.model.Output;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzQ2OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833469", "bodyText": "Not sure this is the expected explaination result in case of an exception", "author": "r00ta", "createdAt": "2020-08-24T19:07:15Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5NjE5OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476696199", "bodyText": "This code was wrong, now has changed", "author": "danielezonca", "createdAt": "2020-08-25T19:46:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzQ2OQ=="}], "type": "inlineReview", "revised_code": {"commit": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\nindex 63d539fc5..e423dc7d7 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n\n@@ -33,6 +33,8 @@ import javax.inject.Inject;\n import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n import org.kie.kogito.explainability.model.Feature;\n import org.kie.kogito.explainability.model.FeatureImportance;\n import org.kie.kogito.explainability.model.Output;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzgxNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475833817", "bodyText": "debug?", "author": "r00ta", "createdAt": "2020-08-24T19:07:50Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,162 @@\n \n package org.kie.kogito.explainability;\n \n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n import java.util.concurrent.CompletionStage;\n+import java.util.concurrent.ExecutionException;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n \n+import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n     @Inject\n     ManagedExecutor executor;\n \n     @Override\n     public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+        LOG.info(\"** explainAsync called ***\");\n+        // TODO: restore limeExplainer when loop works and fix triggered exceptions\n+//        RemoteKogitoPredictionProvider provider = new RemoteKogitoPredictionProvider(request, Vertx.vertx(), ThreadContext.builder().build());\n+//        LimeExplainer limeExplainer = new LimeExplainer(100, 1);\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return CompletableFuture\n+                // .supplyAsync(() -> limeExplainer.explain(prediction, provider))\n+                .supplyAsync(() -> mockedExplainationOf(prediction))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [1]\", throwable);\n+                    return CompletableFuture.failedFuture(throwable);\n+                })\n+                .thenApplyAsync(inputFuture -> createResultDto(inputFuture, request.getExecutionId()))\n+                .exceptionally((throwable) -> {\n+                    LOG.error(\"Exception thrown during explainAsync [2]\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+        // .thenApplyAsync(saliencies -> new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap()), executor);\n+    }\n+\n+    private static CompletableFuture<Map<String, Saliency>> mockedExplainationOf(Prediction prediction) {\n+        return CompletableFuture.completedFuture(\n+                prediction.getOutput().getOutputs().stream()\n+                        .collect(HashMap::new, (m, v) -> m.put(v.getName(), mockedSaliencyOf(prediction.getInput(), v)), HashMap::putAll)\n+        );\n+    }\n+\n+    private static Saliency mockedSaliencyOf(PredictionInput input, Output output) {\n+        return new Saliency(\n+                output,\n+                input.getFeatures().stream()\n+                        .map(f -> new FeatureImportance(f, 1.0))\n+                        .collect(Collectors.toList())\n+        );\n+    }\n+\n+    private static ExplainabilityResultDto createResultDto(CompletableFuture<Map<String, Saliency>> inputFuture, String executionId) {\n+        if (!inputFuture.isDone() || inputFuture.isCompletedExceptionally() || inputFuture.isCancelled()) {\n+            return new ExplainabilityResultDto(executionId, Collections.emptyMap());\n+        }\n+        try {\n+            Map<String, Map<String, Double>> saliency = inputFuture.get().entrySet().stream().collect(Collectors.toMap(\n+                    Map.Entry::getKey,\n+                    e -> e.getValue().getPerFeatureImportance().stream().collect(Collectors.toMap(\n+                            v -> v.getFeature().getName(),\n+                            FeatureImportance::getScore\n+                    ))\n+            ));\n+            return new ExplainabilityResultDto(executionId, saliency);\n+        } catch (ExecutionException | InterruptedException e) {\n+            LOG.error(\"Exception on createResultDto\", e);\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private static Prediction getPrediction(Map<String, TypedValue> inputs, Map<String, TypedValue> outputs) {\n+        PredictionInput input = getPredictionInput(inputs);\n+        PredictionOutput output = getPredictionOutput(outputs);\n+        return new Prediction(input, output);\n+    }\n+\n+    private static PredictionInput getPredictionInput(Map<String, TypedValue> inputs) {\n+        // TODO : convert inputs to a PredictionInput\n+        LOG.info(\"** getPredictionInput called with \" + inputs.size() + \" inputs ***\");", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI1NTQ5NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478255494", "bodyText": "It was a WIP, removed", "author": "danielezonca", "createdAt": "2020-08-27T08:43:01Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzMzgxNw=="}], "type": "inlineReview", "revised_code": {"commit": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\nindex 63d539fc5..e423dc7d7 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java\n\n@@ -33,6 +33,8 @@ import javax.inject.Inject;\n import com.fasterxml.jackson.databind.JsonNode;\n import org.eclipse.microprofile.context.ManagedExecutor;\n import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n import org.kie.kogito.explainability.model.Feature;\n import org.kie.kogito.explainability.model.FeatureImportance;\n import org.kie.kogito.explainability.model.Output;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzEyMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475837120", "bodyText": "Maybe it's not really related to this PR, but why the score in the Output is set to 1? what's that?", "author": "r00ta", "createdAt": "2020-08-24T19:14:21Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzM4MDIwMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r477380203", "bodyText": "That number is the confidence of output value. We don't have this concept with Kogito so it is always 1 (aka confidence 100%). You can find some usage with OpenNLP tests ( link )", "author": "danielezonca", "createdAt": "2020-08-26T15:14:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzEyMA=="}], "type": "inlineReview", "revised_code": {"commit": "5416e7cbedfd25943ab1f45dab230e3ff6d94ced", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java\nindex 1680e739d..adc7a83aa 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java\n\n@@ -7,12 +7,13 @@ import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Stream;\n \n+import io.vertx.core.json.Json;\n import io.vertx.core.json.JsonObject;\n import io.vertx.ext.web.client.WebClientOptions;\n import io.vertx.mutiny.core.Vertx;\n-import io.vertx.mutiny.core.buffer.Buffer;\n-import io.vertx.mutiny.ext.web.client.HttpRequest;\n import io.vertx.mutiny.ext.web.client.WebClient;\n import org.eclipse.microprofile.context.ThreadContext;\n import org.kie.kogito.explainability.model.Feature;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzk2MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475837961", "bodyText": "Is this going to work if there are more than 2 levels of nesting for structures? a test for that?", "author": "r00ta", "createdAt": "2020-08-24T19:15:54Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java", "diffHunk": "@@ -0,0 +1,125 @@\n+package org.kie.kogito.explainability;\n+\n+import java.net.URI;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.mutiny.core.Vertx;\n+import io.vertx.mutiny.core.buffer.Buffer;\n+import io.vertx.mutiny.ext.web.client.HttpRequest;\n+import io.vertx.mutiny.ext.web.client.WebClient;\n+import org.eclipse.microprofile.context.ThreadContext;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.explainability.models.PredictInput;\n+\n+import static java.util.Collections.emptyList;\n+import static java.util.concurrent.CompletableFuture.completedFuture;\n+\n+public class RemoteKogitoPredictionProvider implements PredictionProvider {\n+\n+    private final ExplainabilityRequest request;\n+    private final ThreadContext threadContext;\n+    private final WebClient client;\n+\n+    public RemoteKogitoPredictionProvider(ExplainabilityRequest request, Vertx vertx, ThreadContext threadContext) {\n+\n+        this.request = request;\n+        String serviceUrl = request.getServiceUrl();\n+        URI uri = URI.create(serviceUrl);\n+        this.client = WebClient.create(vertx, new WebClientOptions().setDefaultHost(uri.getHost()).setDefaultPort(\n+                uri.getPort()).setSsl(\"https\".equalsIgnoreCase(uri.getScheme())));\n+        this.threadContext = threadContext;\n+    }\n+\n+    @Override\n+    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+        String[] namespaceAndName = extractNamespaceAndName(request.getExecutionId());\n+\n+        return inputs.stream()\n+                .map(input -> sendPredictRequest(input, namespaceAndName))\n+                .reduce(completedFuture(emptyList()),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::addElement),\n+                        (cf1, cf2) -> cf1.thenCombine(cf2, this::merge));\n+    }\n+\n+    private PredictionOutput toPredictionOutput(JsonObject json) {\n+        List<Output> outputs = new LinkedList<>();\n+        for (Map.Entry<String, Object> entry : json) {\n+            Output output = new Output(entry.getKey(), Type.UNDEFINED, new Value<>(entry.getValue()), 1d);\n+            outputs.add(output);\n+        }\n+        return new PredictionOutput(outputs);\n+    }\n+\n+    private List<PredictionOutput> addElement(List<PredictionOutput> l1, PredictionOutput elem) {\n+        List<PredictionOutput> result = new ArrayList<>(l1);\n+        result.add(elem);\n+        return result;\n+    }\n+\n+    private List<PredictionOutput> merge(List<PredictionOutput> l1, List<PredictionOutput> l2) {\n+        List<PredictionOutput> result = new ArrayList<>();\n+        result.addAll(l1);\n+        result.addAll(l2);\n+        return result;\n+    }\n+\n+    private CompletableFuture<PredictionOutput> sendPredictRequest(PredictionInput input, String[] namespaceAndName) {\n+        HttpRequest<Buffer> post = client.post(\"/predict\");\n+        Map<String, Object> map = toMap(input.getFeatures());\n+        PredictInput pi = new PredictInput();\n+        pi.setRequest(map);\n+        pi.setModelIdentifier(new ModelIdentifier(namespaceAndName[0], namespaceAndName[1]));\n+        return threadContext.withContextCapture(post.sendJson(pi).subscribeAsCompletionStage())\n+                .thenApply(r -> toPredictionOutput(r.bodyAsJsonObject()));\n+    }\n+\n+    private String[] extractNamespaceAndName(String resourceId) {\n+        int index = resourceId.lastIndexOf(ModelIdentifier.RESOURCE_ID_SEPARATOR);\n+        if (index < 0 || index == resourceId.length()) {\n+            throw new IllegalArgumentException(\"Malformed resourceId \" + resourceId);\n+        }\n+        return new String[]{resourceId.substring(0, index), resourceId.substring(index + 1)};\n+    }\n+\n+    private Map<String, Object> toMap(List<Feature> features) {\n+        Map<String, Object> map = new HashMap<>();\n+        for (Feature f : features) {\n+            if (Type.COMPOSITE.equals(f.getType())) {\n+                List<Feature> compositeFeatures = (List<Feature>) f.getValue().getUnderlyingObject();\n+                Map<String, Object> maps = new HashMap<>();\n+                for (Feature cf : compositeFeatures) {\n+                    Map<String, Object> compositeFeatureMap = toMap(List.of(cf));\n+                    maps.putAll(compositeFeatureMap);\n+                }\n+                map.put(f.getName(), maps);", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI2Mjg4MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478262880", "bodyText": "Done, added a test for this scenario", "author": "danielezonca", "createdAt": "2020-08-27T08:55:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzNzk2MQ=="}], "type": "inlineReview", "revised_code": {"commit": "5416e7cbedfd25943ab1f45dab230e3ff6d94ced", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java\nindex 1680e739d..adc7a83aa 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/RemoteKogitoPredictionProvider.java\n\n@@ -7,12 +7,13 @@ import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.Executor;\n+import java.util.stream.Stream;\n \n+import io.vertx.core.json.Json;\n import io.vertx.core.json.JsonObject;\n import io.vertx.ext.web.client.WebClientOptions;\n import io.vertx.mutiny.core.Vertx;\n-import io.vertx.mutiny.core.buffer.Buffer;\n-import io.vertx.mutiny.ext.web.client.HttpRequest;\n import io.vertx.mutiny.ext.web.client.WebClient;\n import org.eclipse.microprofile.context.ThreadContext;\n import org.kie.kogito.explainability.model.Feature;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzOTc3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475839773", "bodyText": "Still to be done? Link to ticket?", "author": "r00ta", "createdAt": "2020-08-24T19:19:28Z", "path": "trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java", "diffHunk": "@@ -0,0 +1,52 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import java.util.List;\n+\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+\n+import org.eclipse.microprofile.openapi.annotations.Operation;\n+import org.eclipse.microprofile.openapi.annotations.enums.SchemaType;\n+import org.eclipse.microprofile.openapi.annotations.media.Content;\n+import org.eclipse.microprofile.openapi.annotations.media.Schema;\n+import org.eclipse.microprofile.openapi.annotations.parameters.Parameter;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponse;\n+import org.eclipse.microprofile.openapi.annotations.responses.APIResponses;\n+import org.jboss.resteasy.annotations.jaxrs.PathParam;\n+import org.kie.kogito.trusty.service.responses.DecisionStructuredInputsResponse;\n+import org.kie.kogito.trusty.service.responses.FeatureImportanceResponse;\n+import org.kie.kogito.trusty.service.responses.FeaturesImportanceResponse;\n+\n+@Path(\"executions/decisions\")\n+public class ExplainabilityApiV1 {\n+\n+    @GET\n+    @Path(\"/{executionId}/featureImportance\")\n+    @APIResponses(value = {\n+            @APIResponse(description = \"Gets the local explanation of a decision.\", responseCode = \"200\", content = @Content(mediaType = MediaType.APPLICATION_JSON, schema = @Schema(type = SchemaType.OBJECT, implementation = DecisionStructuredInputsResponse.class))),\n+            @APIResponse(description = \"Bad Request\", responseCode = \"400\", content = @Content(mediaType = MediaType.TEXT_PLAIN))\n+    }\n+    )\n+    @Operation(\n+            summary = \"Returns the feature importance for a decision.\",\n+            description = \"Returns the feature importance for a particular decision calculated using the lime algorithm.\"\n+    )\n+    @Produces(MediaType.APPLICATION_JSON)\n+    public Response getStructuredInputs(\n+            @Parameter(\n+                    name = \"executionId\",\n+                    description = \"The execution ID.\",\n+                    required = true,\n+                    schema = @Schema(implementation = String.class)\n+            ) @PathParam(\"executionId\") String executionId) {\n+        // TODO: implement this\n+        return Response.ok(new FeaturesImportanceResponse(List.of(", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjY5Nzg3Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r476697873", "bodyText": "Now it is implemented", "author": "danielezonca", "createdAt": "2020-08-25T19:49:53Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgzOTc3Mw=="}], "type": "inlineReview", "revised_code": {"commit": "f1453d2364fe66960068cd4a9eb2245d6178553c", "chunk": "diff --git a/trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java b/trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java\nindex 631b60b91..91e39c03c 100644\n--- a/trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java\n+++ b/trusty/trusty-service/src/main/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1.java\n\n@@ -1,7 +1,10 @@\n package org.kie.kogito.trusty.service.api;\n \n-import java.util.List;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n \n+import javax.inject.Inject;\n import javax.ws.rs.GET;\n import javax.ws.rs.Path;\n import javax.ws.rs.Produces;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MDUyOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r475840528", "bodyText": "still to be done?", "author": "r00ta", "createdAt": "2020-08-24T19:21:00Z", "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java", "diffHunk": "@@ -0,0 +1,19 @@\n+package org.kie.kogito.trusty.service.api;\n+\n+import io.quarkus.test.junit.QuarkusTest;\n+import io.restassured.filter.log.ResponseLoggingFilter;\n+import org.junit.jupiter.api.Test;\n+\n+import static io.restassured.RestAssured.given;\n+\n+@QuarkusTest\n+public class ExplainabilityApiV1IT {\n+\n+    @Test\n+    void testFeatureImportance() {\n+        // TODO: implement this\n+        given().filter(new ResponseLoggingFilter())\n+                .when().get(\"/executions/decisions/ID/featureImportance\")", "originalCommit": "5041a4994ddecfb6f2d5da83853c32c577de2eba", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI3NDQzMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478274431", "bodyText": "Done now", "author": "kostola", "createdAt": "2020-08-27T09:14:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MDUyOA=="}], "type": "inlineReview", "revised_code": {"commit": "f1453d2364fe66960068cd4a9eb2245d6178553c", "chunk": "diff --git a/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java b/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java\nindex 6a1233c63..b4caca719 100644\n--- a/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java\n+++ b/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/api/ExplainabilityApiV1IT.java\n\n@@ -14,6 +14,6 @@ public class ExplainabilityApiV1IT {\n         // TODO: implement this\n         given().filter(new ResponseLoggingFilter())\n                 .when().get(\"/executions/decisions/ID/featureImportance\")\n-                .then().statusCode(200);\n+                .then().statusCode(404);\n     }\n }\n"}}, {"oid": "97188aa0a726be6c427428bcc952738a97e563c0", "url": "https://github.com/kiegroup/kogito-apps/commit/97188aa0a726be6c427428bcc952738a97e563c0", "message": "Merge branch 'master' into 'KOGITO-2914'", "committedDate": "2020-08-25T08:01:20Z", "type": "commit"}, {"oid": "3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "url": "https://github.com/kiegroup/kogito-apps/commit/3fbef414ba53a2c43d3c76ddb7707d8e95a59186", "message": "KOGITO-2914: implement persistence of ExplainabilityResult", "committedDate": "2020-08-25T10:30:59Z", "type": "commit"}, {"oid": "f1453d2364fe66960068cd4a9eb2245d6178553c", "url": "https://github.com/kiegroup/kogito-apps/commit/f1453d2364fe66960068cd4a9eb2245d6178553c", "message": "KOGITO-2914: implement ExplainabilityApiV1", "committedDate": "2020-08-25T11:33:21Z", "type": "commit"}, {"oid": "c2217030d4f8e8febeadd8720185df80a1da8088", "url": "https://github.com/kiegroup/kogito-apps/commit/c2217030d4f8e8febeadd8720185df80a1da8088", "message": "[KOGITO-2914] Review CompletableFuture usages in expl-core", "committedDate": "2020-08-25T12:31:52Z", "type": "commit"}, {"oid": "5416e7cbedfd25943ab1f45dab230e3ff6d94ced", "url": "https://github.com/kiegroup/kogito-apps/commit/5416e7cbedfd25943ab1f45dab230e3ff6d94ced", "message": "KOGITO-2914: fix call from explainability service to predict endpoint", "committedDate": "2020-08-25T16:46:41Z", "type": "commit"}, {"oid": "3bc7ce079e81d8f26984846a5b0ddf10393101ef", "url": "https://github.com/kiegroup/kogito-apps/commit/3bc7ce079e81d8f26984846a5b0ddf10393101ef", "message": "[KOGITO-2914] Review DTO to use ModelIdentifier + Fix jandex index + RemoteKogitoPredictionProvider now sends all the inputs together", "committedDate": "2020-08-25T19:41:07Z", "type": "commit"}, {"oid": "fe3fb4c5cbf2a3db4d60f727f738fc35820362a2", "url": "https://github.com/kiegroup/kogito-apps/commit/fe3fb4c5cbf2a3db4d60f727f738fc35820362a2", "message": "KOGITO-2914: improve input/output parsing in explainability service", "committedDate": "2020-08-26T09:22:09Z", "type": "commit"}, {"oid": "baee3426acbd1e3cdef7a9f384ecb839d0a2d441", "url": "https://github.com/kiegroup/kogito-apps/commit/baee3426acbd1e3cdef7a9f384ecb839d0a2d441", "message": "KOGITO-2914: add comment in RemoteKogitoPredictionProvider to explain a particular behavior", "committedDate": "2020-08-26T10:22:37Z", "type": "commit"}, {"oid": "7b9972dadf8e865f035dfdb219b5056520cb0e9b", "url": "https://github.com/kiegroup/kogito-apps/commit/7b9972dadf8e865f035dfdb219b5056520cb0e9b", "message": "[KOGITO-2914] Fix rety mechanism in case of not separable dataset", "committedDate": "2020-08-26T13:59:18Z", "type": "commit"}, {"oid": "7d39fe0cb5e89309db8fbf3585a32df77dc7a3d2", "url": "https://github.com/kiegroup/kogito-apps/commit/7d39fe0cb5e89309db8fbf3585a32df77dc7a3d2", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914", "committedDate": "2020-08-26T13:59:32Z", "type": "commit"}, {"oid": "438aa5bda5553df0eb10b903cac43df4d5585c21", "url": "https://github.com/kiegroup/kogito-apps/commit/438aa5bda5553df0eb10b903cac43df4d5585c21", "message": "[KOGITO-2914] Fix rety mechanism in case of not separable dataset", "committedDate": "2020-08-26T14:12:30Z", "type": "commit"}, {"oid": "75bd0e34ab27cd9bcafe03aa4b2e64a497aaa086", "url": "https://github.com/kiegroup/kogito-apps/commit/75bd0e34ab27cd9bcafe03aa4b2e64a497aaa086", "message": "KOGITO-2914: improve coverage", "committedDate": "2020-08-26T15:53:08Z", "type": "commit"}, {"oid": "de1d89b35d77e657d62f0fab17d7af67d394ef3d", "url": "https://github.com/kiegroup/kogito-apps/commit/de1d89b35d77e657d62f0fab17d7af67d394ef3d", "message": "[KOGITO-2914] explainability-service refactoring to make it testable + test coverage", "committedDate": "2020-08-26T22:09:56Z", "type": "commit"}, {"oid": "1c4000afce63d022f732a8dbef06b05c5cc2b58c", "url": "https://github.com/kiegroup/kogito-apps/commit/1c4000afce63d022f732a8dbef06b05c5cc2b58c", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell", "committedDate": "2020-08-27T07:04:05Z", "type": "commit"}, {"oid": "013ea031450abd9d28e848412e49645d5b2b0e9e", "url": "https://github.com/kiegroup/kogito-apps/commit/013ea031450abd9d28e848412e49645d5b2b0e9e", "message": "KOGITO-2914: improve trusty-service coverage", "committedDate": "2020-08-27T07:05:04Z", "type": "commit"}, {"oid": "1d105d13d1607fece46c0248b1f005747a59d20d", "url": "https://github.com/kiegroup/kogito-apps/commit/1d105d13d1607fece46c0248b1f005747a59d20d", "message": "Merge branch 'master' into 'KOGITO-2914'", "committedDate": "2020-08-27T07:05:12Z", "type": "commit"}, {"oid": "29af97856bd7f07e5c96ec6fba9c7c95fed7c944", "url": "https://github.com/kiegroup/kogito-apps/commit/29af97856bd7f07e5c96ec6fba9c7c95fed7c944", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell (removed duplicated class)", "committedDate": "2020-08-27T07:08:27Z", "type": "commit"}, {"oid": "8a6da048283f548cbcfaff46ecdc80809f2cb8c9", "url": "https://github.com/kiegroup/kogito-apps/commit/8a6da048283f548cbcfaff46ecdc80809f2cb8c9", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell", "committedDate": "2020-08-27T07:29:06Z", "type": "commit"}, {"oid": "1e2af340ebb00c44a28e756dbfa1299922d5a752", "url": "https://github.com/kiegroup/kogito-apps/commit/1e2af340ebb00c44a28e756dbfa1299922d5a752", "message": "[KOGITO-2914] Fix SonarCloud bugs/codesmell", "committedDate": "2020-08-27T07:31:06Z", "type": "commit"}, {"oid": "e2acfadf15ebdc0b148c05eb65053be3ddc29062", "url": "https://github.com/kiegroup/kogito-apps/commit/e2acfadf15ebdc0b148c05eb65053be3ddc29062", "message": "[KOGITO-2914] Improve test coverage", "committedDate": "2020-08-27T08:22:47Z", "type": "commit"}, {"oid": "2e78a977dad88620eedbdfdda17717db025a4d1f", "url": "https://github.com/kiegroup/kogito-apps/commit/2e78a977dad88620eedbdfdda17717db025a4d1f", "message": "[KOGITO-2914] Changes based on PR comments", "committedDate": "2020-08-27T08:54:43Z", "type": "commit"}, {"oid": "5f9f94981e066dc495b56f3f8d7dff5950a70ad8", "url": "https://github.com/kiegroup/kogito-apps/commit/5f9f94981e066dc495b56f3f8d7dff5950a70ad8", "message": "KOGITO-2914: improve coverage of trusty-service", "committedDate": "2020-08-27T09:01:35Z", "type": "commit"}, {"oid": "a8b4287fe92ec8e8c650fde990ca2f22fee5f49e", "url": "https://github.com/kiegroup/kogito-apps/commit/a8b4287fe92ec8e8c650fde990ca2f22fee5f49e", "message": "Merge branch 'KOGITO-2914' of kostola/kogito-apps into 'KOGITO-2914'", "committedDate": "2020-08-27T09:01:38Z", "type": "commit"}, {"oid": "dda6ade677296eb1f82a6a34979d9de8d7e5305a", "url": "https://github.com/kiegroup/kogito-apps/commit/dda6ade677296eb1f82a6a34979d9de8d7e5305a", "message": "[KOGITO-2914] Improve coverage + codesmell", "committedDate": "2020-08-27T09:23:21Z", "type": "commit"}, {"oid": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "url": "https://github.com/kiegroup/kogito-apps/commit/64d149a68d9f91edaede7dea4655886f3e0f06e1", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914", "committedDate": "2020-08-27T09:23:28Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTQxNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478285417", "bodyText": "since we throw the same checked exception, isnt't better to log on the consumer side of the method?", "author": "r00ta", "createdAt": "2020-08-27T09:33:06Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java", "diffHunk": "@@ -108,8 +111,15 @@ public PartialDependencePlotExplainer() {\n                         predictionInputs.add(input);\n                     }\n \n+                    List<PredictionOutput> predictionOutputs;\n+                    try {\n+                        predictionOutputs = model.predict(predictionInputs).get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+                    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+                        LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "originalCommit": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODMzMzc1OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478333758", "bodyText": "I prefer to have the log here instead of add a similar code every time this method is invoked. Then the caller can decide to mute or propagate again the exception but the log will be preserved", "author": "danielezonca", "createdAt": "2020-08-27T11:02:44Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTQxNw=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java\nindex 2d5d3e2ee..a54bda4a8 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainer.java\n\n@@ -113,7 +113,7 @@ public class PartialDependencePlotExplainer implements GlobalExplainer<Collectio\n \n                     List<PredictionOutput> predictionOutputs;\n                     try {\n-                        predictionOutputs = model.predict(predictionInputs).get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+                        predictionOutputs = model.predictAsync(predictionInputs).get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n                     } catch (InterruptedException | ExecutionException | TimeoutException e) {\n                         LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n                         throw e;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTY2Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478285666", "bodyText": "same here", "author": "r00ta", "createdAt": "2020-08-27T09:33:30Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());", "originalCommit": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODMzMzgzNA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478333834", "bodyText": "Same as above :)", "author": "danielezonca", "createdAt": "2020-08-27T11:02:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NTY2Ng=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\nindex f520aea8b..a1ee70a1d 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n\n@@ -75,7 +75,7 @@ public class ExplainabilityMetrics {\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws InterruptedException, ExecutionException, TimeoutException {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478286291", "bodyText": "is this a random unit test?", "author": "r00ta", "createdAt": "2020-08-27T09:34:37Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +40,37 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new Random());", "originalCommit": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQwMDQyMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478400420", "bodyText": "Please use at least static seed.", "author": "jiripetrlik", "createdAt": "2020-08-27T13:00:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQwNzAxNA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478407014", "bodyText": "This test generates a random set of data because it just tests the cardinality of the result and not the specific value", "author": "danielezonca", "createdAt": "2020-08-27T13:10:55Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODQxNzcxMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478417710", "bodyText": "Btw random removed :)", "author": "danielezonca", "createdAt": "2020-08-27T13:26:40Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NjI5MQ=="}], "type": "inlineReview", "revised_code": {"commit": "a6d943f45041ce233977a2db707c677321bc15a2", "chunk": "diff --git a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java\nindex 535dcd08b..b7a521d2d 100644\n--- a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java\n+++ b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java\n\n@@ -40,6 +33,13 @@ import org.kie.kogito.explainability.model.Type;\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478287133", "bodyText": "what is the expectation of this test? Should this call raise a LocalExplanationException or should it run without exceptions?", "author": "r00ta", "createdAt": "2020-08-27T09:36:03Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java", "diffHunk": "@@ -31,41 +27,60 @@\n import org.kie.kogito.explainability.model.PredictionProvider;\n import org.kie.kogito.explainability.model.Saliency;\n \n-import static org.junit.jupiter.api.Assertions.assertEquals;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeoutException;\n+\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n-import static org.mockito.Mockito.mock;\n+import static org.junit.jupiter.api.Assertions.fail;\n \n class LimeExplainerTest {\n \n     @Test\n-    void testEmptyPrediction() {\n+    void testEmptyPrediction() throws ExecutionException, InterruptedException, TimeoutException {\n         Random random = new Random();\n         for (int seed = 0; seed < 5; seed++) {\n             random.setSeed(seed);\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n-            PredictionOutput output = mock(PredictionOutput.class);\n-            PredictionInput input = mock(PredictionInput.class);\n+            PredictionInput input = new PredictionInput(Collections.emptyList());\n+            PredictionProvider model = TestUtils.getSumSkipModel(0);\n+            PredictionOutput output = model.predict(List.of(input))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n+                    .get(0);\n             Prediction prediction = new Prediction(input, output);\n-            PredictionProvider model = mock(PredictionProvider.class);\n-            Assertions.assertThrows(LocalExplanationException.class, () -> limeExplainer.explain(prediction, model));\n+            try {\n+                limeExplainer.explainAsync(prediction, model)\n+                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+            } catch (LocalExplanationException e) {\n+                // this is expected", "originalCommit": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODMzMjg0MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478332841", "bodyText": "LocalExplainationException is expected, the previous code was using assertThrows but SonarCloud complained that this code\nlimeExplainer.explainAsync(prediction, model)\n      .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\ncan throws multiple exceptions so I changed it to explicitly catch the only expected exception and let the test fails otherwise", "author": "danielezonca", "createdAt": "2020-08-27T11:00:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY2MjE1Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478662153", "bodyText": "@danielezonca\nThrowable throwable = catchThrowable(() -> limeExplainer.explainAsync(prediction, model)\n                        .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit()));\nassertThat(throwable).isInstanceOf(LocalExplanationException.class)\n\n?", "author": "r00ta", "createdAt": "2020-08-27T19:59:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODc4Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448787", "bodyText": "My bad, the exception is thrown directly by explainAsync without the need of the additional get. I have updated the test with the original assertThrows and it should be SonarCloud friendly too :)", "author": "danielezonca", "createdAt": "2020-08-28T17:43:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4NzEzMw=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java\nindex 2e6b2282f..2e7d76bd8 100644\n--- a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java\n+++ b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/local/lime/LimeExplainerTest.java\n\n@@ -48,7 +47,7 @@ class LimeExplainerTest {\n             LimeExplainer limeExplainer = new LimeExplainer(10, 1, random);\n             PredictionInput input = new PredictionInput(Collections.emptyList());\n             PredictionProvider model = TestUtils.getSumSkipModel(0);\n-            PredictionOutput output = model.predict(List.of(input))\n+            PredictionOutput output = model.predictAsync(List.of(input))\n                     .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit())\n                     .get(0);\n             Prediction prediction = new Prediction(input, output);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4OTQ4Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478289486", "bodyText": "don't we want to use vertx executors?", "author": "r00ta", "createdAt": "2020-08-27T09:40:05Z", "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -78,8 +73,7 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n             }\n \n             CloudEventImpl<ExplainabilityRequestDto> cloudEvent = cloudEventOpt.get();\n-            return CompletableFuture\n-                    .supplyAsync(() -> handleCloudEvent(cloudEvent), executor)", "originalCommit": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM5NjI5NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478396295", "bodyText": "I did a quick review of the usage of CompletableFuture.*Async in some classes because I think we should use it only when it is really needed (aka long running/blocking tasks): every time we use that code, a new task is scheduled on Vert.x task list for the next loop and this has a cost. We should use it when we start a long task or when we compose an existing one with another long task.\nIn this case the full execution flow is:\n\nexplanationService.explainAsync -> this is the starting point and it already uses (in RemotePredictionProvider) Vert.x WebClient to dispatch the REST call as async task\nsendEvent -> this should not be blocking because it builds cloud event and then just schedule it with onNext\nmessage.ack -> this is a terminal operation that complete the CompletableFuture so it is not blocking\n\nBtw we can easily re-introduce it if needed :)", "author": "danielezonca", "createdAt": "2020-08-27T12:54:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI4OTQ4Ng=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MDc1MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478290751", "bodyText": "why do we create a new instance at every event?", "author": "r00ta", "createdAt": "2020-08-27T09:42:09Z", "path": "explainability/explainability-service-messaging/src/main/java/org/kie/kogito/explainability/messaging/ExplainabilityMessagingHandler.java", "diffHunk": "@@ -107,15 +101,16 @@ public ExplainabilityMessagingHandler(ExplanationService explanationService, Exe\n \n         LOGGER.info(\"Received CloudEvent with id {} from {}\", attributes.getId(), attributes.getSource());\n \n-        ExplainabilityRequestDto explainabilityResult = optData.get();\n+        ExplainabilityRequest request = ExplainabilityRequest.from(optData.get());\n+        PredictionProvider provider = predictionProviderFactory.createPredictionProvider(request);", "originalCommit": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM1NjYyMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478356623", "bodyText": "Prediction provider is tied to request information: for now it is only using serviceUrl but in the future I expect we will support multiple predictionProviders and based on the request it will produce the proper one.", "author": "danielezonca", "createdAt": "2020-08-27T11:48:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MDc1MQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MzE0Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478293143", "bodyText": "Why a test class is renamed/moved to the src folder?", "author": "r00ta", "createdAt": "2020-08-27T09:45:58Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/PredictionProviderFactory.java", "diffHunk": "@@ -16,6 +16,10 @@\n \n package org.kie.kogito.explainability;\n \n-public class ExplanationServiceTest {\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n \n+public interface PredictionProviderFactory {", "originalCommit": "64d149a68d9f91edaede7dea4655886f3e0f06e1", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODM1NTc3OA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478355778", "bodyText": "The original class was empty so probably I moved it and reused, no real reason :)", "author": "danielezonca", "createdAt": "2020-08-27T11:46:48Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODI5MzE0Mw=="}], "type": "inlineReview", "revised_code": null}, {"oid": "72c5a84c7362efe2259ed4916d5d2a49f7e1a3bf", "url": "https://github.com/kiegroup/kogito-apps/commit/72c5a84c7362efe2259ed4916d5d2a49f7e1a3bf", "message": "Merge remote-tracking branch 'upstream/master' into KOGITO-2914\n\n# Conflicts:\n#\ttrusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "committedDate": "2020-08-27T10:26:16Z", "type": "commit"}, {"oid": "9d33ed5ae54e37af02eacae5e94fd9d176636caf", "url": "https://github.com/kiegroup/kogito-apps/commit/9d33ed5ae54e37af02eacae5e94fd9d176636caf", "message": "[KOGITO-2914] Post merge fix", "committedDate": "2020-08-27T11:08:18Z", "type": "commit"}, {"oid": "c3543c15505d5cb6154f07f7000959fb7c0090d3", "url": "https://github.com/kiegroup/kogito-apps/commit/c3543c15505d5cb6154f07f7000959fb7c0090d3", "message": "Merge remote-tracking branch 'upstream/master' into KOGITO-2914", "committedDate": "2020-08-27T12:17:40Z", "type": "commit"}, {"oid": "08d0146452e4a4aff7e549468d9dfbb9fef18b7a", "url": "https://github.com/kiegroup/kogito-apps/commit/08d0146452e4a4aff7e549468d9dfbb9fef18b7a", "message": "[KOGITO-2914] Minor changes", "committedDate": "2020-08-27T12:18:41Z", "type": "commit"}, {"oid": "a6d943f45041ce233977a2db707c677321bc15a2", "url": "https://github.com/kiegroup/kogito-apps/commit/a6d943f45041ce233977a2db707c677321bc15a2", "message": "[KOGITO-2914] Create FakeRandom for testing purpose", "committedDate": "2020-08-27T13:26:01Z", "type": "commit"}, {"oid": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "url": "https://github.com/kiegroup/kogito-apps/commit/e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "message": "KOGITO-2914: remove TODO line that was done previously", "committedDate": "2020-08-27T13:31:15Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMTc0NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478621745", "bodyText": "refactor import java.util.*; ;)", "author": "r00ta", "createdAt": "2020-08-27T18:42:02Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -43,6 +34,14 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import java.security.SecureRandom;\n+import java.util.*;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.stream.Collectors;", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkxOTYzNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478919635", "bodyText": "Done", "author": "danielezonca", "createdAt": "2020-08-28T08:08:51Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMTc0NQ=="}], "type": "inlineReview", "revised_code": {"commit": "98389345bd3c8aa3985e74dd0e65eb36405932cf", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\nindex 49b623af7..8a6fce76c 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n\n@@ -35,7 +35,12 @@ import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n import java.security.SecureRandom;\n-import java.util.*;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n import java.util.concurrent.CompletableFuture;\n import java.util.stream.Collectors;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMjU4Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478622582", "bodyText": "why protected?", "author": "r00ta", "createdAt": "2020-08-27T18:43:37Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg3MzM1MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478873350", "bodyText": "No specific reason, it is the \"core\" method so I prefer to keep it protected to allow override if needed", "author": "danielezonca", "createdAt": "2020-08-28T07:09:24Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyMjU4Mg=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\nindex 49b623af7..c87a90ce7 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n\n@@ -141,7 +146,7 @@ public class LimeExplainer implements LocalExplainer<Map<String, Saliency>> {\n \n         List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n \n-        return model.predict(perturbedInputs)\n+        return model.predictAsync(perturbedInputs)\n                 .thenCompose(predictionOutputs -> {\n                     try {\n                         List<LimeInputs> limeInputsList = getLimeInputs(linearizedTargetInputFeatures, actualOutputs, perturbedInputs, predictionOutputs);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNTMwMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478625300", "bodyText": "shouldn't model.predict be an async task as well? Use vertx executors?", "author": "r00ta", "createdAt": "2020-08-27T18:48:49Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4OTIxNw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478889217", "bodyText": "I prefer to let the implementation of PredictionProvider to decide how to provide the result: if it is heavy computation do it on a new thread or just return the value if not. In case of RemotePredictionProvider is already async ( link )", "author": "danielezonca", "createdAt": "2020-08-28T07:34:45Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNTMwMA=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\nindex 49b623af7..c87a90ce7 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n\n@@ -141,7 +146,7 @@ public class LimeExplainer implements LocalExplainer<Map<String, Saliency>> {\n \n         List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n \n-        return model.predict(perturbedInputs)\n+        return model.predictAsync(perturbedInputs)\n                 .thenCompose(predictionOutputs -> {\n                     try {\n                         List<LimeInputs> limeInputsList = getLimeInputs(linearizedTargetInputFeatures, actualOutputs, perturbedInputs, predictionOutputs);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNjc0Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478626746", "bodyText": "if this condition is false we are going to return a kind of empty explaination without any additional information, is this correct from a user perspective?", "author": "r00ta", "createdAt": "2020-08-27T18:51:29Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java", "diffHunk": "@@ -97,139 +96,175 @@ public LimeExplainer(int noOfSamples, int noOfPerturbations, int noOfRetries, Ra\n         this.noOfRetries = noOfRetries;\n     }\n \n-    @Override\n-    public Map<String, Saliency> explain(Prediction prediction, PredictionProvider model) {\n+    public int getNoOfSamples() {\n+        return noOfSamples;\n+    }\n+\n+    public PerturbationContext getPerturbationContext() {\n+        return perturbationContext;\n+    }\n \n-        long start = System.currentTimeMillis();\n+    public int getNoOfRetries() {\n+        return noOfRetries;\n+    }\n \n+    @Override\n+    public CompletableFuture<Map<String, Saliency>> explainAsync(Prediction prediction, PredictionProvider model) {\n         PredictionInput originalInput = prediction.getInput();\n-        List<Feature> inputFeatures = originalInput.getFeatures();\n-        Map<String, Saliency> result = new HashMap<>();\n-        if (inputFeatures.size() > 0) {\n-            // in case of composite / nested features, \"linearize\" the features\n-            List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n-            if (linearizedInputs.size() > 0) {\n-                PredictionInput targetInput = linearizedInputs.get(0);\n-                List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n-\n-                List<Output> actualOutputs = prediction.getOutput().getOutputs();\n-                int noOfInputFeatures = inputFeatures.size();\n-                int noOfOutputFeatures = linearizedTargetInputFeatures.size();\n-                double[] weights = new double[noOfOutputFeatures];\n-\n-                // iterate through the different outputs in the prediction and explain each one separately\n-                for (int o = 0; o < actualOutputs.size(); o++) {\n-                    List<FeatureImportance> featureImportanceList = new LinkedList<>();\n-                    boolean separableDataset = false;\n-\n-                    List<PredictionInput> trainingInputs = new LinkedList<>();\n-                    List<PredictionOutput> trainingOutputs = new LinkedList<>();\n-\n-                    Output currentOutput = actualOutputs.get(o);\n-                    // do not explain the current output if it is 'null'\n-                    if (currentOutput.getValue() != null && currentOutput.getValue().getUnderlyingObject() != null) {\n-                        Map<Double, Long> rawClassesBalance = new HashMap<>();\n-\n-                        /*\n-                        perturb the inputs so that the perturbed dataset contains more than just one output class, otherwise\n-                        it would be impossible to linearly separate it, and hence learn meaningful weights to be used as\n-                        feature importance scores.\n-                         */\n-\n-                        boolean classification = false;\n-\n-                        // in case of failure in separating the dataset, retry with newly perturbed inputs\n-                        for (int tries = this.noOfRetries; tries > 0; tries--) {\n-                            // perturb the inputs\n-                            List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput, noOfInputFeatures);\n-\n-                            // perform predictions on the perturbed inputs\n-                            List<PredictionOutput> perturbedOutputs = model.predict(perturbedInputs);\n-\n-                            // calculate the no. of samples belonging to each output class\n-                            Value<?> fv = currentOutput.getValue();\n-                            int finalO = o;\n-                            rawClassesBalance = perturbedOutputs.stream()\n-                                    .map(p -> p.getOutputs().get(finalO)) // get the (perturbed) output value corresponding to the one to be explained\n-                                    .map(output -> (Type.NUMBER.equals(output.getType())) ?\n-                                            output.getValue().asNumber() : // if numeric use it as it is\n-                                            (((output.getValue().getUnderlyingObject() == null // otherwise check if target and perturbed outputs are both null\n-                                                    && fv.getUnderlyingObject() == null)\n-                                                    || (output.getValue().getUnderlyingObject() != null  // if not null, check for underlying value equality\n-                                                    && output.getValue().asString().equals(fv.asString()))) ? 1d : 0d))\n-                                    .collect(Collectors.groupingBy(Double::doubleValue, Collectors.counting())); // then group-count distinct output values\n-                            LOGGER.debug(\"raw samples per class: {}\", rawClassesBalance);\n-\n-                            // check if the dataset is separable and also if the linear model should fit a regressor or a classifier\n-                            if (rawClassesBalance.size() > 1) {\n-                                Long max = rawClassesBalance.values().stream().max(Long::compareTo).orElse(1L);\n-                                if ((double) max / (double) perturbedInputs.size() < SEPARABLE_DATASET_RATIO) {\n-                                    separableDataset = true;\n-                                    classification = rawClassesBalance.size() == 2;\n-\n-                                    // if dataset creation process succeeds use it to train the linear model\n-                                    trainingInputs.addAll(perturbedInputs);\n-                                    trainingOutputs.addAll(perturbedOutputs);\n-                                    break;\n-                                }\n-                            }\n-                        }\n-                        if (!separableDataset) { // fail the explanation if the dataset is not separable\n-                            throw new DatasetNotSeparableException(currentOutput, rawClassesBalance);\n-                        }\n+        if (originalInput.getFeatures().isEmpty()) {\n+            throw new LocalExplanationException(\"cannot explain a prediction whose input is empty\");\n+        }\n+        List<PredictionInput> linearizedInputs = DataUtils.linearizeInputs(List.of(originalInput));\n+        PredictionInput targetInput = linearizedInputs.get(0);\n+        List<Feature> linearizedTargetInputFeatures = targetInput.getFeatures();\n+        if (linearizedTargetInputFeatures.isEmpty()) {\n+            throw new LocalExplanationException(\"input features linearization failed\");\n+        }\n+        List<Output> actualOutputs = prediction.getOutput().getOutputs();\n+\n+        return explainRetryCycle(\n+                model,\n+                originalInput,\n+                targetInput,\n+                linearizedTargetInputFeatures,\n+                actualOutputs,\n+                noOfRetries);\n+    }\n \n-                        // only fetch the single output to explain in the generated prediction outputs\n-                        List<Output> predictedOutputs = new LinkedList<>();\n-                        for (PredictionOutput trainingOutput : trainingOutputs) {\n-                            Output output = trainingOutput.getOutputs().get(o);\n-                            predictedOutputs.add(output);\n+    protected CompletableFuture<Map<String, Saliency>> explainRetryCycle(\n+            PredictionProvider model,\n+            PredictionInput originalInput,\n+            PredictionInput targetInput,\n+            List<Feature> linearizedTargetInputFeatures,\n+            List<Output> actualOutputs,\n+            int noOfRetries) {\n+\n+        List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n+\n+        return model.predict(perturbedInputs)\n+                .thenCompose(predictionOutputs -> {\n+                    try {\n+                        List<LimeInputs> limeInputsList = getLimeInputs(linearizedTargetInputFeatures, actualOutputs, perturbedInputs, predictionOutputs);\n+                        return completedFuture(getSaliencies(targetInput, linearizedTargetInputFeatures, actualOutputs, limeInputsList));\n+                    } catch (DatasetNotSeparableException e) {\n+                        if (noOfRetries > 0) {\n+                            return explainRetryCycle(model, originalInput, targetInput, linearizedTargetInputFeatures, actualOutputs, noOfRetries - 1);\n                         }\n+                        throw e;\n+                    }\n+                });\n+    }\n \n-                        Output originalOutput = prediction.getOutput().getOutputs().get(o);\n+    private List<LimeInputs> getLimeInputs(List<Feature> linearizedTargetInputFeatures,\n+                                           List<Output> actualOutputs,\n+                                           List<PredictionInput> perturbedInputs,\n+                                           List<PredictionOutput> predictionOutputs) {\n+        List<LimeInputs> limeInputsList = new LinkedList<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            Output currentOutput = actualOutputs.get(o);\n+            LimeInputs limeInputs = prepareInputs(perturbedInputs, predictionOutputs, linearizedTargetInputFeatures,\n+                    o, currentOutput);\n+            limeInputsList.add(limeInputs);\n+        }\n+        return limeInputsList;\n+    }\n \n-                        // encode the training data so that it can be fed into the linear model\n-                        DatasetEncoder datasetEncoder = new DatasetEncoder(trainingInputs, predictedOutputs, targetInput, originalOutput);\n-                        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+    private Map<String, Saliency> getSaliencies(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, List<Output> actualOutputs, List<LimeInputs> limeInputsList) {\n+        Map<String, Saliency> result = new HashMap<>();\n+        for (int o = 0; o < actualOutputs.size(); o++) {\n+            LimeInputs limeInputs = limeInputsList.get(o);\n+            Output originalOutput = actualOutputs.get(o);\n \n-                        // weight the training samples based on the proximity to the target input to explain\n-                        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+            getSaliency(targetInput, linearizedTargetInputFeatures, result, limeInputs, originalOutput);\n+            LOGGER.debug(\"weights set for output {}\", originalOutput);\n+        }\n+        return result;\n+    }\n \n-                        // fit the linear model\n-                        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), classification);\n-                        double loss = linearModel.fit(trainingSet, sampleWeights);\n+    private void getSaliency(PredictionInput targetInput, List<Feature> linearizedTargetInputFeatures, Map<String, Saliency> result, LimeInputs limeInputs, Output originalOutput) {\n+        List<FeatureImportance> featureImportanceList = new LinkedList<>();\n+\n+        // encode the training data so that it can be fed into the linear model\n+        DatasetEncoder datasetEncoder = new DatasetEncoder(limeInputs.getPerturbedInputs(),\n+                limeInputs.getPerturbedOutputs(),\n+                targetInput, originalOutput);\n+        Collection<Pair<double[], Double>> trainingSet = datasetEncoder.getEncodedTrainingSet();\n+\n+        // weight the training samples based on the proximity to the target input to explain\n+        double[] sampleWeights = SampleWeighter.getSampleWeights(targetInput, trainingSet);\n+        LinearModel linearModel = new LinearModel(linearizedTargetInputFeatures.size(), limeInputs.isClassification());\n+        double loss = linearModel.fit(trainingSet, sampleWeights);\n+        if (!Double.isNaN(loss)) {\n+            // create the output saliency\n+            int i = 0;\n+            for (Feature linearizedFeature : linearizedTargetInputFeatures) {\n+                FeatureImportance featureImportance = new FeatureImportance(linearizedFeature, linearModel.getWeights()[i]);\n+                featureImportanceList.add(featureImportance);\n+                i++;\n+            }\n+        }", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQyMDg4NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479420884", "bodyText": "Ticket created https://issues.redhat.com/browse/KOGITO-3213", "author": "danielezonca", "createdAt": "2020-08-28T16:47:17Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyNjc0Ng=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\nindex 49b623af7..c87a90ce7 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/local/lime/LimeExplainer.java\n\n@@ -141,7 +146,7 @@ public class LimeExplainer implements LocalExplainer<Map<String, Saliency>> {\n \n         List<PredictionInput> perturbedInputs = getPerturbedInputs(originalInput.getFeatures());\n \n-        return model.predict(perturbedInputs)\n+        return model.predictAsync(perturbedInputs)\n                 .thenCompose(predictionOutputs -> {\n                     try {\n                         List<LimeInputs> limeInputsList = getLimeInputs(linearizedTargetInputFeatures, actualOutputs, perturbedInputs, predictionOutputs);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyODkxNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478628916", "bodyText": "predictAsync?", "author": "r00ta", "createdAt": "2020-08-27T18:55:34Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java", "diffHunk": "@@ -16,18 +16,19 @@\n package org.kie.kogito.explainability.model;\n \n import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n \n /**\n  * A provider of predictions.\n  * This can be any model, service or function, like (local / remote) DMN, PMML services or any other ML model.\n  */\n+@FunctionalInterface\n public interface PredictionProvider {\n \n     /**\n      * Perform a batch of predictions, given a batch of inputs.\n      * @param inputs the input batch\n      * @return a batch of prediction outputs\n      */\n-    List<PredictionOutput> predict(List<PredictionInput> inputs);\n-\n+    CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs);", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDAyNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920025", "bodyText": "Done", "author": "danielezonca", "createdAt": "2020-08-28T08:09:16Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYyODkxNg=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java\nindex 9975c27f9..f06801faa 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/model/PredictionProvider.java\n\n@@ -30,5 +30,5 @@ public interface PredictionProvider {\n      * @param inputs the input batch\n      * @return a batch of prediction outputs\n      */\n-    CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs);\n+    CompletableFuture<List<PredictionOutput>> predictAsync(List<PredictionInput> inputs);\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNTE1MA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478635150", "bodyText": "throws Exception?", "author": "r00ta", "createdAt": "2020-08-27T19:07:14Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDEyOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920129", "bodyText": "Fixed", "author": "danielezonca", "createdAt": "2020-08-28T08:09:22Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzNTE1MA=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\nindex f520aea8b..a1ee70a1d 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n\n@@ -75,7 +75,7 @@ public class ExplainabilityMetrics {\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws InterruptedException, ExecutionException, TimeoutException {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzODM2NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478638365", "bodyText": "I have mixed feelings about this test in general, but isnt't generating only 1s? Not sure this is really representative data, if this is actually meaningful for the test itself..", "author": "r00ta", "createdAt": "2020-08-27T19:13:30Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4Nzc4MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478887781", "bodyText": "I agree that this test is not really meaningful so I have created this ticket to improve it\nhttps://issues.redhat.com/browse/FAI-249", "author": "danielezonca", "createdAt": "2020-08-28T07:32:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzODM2NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzOTQyMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478639421", "bodyText": "why score is set to 0?", "author": "r00ta", "createdAt": "2020-08-27T19:15:23Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -35,35 +33,44 @@\n import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.utils.DataUtils;\n \n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+\n+import static java.util.concurrent.CompletableFuture.supplyAsync;\n import static org.junit.jupiter.api.Assertions.assertEquals;\n import static org.junit.jupiter.api.Assertions.assertNotNull;\n \n class PartialDependencePlotExplainerTest {\n \n-    @Test\n-    void testPdpTextClassifier() {\n-        PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n-        PredictionProvider modelInfo = TestUtils.getDummyTextClassifier();\n-        PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n-            @Override\n-            public DataDistribution getDataDistribution() {\n-                return DataUtils.generateRandomDataDistribution(10, 100, new Random());\n-            }\n+    PartialDependencePlotExplainer partialDependencePlotProvider = new PartialDependencePlotExplainer();\n+    PredictionProviderMetadata metadata = new PredictionProviderMetadata() {\n+        @Override\n+        public DataDistribution getDataDistribution() {\n+            return DataUtils.generateRandomDataDistribution(10, 100, new FakeRandom());\n+        }\n \n-            @Override\n-            public PredictionInput getInputShape() {\n-                List<Feature> features = new LinkedList<>();\n-                features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n-                return new PredictionInput(features);\n-            }\n+        @Override\n+        public PredictionInput getInputShape() {\n+            List<Feature> features = new LinkedList<>();\n+            features.add(FeatureFactory.newTextFeature(\"text\", \"\"));\n+            return new PredictionInput(features);\n+        }\n+\n+        @Override\n+        public PredictionOutput getOutputShape() {\n+            List<Output> outputs = new LinkedList<>();\n+            outputs.add(new Output(\"spam\", Type.BOOLEAN, new Value<>(null), 0d));", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4NDY1Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478884652", "bodyText": "This value is not important in this test so it is mocked", "author": "danielezonca", "createdAt": "2020-08-28T07:29:14Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODYzOTQyMQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478641797", "bodyText": "why moving the division inside the sum?", "author": "r00ta", "createdAt": "2020-08-27T19:19:53Z", "path": "explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java", "diffHunk": "@@ -68,24 +75,32 @@ public static double quantifyExplainability(int inputCognitiveChunks, int output\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n         }\n \n         PredictionInput predictionInput = new PredictionInput(copy);\n-        List<PredictionOutput> predictionOutputs = model.predict(List.of(predictionInput));\n-        PredictionOutput predictionOutput = predictionOutputs.get(0);\n+        List<PredictionOutput> predictionOutputs;\n+        try {\n+            predictionOutputs = model.predict(List.of(predictionInput))\n+                    .get(Config.INSTANCE.getAsyncTimeout(), Config.INSTANCE.getAsyncTimeUnit());\n+        } catch (InterruptedException | ExecutionException | TimeoutException e) {\n+            LOGGER.error(\"Impossible to obtain prediction {}\", e.getMessage());\n+            throw e;\n+        }\n         double impact = 0d;\n-        double size = predictionOutput.getOutputs().size();\n-        for (int i = 0; i < size; i++) {\n-            Output original = prediction.getOutput().getOutputs().get(i);\n-            Output modified = predictionOutput.getOutputs().get(i);\n-            impact += (!original.getValue().asString().equals(modified.getValue().asString())\n-                    || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d : 0d;\n+        for (PredictionOutput predictionOutput : predictionOutputs) {\n+            double size = predictionOutput.getOutputs().size();\n+            for (int i = 0; i < size; i++) {\n+                Output original = prediction.getOutput().getOutputs().get(i);\n+                Output modified = predictionOutput.getOutputs().get(i);\n+                impact += (!original.getValue().asString().equals(modified.getValue().asString())\n+                        || modified.getScore() < original.getScore() * CONFIDENCE_DROP_RATIO) ? 1d / size : 0d;\n+            }\n         }\n-        return impact / size;\n+        return impact;", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQzMzc5Ng==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479433796", "bodyText": "The previous code was considering only one PredictionOutput to calculate the impact while now it consider all of them (excluding the top one on purpose). Adding this additional for required to move the division inside the loop.", "author": "danielezonca", "createdAt": "2020-08-28T17:12:47Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk1MTg2NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479951865", "bodyText": "Understood, but then I have the doubt that now the method is doing something different: in this method  model.predictAsync is used with just one request, predictionOutputs should a list of just 1 element as before right?", "author": "r00ta", "createdAt": "2020-08-31T07:38:46Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTk4NDEyMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479984120", "bodyText": "It was a bug not shown by the test: the test is providing 2 features, 1 is removed (top feature) and the other 1 was used for the calculus so the old value was correct (aka equivalent to the new one)", "author": "danielezonca", "createdAt": "2020-08-31T08:42:57Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0MTc5Nw=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\nindex f520aea8b..a1ee70a1d 100644\n--- a/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n+++ b/explainability/explainability-core/src/main/java/org/kie/kogito/explainability/utils/ExplainabilityMetrics.java\n\n@@ -75,7 +75,7 @@ public class ExplainabilityMetrics {\n      * @param topFeatures the list of important features that should be dropped\n      * @return the saliency impact\n      */\n-    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws Exception {\n+    public static double impactScore(PredictionProvider model, Prediction prediction, List<FeatureImportance> topFeatures) throws InterruptedException, ExecutionException, TimeoutException {\n         List<Feature> copy = List.copyOf(prediction.getInput().getFeatures());\n         for (FeatureImportance featureImportance : topFeatures) {\n             copy = DataUtils.dropFeature(copy, featureImportance.getFeature());\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0NjYzOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478646638", "bodyText": "is this used?", "author": "r00ta", "createdAt": "2020-08-27T19:29:19Z", "path": "explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability.rest;\n+\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.concurrent.CompletableFuture;\n+\n+public class PredictionProviderMock implements PredictionProvider {", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg5MDYwOA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478890608", "bodyText": "Yes it is used by this mock", "author": "danielezonca", "createdAt": "2020-08-28T07:36:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0NjYzOA=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java b/explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java\nindex 2e2abae66..b4fc217e1 100644\n--- a/explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java\n+++ b/explainability/explainability-service-rest/src/test/java/org/kie/kogito/explainability/rest/PredictionProviderMock.java\n\n@@ -26,7 +26,7 @@ import java.util.concurrent.CompletableFuture;\n public class PredictionProviderMock implements PredictionProvider {\n \n     @Override\n-    public CompletableFuture<List<PredictionOutput>> predict(List<PredictionInput> inputs) {\n+    public CompletableFuture<List<PredictionOutput>> predictAsync(List<PredictionInput> inputs) {\n         return CompletableFuture.completedFuture(Collections.emptyList());\n     }\n }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODI4NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478648285", "bodyText": "Don't we use vertx?", "author": "r00ta", "createdAt": "2020-08-27T19:32:29Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg5Mjk3MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478892971", "bodyText": "We are using context propagation abstraction to decouple from the specific executor impl ( see Quarkus doc and MP doc )", "author": "danielezonca", "createdAt": "2020-08-28T07:39:19Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODI4NQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODgyMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478648820", "bodyText": "why protected?", "author": "r00ta", "createdAt": "2020-08-27T19:33:30Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());\n+                });\n+    }\n+\n+    protected static ExplainabilityResultDto createResultDto(Map<String, Saliency> saliencies, String executionId) {", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkxNjYzOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478916639", "bodyText": "Why not? :)\nIt is a pure static function so it could be even public :)\nJoking aside, the reason is because it is possible to reuse it if (when?) ExplainableServiceImpl will be extended", "author": "danielezonca", "createdAt": "2020-08-28T08:05:41Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0ODgyMA=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTYwOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478649609", "bodyText": "Can we avoid returning an empty map as result? What about adding a property in the DTO with the success information and eventually the reason why there is no result?", "author": "r00ta", "createdAt": "2020-08-27T19:35:02Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/ExplanationServiceImpl.java", "diffHunk": "@@ -16,25 +16,84 @@\n \n package org.kie.kogito.explainability;\n \n-import java.util.concurrent.CompletableFuture;\n-import java.util.concurrent.CompletionStage;\n+import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n+import org.kie.kogito.explainability.api.FeatureImportanceDto;\n+import org.kie.kogito.explainability.api.SaliencyDto;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.model.Prediction;\n+import org.kie.kogito.explainability.model.PredictionInput;\n+import org.kie.kogito.explainability.model.PredictionOutput;\n+import org.kie.kogito.explainability.model.PredictionProvider;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n import javax.enterprise.context.ApplicationScoped;\n import javax.inject.Inject;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletionStage;\n+import java.util.stream.Collectors;\n \n-import org.eclipse.microprofile.context.ManagedExecutor;\n-import org.kie.kogito.explainability.api.ExplainabilityResultDto;\n-import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import static org.kie.kogito.explainability.ConversionUtils.toFeatureList;\n+import static org.kie.kogito.explainability.ConversionUtils.toOutputList;\n \n @ApplicationScoped\n public class ExplanationServiceImpl implements ExplanationService {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(ExplanationServiceImpl.class);\n+\n+    private final LocalExplainer<Map<String, Saliency>> localExplainer;\n+\n     @Inject\n-    ManagedExecutor executor;\n+    public ExplanationServiceImpl(\n+        LocalExplainer<Map<String, Saliency>> localExplainer) {\n+        this.localExplainer = localExplainer;\n+    }\n \n     @Override\n-    public CompletionStage<ExplainabilityResultDto> explainAsync(ExplainabilityRequest request) {\n-        // TODO: get explainability from expl library https://issues.redhat.com/browse/KOGITO-2920\n-        return CompletableFuture.supplyAsync(() -> new ExplainabilityResultDto(request.getExecutionId()), executor);\n+    public CompletionStage<ExplainabilityResultDto> explainAsync(\n+            ExplainabilityRequest request,\n+            PredictionProvider predictionProvider) {\n+        LOG.debug(\"Explainability request with executionId {} for model {}:{}\",\n+                request.getExecutionId(),\n+                request.getModelIdentifier().getResourceType(),\n+                request.getModelIdentifier().getResourceId());\n+        Prediction prediction = getPrediction(request.getInputs(), request.getOutputs());\n+        return localExplainer.explainAsync(prediction, predictionProvider)\n+                .thenApply(input -> createResultDto(input, request.getExecutionId()))\n+                .exceptionally(throwable -> {\n+                    LOG.error(\"Exception thrown during explainAsync\", throwable);\n+                    return new ExplainabilityResultDto(request.getExecutionId(), Collections.emptyMap());", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTI5MTI5MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479291291", "bodyText": "Ticket created https://issues.redhat.com/browse/KOGITO-3213", "author": "danielezonca", "createdAt": "2020-08-28T13:30:33Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTYwOQ=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTg4NA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478649884", "bodyText": "move at top?", "author": "r00ta", "createdAt": "2020-08-27T19:35:36Z", "path": "explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java", "diffHunk": "@@ -0,0 +1,52 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import org.eclipse.microprofile.config.inject.ConfigProperty;\n+import org.kie.kogito.explainability.local.LocalExplainer;\n+import org.kie.kogito.explainability.local.lime.LimeExplainer;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.enterprise.context.ApplicationScoped;\n+import javax.enterprise.inject.Produces;\n+import javax.inject.Inject;\n+import java.util.Map;\n+\n+@ApplicationScoped\n+public class LimeExplainerProducer {\n+\n+    private final Integer numberOfSamples;\n+    private final Integer numberOfPerturbations;\n+\n+    @Inject\n+    public LimeExplainerProducer(\n+            @ConfigProperty(name = \"trusty.explainability.numberOfSamples\", defaultValue = \"100\") Integer numberOfSamples,\n+            @ConfigProperty(name = \"trusty.explainability.numberOfPerturbations\", defaultValue = \"1\") Integer numberOfPerturbations) {\n+        this.numberOfSamples = numberOfSamples;\n+        this.numberOfPerturbations = numberOfPerturbations;\n+    }\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(LimeExplainerProducer.class);", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDM4Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920382", "bodyText": "Done", "author": "danielezonca", "createdAt": "2020-08-28T08:09:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY0OTg4NA=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java\nindex 2ac86fc12..13dede0d1 100644\n--- a/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java\n+++ b/explainability/explainability-service/src/main/java/org/kie/kogito/explainability/LimeExplainerProducer.java\n\n@@ -31,6 +31,8 @@ import java.util.Map;\n @ApplicationScoped\n public class LimeExplainerProducer {\n \n+    private static final Logger LOG = LoggerFactory.getLogger(LimeExplainerProducer.class);\n+\n     private final Integer numberOfSamples;\n     private final Integer numberOfPerturbations;\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MjM1OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478652359", "bodyText": "remove wildcard?", "author": "r00ta", "createdAt": "2020-08-27T19:40:34Z", "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java", "diffHunk": "@@ -0,0 +1,160 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.*;", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMDk1Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478920953", "bodyText": "Done", "author": "danielezonca", "createdAt": "2020-08-28T08:10:06Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1MjM1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "98389345bd3c8aa3985e74dd0e65eb36405932cf", "chunk": "diff --git a/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java b/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java\nindex 62e647c28..ad97d0154 100644\n--- a/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java\n+++ b/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/ConversionUtilsTest.java\n\n@@ -16,7 +16,11 @@\n package org.kie.kogito.explainability;\n \n import com.fasterxml.jackson.databind.JsonNode;\n-import com.fasterxml.jackson.databind.node.*;\n+import com.fasterxml.jackson.databind.node.BooleanNode;\n+import com.fasterxml.jackson.databind.node.DoubleNode;\n+import com.fasterxml.jackson.databind.node.JsonNodeFactory;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n import io.vertx.core.json.JsonObject;\n import org.apache.commons.lang3.tuple.Pair;\n import org.junit.jupiter.api.Test;\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjAyOQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478656029", "bodyText": "Remove these assignments ;)", "author": "r00ta", "createdAt": "2020-08-27T19:47:28Z", "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -61,7 +82,7 @@ void givenADecisionWhenStoreDecisionIsCalledThenNoExceptionsAreThrown() {\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void givenADecisionWhenADecisionIsStoredAndRetrievedThenTheOriginalObjectIsReturned() {\n-        String executionId = \"executionId\";\n+        String executionId = TEST_EXECUTION_ID;", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODkyMTA0MQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478921041", "bodyText": "Done", "author": "danielezonca", "createdAt": "2020-08-28T08:10:12Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjAyOQ=="}], "type": "inlineReview", "revised_code": {"commit": "8050f6eb00c8902273c656bbda15309fa095ddee", "chunk": "diff --git a/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java b/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java\nindex b85ece6d9..eab1da54e 100644\n--- a/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java\n+++ b/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java\n\n@@ -82,9 +82,8 @@ public class TrustyServiceTest {\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void givenADecisionWhenADecisionIsStoredAndRetrievedThenTheOriginalObjectIsReturned() {\n-        String executionId = TEST_EXECUTION_ID;\n         Decision decision = new Decision();\n-        decision.setExecutionId(executionId);\n+        decision.setExecutionId(TEST_EXECUTION_ID);\n \n         Query queryMock = mock(Query.class);\n         when(queryMock.filter(any(List.class))).thenReturn(queryMock);\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjkzMA==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478656930", "bodyText": "move to another file?", "author": "r00ta", "createdAt": "2020-08-27T19:49:13Z", "path": "trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan;\n+\n+import java.io.IOException;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.kie.kogito.trusty.storage.api.model.ExplainabilityResult;\n+import org.kie.kogito.trusty.storage.api.model.Saliency;\n+\n+public class ExplainabilityResultItemMarshaller extends AbstractModelMarshaller<ExplainabilityResultItem> {\n+\n+    public ExplainabilityResultItemMarshaller(ObjectMapper mapper) {\n+        super(mapper, ExplainabilityResultItem.class);\n+    }\n+\n+    @Override\n+    public ExplainabilityResultItem readFrom(ProtoStreamReader reader) throws IOException {\n+        return new ExplainabilityResultItem(\n+                reader.readString(ExplainabilityResultItem.ID_FIELD),\n+                reader.readObject(ExplainabilityResultItem.SALIENCY_FIELD, Saliency.class)\n+        );\n+    }\n+\n+    @Override\n+    public void writeTo(ProtoStreamWriter writer, ExplainabilityResultItem input) throws IOException {\n+        writer.writeString(ExplainabilityResultItem.ID_FIELD, input.getId());\n+        writer.writeObject(ExplainabilityResultItem.SALIENCY_FIELD, input.getSaliency(), Saliency.class);\n+    }\n+\n+    @Override\n+    public String getTypeName() {\n+        return String.format(\"%s.%s\", ExplainabilityResult.class.getPackageName(), ExplainabilityResultItem.class.getSimpleName());\n+    }\n+}\n+\n+class ExplainabilityResultItem {", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODU1OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448559", "bodyText": "In general I am no a fan of not public inner classes but I think it makes sense in this case: this is an utility class used only to properly serialize and de-serialize a Map with proto. We can create a new file but it is not supposed to be used and it could be even dangerous to have it: someone might see this class and modify it for other reason while this should never happen.\nI added a javadoc to clarify", "author": "danielezonca", "createdAt": "2020-08-28T17:43:25Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1NjkzMA=="}], "type": "inlineReview", "revised_code": {"commit": "d4d7e110f74131ec144d4eb254999855a8ee13ab", "chunk": "diff --git a/trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java b/trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java\nindex 83f26735d..d090cdc45 100644\n--- a/trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java\n+++ b/trusty/trusty-storage/trusty-storage-infinispan/src/main/java/org/kie/kogito/trusty/storage/infinispan/ExplainabilityResultItemMarshaller.java\n\n@@ -49,6 +49,10 @@ public class ExplainabilityResultItemMarshaller extends AbstractModelMarshaller<\n     }\n }\n \n+/**\n+ * This is an utility class used for ExplainabilityResult proto serialization (see decision.proto). It is needed to support\n+ * the handling of a Map<String, Saliency>\n+ */\n class ExplainabilityResultItem {\n \n     public static final String ID_FIELD = \"id\";\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1ODU1Mw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478658553", "bodyText": "what's that?", "author": "r00ta", "createdAt": "2020-08-27T19:52:21Z", "path": "trusty/trusty-storage/trusty-storage-infinispan/src/test/java/org/kie/kogito/trusty/storage/infinispan/testfield/MapToListTestField.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ *  Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *        http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ */\n+\n+package org.kie.kogito.trusty.storage.infinispan.testfield;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+\n+public class MapToListTestField<M, K, V, L> extends ListTestField<M, L> {", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQyMzMxNQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479423315", "bodyText": "It is an utility test class to handle map and reuse MarshallerTestTemplate mechanism", "author": "danielezonca", "createdAt": "2020-08-28T16:52:07Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1ODU1Mw=="}], "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478659467", "bodyText": "everything with capital letters?", "author": "r00ta", "createdAt": "2020-08-27T19:54:12Z", "path": "explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2020 Red Hat, Inc. and/or its affiliates.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.kie.kogito.explainability;\n+\n+import com.fasterxml.jackson.databind.node.DoubleNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import org.kie.kogito.explainability.model.*;\n+import org.kie.kogito.explainability.models.ExplainabilityRequest;\n+import org.kie.kogito.explainability.models.ModelIdentifier;\n+import org.kie.kogito.tracing.typedvalue.TypedValue;\n+import org.kie.kogito.tracing.typedvalue.UnitValue;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static java.util.Arrays.asList;\n+import static java.util.Collections.*;\n+\n+public class TestUtils {\n+\n+    private TestUtils() {\n+        // prevent initialization\n+    }\n+\n+    public static final String executionId = \"executionId\";\n+    public static final String serviceUrl = \"localhost:8080\";\n+\n+    public static final ModelIdentifier modelIdentifier = new ModelIdentifier(\"dmn\", \"name:namespace\");", "originalCommit": "e84a36f5a6ebf2afb48dab3d3edee557b684b1bc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg1Mzc1NQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478853755", "bodyText": "why? \ud83e\udd14", "author": "kostola", "createdAt": "2020-08-28T06:19:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODg4NjYyNg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r478886626", "bodyText": "because they are constants https://www.oracle.com/java/technologies/javase/codeconventions-namingconventions.html", "author": "r00ta", "createdAt": "2020-08-28T07:31:34Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw=="}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODQ5Nw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448497", "bodyText": "Done", "author": "danielezonca", "createdAt": "2020-08-28T17:43:18Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3ODY1OTQ2Nw=="}], "type": "inlineReview", "revised_code": {"commit": "98389345bd3c8aa3985e74dd0e65eb36405932cf", "chunk": "diff --git a/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java b/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java\nindex fd257c92d..2b413493d 100644\n--- a/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java\n+++ b/explainability/explainability-service/src/test/java/org/kie/kogito/explainability/TestUtils.java\n\n@@ -18,7 +18,12 @@ package org.kie.kogito.explainability;\n \n import com.fasterxml.jackson.databind.node.DoubleNode;\n import com.fasterxml.jackson.databind.node.TextNode;\n-import org.kie.kogito.explainability.model.*;\n+import org.kie.kogito.explainability.model.Feature;\n+import org.kie.kogito.explainability.model.FeatureImportance;\n+import org.kie.kogito.explainability.model.Output;\n+import org.kie.kogito.explainability.model.Saliency;\n+import org.kie.kogito.explainability.model.Type;\n+import org.kie.kogito.explainability.model.Value;\n import org.kie.kogito.explainability.models.ExplainabilityRequest;\n import org.kie.kogito.explainability.models.ModelIdentifier;\n import org.kie.kogito.tracing.typedvalue.TypedValue;\n"}}, {"oid": "98389345bd3c8aa3985e74dd0e65eb36405932cf", "url": "https://github.com/kiegroup/kogito-apps/commit/98389345bd3c8aa3985e74dd0e65eb36405932cf", "message": "[KOGITO-2914] Update imports", "committedDate": "2020-08-28T07:06:08Z", "type": "commit"}, {"oid": "8050f6eb00c8902273c656bbda15309fa095ddee", "url": "https://github.com/kiegroup/kogito-apps/commit/8050f6eb00c8902273c656bbda15309fa095ddee", "message": "[KOGITO-2914] PR comments", "committedDate": "2020-08-28T08:08:36Z", "type": "commit"}, {"oid": "beeaeb4b50343bad73de57f5393da730ef3a4ea7", "url": "https://github.com/kiegroup/kogito-apps/commit/beeaeb4b50343bad73de57f5393da730ef3a4ea7", "message": "Merge remote-tracking branch 'kostola/KOGITO-2914' into KOGITO-2914", "committedDate": "2020-08-28T08:08:58Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE3ODEwMw==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479178103", "bodyText": "Can we add some description here?", "author": "jiripetrlik", "createdAt": "2020-08-28T11:41:54Z", "path": "explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java", "diffHunk": "@@ -74,4 +81,25 @@ public PredictionOutput getOutputShape() {\n         }\n     }\n \n+    @Test\n+    void testBrokenPredict() {\n+        Config.INSTANCE.setAsyncTimeout(1);\n+        Config.INSTANCE.setAsyncTimeUnit(TimeUnit.MILLISECONDS);\n+\n+        PredictionProvider brokenProvider = inputs -> supplyAsync(\n+                () -> {\n+                    try {\n+                        Thread.sleep(1000);\n+                        return Collections.emptyList();\n+                    } catch (InterruptedException e) {\n+                        throw new RuntimeException(e);", "originalCommit": "beeaeb4b50343bad73de57f5393da730ef3a4ea7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0NzcyMQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479447721", "bodyText": "I just wanted to simulated a long call to check the timeout. Improved the message", "author": "danielezonca", "createdAt": "2020-08-28T17:41:36Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE3ODEwMw=="}], "type": "inlineReview", "revised_code": {"commit": "d4d7e110f74131ec144d4eb254999855a8ee13ab", "chunk": "diff --git a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java\nindex b7a521d2d..2c99ae8a3 100644\n--- a/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java\n+++ b/explainability/explainability-core/src/test/java/org/kie/kogito/explainability/global/pdp/PartialDependencePlotExplainerTest.java\n\n@@ -92,7 +92,7 @@ class PartialDependencePlotExplainerTest {\n                         Thread.sleep(1000);\n                         return Collections.emptyList();\n                     } catch (InterruptedException e) {\n-                        throw new RuntimeException(e);\n+                        throw new RuntimeException(\"this is a test\");\n                     }\n                 });\n \n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE5MDM5OQ==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479190399", "bodyText": "Is this correct behaviour? Shouldn't we throw an exception instead?", "author": "jiripetrlik", "createdAt": "2020-08-28T11:52:32Z", "path": "trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java", "diffHunk": "@@ -205,12 +284,68 @@ void givenAModelWhenAModelIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturne\n     @Test\n     @SuppressWarnings(\"unchecked\")\n     void whenAModelIsNotStoredAndRetrievedByIdThenExceptionIsThrown() {\n-        String modelId = \"name:namespace\";\n+        String modelId = TEST_MODEL_ID;\n         Storage storageMock = mock(Storage.class);\n \n         when(storageMock.containsKey(modelId)).thenReturn(false);\n         when(trustyStorageServiceMock.getModelStorage()).thenReturn(storageMock);\n \n-        Assertions.assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getModelById(modelId));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledThenNoExceptionsAreThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        Assertions.assertDoesNotThrow(() -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultWhenStoreModelIsCalledMoreThanOnceForSameModelThenExceptionIsThrown() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(true);\n+        when(storageMock.put(eq(TEST_EXECUTION_ID), any(ExplainabilityResult.class))).thenReturn(result);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result));\n+    }\n+\n+    @Test\n+    void givenAnExplainabilityResultWhenAnExplainabilityResultIsStoredAndRetrievedByIdThenTheOriginalObjectIsReturned() {\n+        ExplainabilityResult result = new ExplainabilityResult(TEST_EXECUTION_ID, Collections.emptyMap());\n+        Storage<String, ExplainabilityResult> storageMock = new StorageImplMock<>(String.class);\n+\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        trustyService.storeExplainabilityResult(TEST_EXECUTION_ID, result);\n+\n+        Assertions.assertEquals(result, trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    @Test\n+    @SuppressWarnings(\"unchecked\")\n+    void givenAnExplainabilityResultNotStoredWhenRetrievedByIdThenExceptionIsThrown() {\n+        Storage<String, ExplainabilityResult> storageMock = mock(Storage.class);\n+\n+        when(storageMock.containsKey(eq(TEST_EXECUTION_ID))).thenReturn(false);\n+        when(trustyStorageServiceMock.getExplainabilityResultStorage()).thenReturn(storageMock);\n+\n+        assertThrows(IllegalArgumentException.class, () -> trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n+    }\n+\n+    private static JsonNode toJsonNode(String jsonString) {\n+        try {\n+            return MAPPER.reader().readTree(jsonString);\n+        } catch (JsonProcessingException e) {\n+            return null;", "originalCommit": "beeaeb4b50343bad73de57f5393da730ef3a4ea7", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ0ODQ0Mg==", "url": "https://github.com/kiegroup/kogito-apps/pull/410#discussion_r479448442", "bodyText": "Fixed", "author": "danielezonca", "createdAt": "2020-08-28T17:43:10Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTE5MDM5OQ=="}], "type": "inlineReview", "revised_code": {"commit": "d4d7e110f74131ec144d4eb254999855a8ee13ab", "chunk": "diff --git a/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java b/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java\nindex eab1da54e..765029904 100644\n--- a/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java\n+++ b/trusty/trusty-service/src/test/java/org/kie/kogito/trusty/service/TrustyServiceTest.java\n\n@@ -341,11 +341,7 @@ public class TrustyServiceTest {\n         assertThrows(IllegalArgumentException.class, () -> trustyService.getExplainabilityResultById(TEST_EXECUTION_ID));\n     }\n \n-    private static JsonNode toJsonNode(String jsonString) {\n-        try {\n-            return MAPPER.reader().readTree(jsonString);\n-        } catch (JsonProcessingException e) {\n-            return null;\n-        }\n+    private static JsonNode toJsonNode(String jsonString) throws JsonProcessingException {\n+        return MAPPER.reader().readTree(jsonString);\n     }\n }\n"}}, {"oid": "e326e678ee96baab70addbc3355833da8aea0f94", "url": "https://github.com/kiegroup/kogito-apps/commit/e326e678ee96baab70addbc3355833da8aea0f94", "message": "Merge remote-tracking branch 'upstream/master' into KOGITO-2914", "committedDate": "2020-08-28T16:31:44Z", "type": "commit"}, {"oid": "d4d7e110f74131ec144d4eb254999855a8ee13ab", "url": "https://github.com/kiegroup/kogito-apps/commit/d4d7e110f74131ec144d4eb254999855a8ee13ab", "message": "[KOGITO-2914] PR comments + test coverage", "committedDate": "2020-08-28T17:48:48Z", "type": "commit"}]}