{"pr_number": 4142, "pr_title": "[RW-5046][risk=no] Generate code for microarray cohort extraction and Plink analysis demo", "pr_createdAt": "2020-10-09T16:40:45Z", "pr_url": "https://github.com/all-of-us/workbench/pull/4142", "timeline": [{"oid": "4a4352241016ecc67f98ccaa7163bba2d797ab18", "url": "https://github.com/all-of-us/workbench/commit/4a4352241016ecc67f98ccaa7163bba2d797ab18", "message": "WIP - plink code gen", "committedDate": "2020-10-08T23:12:37Z", "type": "commit"}, {"oid": "bf0bbe2a12145b620b60c0ddaeb1a04995ad5e04", "url": "https://github.com/all-of-us/workbench/commit/bf0bbe2a12145b620b60c0ddaeb1a04995ad5e04", "message": "move codegen into DataSetService", "committedDate": "2020-10-09T16:05:01Z", "type": "commit"}, {"oid": "b6499221127210d60d20e74b502ce4b6f15602a0", "url": "https://github.com/all-of-us/workbench/commit/b6499221127210d60d20e74b502ce4b6f15602a0", "message": "spotless", "committedDate": "2020-10-09T16:49:31Z", "type": "commit"}, {"oid": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "url": "https://github.com/all-of-us/workbench/commit/efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "message": "forgot to flip back booleans", "committedDate": "2020-10-09T20:53:47Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0NTk2Ng==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504145966", "bodyText": "Is our codegen inconsistent about this key name?", "author": "calbach", "createdAt": "2020-10-13T17:50:10Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0NzAyNQ==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504147025", "bodyText": "In general, different codegen notebooks should be independent, so I would put something distinctive in the filename, e.g. the dataset ID; OR this should just use a purely temporary file", "author": "calbach", "createdAt": "2020-10-13T17:52:01Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0ODUwNg==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504148506", "bodyText": "Please leave a TODO here so the hardcoded value doesn't look like a bug: I filed RW-5735.", "author": "calbach", "createdAt": "2020-10-13T17:54:35Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE0OTQ3MA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504149470", "bodyText": "This is not portable to duplication, code copying etc - instead use ${GOOGLE_PROJECT}", "author": "calbach", "createdAt": "2020-10-13T17:56:07Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MDgyOQ==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504150829", "bodyText": "This is not portable to other CDR versions, we will eventually want an env var like WORKSPACE_CDR_MICROARRAY; I think this is fine for now but please leave a TODO and file a ticket if you don't mind", "author": "calbach", "createdAt": "2020-10-13T17:58:23Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MTEyMw==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504151123", "bodyText": "per above, would use an identifier", "author": "calbach", "createdAt": "2020-10-13T17:58:49Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjEzOQ==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504152139", "bodyText": "I'm wondering if this should be a separate code cell. Both of these steps are going to be quite slow", "author": "calbach", "createdAt": "2020-10-13T18:00:33Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTEyMjE3MA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505122170", "bodyText": "Decided to keep together so the user can run all of the extract stuff in 1 go", "author": "ericsong", "createdAt": "2020-10-15T02:10:15Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjEzOQ=="}], "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjgyOA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504152828", "bodyText": "What is this project ID being used for? I'd expect the workspace project might be more appropriate", "author": "calbach", "createdAt": "2020-10-13T18:01:44Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTEyNDUyNA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505124524", "bodyText": "I poked around GATK and it turns out its not being used at all. I changed it to the workspace env var but we may be able to take it out entirely if GATK is refactored to just remove the argument.", "author": "ericsong", "createdAt": "2020-10-15T02:19:00Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MjgyOA=="}], "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE1MzAyOA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504153028", "bodyText": "I'd probably rather take a default - what happens if you just leave this unspecified?", "author": "calbach", "createdAt": "2020-10-13T18:02:06Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NDU1Mg==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504164552", "bodyText": "probably should have some identifier", "author": "calbach", "createdAt": "2020-10-13T18:17:51Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NTQxOA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504165418", "bodyText": "Assuming it is mounted at /genomics sort of forces us into putting it on the image, or localizing the reference fasta in the startup script.\nHave you tried just supplying a gs:// path to this flag?", "author": "calbach", "createdAt": "2020-10-13T18:18:48Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTkxMzI4NA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505913284", "bodyText": "Still curious about this - same for probe_info", "author": "calbach", "createdAt": "2020-10-15T23:06:52Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NTQxOA=="}], "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NjI2MA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504166260", "bodyText": "I guess plink is the default filename, but I find this pretty confusing. I would expect this to be called something like cohort.bed or similar; wdyt about specifying the output filename here?", "author": "calbach", "createdAt": "2020-10-13T18:20:18Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");\n+  }\n+\n+  @Override\n+  public List<String> generatePlinkDemoCode() {\n+    return ImmutableList.of(\n+        \"import random\\n\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    family_id = 0\\n\"\n+            + \"    person_id = person_id\\n\"\n+            + \"    phenotype_1 = random.randint(0, 2) # Change this value to what makes sense for your research by looking through the dataset(s)\\n\"\n+            + \"    phenotype_2 = random.randint(0, 2) # Change this value as well or remove if you are only processing one phenotype \\n\"\n+            + \"    phenotypes_table.append([family_id, person_id, phenotype_1, phenotype_2])\\n\"\n+            + \"\\n\"\n+            + \"cohort_phenotypes = pandas.DataFrame(phenotypes_table) \\n\"\n+            + \"cohort_phenotypes.to_csv('phenotypes.phe', header=False, index=False, sep=' ')\",\n+        \"%%bash\\n\\n\"\n+            + \"plink --vcf-half-call m --const-fid 0 --vcf cohort.vcf\\n\"\n+            + \"plink --bfile plink --pheno phenotypes.phe --all-pheno --allow-no-sex --assoc --out results\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE2NzQwMw==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504167403", "bodyText": "Comments for each of these CLIs probably make sense, e.g.\n# Covert the VCF into .bed: PLINK's binary format\n...\n\n# Run the GWAS.", "author": "calbach", "createdAt": "2020-10-13T18:22:25Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");\n+  }\n+\n+  @Override\n+  public List<String> generatePlinkDemoCode() {\n+    return ImmutableList.of(\n+        \"import random\\n\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    family_id = 0\\n\"\n+            + \"    person_id = person_id\\n\"\n+            + \"    phenotype_1 = random.randint(0, 2) # Change this value to what makes sense for your research by looking through the dataset(s)\\n\"\n+            + \"    phenotype_2 = random.randint(0, 2) # Change this value as well or remove if you are only processing one phenotype \\n\"\n+            + \"    phenotypes_table.append([family_id, person_id, phenotype_1, phenotype_2])\\n\"\n+            + \"\\n\"\n+            + \"cohort_phenotypes = pandas.DataFrame(phenotypes_table) \\n\"\n+            + \"cohort_phenotypes.to_csv('phenotypes.phe', header=False, index=False, sep=' ')\",\n+        \"%%bash\\n\\n\"\n+            + \"plink --vcf-half-call m --const-fid 0 --vcf cohort.vcf\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE3MDg4NA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504170884", "bodyText": "This doesn't need to happen in this PR, but one eventual goal would be to make the extraction portion idempotent. Rough pseudocode version of this:\nif [[ gsutil exists $COHORT_VCF ]]; do\n    gsutil cp $COHORT_VCF cohort.vcf\nelse \n  ... # extract\n  gsutil cp cohort.vcf $COHORT_VCF\nfi\n\nThis avoids having to rerun extraction every time your runtime gets restarted.", "author": "calbach", "createdAt": "2020-10-13T18:28:38Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDE3MTQxNA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r504171414", "bodyText": "Can you leave a Java or Python comment about family ID, and why it is hardcoded to 0?", "author": "calbach", "createdAt": "2020-10-13T18:29:35Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -686,6 +686,85 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('cohort_sample_names.txt', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project \"\n+            + dbWorkspace.getWorkspaceNamespace()\n+            + \" \\\\\\n\"\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file cohort_sample_names.txt \\\\\\n\"\n+            + \"          --sample_map_outfile cohort_sample_map.csv\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R /genomics/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O cohort.vcf \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"\n+            + \"        --project-id fc-aou-cdr-synth-test \\\\\\n\"\n+            + \"        --cohort-sample-file cohort_sample_map.csv \\\\\\n\"\n+            + \"        --use-compressed-data \\\"false\\\" \\\\\\n\"\n+            + \"        --cohort-extract-table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"        --local-sort-max-records-in-ram \\\"1000000\\\"\");\n+  }\n+\n+  @Override\n+  public List<String> generatePlinkDemoCode() {\n+    return ImmutableList.of(\n+        \"import random\\n\\n\"\n+            + \"phenotypes_table = []\\n\"\n+            + \"for person_id in person_ids:\\n\"\n+            + \"    family_id = 0\\n\"", "originalCommit": "efdc3ece8418bd96f7f53ccad39b43feb529c3fc", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "c6d33db794a8149705c970698a267925806601c4", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\nindex 5f37913f7..b9b2d76f9 100644\n--- a/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n+++ b/api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java\n\n@@ -702,6 +702,10 @@ public class DataSetServiceImpl implements DataSetService, GaugeDataCollector {\n                         + \"_df\")\n             .collect(Collectors.joining(\", \"));\n \n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n     return ImmutableList.of(\n         \"person_ids = set()\\n\"\n             + \"datasets = [\"\n"}}, {"oid": "c6d33db794a8149705c970698a267925806601c4", "url": "https://github.com/all-of-us/workbench/commit/c6d33db794a8149705c970698a267925806601c4", "message": "code review edits", "committedDate": "2020-10-15T15:02:55Z", "type": "commit"}, {"oid": "f785370e4d39424c61e5ea5289a546c9669c44a8", "url": "https://github.com/all-of-us/workbench/commit/f785370e4d39424c61e5ea5289a546c9669c44a8", "message": "revert numWorkers", "committedDate": "2020-10-15T18:09:38Z", "type": "commit"}, {"oid": "edf87ceb2d84e2acf1f104685c279abc60bc8cad", "url": "https://github.com/all-of-us/workbench/commit/edf87ceb2d84e2acf1f104685c279abc60bc8cad", "message": "lint", "committedDate": "2020-10-15T19:21:45Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTkxMjg3OA==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r505912878", "bodyText": "If it's easy to check the CDR version (for the workspace, e.g. workspace.getCdrVersion()) here - an assertion about whether this workspace has genomics data could be a nice addition as well. I'd consider that failure mode to be a 412 failed precondition since it's dependent on CDR version state.", "author": "calbach", "createdAt": "2020-10-15T23:05:41Z", "path": "api/src/main/java/org/pmiops/workbench/api/DataSetController.java", "diffHunk": "@@ -336,6 +338,20 @@ private void formatTimestampValues(List<DataSetPreviewValueList> valuePreviewLis\n             qualifier,\n             queriesByDomain);\n \n+    if (GenomicsDataTypeEnum.MICROARRAY.equals(dataSetExportRequest.getGenomicsDataType())) {\n+      if (!dataSetExportRequest.getKernelType().equals(KernelTypeEnum.PYTHON)) {", "originalCommit": "edf87ceb2d84e2acf1f104685c279abc60bc8cad", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "10a56b400b9bd9b0424872360068b6d6a4a2c042", "chunk": "diff --git a/api/src/main/java/org/pmiops/workbench/api/DataSetController.java b/api/src/main/java/org/pmiops/workbench/api/DataSetController.java\nindex a6bd9e8ff..fa8523b07 100644\n--- a/api/src/main/java/org/pmiops/workbench/api/DataSetController.java\n+++ b/api/src/main/java/org/pmiops/workbench/api/DataSetController.java\n\n@@ -339,6 +340,9 @@ public class DataSetController implements DataSetApiDelegate {\n             queriesByDomain);\n \n     if (GenomicsDataTypeEnum.MICROARRAY.equals(dataSetExportRequest.getGenomicsDataType())) {\n+      if (dbWorkspace.getCdrVersion().getMicroarrayBigqueryDataset() == null) {\n+        throw new FailedPreconditionException(\"The workspace CDR version does not have microarray data\");\n+      }\n       if (!dataSetExportRequest.getKernelType().equals(KernelTypeEnum.PYTHON)) {\n         throw new BadRequestException(\"Genomics code generation is only supported in Python\");\n       }\n"}}, {"oid": "10a56b400b9bd9b0424872360068b6d6a4a2c042", "url": "https://github.com/all-of-us/workbench/commit/10a56b400b9bd9b0424872360068b6d6a4a2c042", "message": "add cdr version requirements check", "committedDate": "2020-10-16T16:32:58Z", "type": "commit"}, {"oid": "810bba1adb902b1d7155d3d1afa8cab086213ca1", "url": "https://github.com/all-of-us/workbench/commit/810bba1adb902b1d7155d3d1afa8cab086213ca1", "message": "spotless", "committedDate": "2020-10-16T17:04:03Z", "type": "commit"}, {"oid": "aba0fc2d5d2aae64274e2ac7e495cb392a40815b", "url": "https://github.com/all-of-us/workbench/commit/aba0fc2d5d2aae64274e2ac7e495cb392a40815b", "message": "Merge branch 'master' of github.com:all-of-us/workbench into songe/RW-5046", "committedDate": "2020-10-16T17:43:19Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNjc2NzMwNQ==", "url": "https://github.com/all-of-us/workbench/pull/4142#discussion_r506767305", "bodyText": "Looking at the code - it seems we can probably skip this flag entirely - and it will read this from the table: https://github.com/broadinstitute/gatk/blob/ah_var_store/src/main/java/org/broadinstitute/hellbender/tools/variantdb/arrays/ArrayExtractCohort.java#L199-L204", "author": "calbach", "createdAt": "2020-10-17T00:00:34Z", "path": "api/src/main/java/org/pmiops/workbench/dataset/DataSetServiceImpl.java", "diffHunk": "@@ -702,6 +702,119 @@ private String getQualifiedColumnName(Domain currentDomain, String columnName) {\n         .collect(Collectors.toList());\n   }\n \n+  @Override\n+  public List<String> generateMicroarrayCohortExtractCodeCells(\n+      DbWorkspace dbWorkspace,\n+      String qualifier,\n+      Map<String, QueryJobConfiguration> queriesByDomain) {\n+    String joinedDatasetVariableNames =\n+        queriesByDomain.entrySet().stream()\n+            .map(\n+                e ->\n+                    \"dataset_\"\n+                        + qualifier\n+                        + \"_\"\n+                        + Domain.fromValue(e.getKey()).toString().toLowerCase()\n+                        + \"_df\")\n+            .collect(Collectors.joining(\", \"));\n+\n+    final String cohortSampleNamesFilename = \"cohort_sample_names_\" + qualifier + \".txt\";\n+    final String cohortSampleMapFilename = \"cohort_sample_map_\" + qualifier + \".csv\";\n+    final String cohortVcfFilename = \"cohort_\" + qualifier + \".vcf\";\n+\n+    return ImmutableList.of(\n+        \"person_ids = set()\\n\"\n+            + \"datasets = [\"\n+            + joinedDatasetVariableNames\n+            + \"]\\n\"\n+            + \"\\n\"\n+            + \"for dataset in datasets:\\n\"\n+            + \"    if 'PERSON_ID' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['PERSON_ID'])\\n\"\n+            + \"    elif 'person_id' in dataset:\\n\"\n+            + \"        person_ids = person_ids.union(dataset['person_id']) \\n\"\n+            + \"\\n\\n\"\n+            + \"with open('\"\n+            + cohortSampleNamesFilename\n+            + \"', 'w') as cohort_file:\\n\"\n+            + \"    for person_id in person_ids:\\n\"\n+            + \"        cohort_file.write(str(person_id) + '\\\\n')\\n\"\n+            + \"    cohort_file.close()\\n\",\n+        \"%%bash\\n\\n\"\n+            + \"uuid=$(cat /proc/sys/kernel/random/uuid | sed s/-/_/g)\\n\"\n+            // TODO: Writing to the \"tmp\" dataset is a temporary workaround until an alternative,\n+            // RW-5735\n+            + \"EXPORT_TABLE=\\\"fc-aou-cdr-synth-test.tmp_shared_cohort_extract.${uuid}\\\"\\n\"\n+            + \"\\n\"\n+            + \"python3 /genomics/microarray/raw_array_cohort_extract.py \\\\\\n\"\n+            + \"          --dataset fc-aou-cdr-synth-test.microarray_data \\\\\\n\"\n+            + \"          --fq_destination_table ${EXPORT_TABLE} \\\\\\n\"\n+            + \"          --query_project ${GOOGLE_PROJECT} \\\\\\n\"\n+            // TODO: Replace hardcoded dataset reference: RW-5748\n+            + \"          --sample_mapping_table fc-aou-cdr-synth-test.microarray_data.sample_list \\\\\\n\"\n+            + \"          --cohort_sample_names_file \"\n+            + cohortSampleNamesFilename\n+            + \" \\\\\\n\"\n+            + \"          --sample_map_outfile \"\n+            + cohortSampleMapFilename\n+            + \"\\n\"\n+            + \"\\n\"\n+            + \"gatk ArrayExtractCohort \\\\\\n\"\n+            + \"        -R gs://fc-aou-cdr-synth-test-genomics/extract_resources/Homo_sapiens_assembly19.fasta \\\\\\n\"\n+            + \"        -O \"\n+            + cohortVcfFilename\n+            + \" \\\\\\n\"\n+            + \"        --probe-info-csv /genomics/microarray/probe_info.csv \\\\\\n\"", "originalCommit": "aba0fc2d5d2aae64274e2ac7e495cb392a40815b", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}