{"pr_number": 1270, "pr_title": "Rework of All Ids Table for External Query", "pr_createdAt": "2020-07-14T07:47:51Z", "pr_url": "https://github.com/bakdata/conquery/pull/1270", "timeline": [{"oid": "230086e7259681c50653c8c8d9128bcc4268c211", "url": "https://github.com/bakdata/conquery/commit/230086e7259681c50653c8c8d9128bcc4268c211", "message": "try and refactor ALL_IDS_TABLE into less unreliable with regards to re-imports", "committedDate": "2020-04-02T12:46:14Z", "type": "commit"}, {"oid": "ae206410b91c214e447a33d12ac716ca4f5a1d8a", "url": "https://github.com/bakdata/conquery/commit/ae206410b91c214e447a33d12ac716ca4f5a1d8a", "message": "Manual reimplementation towards ALL_ID_TABLE: This has the same behaviour as what's currently happening except that we can now control it completely.", "committedDate": "2020-07-14T07:29:18Z", "type": "commit"}, {"oid": "11c8a668505589bfafd7a8665a116a608256382a", "url": "https://github.com/bakdata/conquery/commit/11c8a668505589bfafd7a8665a116a608256382a", "message": "some documentation", "committedDate": "2020-07-20T10:25:03Z", "type": "commit"}, {"oid": "922024bf633ed523f48856c20739fc0d58c8ea33", "url": "https://github.com/bakdata/conquery/commit/922024bf633ed523f48856c20739fc0d58c8ea33", "message": "Remove as many references to ALL_IDS_TABLE as possible", "committedDate": "2020-07-20T13:57:36Z", "type": "commit"}, {"oid": "e8ba8a67aa567bc326d59a2567d1263f680f71e5", "url": "https://github.com/bakdata/conquery/commit/e8ba8a67aa567bc326d59a2567d1263f680f71e5", "message": "Refactor nextTable towards taking a tableId instead of a Table", "committedDate": "2020-07-20T13:58:33Z", "type": "commit"}, {"oid": "25fd72e891416e27e89d114426b928e294c6654a", "url": "https://github.com/bakdata/conquery/commit/25fd72e891416e27e89d114426b928e294c6654a", "message": "Fix a bug over equality with change to TableId", "committedDate": "2020-07-20T15:26:51Z", "type": "commit"}, {"oid": "be63dc241eb7751a2f079cfe2a3cb6c5f51c8504", "url": "https://github.com/bakdata/conquery/commit/be63dc241eb7751a2f079cfe2a3cb6c5f51c8504", "message": "Change ConceptQueryPlan to always run a single pass with ConqueryConstants.ALL_IDS_TABLE and refactor ExternalNode", "committedDate": "2020-07-20T15:28:29Z", "type": "commit"}, {"oid": "e6312ee6f58921ba5d97f103f60067db8decc4f1", "url": "https://github.com/bakdata/conquery/commit/e6312ee6f58921ba5d97f103f60067db8decc4f1", "message": "Cleanup", "committedDate": "2020-07-21T13:01:27Z", "type": "commit"}, {"oid": "fe401a918465d4fb541d862aa21f8c4a3a3e4174", "url": "https://github.com/bakdata/conquery/commit/fe401a918465d4fb541d862aa21f8c4a3a3e4174", "message": "Some more documentation", "committedDate": "2020-07-21T13:04:05Z", "type": "commit"}, {"oid": "86b15af1e29b696000add83ef24d07a81583fc69", "url": "https://github.com/bakdata/conquery/commit/86b15af1e29b696000add83ef24d07a81583fc69", "message": "Fix counting of Imports in DeletionTests", "committedDate": "2020-07-21T13:56:21Z", "type": "commit"}, {"oid": "f9c63fc6c29795c4da7e0b300ef0a5db6c209764", "url": "https://github.com/bakdata/conquery/commit/f9c63fc6c29795c4da7e0b300ef0a5db6c209764", "message": "Delete ImportDeletionTest2.java", "committedDate": "2020-07-21T14:14:02Z", "type": "commit"}, {"oid": "c8d834cfcd264eb47ee4a477631c9e5bc9aeaff5", "url": "https://github.com/bakdata/conquery/commit/c8d834cfcd264eb47ee4a477631c9e5bc9aeaff5", "message": "Add Dataset.isAllIdsTable and make requiredTables ThreadLocal to avoid locking", "committedDate": "2020-07-21T14:20:48Z", "type": "commit"}, {"oid": "8438ace6add1409aec90148b10e4099241d72874", "url": "https://github.com/bakdata/conquery/commit/8438ace6add1409aec90148b10e4099241d72874", "message": "Merge branch 'develop' into feature/all-ids-table-empty-imports", "committedDate": "2020-07-22T14:24:10Z", "type": "commit"}, {"oid": "efe35e02dfd2c5bd61999be141c7cbc719997992", "url": "https://github.com/bakdata/conquery/commit/efe35e02dfd2c5bd61999be141c7cbc719997992", "message": "Fix post merge problems", "committedDate": "2020-07-22T14:53:54Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI2NzQ2Ng==", "url": "https://github.com/bakdata/conquery/pull/1270#discussion_r459267466", "bodyText": "Ich glaube dieser Log braucht jetzt keinen ProgressReport mehr :D", "author": "thoniTUB", "createdAt": "2020-07-23T07:41:29Z", "path": "backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java", "diffHunk": "@@ -115,14 +111,7 @@ public void execute() throws JSONException {\n \n \t\t\t//update the allIdsTable\n \t\t\tlog.info(\"\\tupdating id information\");", "originalCommit": "efe35e02dfd2c5bd61999be141c7cbc719997992", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1af3916e1e5fa332e7b00357a14a355769373faa", "chunk": "diff --git a/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java b/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java\nindex efe81132e..33586265a 100644\n--- a/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java\n+++ b/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java\n\n@@ -108,40 +105,29 @@ public class ImportJob extends Job {\n \t\t\t\t}\n \t\t\t}\n \n-\n-\t\t\t//update the allIdsTable\n-\t\t\tlog.info(\"\\tupdating id information\");\n-\n-\t\t\tthis.progressReporter.report(1);\n-\n-\n \t\t\t//create data import and store/send it\n \t\t\tlog.info(\"\\tupdating import information\");\n \t\t\t//if mapping is not required we can also use the old infos here\n \t\t\tImport outImport = createImport(header, !mappingRequired);\n \t\t\tImport inImport = createImport(header, true);\n+\n \t\t\tinImport.setSuffix(inImport.getSuffix() + \"_old\");\n+\n \t\t\tnamespace.getStorage().updateImport(outImport);\n \t\t\tnamespace.sendToAll(new AddImport(outImport));\n \n \t\t\tthis.progressReporter.report(1);\n-\t\t\tint bucketSize = ConqueryConfig.getInstance().getCluster().getEntityBucketSize();\n \n-\t\t\tif (primaryMapping.getNewIds() != null) {\n-\t\t\t\tlog.info(\"Primary mapping contained {} new Ids\", primaryMapping.getNumberOfNewIds());\n-\t\t\t}\n-\t\t\telse {\n-\t\t\t\tlog.warn(\"Primary mapping contained no new Ids.\");\n-\t\t\t}\n \n \t\t\t//import the actual data\n \t\t\tlog.info(\"\\timporting\");\n \n+\t\t\tint bucketSize = ConqueryConfig.getInstance().getCluster().getEntityBucketSize();\n+\n \t\t\tInt2ObjectMap<ImportBucket> buckets = new Int2ObjectOpenHashMap<>(primaryMapping.getUsedBuckets().size());\n \t\t\tInt2ObjectMap<List<byte[]>> bytes = new Int2ObjectOpenHashMap<>(primaryMapping.getUsedBuckets().size());\n \n-\t\t\tProgressReporter child = this.progressReporter.subJob(5);\n-\t\t\tchild.setMax(header.getGroups() + 1);\n+\t\t\tProgressReporter child = this.progressReporter.subJob(header.getGroups());\n \n \t\t\ttry (Input in = new Input(file.readContent())) {\n \t\t\t\tfor (long group = 0; group < header.getGroups(); group++) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI2ODAzMw==", "url": "https://github.com/bakdata/conquery/pull/1270#discussion_r459268033", "bodyText": "Das w\u00e4re f\u00fcr mich eine Info, aber keine warning", "author": "thoniTUB", "createdAt": "2020-07-23T07:42:45Z", "path": "backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java", "diffHunk": "@@ -138,38 +127,11 @@ public void execute() throws JSONException {\n \t\t\tthis.progressReporter.report(1);\n \t\t\tint bucketSize = ConqueryConfig.getInstance().getCluster().getEntityBucketSize();\n \n-\t\t\t//import the new ids into the ALL_IDS_TABLE\n \t\t\tif (primaryMapping.getNewIds() != null) {\n-\n-\t\t\t\tBlockFactory factory = allIdsImp.getBlockFactory();\n-\n-\t\t\t\tInt2ObjectMap<ImportBucket> allIdsBuckets = new Int2ObjectOpenHashMap<>(primaryMapping.getUsedBuckets().size());\n-\t\t\t\tInt2ObjectMap<List<byte[]>> allIdsBytes = new Int2ObjectOpenHashMap<>(primaryMapping.getUsedBuckets().size());\n-\n-\t\t\t\ttry (Output buffer = new Output(2048)) {\n-\t\t\t\t\tProgressReporter child = this.progressReporter.subJob(5);\n-\t\t\t\t\tchild.setMax(primaryMapping.getNumberOfNewIds());\n-\n-\t\t\t\t\tfor (int entityId : RangeUtil.iterate(primaryMapping.getNewIds())) {\n-\t\t\t\t\t\tbuffer.reset();\n-\t\t\t\t\t\tBucket bucket = factory.create(allIdsImp, Collections.singletonList(new Object[0]));\n-\t\t\t\t\t\tbucket.writeContent(buffer);\n-\n-\t\t\t\t\t\t//copy content into ImportBucket\n-\t\t\t\t\t\tint bucketNumber = Entity.getBucket(entityId, bucketSize);\n-\n-\t\t\t\t\t\tImportBucket impBucket = allIdsBuckets\n-\t\t\t\t\t\t\t\t\t\t\t\t\t\t .computeIfAbsent(bucketNumber, b -> new ImportBucket(new BucketId(allIdsImp.getId(), b)));\n-\n-\t\t\t\t\t\timpBucket.getIncludedEntities().add(entityId);\n-\n-\t\t\t\t\t\tallIdsBytes.computeIfAbsent(bucketNumber, i -> new ArrayList<>())\n-\t\t\t\t\t\t\t\t   .add(buffer.toBytes());\n-\n-\t\t\t\t\t\tchild.report(1);\n-\t\t\t\t\t}\n-\t\t\t\t}\n-\t\t\t\tsendBuckets(primaryMapping, allIdsBuckets, allIdsBytes);\n+\t\t\t\tlog.info(\"Primary mapping contained {} new Ids\", primaryMapping.getNumberOfNewIds());\n+\t\t\t}\n+\t\t\telse {\n+\t\t\t\tlog.warn(\"Primary mapping contained no new Ids.\");", "originalCommit": "efe35e02dfd2c5bd61999be141c7cbc719997992", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1af3916e1e5fa332e7b00357a14a355769373faa", "chunk": "diff --git a/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java b/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java\nindex efe81132e..33586265a 100644\n--- a/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java\n+++ b/backend/src/main/java/com/bakdata/conquery/models/jobs/ImportJob.java\n\n@@ -108,40 +105,29 @@ public class ImportJob extends Job {\n \t\t\t\t}\n \t\t\t}\n \n-\n-\t\t\t//update the allIdsTable\n-\t\t\tlog.info(\"\\tupdating id information\");\n-\n-\t\t\tthis.progressReporter.report(1);\n-\n-\n \t\t\t//create data import and store/send it\n \t\t\tlog.info(\"\\tupdating import information\");\n \t\t\t//if mapping is not required we can also use the old infos here\n \t\t\tImport outImport = createImport(header, !mappingRequired);\n \t\t\tImport inImport = createImport(header, true);\n+\n \t\t\tinImport.setSuffix(inImport.getSuffix() + \"_old\");\n+\n \t\t\tnamespace.getStorage().updateImport(outImport);\n \t\t\tnamespace.sendToAll(new AddImport(outImport));\n \n \t\t\tthis.progressReporter.report(1);\n-\t\t\tint bucketSize = ConqueryConfig.getInstance().getCluster().getEntityBucketSize();\n \n-\t\t\tif (primaryMapping.getNewIds() != null) {\n-\t\t\t\tlog.info(\"Primary mapping contained {} new Ids\", primaryMapping.getNumberOfNewIds());\n-\t\t\t}\n-\t\t\telse {\n-\t\t\t\tlog.warn(\"Primary mapping contained no new Ids.\");\n-\t\t\t}\n \n \t\t\t//import the actual data\n \t\t\tlog.info(\"\\timporting\");\n \n+\t\t\tint bucketSize = ConqueryConfig.getInstance().getCluster().getEntityBucketSize();\n+\n \t\t\tInt2ObjectMap<ImportBucket> buckets = new Int2ObjectOpenHashMap<>(primaryMapping.getUsedBuckets().size());\n \t\t\tInt2ObjectMap<List<byte[]>> bytes = new Int2ObjectOpenHashMap<>(primaryMapping.getUsedBuckets().size());\n \n-\t\t\tProgressReporter child = this.progressReporter.subJob(5);\n-\t\t\tchild.setMax(header.getGroups() + 1);\n+\t\t\tProgressReporter child = this.progressReporter.subJob(header.getGroups());\n \n \t\t\ttry (Input in = new Input(file.readContent())) {\n \t\t\t\tfor (long group = 0; group < header.getGroups(); group++) {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTI2OTU1Mw==", "url": "https://github.com/bakdata/conquery/pull/1270#discussion_r459269553", "bodyText": "eigentlich w\u00fcrde ich gerne von TableIds auf den Workern weg kommen", "author": "thoniTUB", "createdAt": "2020-07-23T07:46:02Z", "path": "backend/src/main/java/com/bakdata/conquery/models/query/filter/AggregationResultFilterNode.java", "diffHunk": "@@ -32,7 +30,7 @@ public void collectRequiredTables(Set<TableId> out) {\n \t}\n \n \t@Override\n-\tpublic void nextTable(QueryExecutionContext ctx, Table currentTable) {\n+\tpublic void nextTable(QueryExecutionContext ctx, TableId currentTable) {", "originalCommit": "efe35e02dfd2c5bd61999be141c7cbc719997992", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"oid": "1af3916e1e5fa332e7b00357a14a355769373faa", "url": "https://github.com/bakdata/conquery/commit/1af3916e1e5fa332e7b00357a14a355769373faa", "message": "Reduce no longer used logging and code", "committedDate": "2020-07-23T15:32:29Z", "type": "commit"}, {"oid": "9c302eb0221123d3da01e8de4776e672b49be6f9", "url": "https://github.com/bakdata/conquery/commit/9c302eb0221123d3da01e8de4776e672b49be6f9", "message": "fix ProgressReporter usage in ImportJob", "committedDate": "2020-07-23T16:59:25Z", "type": "commit"}, {"oid": "b1f8854c528c066760878a3a8442fa87518d0a3d", "url": "https://github.com/bakdata/conquery/commit/b1f8854c528c066760878a3a8442fa87518d0a3d", "message": "Merge branch 'develop' into feature/all-ids-table-empty-imports", "committedDate": "2020-07-23T17:26:57Z", "type": "commit"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTg4MTAyOQ==", "url": "https://github.com/bakdata/conquery/pull/1270#discussion_r459881029", "bodyText": "Jetzt passt die Fehlermeldung nicht mehr", "author": "thoniTUB", "createdAt": "2020-07-24T06:54:57Z", "path": "backend/src/main/java/com/bakdata/conquery/util/progressreporter/ProgressReporterImpl.java", "diffHunk": "@@ -84,12 +84,14 @@ public void report(double steps) {\n \n \t@Override\n \tpublic void setMax(double max) {\n-\t\tif(getProgress() != 0) {\n+\t\tif(getProgress() > max) {\n \t\t\tthrow new IllegalStateException(\"No modification of Limits allowed after progress has been made\");", "originalCommit": "b1f8854c528c066760878a3a8442fa87518d0a3d", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "25bca2d69b6d9170df46361f1f07dd79e555332b", "chunk": "diff --git a/backend/src/main/java/com/bakdata/conquery/util/progressreporter/ProgressReporterImpl.java b/backend/src/main/java/com/bakdata/conquery/util/progressreporter/ProgressReporterImpl.java\nindex 25d2d4c81..a7a45ac07 100644\n--- a/backend/src/main/java/com/bakdata/conquery/util/progressreporter/ProgressReporterImpl.java\n+++ b/backend/src/main/java/com/bakdata/conquery/util/progressreporter/ProgressReporterImpl.java\n\n@@ -69,26 +78,25 @@ public class ProgressReporterImpl implements ProgressReporter{\n \n \t@Override\n \tpublic String getEstimate() {\n-\t\tdouble totalProgress = getProgress();\n-\t\tlong nanosElapsed = stopwatch.elapsed().getNano();\n-\t\treturn ProgressReporterUtil.buildProgressReportString(done, totalProgress, nanosElapsed, getWaitedNanos());\n+\t\treturn ProgressReporterUtil.buildProgressReportString(isDone(), getProgress(), System.currentTimeMillis() - begin, begin - waitBegin);\n \t}\n \n \t@Override\n-\tpublic void report(double steps) {\n-\t\tif(innerProgress + reservedForChildren + steps > max) {\n+\tpublic void report(int steps) {\n+\t\tif (innerProgress + reservedForChildren + steps > max) {\n \t\t\tthrow new IllegalArgumentException(\"Progress + Steps is bigger than the Maximum Progress\");\n \t\t}\n+\n \t\tinnerProgress += steps;\n \t}\n \n \t@Override\n-\tpublic void setMax(double max) {\n-\t\tif(getProgress() > max) {\n-\t\t\tthrow new IllegalStateException(\"No modification of Limits allowed after progress has been made\");\n+\tpublic void setMax(int max) {\n+\t\tif (getProgress() > max) {\n+\t\t\tthrow new IllegalStateException(\"Max cannot be less than already made progress.\");\n \t\t}\n \n-\t\tif(max <= 0) {\n+\t\tif (max <= 0) {\n \t\t\tthrow new IllegalArgumentException(\"Max can not be 0 or less\");\n \t\t}\n \n"}}, {"oid": "25bca2d69b6d9170df46361f1f07dd79e555332b", "url": "https://github.com/bakdata/conquery/commit/25bca2d69b6d9170df46361f1f07dd79e555332b", "message": "cleanup ProgressReporter", "committedDate": "2020-07-24T09:48:15Z", "type": "commit"}, {"oid": "4c9eb79fa9d52d00f9a1fa738c0e5e5d1bfd6091", "url": "https://github.com/bakdata/conquery/commit/4c9eb79fa9d52d00f9a1fa738c0e5e5d1bfd6091", "message": "fix ProgressReporterTest to not go over max", "committedDate": "2020-07-24T09:52:31Z", "type": "commit"}, {"oid": "802af0bb81ffc06b8dc2469e721e495a00dae02c", "url": "https://github.com/bakdata/conquery/commit/802af0bb81ffc06b8dc2469e721e495a00dae02c", "message": "Change ETA estimation", "committedDate": "2020-07-24T10:18:39Z", "type": "commit"}, {"oid": "265afb07474ea15fc0ac9b0cfcc2a7c65bea35c0", "url": "https://github.com/bakdata/conquery/commit/265afb07474ea15fc0ac9b0cfcc2a7c65bea35c0", "message": "Merge branch 'develop' into feature/all-ids-table-empty-imports", "committedDate": "2020-07-24T10:25:39Z", "type": "commit"}, {"oid": "c07d3b1250b8c1ff6ca77681f96ceefedc2ba962", "url": "https://github.com/bakdata/conquery/commit/c07d3b1250b8c1ff6ca77681f96ceefedc2ba962", "message": "Change ProgressReporter sizes to long", "committedDate": "2020-07-24T10:34:25Z", "type": "commit"}, {"oid": "54ede948a5ffad94efa2d00c11a925f59366329a", "url": "https://github.com/bakdata/conquery/commit/54ede948a5ffad94efa2d00c11a925f59366329a", "message": "Merge branch 'develop' into feature/all-ids-table-empty-imports", "committedDate": "2020-07-24T10:36:55Z", "type": "commit"}, {"oid": "dacb03b74dd2ed898ecea85dcc8f2cab176d50d9", "url": "https://github.com/bakdata/conquery/commit/dacb03b74dd2ed898ecea85dcc8f2cab176d50d9", "message": "fix merging error", "committedDate": "2020-07-24T10:40:33Z", "type": "commit"}]}