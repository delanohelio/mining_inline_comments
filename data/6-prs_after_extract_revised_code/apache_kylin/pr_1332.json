{"pr_number": 1332, "pr_title": "KYLIN-4660 Normalize variable and file naming", "pr_createdAt": "2020-07-28T06:57:20Z", "pr_url": "https://github.com/apache/kylin/pull/1332", "timeline": [{"oid": "18e7cb650ed51dab367d82201616832695b40600", "url": "https://github.com/apache/kylin/commit/18e7cb650ed51dab367d82201616832695b40600", "message": "KYLIN-4660 Normalize variable and file naming", "committedDate": "2020-07-28T07:49:03Z", "type": "forcePushed"}, {"oid": "117ab7e3af7f45e90f718a31a3bf855604e04b9c", "url": "https://github.com/apache/kylin/commit/117ab7e3af7f45e90f718a31a3bf855604e04b9c", "message": "KYLIN-4660 Normalize variable and file naming", "committedDate": "2020-07-28T13:48:48Z", "type": "forcePushed"}, {"oid": "0e9535d20f0a3d396f627b64024b0003b094d44b", "url": "https://github.com/apache/kylin/commit/0e9535d20f0a3d396f627b64024b0003b094d44b", "message": "KYLIN-4660 Normalize variable and file naming", "committedDate": "2020-07-28T14:00:47Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMDE5MA==", "url": "https://github.com/apache/kylin/pull/1332#discussion_r462030190", "bodyText": "What's the reason of getParentDS?", "author": "hit-lacus", "createdAt": "2020-07-29T04:26:05Z", "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java", "diffHunk": "@@ -120,7 +120,7 @@ protected void doExecute() throws Exception {\n                 infos.recordSpanningTree(segId, spanningTree);\n \n                 logger.info(\"Updating segment info\");\n-                updateSegmentInfo(getParam(MetadataConstants.P_CUBE_ID), seg, buildFromFlatTable.getCount());\n+                updateSegmentInfo(getParam(MetadataConstants.P_CUBE_ID), seg, buildFromFlatTable.getParentDS().count());", "originalCommit": "0e9535d20f0a3d396f627b64024b0003b094d44b", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMjg5NQ==", "url": "https://github.com/apache/kylin/pull/1332#discussion_r462032895", "bodyText": "Well, it'd be better to use getFlattableDS.", "author": "RupengWang", "createdAt": "2020-07-29T04:36:54Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjAzMDE5MA=="}], "type": "inlineReview", "revised_code": {"commit": "78d415103d73652a0d69aeb88780a2419d305e8d", "chunk": "diff --git a/kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java b/kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java\nindex df2f3a7a2..e55dfcfbd 100644\n--- a/kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java\n+++ b/kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/job/CubeBuildJob.java\n\n@@ -120,7 +120,7 @@ public class CubeBuildJob extends SparkApplication {\n                 infos.recordSpanningTree(segId, spanningTree);\n \n                 logger.info(\"Updating segment info\");\n-                updateSegmentInfo(getParam(MetadataConstants.P_CUBE_ID), seg, buildFromFlatTable.getParentDS().count());\n+                updateSegmentInfo(getParam(MetadataConstants.P_CUBE_ID), seg, buildFromFlatTable.getFlattableDS().count());\n             }\n             updateSegmentSourceBytesSize(getParam(MetadataConstants.P_CUBE_ID),\n                     ResourceDetectUtils.getSegmentSourceSize(shareDir));\n"}}, {"oid": "78d415103d73652a0d69aeb88780a2419d305e8d", "url": "https://github.com/apache/kylin/commit/78d415103d73652a0d69aeb88780a2419d305e8d", "message": "KYLIN-4660 Normalize variable and file naming", "committedDate": "2020-07-29T04:30:22Z", "type": "commit"}, {"oid": "78d415103d73652a0d69aeb88780a2419d305e8d", "url": "https://github.com/apache/kylin/commit/78d415103d73652a0d69aeb88780a2419d305e8d", "message": "KYLIN-4660 Normalize variable and file naming", "committedDate": "2020-07-29T04:30:22Z", "type": "forcePushed"}]}