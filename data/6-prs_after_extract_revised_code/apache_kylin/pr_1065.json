{"pr_number": 1065, "pr_title": "KYLIN-4349 Close InputStream in RowRecordReader.initReaders()", "pr_createdAt": "2020-01-16T02:59:21Z", "pr_url": "https://github.com/apache/kylin/pull/1065", "timeline": [{"oid": "3a2ecde43662553338ce99a3921005b1077dff80", "url": "https://github.com/apache/kylin/commit/3a2ecde43662553338ce99a3921005b1077dff80", "message": "KYLIN-4349 Close InputStream in RowRecordReader.initReaders()", "committedDate": "2020-01-16T03:00:09Z", "type": "commit"}, {"oid": "3a2ecde43662553338ce99a3921005b1077dff80", "url": "https://github.com/apache/kylin/commit/3a2ecde43662553338ce99a3921005b1077dff80", "message": "KYLIN-4349 Close InputStream in RowRecordReader.initReaders()", "committedDate": "2020-01-16T03:00:09Z", "type": "forcePushed"}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjMwNDMwOA==", "url": "https://github.com/apache/kylin/pull/1065#discussion_r376304308", "bodyText": "Should NOT close dimInputStream here, otherwise dimensionColumnReaderItrs will be broken. These InputStream will be closed in close method of RowRecordReader.java.", "author": "hit-lacus", "createdAt": "2020-02-07T09:54:45Z", "path": "engine-mr/src/main/java/org/apache/kylin/engine/mr/streaming/RowRecordReader.java", "diffHunk": "@@ -82,51 +82,72 @@ public RowRecordReader(CubeDesc cubeDesc, Path path, FileSystem fileSystem) thro\n     }\n \n     public void initReaders() throws IOException {\n-        FSDataInputStream in = fs.open(metaFilePath);\n-        FragmentMetaInfo fragmentMetaInfo = JsonUtil.readValue(in, FragmentMetaInfo.class);\n-        CuboidMetaInfo basicCuboidMetaInfo = fragmentMetaInfo.getBasicCuboidMetaInfo();\n-        FSDataInputStream dictInputStream = fs.open(dataFilePath);\n+        FSDataInputStream in = null;\n+        try {\n+            in = fs.open(metaFilePath);\n+            FragmentMetaInfo fragmentMetaInfo = JsonUtil.readValue(in, FragmentMetaInfo.class);\n+            CuboidMetaInfo basicCuboidMetaInfo = fragmentMetaInfo.getBasicCuboidMetaInfo();\n+            FSDataInputStream dictInputStream = fs.open(dataFilePath);\n \n-        List<DimensionMetaInfo> allDimensions = basicCuboidMetaInfo.getDimensionsInfo();\n-        Map<String, DimensionEncoding> dimensionEncodingMap = getDimensionEncodings(fragmentMetaInfo, allDimensions,\n-                dictInputStream);\n-        dimensionColumnReaders = Lists.newArrayList();\n-        dimensionColumnReaderItrs = Lists.newArrayList();\n-        dimensionEncodings = Lists.newArrayList();\n-        for (DimensionMetaInfo dimensionMetaInfo : allDimensions) {\n-            FSDataInputStream dimInputStream = fs.open(dataFilePath);\n-            String dimName = dimensionMetaInfo.getName();\n-            DimensionEncoding dimEncoding = dimensionEncodingMap.get(dimName);\n-            ColumnarStoreDimDesc dimDesc = new ColumnarStoreDimDesc(dimEncoding.getLengthOfEncoding(),\n-                    dimensionMetaInfo.getCompressionType());\n-            ColumnDataReader dimDataReader = dimDesc.getDimReaderFromFSInput(dimInputStream,\n-                    dimensionMetaInfo.getStartOffset(), dimensionMetaInfo.getDataLength(),\n-                    (int) basicCuboidMetaInfo.getNumberOfRows());\n-            dimensionColumnReaders.add(dimDataReader);\n-            dimensionColumnReaderItrs.add(dimDataReader.iterator());\n-            dimensionEncodings.add(dimEncoding);\n-        }\n-        rowDimensionValues = new String[dimensionColumnReaders.size()];\n+            List<DimensionMetaInfo> allDimensions = basicCuboidMetaInfo.getDimensionsInfo();\n+            Map<String, DimensionEncoding> dimensionEncodingMap = getDimensionEncodings(fragmentMetaInfo, allDimensions,\n+                    dictInputStream);\n+            dimensionColumnReaders = Lists.newArrayList();\n+            dimensionColumnReaderItrs = Lists.newArrayList();\n+            dimensionEncodings = Lists.newArrayList();\n+            for (DimensionMetaInfo dimensionMetaInfo : allDimensions) {\n+                FSDataInputStream dimInputStream = null;\n+                try {\n+                    dimInputStream = fs.open(dataFilePath);\n+                    String dimName = dimensionMetaInfo.getName();\n+                    DimensionEncoding dimEncoding = dimensionEncodingMap.get(dimName);\n+                    ColumnarStoreDimDesc dimDesc = new ColumnarStoreDimDesc(dimEncoding.getLengthOfEncoding(),\n+                            dimensionMetaInfo.getCompressionType());\n+                    ColumnDataReader dimDataReader = dimDesc.getDimReaderFromFSInput(dimInputStream,\n+                            dimensionMetaInfo.getStartOffset(), dimensionMetaInfo.getDataLength(),\n+                            (int) basicCuboidMetaInfo.getNumberOfRows());\n+                    dimensionColumnReaders.add(dimDataReader);\n+                    dimensionColumnReaderItrs.add(dimDataReader.iterator());\n+                    dimensionEncodings.add(dimEncoding);\n+                } finally {\n+                    if (null != dimInputStream) {\n+                        dimInputStream.close();", "originalCommit": "3a2ecde43662553338ce99a3921005b1077dff80", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjMwNjU2Mw==", "url": "https://github.com/apache/kylin/pull/1065#discussion_r376306563", "bodyText": "metricsInputStream  should not be closed for the same reason.", "author": "hit-lacus", "createdAt": "2020-02-07T09:59:34Z", "path": "engine-mr/src/main/java/org/apache/kylin/engine/mr/streaming/RowRecordReader.java", "diffHunk": "@@ -82,51 +82,72 @@ public RowRecordReader(CubeDesc cubeDesc, Path path, FileSystem fileSystem) thro\n     }\n \n     public void initReaders() throws IOException {\n-        FSDataInputStream in = fs.open(metaFilePath);\n-        FragmentMetaInfo fragmentMetaInfo = JsonUtil.readValue(in, FragmentMetaInfo.class);\n-        CuboidMetaInfo basicCuboidMetaInfo = fragmentMetaInfo.getBasicCuboidMetaInfo();\n-        FSDataInputStream dictInputStream = fs.open(dataFilePath);\n+        FSDataInputStream in = null;\n+        try {\n+            in = fs.open(metaFilePath);\n+            FragmentMetaInfo fragmentMetaInfo = JsonUtil.readValue(in, FragmentMetaInfo.class);\n+            CuboidMetaInfo basicCuboidMetaInfo = fragmentMetaInfo.getBasicCuboidMetaInfo();\n+            FSDataInputStream dictInputStream = fs.open(dataFilePath);\n \n-        List<DimensionMetaInfo> allDimensions = basicCuboidMetaInfo.getDimensionsInfo();\n-        Map<String, DimensionEncoding> dimensionEncodingMap = getDimensionEncodings(fragmentMetaInfo, allDimensions,\n-                dictInputStream);\n-        dimensionColumnReaders = Lists.newArrayList();\n-        dimensionColumnReaderItrs = Lists.newArrayList();\n-        dimensionEncodings = Lists.newArrayList();\n-        for (DimensionMetaInfo dimensionMetaInfo : allDimensions) {\n-            FSDataInputStream dimInputStream = fs.open(dataFilePath);\n-            String dimName = dimensionMetaInfo.getName();\n-            DimensionEncoding dimEncoding = dimensionEncodingMap.get(dimName);\n-            ColumnarStoreDimDesc dimDesc = new ColumnarStoreDimDesc(dimEncoding.getLengthOfEncoding(),\n-                    dimensionMetaInfo.getCompressionType());\n-            ColumnDataReader dimDataReader = dimDesc.getDimReaderFromFSInput(dimInputStream,\n-                    dimensionMetaInfo.getStartOffset(), dimensionMetaInfo.getDataLength(),\n-                    (int) basicCuboidMetaInfo.getNumberOfRows());\n-            dimensionColumnReaders.add(dimDataReader);\n-            dimensionColumnReaderItrs.add(dimDataReader.iterator());\n-            dimensionEncodings.add(dimEncoding);\n-        }\n-        rowDimensionValues = new String[dimensionColumnReaders.size()];\n+            List<DimensionMetaInfo> allDimensions = basicCuboidMetaInfo.getDimensionsInfo();\n+            Map<String, DimensionEncoding> dimensionEncodingMap = getDimensionEncodings(fragmentMetaInfo, allDimensions,\n+                    dictInputStream);\n+            dimensionColumnReaders = Lists.newArrayList();\n+            dimensionColumnReaderItrs = Lists.newArrayList();\n+            dimensionEncodings = Lists.newArrayList();\n+            for (DimensionMetaInfo dimensionMetaInfo : allDimensions) {\n+                FSDataInputStream dimInputStream = null;\n+                try {\n+                    dimInputStream = fs.open(dataFilePath);\n+                    String dimName = dimensionMetaInfo.getName();\n+                    DimensionEncoding dimEncoding = dimensionEncodingMap.get(dimName);\n+                    ColumnarStoreDimDesc dimDesc = new ColumnarStoreDimDesc(dimEncoding.getLengthOfEncoding(),\n+                            dimensionMetaInfo.getCompressionType());\n+                    ColumnDataReader dimDataReader = dimDesc.getDimReaderFromFSInput(dimInputStream,\n+                            dimensionMetaInfo.getStartOffset(), dimensionMetaInfo.getDataLength(),\n+                            (int) basicCuboidMetaInfo.getNumberOfRows());\n+                    dimensionColumnReaders.add(dimDataReader);\n+                    dimensionColumnReaderItrs.add(dimDataReader.iterator());\n+                    dimensionEncodings.add(dimEncoding);\n+                } finally {\n+                    if (null != dimInputStream) {\n+                        dimInputStream.close();\n+                    }\n+                }\n+            }\n+            rowDimensionValues = new String[dimensionColumnReaders.size()];\n \n-        metricsColumnReaders = Lists.newArrayList();\n-        metricsColumnReaderItrs = Lists.newArrayList();\n-        metricsDataTransformers = Lists.newArrayList();\n-        for (MetricMetaInfo metricMetaInfo : basicCuboidMetaInfo.getMetricsInfo()) {\n-            FSDataInputStream metricsInputStream = fs.open(dataFilePath);\n-            MeasureDesc measure = findMeasure(metricMetaInfo.getName());\n-            DataType metricsDataType = measure.getFunction().getReturnDataType();\n-            ColumnarMetricsEncoding metricsEncoding = ColumnarMetricsEncodingFactory.create(metricsDataType);\n-            ColumnarStoreMetricsDesc metricsDesc = new ColumnarStoreMetricsDesc(metricsEncoding,\n-                    metricMetaInfo.getCompressionType());\n-            ColumnDataReader metricsDataReader = metricsDesc.getMetricsReaderFromFSInput(metricsInputStream,\n-                    metricMetaInfo.getStartOffset(), metricMetaInfo.getMetricLength(),\n-                    (int) basicCuboidMetaInfo.getNumberOfRows());\n-            metricsColumnReaders.add(metricsDataReader);\n-            metricsColumnReaderItrs.add(metricsDataReader.iterator());\n-            metricsDataTransformers.add(new MetricsDataTransformer(metricsEncoding.asDataTypeSerializer(),\n-                    DataTypeSerializer.create(metricsDataType)));\n+            metricsColumnReaders = Lists.newArrayList();\n+            metricsColumnReaderItrs = Lists.newArrayList();\n+            metricsDataTransformers = Lists.newArrayList();\n+            for (MetricMetaInfo metricMetaInfo : basicCuboidMetaInfo.getMetricsInfo()) {\n+                FSDataInputStream metricsInputStream = null;\n+                try {\n+                    metricsInputStream = fs.open(dataFilePath);\n+                    MeasureDesc measure = findMeasure(metricMetaInfo.getName());\n+                    DataType metricsDataType = measure.getFunction().getReturnDataType();\n+                    ColumnarMetricsEncoding metricsEncoding = ColumnarMetricsEncodingFactory.create(metricsDataType);\n+                    ColumnarStoreMetricsDesc metricsDesc = new ColumnarStoreMetricsDesc(metricsEncoding,\n+                            metricMetaInfo.getCompressionType());\n+                    ColumnDataReader metricsDataReader = metricsDesc.getMetricsReaderFromFSInput(metricsInputStream,\n+                            metricMetaInfo.getStartOffset(), metricMetaInfo.getMetricLength(),\n+                            (int) basicCuboidMetaInfo.getNumberOfRows());\n+                    metricsColumnReaders.add(metricsDataReader);\n+                    metricsColumnReaderItrs.add(metricsDataReader.iterator());\n+                    metricsDataTransformers.add(new MetricsDataTransformer(metricsEncoding.asDataTypeSerializer(),\n+                            DataTypeSerializer.create(metricsDataType)));\n+                } finally {\n+                    if (null != metricsInputStream) {", "originalCommit": "3a2ecde43662553338ce99a3921005b1077dff80", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": null}]}