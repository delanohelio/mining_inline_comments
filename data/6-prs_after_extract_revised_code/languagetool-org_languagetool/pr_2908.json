{"pr_number": 2908, "pr_title": "Fix HunspellRuleTest on Windows", "pr_createdAt": "2020-05-11T15:20:13Z", "pr_url": "https://github.com/languagetool-org/languagetool/pull/2908", "timeline": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEyNDU1OQ==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423124559", "bodyText": "I'm not sure if this is a good idea, the input file could be very large and would be loaded into memory this way (the same is true for other cases in HttpApiSentenceChecler)...", "author": "danielnaber", "createdAt": "2020-05-11T15:28:57Z", "path": "languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java", "diffHunk": "@@ -80,15 +80,8 @@ private String formatDuration(Duration duration) {\n     return String.format(\"%d:%02d:%02d\", absSeconds / 3600, (absSeconds % 3600) / 60, absSeconds % 60);\n   }\n \n-  private int countLines(File input) throws FileNotFoundException {\n-    int count = 0;\n-    try (Scanner sc = new Scanner(input)) {\n-      while (sc.hasNextLine()) {\n-        sc.nextLine();\n-        count++;\n-      }\n-    }\n-    return count;\n+  private int countLines(File input) throws IOException {\n+    return Files.readAllLines(input.toPath()).size();", "originalCommit": "018ed4f577081d1ad23bf6cc3cc05b0048fd128d", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE0ODY3Nw==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423148677", "bodyText": "You are definitely right, this approach doesn't work for large files.\nIt has been changed, please let me know if other places also need lines to be read one-by-one.", "author": "asashour", "createdAt": "2020-05-11T16:03:50Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEyNDU1OQ=="}], "type": "inlineReview", "revised_code": {"commit": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "chunk": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\nindex 8e18eaefb1..1e3b121695 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/httpchecker/HttpApiSentenceChecker.java\n\n@@ -81,7 +81,13 @@ class HttpApiSentenceChecker {\n   }\n \n   private int countLines(File input) throws IOException {\n-    return Files.readAllLines(input.toPath()).size();\n+    int count = 0;\n+    try (BufferedReader reader = Files.newBufferedReader(input.toPath())) {\n+      while (reader.readLine() != null) {\n+        count++;\n+      }\n+    }\n+    return count;\n   }\n \n   private List<File> splitInput(int lines, File input, int threadCount) throws IOException {\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MDkxNQ==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423570915", "bodyText": "This should also use scanner to avoid reading everything into RAM.", "author": "danielnaber", "createdAt": "2020-05-12T08:52:19Z", "path": "languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java", "diffHunk": "@@ -56,16 +57,13 @@ private void index(File outputDir, String[] inputFiles) throws IOException {\n   private void indexFile(IndexWriter indexWriter, String inputFile) throws IOException {\n     System.out.println(\"Indexing \" + inputFile);\n     int lineCount = 0;\n-    try (Scanner scanner = new Scanner(new File(inputFile))) {\n-      while (scanner.hasNextLine()) {\n-        String line = scanner.nextLine();\n-        Document doc = new Document();\n-        doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n-        doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n-        indexWriter.addDocument(doc);\n-        if (++lineCount % 10_000 == 0) {\n-          System.out.println(lineCount + \"...\");\n-        }\n+    for (String line : Files.readAllLines(Paths.get(inputFile))) {", "originalCommit": "5eaf9a64758588ab86fc824341e850020b676390", "replyToReviewId": null, "replies": null, "type": "inlineReview", "revised_code": {"commit": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "chunk": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java b/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\nindex e4f07cfee8..018910fc59 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/bigdata/TextIndexCreator.java\n\n@@ -57,13 +58,16 @@ class TextIndexCreator {\n   private void indexFile(IndexWriter indexWriter, String inputFile) throws IOException {\n     System.out.println(\"Indexing \" + inputFile);\n     int lineCount = 0;\n-    for (String line : Files.readAllLines(Paths.get(inputFile))) {\n-      Document doc = new Document();\n-      doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n-      doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n-      indexWriter.addDocument(doc);\n-      if (++lineCount % 10_000 == 0) {\n-        System.out.println(lineCount + \"...\");\n+    try (BufferedReader br = Files.newBufferedReader(Paths.get(inputFile))) {\n+      String line;\n+      while ((line = br.readLine()) != null) {\n+        Document doc = new Document();\n+        doc.add(new TextField(Lucene.FIELD_NAME, line, Field.Store.YES));\n+        doc.add(new TextField(Lucene.FIELD_NAME_LOWERCASE, line.toLowerCase(), Field.Store.YES));\n+        indexWriter.addDocument(doc);\n+        if (++lineCount % 10_000 == 0) {\n+          System.out.println(lineCount + \"...\");\n+        }\n       }\n     }\n   }\n"}}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MTA5OA==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423571098", "bodyText": "This should also use scanner to avoid reading everything into RAM.", "author": "danielnaber", "createdAt": "2020-05-12T08:52:35Z", "path": "languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java", "diffHunk": "@@ -54,18 +55,17 @@\n     ObjectMapper mapper = new ObjectMapper();\n     List<LightRuleMatch> ruleMatches = new ArrayList<>();\n     int lineCount = 1;\n-    try (Scanner scanner = new Scanner(inputFile)) {\n-      while (scanner.hasNextLine()) {\n-        String line = scanner.nextLine();\n+    for (String line : Files.readAllLines(inputFile.toPath())) {", "originalCommit": "5eaf9a64758588ab86fc824341e850020b676390", "replyToReviewId": null, "replies": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU4MjQwNQ==", "url": "https://github.com/languagetool-org/languagetool/pull/2908#discussion_r423582405", "bodyText": "Done, and I removed the try/catch, because no exception is thrown from the enclosed methods.", "author": "asashour", "createdAt": "2020-05-12T09:09:56Z", "replyToReviewId": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MTA5OA=="}], "type": "inlineReview", "revised_code": {"commit": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "chunk": "diff --git a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\nindex 346871bdfc..2187aaf3f4 100644\n--- a/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n+++ b/languagetool-dev/src/main/java/org/languagetool/dev/diff/LightRuleMatchParser.java\n\n@@ -54,17 +55,14 @@ class LightRuleMatchParser {\n   private List<LightRuleMatch> parseAggregatedJson(File inputFile) throws IOException {\n     ObjectMapper mapper = new ObjectMapper();\n     List<LightRuleMatch> ruleMatches = new ArrayList<>();\n-    int lineCount = 1;\n-    for (String line : Files.readAllLines(inputFile.toPath())) {\n-      try {\n+    try (BufferedReader br = Files.newBufferedReader(inputFile.toPath())) {\n+      String line;\n+      while ((line = br.readLine()) != null) {\n         JsonNode node = mapper.readTree(line);\n         JsonNode matches = node.get(\"matches\");\n         for (JsonNode match : matches) {\n           ruleMatches.add(nodeToLightMatch(node.get(\"title\").asText(), match));\n         }\n-        lineCount++;\n-      } catch (Exception e) {\n-        throw new RuntimeException(\"Failed to parse line \" + lineCount + \" of \" + inputFile, e);\n       }\n     }\n     return ruleMatches;\n"}}, {"oid": "1baebe695df3229b46aaa68f78292ac2f34ab20f", "url": "https://github.com/languagetool-org/languagetool/commit/1baebe695df3229b46aaa68f78292ac2f34ab20f", "message": "Fix HunspellRuleTest\n\nFixes #2202", "committedDate": "2020-05-12T09:04:48Z", "type": "commit"}]}